// *** WARNING: this file was generated by crd2pulumi. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

import * as pulumi from "@pulumi/pulumi";
import * as inputs from "../types/input";
import * as outputs from "../types/output";

import {ObjectMeta} from "../meta/v1";

export namespace acme {
    export namespace v1 {
        export interface ChallengeSpec {
            /**
             * The URL to the ACME Authorization resource that this challenge is a part of.
             */
            authorizationURL: string;
            /**
             * dnsName is the identifier that this challenge is for, e.g. example.com. If the requested DNSName is a 'wildcard', this field MUST be set to the non-wildcard domain, e.g. for `*.example.com`, it must be `example.com`.
             */
            dnsName: string;
            /**
             * References a properly configured ACME-type Issuer which should be used to create this Challenge. If the Issuer does not exist, processing will be retried. If the Issuer is not an 'ACME' Issuer, an error will be returned and the Challenge will be marked as failed.
             */
            issuerRef: outputs.acme.v1.ChallengeSpecIssuerRef;
            /**
             * The ACME challenge key for this challenge For HTTP01 challenges, this is the value that must be responded with to complete the HTTP01 challenge in the format: `<private key JWK thumbprint>.<key from acme server for challenge>`. For DNS01 challenges, this is the base64 encoded SHA256 sum of the `<private key JWK thumbprint>.<key from acme server for challenge>` text that must be set as the TXT record content.
             */
            key: string;
            /**
             * Contains the domain solving configuration that should be used to solve this challenge resource.
             */
            solver: outputs.acme.v1.ChallengeSpecSolver;
            /**
             * The ACME challenge token for this challenge. This is the raw value returned from the ACME server.
             */
            token: string;
            /**
             * The type of ACME challenge this resource represents. One of "HTTP-01" or "DNS-01".
             */
            type: string;
            /**
             * The URL of the ACME Challenge resource for this challenge. This can be used to lookup details about the status of this challenge.
             */
            url: string;
            /**
             * wildcard will be true if this challenge is for a wildcard identifier, for example '*.example.com'.
             */
            wildcard?: boolean;
        }

        /**
         * References a properly configured ACME-type Issuer which should be used to create this Challenge. If the Issuer does not exist, processing will be retried. If the Issuer is not an 'ACME' Issuer, an error will be returned and the Challenge will be marked as failed.
         */
        export interface ChallengeSpecIssuerRef {
            /**
             * Group of the resource being referred to.
             */
            group?: string;
            /**
             * Kind of the resource being referred to.
             */
            kind?: string;
            /**
             * Name of the resource being referred to.
             */
            name: string;
        }

        /**
         * Contains the domain solving configuration that should be used to solve this challenge resource.
         */
        export interface ChallengeSpecSolver {
            /**
             * Configures cert-manager to attempt to complete authorizations by performing the DNS01 challenge flow.
             */
            dns01?: outputs.acme.v1.ChallengeSpecSolverDns01;
            /**
             * Configures cert-manager to attempt to complete authorizations by performing the HTTP01 challenge flow. It is not possible to obtain certificates for wildcard domain names (e.g. `*.example.com`) using the HTTP01 challenge mechanism.
             */
            http01?: outputs.acme.v1.ChallengeSpecSolverHttp01;
            /**
             * Selector selects a set of DNSNames on the Certificate resource that should be solved using this challenge solver. If not specified, the solver will be treated as the 'default' solver with the lowest priority, i.e. if any other solver has a more specific match, it will be used instead.
             */
            selector?: outputs.acme.v1.ChallengeSpecSolverSelector;
        }

        /**
         * Configures cert-manager to attempt to complete authorizations by performing the DNS01 challenge flow.
         */
        export interface ChallengeSpecSolverDns01 {
            /**
             * Use the 'ACME DNS' (https://github.com/joohoi/acme-dns) API to manage DNS01 challenge records.
             */
            acmeDNS?: outputs.acme.v1.ChallengeSpecSolverDns01AcmeDNS;
            /**
             * Use the Akamai DNS zone management API to manage DNS01 challenge records.
             */
            akamai?: outputs.acme.v1.ChallengeSpecSolverDns01Akamai;
            /**
             * Use the Microsoft Azure DNS API to manage DNS01 challenge records.
             */
            azureDNS?: outputs.acme.v1.ChallengeSpecSolverDns01AzureDNS;
            /**
             * Use the Google Cloud DNS API to manage DNS01 challenge records.
             */
            cloudDNS?: outputs.acme.v1.ChallengeSpecSolverDns01CloudDNS;
            /**
             * Use the Cloudflare API to manage DNS01 challenge records.
             */
            cloudflare?: outputs.acme.v1.ChallengeSpecSolverDns01Cloudflare;
            /**
             * CNAMEStrategy configures how the DNS01 provider should handle CNAME records when found in DNS zones.
             */
            cnameStrategy?: string;
            /**
             * Use the DigitalOcean DNS API to manage DNS01 challenge records.
             */
            digitalocean?: outputs.acme.v1.ChallengeSpecSolverDns01Digitalocean;
            /**
             * Use RFC2136 ("Dynamic Updates in the Domain Name System") (https://datatracker.ietf.org/doc/rfc2136/) to manage DNS01 challenge records.
             */
            rfc2136?: outputs.acme.v1.ChallengeSpecSolverDns01Rfc2136;
            /**
             * Use the AWS Route53 API to manage DNS01 challenge records.
             */
            route53?: outputs.acme.v1.ChallengeSpecSolverDns01Route53;
            /**
             * Configure an external webhook based DNS01 challenge solver to manage DNS01 challenge records.
             */
            webhook?: outputs.acme.v1.ChallengeSpecSolverDns01Webhook;
        }

        /**
         * Use the 'ACME DNS' (https://github.com/joohoi/acme-dns) API to manage DNS01 challenge records.
         */
        export interface ChallengeSpecSolverDns01AcmeDNS {
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            accountSecretRef: outputs.acme.v1.ChallengeSpecSolverDns01AcmeDNSAccountSecretRef;
            host: string;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface ChallengeSpecSolverDns01AcmeDNSAccountSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the Akamai DNS zone management API to manage DNS01 challenge records.
         */
        export interface ChallengeSpecSolverDns01Akamai {
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            accessTokenSecretRef: outputs.acme.v1.ChallengeSpecSolverDns01AkamaiAccessTokenSecretRef;
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            clientSecretSecretRef: outputs.acme.v1.ChallengeSpecSolverDns01AkamaiClientSecretSecretRef;
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            clientTokenSecretRef: outputs.acme.v1.ChallengeSpecSolverDns01AkamaiClientTokenSecretRef;
            serviceConsumerDomain: string;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface ChallengeSpecSolverDns01AkamaiAccessTokenSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface ChallengeSpecSolverDns01AkamaiClientSecretSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface ChallengeSpecSolverDns01AkamaiClientTokenSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the Microsoft Azure DNS API to manage DNS01 challenge records.
         */
        export interface ChallengeSpecSolverDns01AzureDNS {
            /**
             * if both this and ClientSecret are left unset MSI will be used
             */
            clientID?: string;
            /**
             * if both this and ClientID are left unset MSI will be used
             */
            clientSecretSecretRef?: outputs.acme.v1.ChallengeSpecSolverDns01AzureDNSClientSecretSecretRef;
            environment?: string;
            hostedZoneName?: string;
            resourceGroupName: string;
            subscriptionID: string;
            /**
             * when specifying ClientID and ClientSecret then this field is also needed
             */
            tenantID?: string;
        }

        /**
         * if both this and ClientID are left unset MSI will be used
         */
        export interface ChallengeSpecSolverDns01AzureDNSClientSecretSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the Google Cloud DNS API to manage DNS01 challenge records.
         */
        export interface ChallengeSpecSolverDns01CloudDNS {
            /**
             * HostedZoneName is an optional field that tells cert-manager in which Cloud DNS zone the challenge record has to be created. If left empty cert-manager will automatically choose a zone.
             */
            hostedZoneName?: string;
            project: string;
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            serviceAccountSecretRef?: outputs.acme.v1.ChallengeSpecSolverDns01CloudDNSServiceAccountSecretRef;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface ChallengeSpecSolverDns01CloudDNSServiceAccountSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the Cloudflare API to manage DNS01 challenge records.
         */
        export interface ChallengeSpecSolverDns01Cloudflare {
            /**
             * API key to use to authenticate with Cloudflare. Note: using an API token to authenticate is now the recommended method as it allows greater control of permissions.
             */
            apiKeySecretRef?: outputs.acme.v1.ChallengeSpecSolverDns01CloudflareApiKeySecretRef;
            /**
             * API token used to authenticate with Cloudflare.
             */
            apiTokenSecretRef?: outputs.acme.v1.ChallengeSpecSolverDns01CloudflareApiTokenSecretRef;
            /**
             * Email of the account, only required when using API key based authentication.
             */
            email?: string;
        }

        /**
         * API key to use to authenticate with Cloudflare. Note: using an API token to authenticate is now the recommended method as it allows greater control of permissions.
         */
        export interface ChallengeSpecSolverDns01CloudflareApiKeySecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * API token used to authenticate with Cloudflare.
         */
        export interface ChallengeSpecSolverDns01CloudflareApiTokenSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the DigitalOcean DNS API to manage DNS01 challenge records.
         */
        export interface ChallengeSpecSolverDns01Digitalocean {
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            tokenSecretRef: outputs.acme.v1.ChallengeSpecSolverDns01DigitaloceanTokenSecretRef;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface ChallengeSpecSolverDns01DigitaloceanTokenSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use RFC2136 ("Dynamic Updates in the Domain Name System") (https://datatracker.ietf.org/doc/rfc2136/) to manage DNS01 challenge records.
         */
        export interface ChallengeSpecSolverDns01Rfc2136 {
            /**
             * The IP address or hostname of an authoritative DNS server supporting RFC2136 in the form host:port. If the host is an IPv6 address it must be enclosed in square brackets (e.g [2001:db8::1]) ; port is optional. This field is required.
             */
            nameserver: string;
            /**
             * The TSIG Algorithm configured in the DNS supporting RFC2136. Used only when ``tsigSecretSecretRef`` and ``tsigKeyName`` are defined. Supported values are (case-insensitive): ``HMACMD5`` (default), ``HMACSHA1``, ``HMACSHA256`` or ``HMACSHA512``.
             */
            tsigAlgorithm?: string;
            /**
             * The TSIG Key name configured in the DNS. If ``tsigSecretSecretRef`` is defined, this field is required.
             */
            tsigKeyName?: string;
            /**
             * The name of the secret containing the TSIG value. If ``tsigKeyName`` is defined, this field is required.
             */
            tsigSecretSecretRef?: outputs.acme.v1.ChallengeSpecSolverDns01Rfc2136TsigSecretSecretRef;
        }

        /**
         * The name of the secret containing the TSIG value. If ``tsigKeyName`` is defined, this field is required.
         */
        export interface ChallengeSpecSolverDns01Rfc2136TsigSecretSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the AWS Route53 API to manage DNS01 challenge records.
         */
        export interface ChallengeSpecSolverDns01Route53 {
            /**
             * The AccessKeyID is used for authentication. If not set we fall-back to using env vars, shared credentials file or AWS Instance metadata see: https://docs.aws.amazon.com/sdk-for-go/v1/developer-guide/configuring-sdk.html#specifying-credentials
             */
            accessKeyID?: string;
            /**
             * If set, the provider will manage only this zone in Route53 and will not do an lookup using the route53:ListHostedZonesByName api call.
             */
            hostedZoneID?: string;
            /**
             * Always set the region when using AccessKeyID and SecretAccessKey
             */
            region: string;
            /**
             * Role is a Role ARN which the Route53 provider will assume using either the explicit credentials AccessKeyID/SecretAccessKey or the inferred credentials from environment variables, shared credentials file or AWS Instance metadata
             */
            role?: string;
            /**
             * The SecretAccessKey is used for authentication. If not set we fall-back to using env vars, shared credentials file or AWS Instance metadata https://docs.aws.amazon.com/sdk-for-go/v1/developer-guide/configuring-sdk.html#specifying-credentials
             */
            secretAccessKeySecretRef?: outputs.acme.v1.ChallengeSpecSolverDns01Route53SecretAccessKeySecretRef;
        }

        /**
         * The SecretAccessKey is used for authentication. If not set we fall-back to using env vars, shared credentials file or AWS Instance metadata https://docs.aws.amazon.com/sdk-for-go/v1/developer-guide/configuring-sdk.html#specifying-credentials
         */
        export interface ChallengeSpecSolverDns01Route53SecretAccessKeySecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Configure an external webhook based DNS01 challenge solver to manage DNS01 challenge records.
         */
        export interface ChallengeSpecSolverDns01Webhook {
            /**
             * Additional configuration that should be passed to the webhook apiserver when challenges are processed. This can contain arbitrary JSON data. Secret values should not be specified in this stanza. If secret values are needed (e.g. credentials for a DNS service), you should use a SecretKeySelector to reference a Secret resource. For details on the schema of this field, consult the webhook provider implementation's documentation.
             */
            config?: {[key: string]: any};
            /**
             * The API group name that should be used when POSTing ChallengePayload resources to the webhook apiserver. This should be the same as the GroupName specified in the webhook provider implementation.
             */
            groupName: string;
            /**
             * The name of the solver to use, as defined in the webhook provider implementation. This will typically be the name of the provider, e.g. 'cloudflare'.
             */
            solverName: string;
        }

        /**
         * Configures cert-manager to attempt to complete authorizations by performing the HTTP01 challenge flow. It is not possible to obtain certificates for wildcard domain names (e.g. `*.example.com`) using the HTTP01 challenge mechanism.
         */
        export interface ChallengeSpecSolverHttp01 {
            /**
             * The ingress based HTTP01 challenge solver will solve challenges by creating or modifying Ingress resources in order to route requests for '/.well-known/acme-challenge/XYZ' to 'challenge solver' pods that are provisioned by cert-manager for each Challenge to be completed.
             */
            ingress?: outputs.acme.v1.ChallengeSpecSolverHttp01Ingress;
        }

        /**
         * The ingress based HTTP01 challenge solver will solve challenges by creating or modifying Ingress resources in order to route requests for '/.well-known/acme-challenge/XYZ' to 'challenge solver' pods that are provisioned by cert-manager for each Challenge to be completed.
         */
        export interface ChallengeSpecSolverHttp01Ingress {
            /**
             * The ingress class to use when creating Ingress resources to solve ACME challenges that use this challenge solver. Only one of 'class' or 'name' may be specified.
             */
            class?: string;
            /**
             * Optional ingress template used to configure the ACME challenge solver ingress used for HTTP01 challenges
             */
            ingressTemplate?: outputs.acme.v1.ChallengeSpecSolverHttp01IngressIngressTemplate;
            /**
             * The name of the ingress resource that should have ACME challenge solving routes inserted into it in order to solve HTTP01 challenges. This is typically used in conjunction with ingress controllers like ingress-gce, which maintains a 1:1 mapping between external IPs and ingress resources.
             */
            name?: string;
            /**
             * Optional pod template used to configure the ACME challenge solver pods used for HTTP01 challenges
             */
            podTemplate?: outputs.acme.v1.ChallengeSpecSolverHttp01IngressPodTemplate;
            /**
             * Optional service type for Kubernetes solver service
             */
            serviceType?: string;
        }

        /**
         * Optional ingress template used to configure the ACME challenge solver ingress used for HTTP01 challenges
         */
        export interface ChallengeSpecSolverHttp01IngressIngressTemplate {
            /**
             * ObjectMeta overrides for the ingress used to solve HTTP01 challenges. Only the 'labels' and 'annotations' fields may be set. If labels or annotations overlap with in-built values, the values here will override the in-built values.
             */
            metadata?: outputs.acme.v1.ChallengeSpecSolverHttp01IngressIngressTemplateMetadata;
        }

        /**
         * ObjectMeta overrides for the ingress used to solve HTTP01 challenges. Only the 'labels' and 'annotations' fields may be set. If labels or annotations overlap with in-built values, the values here will override the in-built values.
         */
        export interface ChallengeSpecSolverHttp01IngressIngressTemplateMetadata {
            /**
             * Annotations that should be added to the created ACME HTTP01 solver ingress.
             */
            annotations?: {[key: string]: string};
            /**
             * Labels that should be added to the created ACME HTTP01 solver ingress.
             */
            labels?: {[key: string]: string};
        }

        /**
         * Optional pod template used to configure the ACME challenge solver pods used for HTTP01 challenges
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplate {
            /**
             * ObjectMeta overrides for the pod used to solve HTTP01 challenges. Only the 'labels' and 'annotations' fields may be set. If labels or annotations overlap with in-built values, the values here will override the in-built values.
             */
            metadata?: outputs.acme.v1.ChallengeSpecSolverHttp01IngressPodTemplateMetadata;
            /**
             * PodSpec defines overrides for the HTTP01 challenge solver pod. Only the 'priorityClassName', 'nodeSelector', 'affinity', 'serviceAccountName' and 'tolerations' fields are supported currently. All other fields will be ignored.
             */
            spec?: outputs.acme.v1.ChallengeSpecSolverHttp01IngressPodTemplateSpec;
        }

        /**
         * ObjectMeta overrides for the pod used to solve HTTP01 challenges. Only the 'labels' and 'annotations' fields may be set. If labels or annotations overlap with in-built values, the values here will override the in-built values.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateMetadata {
            /**
             * Annotations that should be added to the create ACME HTTP01 solver pods.
             */
            annotations?: {[key: string]: string};
            /**
             * Labels that should be added to the created ACME HTTP01 solver pods.
             */
            labels?: {[key: string]: string};
        }

        /**
         * PodSpec defines overrides for the HTTP01 challenge solver pod. Only the 'priorityClassName', 'nodeSelector', 'affinity', 'serviceAccountName' and 'tolerations' fields are supported currently. All other fields will be ignored.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpec {
            /**
             * If specified, the pod's scheduling constraints
             */
            affinity?: outputs.acme.v1.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinity;
            /**
             * NodeSelector is a selector which must be true for the pod to fit on a node. Selector which must match a node's labels for the pod to be scheduled on that node. More info: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/
             */
            nodeSelector?: {[key: string]: string};
            /**
             * If specified, the pod's priorityClassName.
             */
            priorityClassName?: string;
            /**
             * If specified, the pod's service account
             */
            serviceAccountName?: string;
            /**
             * If specified, the pod's tolerations.
             */
            tolerations?: outputs.acme.v1.ChallengeSpecSolverHttp01IngressPodTemplateSpecTolerations[];
        }

        /**
         * If specified, the pod's scheduling constraints
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinity {
            /**
             * Describes node affinity scheduling rules for the pod.
             */
            nodeAffinity?: outputs.acme.v1.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityNodeAffinity;
            /**
             * Describes pod affinity scheduling rules (e.g. co-locate this pod in the same node, zone, etc. as some other pod(s)).
             */
            podAffinity?: outputs.acme.v1.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAffinity;
            /**
             * Describes pod anti-affinity scheduling rules (e.g. avoid putting this pod in the same node, zone, etc. as some other pod(s)).
             */
            podAntiAffinity?: outputs.acme.v1.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAntiAffinity;
        }

        /**
         * Describes node affinity scheduling rules for the pod.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityNodeAffinity {
            /**
             * The scheduler will prefer to schedule pods to nodes that satisfy the affinity expressions specified by this field, but it may choose a node that violates one or more of the expressions. The node that is most preferred is the one with the greatest sum of weights, i.e. for each node that meets all of the scheduling requirements (resource request, requiredDuringScheduling affinity expressions, etc.), compute a sum by iterating through the elements of this field and adding "weight" to the sum if the node matches the corresponding matchExpressions; the node(s) with the highest sum are the most preferred.
             */
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.acme.v1.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            /**
             * If the affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to an update), the system may or may not try to eventually evict the pod from its node.
             */
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.acme.v1.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution;
        }

        /**
         * An empty preferred scheduling term matches all objects with implicit weight 0 (i.e. it's a no-op). A null preferred scheduling term matches no objects (i.e. is also a no-op).
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            /**
             * A node selector term, associated with the corresponding weight.
             */
            preference: outputs.acme.v1.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference;
            /**
             * Weight associated with matching the corresponding nodeSelectorTerm, in the range 1-100.
             */
            weight: number;
        }

        /**
         * A node selector term, associated with the corresponding weight.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference {
            /**
             * A list of node selector requirements by node's labels.
             */
            matchExpressions?: outputs.acme.v1.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions[];
            /**
             * A list of node selector requirements by node's fields.
             */
            matchFields?: outputs.acme.v1.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields[];
        }

        /**
         * A node selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions {
            /**
             * The label key that the selector applies to.
             */
            key: string;
            /**
             * Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
             */
            operator: string;
            /**
             * An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * A node selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields {
            /**
             * The label key that the selector applies to.
             */
            key: string;
            /**
             * Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
             */
            operator: string;
            /**
             * An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * If the affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to an update), the system may or may not try to eventually evict the pod from its node.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            /**
             * Required. A list of node selector terms. The terms are ORed.
             */
            nodeSelectorTerms: outputs.acme.v1.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms[];
        }

        /**
         * A null or empty node selector term matches no objects. The requirements of them are ANDed. The TopologySelectorTerm type implements a subset of the NodeSelectorTerm.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms {
            /**
             * A list of node selector requirements by node's labels.
             */
            matchExpressions?: outputs.acme.v1.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions[];
            /**
             * A list of node selector requirements by node's fields.
             */
            matchFields?: outputs.acme.v1.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields[];
        }

        /**
         * A node selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions {
            /**
             * The label key that the selector applies to.
             */
            key: string;
            /**
             * Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
             */
            operator: string;
            /**
             * An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * A node selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields {
            /**
             * The label key that the selector applies to.
             */
            key: string;
            /**
             * Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
             */
            operator: string;
            /**
             * An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Describes pod affinity scheduling rules (e.g. co-locate this pod in the same node, zone, etc. as some other pod(s)).
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAffinity {
            /**
             * The scheduler will prefer to schedule pods to nodes that satisfy the affinity expressions specified by this field, but it may choose a node that violates one or more of the expressions. The node that is most preferred is the one with the greatest sum of weights, i.e. for each node that meets all of the scheduling requirements (resource request, requiredDuringScheduling affinity expressions, etc.), compute a sum by iterating through the elements of this field and adding "weight" to the sum if the node has pods which matches the corresponding podAffinityTerm; the node(s) with the highest sum are the most preferred.
             */
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.acme.v1.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            /**
             * If the affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to a pod label update), the system may or may not try to eventually evict the pod from its node. When there are multiple elements, the lists of nodes corresponding to each podAffinityTerm are intersected, i.e. all terms must be satisfied.
             */
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.acme.v1.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        /**
         * The weights of all of the matched WeightedPodAffinityTerm fields are added per-node to find the most preferred node(s)
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            /**
             * Required. A pod affinity term, associated with the corresponding weight.
             */
            podAffinityTerm: outputs.acme.v1.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            /**
             * weight associated with matching the corresponding podAffinityTerm, in the range 1-100.
             */
            weight: number;
        }

        /**
         * Required. A pod affinity term, associated with the corresponding weight.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            /**
             * A label query over a set of resources, in this case pods.
             */
            labelSelector?: outputs.acme.v1.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            /**
             * namespaces specifies which namespaces the labelSelector applies to (matches against); null or empty list means "this pod's namespace"
             */
            namespaces?: string[];
            /**
             * This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed.
             */
            topologyKey: string;
        }

        /**
         * A label query over a set of resources, in this case pods.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.acme.v1.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Defines a set of pods (namely those matching the labelSelector relative to the given namespace(s)) that this pod should be co-located (affinity) or not co-located (anti-affinity) with, where co-located is defined as running on a node whose value of the label with key <topologyKey> matches that of any node on which a pod of the set of pods is running
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            /**
             * A label query over a set of resources, in this case pods.
             */
            labelSelector?: outputs.acme.v1.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            /**
             * namespaces specifies which namespaces the labelSelector applies to (matches against); null or empty list means "this pod's namespace"
             */
            namespaces?: string[];
            /**
             * This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed.
             */
            topologyKey: string;
        }

        /**
         * A label query over a set of resources, in this case pods.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.acme.v1.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Describes pod anti-affinity scheduling rules (e.g. avoid putting this pod in the same node, zone, etc. as some other pod(s)).
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAntiAffinity {
            /**
             * The scheduler will prefer to schedule pods to nodes that satisfy the anti-affinity expressions specified by this field, but it may choose a node that violates one or more of the expressions. The node that is most preferred is the one with the greatest sum of weights, i.e. for each node that meets all of the scheduling requirements (resource request, requiredDuringScheduling anti-affinity expressions, etc.), compute a sum by iterating through the elements of this field and adding "weight" to the sum if the node has pods which matches the corresponding podAffinityTerm; the node(s) with the highest sum are the most preferred.
             */
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.acme.v1.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            /**
             * If the anti-affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the anti-affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to a pod label update), the system may or may not try to eventually evict the pod from its node. When there are multiple elements, the lists of nodes corresponding to each podAffinityTerm are intersected, i.e. all terms must be satisfied.
             */
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.acme.v1.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        /**
         * The weights of all of the matched WeightedPodAffinityTerm fields are added per-node to find the most preferred node(s)
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            /**
             * Required. A pod affinity term, associated with the corresponding weight.
             */
            podAffinityTerm: outputs.acme.v1.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            /**
             * weight associated with matching the corresponding podAffinityTerm, in the range 1-100.
             */
            weight: number;
        }

        /**
         * Required. A pod affinity term, associated with the corresponding weight.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            /**
             * A label query over a set of resources, in this case pods.
             */
            labelSelector?: outputs.acme.v1.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            /**
             * namespaces specifies which namespaces the labelSelector applies to (matches against); null or empty list means "this pod's namespace"
             */
            namespaces?: string[];
            /**
             * This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed.
             */
            topologyKey: string;
        }

        /**
         * A label query over a set of resources, in this case pods.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.acme.v1.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Defines a set of pods (namely those matching the labelSelector relative to the given namespace(s)) that this pod should be co-located (affinity) or not co-located (anti-affinity) with, where co-located is defined as running on a node whose value of the label with key <topologyKey> matches that of any node on which a pod of the set of pods is running
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            /**
             * A label query over a set of resources, in this case pods.
             */
            labelSelector?: outputs.acme.v1.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            /**
             * namespaces specifies which namespaces the labelSelector applies to (matches against); null or empty list means "this pod's namespace"
             */
            namespaces?: string[];
            /**
             * This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed.
             */
            topologyKey: string;
        }

        /**
         * A label query over a set of resources, in this case pods.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.acme.v1.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * The pod this Toleration is attached to tolerates any taint that matches the triple <key,value,effect> using the matching operator <operator>.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecTolerations {
            /**
             * Effect indicates the taint effect to match. Empty means match all taint effects. When specified, allowed values are NoSchedule, PreferNoSchedule and NoExecute.
             */
            effect?: string;
            /**
             * Key is the taint key that the toleration applies to. Empty means match all taint keys. If the key is empty, operator must be Exists; this combination means to match all values and all keys.
             */
            key?: string;
            /**
             * Operator represents a key's relationship to the value. Valid operators are Exists and Equal. Defaults to Equal. Exists is equivalent to wildcard for value, so that a pod can tolerate all taints of a particular category.
             */
            operator?: string;
            /**
             * TolerationSeconds represents the period of time the toleration (which must be of effect NoExecute, otherwise this field is ignored) tolerates the taint. By default, it is not set, which means tolerate the taint forever (do not evict). Zero and negative values will be treated as 0 (evict immediately) by the system.
             */
            tolerationSeconds?: number;
            /**
             * Value is the taint value the toleration matches to. If the operator is Exists, the value should be empty, otherwise just a regular string.
             */
            value?: string;
        }

        /**
         * Selector selects a set of DNSNames on the Certificate resource that should be solved using this challenge solver. If not specified, the solver will be treated as the 'default' solver with the lowest priority, i.e. if any other solver has a more specific match, it will be used instead.
         */
        export interface ChallengeSpecSolverSelector {
            /**
             * List of DNSNames that this solver will be used to solve. If specified and a match is found, a dnsNames selector will take precedence over a dnsZones selector. If multiple solvers match with the same dnsNames value, the solver with the most matching labels in matchLabels will be selected. If neither has more matches, the solver defined earlier in the list will be selected.
             */
            dnsNames?: string[];
            /**
             * List of DNSZones that this solver will be used to solve. The most specific DNS zone match specified here will take precedence over other DNS zone matches, so a solver specifying sys.example.com will be selected over one specifying example.com for the domain www.sys.example.com. If multiple solvers match with the same dnsZones value, the solver with the most matching labels in matchLabels will be selected. If neither has more matches, the solver defined earlier in the list will be selected.
             */
            dnsZones?: string[];
            /**
             * A label selector that is used to refine the set of certificate's that this challenge solver will apply to.
             */
            matchLabels?: {[key: string]: string};
        }

        export interface ChallengeStatus {
            /**
             * presented will be set to true if the challenge values for this challenge are currently 'presented'. This *does not* imply the self check is passing. Only that the values have been 'submitted' for the appropriate challenge mechanism (i.e. the DNS01 TXT record has been presented, or the HTTP01 configuration has been configured).
             */
            presented?: boolean;
            /**
             * Used to denote whether this challenge should be processed or not. This field will only be set to true by the 'scheduling' component. It will only be set to false by the 'challenges' controller, after the challenge has reached a final state or timed out. If this field is set to false, the challenge controller will not take any more action.
             */
            processing?: boolean;
            /**
             * Contains human readable information on why the Challenge is in the current state.
             */
            reason?: string;
            /**
             * Contains the current 'state' of the challenge. If not set, the state of the challenge is unknown.
             */
            state?: string;
        }

        export interface OrderSpec {
            /**
             * CommonName is the common name as specified on the DER encoded CSR. If specified, this value must also be present in `dnsNames` or `ipAddresses`. This field must match the corresponding field on the DER encoded CSR.
             */
            commonName?: string;
            /**
             * DNSNames is a list of DNS names that should be included as part of the Order validation process. This field must match the corresponding field on the DER encoded CSR.
             */
            dnsNames?: string[];
            /**
             * Duration is the duration for the not after date for the requested certificate. this is set on order creation as pe the ACME spec.
             */
            duration?: string;
            /**
             * IPAddresses is a list of IP addresses that should be included as part of the Order validation process. This field must match the corresponding field on the DER encoded CSR.
             */
            ipAddresses?: string[];
            /**
             * IssuerRef references a properly configured ACME-type Issuer which should be used to create this Order. If the Issuer does not exist, processing will be retried. If the Issuer is not an 'ACME' Issuer, an error will be returned and the Order will be marked as failed.
             */
            issuerRef: outputs.acme.v1.OrderSpecIssuerRef;
            /**
             * Certificate signing request bytes in DER encoding. This will be used when finalizing the order. This field must be set on the order.
             */
            request: string;
        }

        /**
         * IssuerRef references a properly configured ACME-type Issuer which should be used to create this Order. If the Issuer does not exist, processing will be retried. If the Issuer is not an 'ACME' Issuer, an error will be returned and the Order will be marked as failed.
         */
        export interface OrderSpecIssuerRef {
            /**
             * Group of the resource being referred to.
             */
            group?: string;
            /**
             * Kind of the resource being referred to.
             */
            kind?: string;
            /**
             * Name of the resource being referred to.
             */
            name: string;
        }

        export interface OrderStatus {
            /**
             * Authorizations contains data returned from the ACME server on what authorizations must be completed in order to validate the DNS names specified on the Order.
             */
            authorizations?: outputs.acme.v1.OrderStatusAuthorizations[];
            /**
             * Certificate is a copy of the PEM encoded certificate for this Order. This field will be populated after the order has been successfully finalized with the ACME server, and the order has transitioned to the 'valid' state.
             */
            certificate?: string;
            /**
             * FailureTime stores the time that this order failed. This is used to influence garbage collection and back-off.
             */
            failureTime?: string;
            /**
             * FinalizeURL of the Order. This is used to obtain certificates for this order once it has been completed.
             */
            finalizeURL?: string;
            /**
             * Reason optionally provides more information about a why the order is in the current state.
             */
            reason?: string;
            /**
             * State contains the current state of this Order resource. States 'success' and 'expired' are 'final'
             */
            state?: string;
            /**
             * URL of the Order. This will initially be empty when the resource is first created. The Order controller will populate this field when the Order is first processed. This field will be immutable after it is initially set.
             */
            url?: string;
        }

        /**
         * ACMEAuthorization contains data returned from the ACME server on an authorization that must be completed in order validate a DNS name on an ACME Order resource.
         */
        export interface OrderStatusAuthorizations {
            /**
             * Challenges specifies the challenge types offered by the ACME server. One of these challenge types will be selected when validating the DNS name and an appropriate Challenge resource will be created to perform the ACME challenge process.
             */
            challenges?: outputs.acme.v1.OrderStatusAuthorizationsChallenges[];
            /**
             * Identifier is the DNS name to be validated as part of this authorization
             */
            identifier?: string;
            /**
             * InitialState is the initial state of the ACME authorization when first fetched from the ACME server. If an Authorization is already 'valid', the Order controller will not create a Challenge resource for the authorization. This will occur when working with an ACME server that enables 'authz reuse' (such as Let's Encrypt's production endpoint). If not set and 'identifier' is set, the state is assumed to be pending and a Challenge will be created.
             */
            initialState?: string;
            /**
             * URL is the URL of the Authorization that must be completed
             */
            url: string;
            /**
             * Wildcard will be true if this authorization is for a wildcard DNS name. If this is true, the identifier will be the *non-wildcard* version of the DNS name. For example, if '*.example.com' is the DNS name being validated, this field will be 'true' and the 'identifier' field will be 'example.com'.
             */
            wildcard?: boolean;
        }

        /**
         * Challenge specifies a challenge offered by the ACME server for an Order. An appropriate Challenge resource can be created to perform the ACME challenge process.
         */
        export interface OrderStatusAuthorizationsChallenges {
            /**
             * Token is the token that must be presented for this challenge. This is used to compute the 'key' that must also be presented.
             */
            token: string;
            /**
             * Type is the type of challenge being offered, e.g. 'http-01', 'dns-01', 'tls-sni-01', etc. This is the raw value retrieved from the ACME server. Only 'http-01' and 'dns-01' are supported by cert-manager, other values will be ignored.
             */
            type: string;
            /**
             * URL is the URL of this challenge. It can be used to retrieve additional metadata about the Challenge from the ACME server.
             */
            url: string;
        }
    }

    export namespace v1alpha2 {
        export interface ChallengeSpec {
            /**
             * AuthzURL is the URL to the ACME Authorization resource that this challenge is a part of.
             */
            authzURL: string;
            /**
             * DNSName is the identifier that this challenge is for, e.g. example.com. If the requested DNSName is a 'wildcard', this field MUST be set to the non-wildcard domain, e.g. for `*.example.com`, it must be `example.com`.
             */
            dnsName: string;
            /**
             * IssuerRef references a properly configured ACME-type Issuer which should be used to create this Challenge. If the Issuer does not exist, processing will be retried. If the Issuer is not an 'ACME' Issuer, an error will be returned and the Challenge will be marked as failed.
             */
            issuerRef: outputs.acme.v1alpha2.ChallengeSpecIssuerRef;
            /**
             * Key is the ACME challenge key for this challenge For HTTP01 challenges, this is the value that must be responded with to complete the HTTP01 challenge in the format: `<private key JWK thumbprint>.<key from acme server for challenge>`. For DNS01 challenges, this is the base64 encoded SHA256 sum of the `<private key JWK thumbprint>.<key from acme server for challenge>` text that must be set as the TXT record content.
             */
            key: string;
            /**
             * Solver contains the domain solving configuration that should be used to solve this challenge resource.
             */
            solver: outputs.acme.v1alpha2.ChallengeSpecSolver;
            /**
             * Token is the ACME challenge token for this challenge. This is the raw value returned from the ACME server.
             */
            token: string;
            /**
             * Type is the type of ACME challenge this resource represents. One of "http-01" or "dns-01".
             */
            type: string;
            /**
             * URL is the URL of the ACME Challenge resource for this challenge. This can be used to lookup details about the status of this challenge.
             */
            url: string;
            /**
             * Wildcard will be true if this challenge is for a wildcard identifier, for example '*.example.com'.
             */
            wildcard?: boolean;
        }

        /**
         * IssuerRef references a properly configured ACME-type Issuer which should be used to create this Challenge. If the Issuer does not exist, processing will be retried. If the Issuer is not an 'ACME' Issuer, an error will be returned and the Challenge will be marked as failed.
         */
        export interface ChallengeSpecIssuerRef {
            /**
             * Group of the resource being referred to.
             */
            group?: string;
            /**
             * Kind of the resource being referred to.
             */
            kind?: string;
            /**
             * Name of the resource being referred to.
             */
            name: string;
        }

        /**
         * Solver contains the domain solving configuration that should be used to solve this challenge resource.
         */
        export interface ChallengeSpecSolver {
            /**
             * Configures cert-manager to attempt to complete authorizations by performing the DNS01 challenge flow.
             */
            dns01?: outputs.acme.v1alpha2.ChallengeSpecSolverDns01;
            /**
             * Configures cert-manager to attempt to complete authorizations by performing the HTTP01 challenge flow. It is not possible to obtain certificates for wildcard domain names (e.g. `*.example.com`) using the HTTP01 challenge mechanism.
             */
            http01?: outputs.acme.v1alpha2.ChallengeSpecSolverHttp01;
            /**
             * Selector selects a set of DNSNames on the Certificate resource that should be solved using this challenge solver. If not specified, the solver will be treated as the 'default' solver with the lowest priority, i.e. if any other solver has a more specific match, it will be used instead.
             */
            selector?: outputs.acme.v1alpha2.ChallengeSpecSolverSelector;
        }

        /**
         * Configures cert-manager to attempt to complete authorizations by performing the DNS01 challenge flow.
         */
        export interface ChallengeSpecSolverDns01 {
            /**
             * Use the 'ACME DNS' (https://github.com/joohoi/acme-dns) API to manage DNS01 challenge records.
             */
            acmedns?: outputs.acme.v1alpha2.ChallengeSpecSolverDns01Acmedns;
            /**
             * Use the Akamai DNS zone management API to manage DNS01 challenge records.
             */
            akamai?: outputs.acme.v1alpha2.ChallengeSpecSolverDns01Akamai;
            /**
             * Use the Microsoft Azure DNS API to manage DNS01 challenge records.
             */
            azuredns?: outputs.acme.v1alpha2.ChallengeSpecSolverDns01Azuredns;
            /**
             * Use the Google Cloud DNS API to manage DNS01 challenge records.
             */
            clouddns?: outputs.acme.v1alpha2.ChallengeSpecSolverDns01Clouddns;
            /**
             * Use the Cloudflare API to manage DNS01 challenge records.
             */
            cloudflare?: outputs.acme.v1alpha2.ChallengeSpecSolverDns01Cloudflare;
            /**
             * CNAMEStrategy configures how the DNS01 provider should handle CNAME records when found in DNS zones.
             */
            cnameStrategy?: string;
            /**
             * Use the DigitalOcean DNS API to manage DNS01 challenge records.
             */
            digitalocean?: outputs.acme.v1alpha2.ChallengeSpecSolverDns01Digitalocean;
            /**
             * Use RFC2136 ("Dynamic Updates in the Domain Name System") (https://datatracker.ietf.org/doc/rfc2136/) to manage DNS01 challenge records.
             */
            rfc2136?: outputs.acme.v1alpha2.ChallengeSpecSolverDns01Rfc2136;
            /**
             * Use the AWS Route53 API to manage DNS01 challenge records.
             */
            route53?: outputs.acme.v1alpha2.ChallengeSpecSolverDns01Route53;
            /**
             * Configure an external webhook based DNS01 challenge solver to manage DNS01 challenge records.
             */
            webhook?: outputs.acme.v1alpha2.ChallengeSpecSolverDns01Webhook;
        }

        /**
         * Use the 'ACME DNS' (https://github.com/joohoi/acme-dns) API to manage DNS01 challenge records.
         */
        export interface ChallengeSpecSolverDns01Acmedns {
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            accountSecretRef: outputs.acme.v1alpha2.ChallengeSpecSolverDns01AcmednsAccountSecretRef;
            host: string;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface ChallengeSpecSolverDns01AcmednsAccountSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the Akamai DNS zone management API to manage DNS01 challenge records.
         */
        export interface ChallengeSpecSolverDns01Akamai {
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            accessTokenSecretRef: outputs.acme.v1alpha2.ChallengeSpecSolverDns01AkamaiAccessTokenSecretRef;
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            clientSecretSecretRef: outputs.acme.v1alpha2.ChallengeSpecSolverDns01AkamaiClientSecretSecretRef;
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            clientTokenSecretRef: outputs.acme.v1alpha2.ChallengeSpecSolverDns01AkamaiClientTokenSecretRef;
            serviceConsumerDomain: string;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface ChallengeSpecSolverDns01AkamaiAccessTokenSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface ChallengeSpecSolverDns01AkamaiClientSecretSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface ChallengeSpecSolverDns01AkamaiClientTokenSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the Microsoft Azure DNS API to manage DNS01 challenge records.
         */
        export interface ChallengeSpecSolverDns01Azuredns {
            /**
             * if both this and ClientSecret are left unset MSI will be used
             */
            clientID?: string;
            /**
             * if both this and ClientID are left unset MSI will be used
             */
            clientSecretSecretRef?: outputs.acme.v1alpha2.ChallengeSpecSolverDns01AzurednsClientSecretSecretRef;
            environment?: string;
            hostedZoneName?: string;
            resourceGroupName: string;
            subscriptionID: string;
            /**
             * when specifying ClientID and ClientSecret then this field is also needed
             */
            tenantID?: string;
        }

        /**
         * if both this and ClientID are left unset MSI will be used
         */
        export interface ChallengeSpecSolverDns01AzurednsClientSecretSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the Google Cloud DNS API to manage DNS01 challenge records.
         */
        export interface ChallengeSpecSolverDns01Clouddns {
            /**
             * HostedZoneName is an optional field that tells cert-manager in which Cloud DNS zone the challenge record has to be created. If left empty cert-manager will automatically choose a zone.
             */
            hostedZoneName?: string;
            project: string;
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            serviceAccountSecretRef?: outputs.acme.v1alpha2.ChallengeSpecSolverDns01ClouddnsServiceAccountSecretRef;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface ChallengeSpecSolverDns01ClouddnsServiceAccountSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the Cloudflare API to manage DNS01 challenge records.
         */
        export interface ChallengeSpecSolverDns01Cloudflare {
            /**
             * API key to use to authenticate with Cloudflare. Note: using an API token to authenticate is now the recommended method as it allows greater control of permissions.
             */
            apiKeySecretRef?: outputs.acme.v1alpha2.ChallengeSpecSolverDns01CloudflareApiKeySecretRef;
            /**
             * API token used to authenticate with Cloudflare.
             */
            apiTokenSecretRef?: outputs.acme.v1alpha2.ChallengeSpecSolverDns01CloudflareApiTokenSecretRef;
            /**
             * Email of the account, only required when using API key based authentication.
             */
            email?: string;
        }

        /**
         * API key to use to authenticate with Cloudflare. Note: using an API token to authenticate is now the recommended method as it allows greater control of permissions.
         */
        export interface ChallengeSpecSolverDns01CloudflareApiKeySecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * API token used to authenticate with Cloudflare.
         */
        export interface ChallengeSpecSolverDns01CloudflareApiTokenSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the DigitalOcean DNS API to manage DNS01 challenge records.
         */
        export interface ChallengeSpecSolverDns01Digitalocean {
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            tokenSecretRef: outputs.acme.v1alpha2.ChallengeSpecSolverDns01DigitaloceanTokenSecretRef;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface ChallengeSpecSolverDns01DigitaloceanTokenSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use RFC2136 ("Dynamic Updates in the Domain Name System") (https://datatracker.ietf.org/doc/rfc2136/) to manage DNS01 challenge records.
         */
        export interface ChallengeSpecSolverDns01Rfc2136 {
            /**
             * The IP address or hostname of an authoritative DNS server supporting RFC2136 in the form host:port. If the host is an IPv6 address it must be enclosed in square brackets (e.g [2001:db8::1]) ; port is optional. This field is required.
             */
            nameserver: string;
            /**
             * The TSIG Algorithm configured in the DNS supporting RFC2136. Used only when ``tsigSecretSecretRef`` and ``tsigKeyName`` are defined. Supported values are (case-insensitive): ``HMACMD5`` (default), ``HMACSHA1``, ``HMACSHA256`` or ``HMACSHA512``.
             */
            tsigAlgorithm?: string;
            /**
             * The TSIG Key name configured in the DNS. If ``tsigSecretSecretRef`` is defined, this field is required.
             */
            tsigKeyName?: string;
            /**
             * The name of the secret containing the TSIG value. If ``tsigKeyName`` is defined, this field is required.
             */
            tsigSecretSecretRef?: outputs.acme.v1alpha2.ChallengeSpecSolverDns01Rfc2136TsigSecretSecretRef;
        }

        /**
         * The name of the secret containing the TSIG value. If ``tsigKeyName`` is defined, this field is required.
         */
        export interface ChallengeSpecSolverDns01Rfc2136TsigSecretSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the AWS Route53 API to manage DNS01 challenge records.
         */
        export interface ChallengeSpecSolverDns01Route53 {
            /**
             * The AccessKeyID is used for authentication. If not set we fall-back to using env vars, shared credentials file or AWS Instance metadata see: https://docs.aws.amazon.com/sdk-for-go/v1/developer-guide/configuring-sdk.html#specifying-credentials
             */
            accessKeyID?: string;
            /**
             * If set, the provider will manage only this zone in Route53 and will not do an lookup using the route53:ListHostedZonesByName api call.
             */
            hostedZoneID?: string;
            /**
             * Always set the region when using AccessKeyID and SecretAccessKey
             */
            region: string;
            /**
             * Role is a Role ARN which the Route53 provider will assume using either the explicit credentials AccessKeyID/SecretAccessKey or the inferred credentials from environment variables, shared credentials file or AWS Instance metadata
             */
            role?: string;
            /**
             * The SecretAccessKey is used for authentication. If not set we fall-back to using env vars, shared credentials file or AWS Instance metadata https://docs.aws.amazon.com/sdk-for-go/v1/developer-guide/configuring-sdk.html#specifying-credentials
             */
            secretAccessKeySecretRef?: outputs.acme.v1alpha2.ChallengeSpecSolverDns01Route53SecretAccessKeySecretRef;
        }

        /**
         * The SecretAccessKey is used for authentication. If not set we fall-back to using env vars, shared credentials file or AWS Instance metadata https://docs.aws.amazon.com/sdk-for-go/v1/developer-guide/configuring-sdk.html#specifying-credentials
         */
        export interface ChallengeSpecSolverDns01Route53SecretAccessKeySecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Configure an external webhook based DNS01 challenge solver to manage DNS01 challenge records.
         */
        export interface ChallengeSpecSolverDns01Webhook {
            /**
             * Additional configuration that should be passed to the webhook apiserver when challenges are processed. This can contain arbitrary JSON data. Secret values should not be specified in this stanza. If secret values are needed (e.g. credentials for a DNS service), you should use a SecretKeySelector to reference a Secret resource. For details on the schema of this field, consult the webhook provider implementation's documentation.
             */
            config?: {[key: string]: any};
            /**
             * The API group name that should be used when POSTing ChallengePayload resources to the webhook apiserver. This should be the same as the GroupName specified in the webhook provider implementation.
             */
            groupName: string;
            /**
             * The name of the solver to use, as defined in the webhook provider implementation. This will typically be the name of the provider, e.g. 'cloudflare'.
             */
            solverName: string;
        }

        /**
         * Configures cert-manager to attempt to complete authorizations by performing the HTTP01 challenge flow. It is not possible to obtain certificates for wildcard domain names (e.g. `*.example.com`) using the HTTP01 challenge mechanism.
         */
        export interface ChallengeSpecSolverHttp01 {
            /**
             * The ingress based HTTP01 challenge solver will solve challenges by creating or modifying Ingress resources in order to route requests for '/.well-known/acme-challenge/XYZ' to 'challenge solver' pods that are provisioned by cert-manager for each Challenge to be completed.
             */
            ingress?: outputs.acme.v1alpha2.ChallengeSpecSolverHttp01Ingress;
        }

        /**
         * The ingress based HTTP01 challenge solver will solve challenges by creating or modifying Ingress resources in order to route requests for '/.well-known/acme-challenge/XYZ' to 'challenge solver' pods that are provisioned by cert-manager for each Challenge to be completed.
         */
        export interface ChallengeSpecSolverHttp01Ingress {
            /**
             * The ingress class to use when creating Ingress resources to solve ACME challenges that use this challenge solver. Only one of 'class' or 'name' may be specified.
             */
            class?: string;
            /**
             * Optional ingress template used to configure the ACME challenge solver ingress used for HTTP01 challenges
             */
            ingressTemplate?: outputs.acme.v1alpha2.ChallengeSpecSolverHttp01IngressIngressTemplate;
            /**
             * The name of the ingress resource that should have ACME challenge solving routes inserted into it in order to solve HTTP01 challenges. This is typically used in conjunction with ingress controllers like ingress-gce, which maintains a 1:1 mapping between external IPs and ingress resources.
             */
            name?: string;
            /**
             * Optional pod template used to configure the ACME challenge solver pods used for HTTP01 challenges
             */
            podTemplate?: outputs.acme.v1alpha2.ChallengeSpecSolverHttp01IngressPodTemplate;
            /**
             * Optional service type for Kubernetes solver service
             */
            serviceType?: string;
        }

        /**
         * Optional ingress template used to configure the ACME challenge solver ingress used for HTTP01 challenges
         */
        export interface ChallengeSpecSolverHttp01IngressIngressTemplate {
            /**
             * ObjectMeta overrides for the ingress used to solve HTTP01 challenges. Only the 'labels' and 'annotations' fields may be set. If labels or annotations overlap with in-built values, the values here will override the in-built values.
             */
            metadata?: outputs.acme.v1alpha2.ChallengeSpecSolverHttp01IngressIngressTemplateMetadata;
        }

        /**
         * ObjectMeta overrides for the ingress used to solve HTTP01 challenges. Only the 'labels' and 'annotations' fields may be set. If labels or annotations overlap with in-built values, the values here will override the in-built values.
         */
        export interface ChallengeSpecSolverHttp01IngressIngressTemplateMetadata {
            /**
             * Annotations that should be added to the created ACME HTTP01 solver ingress.
             */
            annotations?: {[key: string]: string};
            /**
             * Labels that should be added to the created ACME HTTP01 solver ingress.
             */
            labels?: {[key: string]: string};
        }

        /**
         * Optional pod template used to configure the ACME challenge solver pods used for HTTP01 challenges
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplate {
            /**
             * ObjectMeta overrides for the pod used to solve HTTP01 challenges. Only the 'labels' and 'annotations' fields may be set. If labels or annotations overlap with in-built values, the values here will override the in-built values.
             */
            metadata?: outputs.acme.v1alpha2.ChallengeSpecSolverHttp01IngressPodTemplateMetadata;
            /**
             * PodSpec defines overrides for the HTTP01 challenge solver pod. Only the 'priorityClassName', 'nodeSelector', 'affinity', 'serviceAccountName' and 'tolerations' fields are supported currently. All other fields will be ignored.
             */
            spec?: outputs.acme.v1alpha2.ChallengeSpecSolverHttp01IngressPodTemplateSpec;
        }

        /**
         * ObjectMeta overrides for the pod used to solve HTTP01 challenges. Only the 'labels' and 'annotations' fields may be set. If labels or annotations overlap with in-built values, the values here will override the in-built values.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateMetadata {
            /**
             * Annotations that should be added to the create ACME HTTP01 solver pods.
             */
            annotations?: {[key: string]: string};
            /**
             * Labels that should be added to the created ACME HTTP01 solver pods.
             */
            labels?: {[key: string]: string};
        }

        /**
         * PodSpec defines overrides for the HTTP01 challenge solver pod. Only the 'priorityClassName', 'nodeSelector', 'affinity', 'serviceAccountName' and 'tolerations' fields are supported currently. All other fields will be ignored.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpec {
            /**
             * If specified, the pod's scheduling constraints
             */
            affinity?: outputs.acme.v1alpha2.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinity;
            /**
             * NodeSelector is a selector which must be true for the pod to fit on a node. Selector which must match a node's labels for the pod to be scheduled on that node. More info: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/
             */
            nodeSelector?: {[key: string]: string};
            /**
             * If specified, the pod's priorityClassName.
             */
            priorityClassName?: string;
            /**
             * If specified, the pod's service account
             */
            serviceAccountName?: string;
            /**
             * If specified, the pod's tolerations.
             */
            tolerations?: outputs.acme.v1alpha2.ChallengeSpecSolverHttp01IngressPodTemplateSpecTolerations[];
        }

        /**
         * If specified, the pod's scheduling constraints
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinity {
            /**
             * Describes node affinity scheduling rules for the pod.
             */
            nodeAffinity?: outputs.acme.v1alpha2.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityNodeAffinity;
            /**
             * Describes pod affinity scheduling rules (e.g. co-locate this pod in the same node, zone, etc. as some other pod(s)).
             */
            podAffinity?: outputs.acme.v1alpha2.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAffinity;
            /**
             * Describes pod anti-affinity scheduling rules (e.g. avoid putting this pod in the same node, zone, etc. as some other pod(s)).
             */
            podAntiAffinity?: outputs.acme.v1alpha2.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAntiAffinity;
        }

        /**
         * Describes node affinity scheduling rules for the pod.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityNodeAffinity {
            /**
             * The scheduler will prefer to schedule pods to nodes that satisfy the affinity expressions specified by this field, but it may choose a node that violates one or more of the expressions. The node that is most preferred is the one with the greatest sum of weights, i.e. for each node that meets all of the scheduling requirements (resource request, requiredDuringScheduling affinity expressions, etc.), compute a sum by iterating through the elements of this field and adding "weight" to the sum if the node matches the corresponding matchExpressions; the node(s) with the highest sum are the most preferred.
             */
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.acme.v1alpha2.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            /**
             * If the affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to an update), the system may or may not try to eventually evict the pod from its node.
             */
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.acme.v1alpha2.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution;
        }

        /**
         * An empty preferred scheduling term matches all objects with implicit weight 0 (i.e. it's a no-op). A null preferred scheduling term matches no objects (i.e. is also a no-op).
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            /**
             * A node selector term, associated with the corresponding weight.
             */
            preference: outputs.acme.v1alpha2.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference;
            /**
             * Weight associated with matching the corresponding nodeSelectorTerm, in the range 1-100.
             */
            weight: number;
        }

        /**
         * A node selector term, associated with the corresponding weight.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference {
            /**
             * A list of node selector requirements by node's labels.
             */
            matchExpressions?: outputs.acme.v1alpha2.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions[];
            /**
             * A list of node selector requirements by node's fields.
             */
            matchFields?: outputs.acme.v1alpha2.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields[];
        }

        /**
         * A node selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions {
            /**
             * The label key that the selector applies to.
             */
            key: string;
            /**
             * Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
             */
            operator: string;
            /**
             * An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * A node selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields {
            /**
             * The label key that the selector applies to.
             */
            key: string;
            /**
             * Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
             */
            operator: string;
            /**
             * An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * If the affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to an update), the system may or may not try to eventually evict the pod from its node.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            /**
             * Required. A list of node selector terms. The terms are ORed.
             */
            nodeSelectorTerms: outputs.acme.v1alpha2.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms[];
        }

        /**
         * A null or empty node selector term matches no objects. The requirements of them are ANDed. The TopologySelectorTerm type implements a subset of the NodeSelectorTerm.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms {
            /**
             * A list of node selector requirements by node's labels.
             */
            matchExpressions?: outputs.acme.v1alpha2.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions[];
            /**
             * A list of node selector requirements by node's fields.
             */
            matchFields?: outputs.acme.v1alpha2.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields[];
        }

        /**
         * A node selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions {
            /**
             * The label key that the selector applies to.
             */
            key: string;
            /**
             * Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
             */
            operator: string;
            /**
             * An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * A node selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields {
            /**
             * The label key that the selector applies to.
             */
            key: string;
            /**
             * Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
             */
            operator: string;
            /**
             * An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Describes pod affinity scheduling rules (e.g. co-locate this pod in the same node, zone, etc. as some other pod(s)).
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAffinity {
            /**
             * The scheduler will prefer to schedule pods to nodes that satisfy the affinity expressions specified by this field, but it may choose a node that violates one or more of the expressions. The node that is most preferred is the one with the greatest sum of weights, i.e. for each node that meets all of the scheduling requirements (resource request, requiredDuringScheduling affinity expressions, etc.), compute a sum by iterating through the elements of this field and adding "weight" to the sum if the node has pods which matches the corresponding podAffinityTerm; the node(s) with the highest sum are the most preferred.
             */
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.acme.v1alpha2.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            /**
             * If the affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to a pod label update), the system may or may not try to eventually evict the pod from its node. When there are multiple elements, the lists of nodes corresponding to each podAffinityTerm are intersected, i.e. all terms must be satisfied.
             */
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.acme.v1alpha2.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        /**
         * The weights of all of the matched WeightedPodAffinityTerm fields are added per-node to find the most preferred node(s)
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            /**
             * Required. A pod affinity term, associated with the corresponding weight.
             */
            podAffinityTerm: outputs.acme.v1alpha2.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            /**
             * weight associated with matching the corresponding podAffinityTerm, in the range 1-100.
             */
            weight: number;
        }

        /**
         * Required. A pod affinity term, associated with the corresponding weight.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            /**
             * A label query over a set of resources, in this case pods.
             */
            labelSelector?: outputs.acme.v1alpha2.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            /**
             * namespaces specifies which namespaces the labelSelector applies to (matches against); null or empty list means "this pod's namespace"
             */
            namespaces?: string[];
            /**
             * This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed.
             */
            topologyKey: string;
        }

        /**
         * A label query over a set of resources, in this case pods.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.acme.v1alpha2.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Defines a set of pods (namely those matching the labelSelector relative to the given namespace(s)) that this pod should be co-located (affinity) or not co-located (anti-affinity) with, where co-located is defined as running on a node whose value of the label with key <topologyKey> matches that of any node on which a pod of the set of pods is running
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            /**
             * A label query over a set of resources, in this case pods.
             */
            labelSelector?: outputs.acme.v1alpha2.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            /**
             * namespaces specifies which namespaces the labelSelector applies to (matches against); null or empty list means "this pod's namespace"
             */
            namespaces?: string[];
            /**
             * This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed.
             */
            topologyKey: string;
        }

        /**
         * A label query over a set of resources, in this case pods.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.acme.v1alpha2.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Describes pod anti-affinity scheduling rules (e.g. avoid putting this pod in the same node, zone, etc. as some other pod(s)).
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAntiAffinity {
            /**
             * The scheduler will prefer to schedule pods to nodes that satisfy the anti-affinity expressions specified by this field, but it may choose a node that violates one or more of the expressions. The node that is most preferred is the one with the greatest sum of weights, i.e. for each node that meets all of the scheduling requirements (resource request, requiredDuringScheduling anti-affinity expressions, etc.), compute a sum by iterating through the elements of this field and adding "weight" to the sum if the node has pods which matches the corresponding podAffinityTerm; the node(s) with the highest sum are the most preferred.
             */
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.acme.v1alpha2.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            /**
             * If the anti-affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the anti-affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to a pod label update), the system may or may not try to eventually evict the pod from its node. When there are multiple elements, the lists of nodes corresponding to each podAffinityTerm are intersected, i.e. all terms must be satisfied.
             */
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.acme.v1alpha2.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        /**
         * The weights of all of the matched WeightedPodAffinityTerm fields are added per-node to find the most preferred node(s)
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            /**
             * Required. A pod affinity term, associated with the corresponding weight.
             */
            podAffinityTerm: outputs.acme.v1alpha2.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            /**
             * weight associated with matching the corresponding podAffinityTerm, in the range 1-100.
             */
            weight: number;
        }

        /**
         * Required. A pod affinity term, associated with the corresponding weight.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            /**
             * A label query over a set of resources, in this case pods.
             */
            labelSelector?: outputs.acme.v1alpha2.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            /**
             * namespaces specifies which namespaces the labelSelector applies to (matches against); null or empty list means "this pod's namespace"
             */
            namespaces?: string[];
            /**
             * This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed.
             */
            topologyKey: string;
        }

        /**
         * A label query over a set of resources, in this case pods.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.acme.v1alpha2.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Defines a set of pods (namely those matching the labelSelector relative to the given namespace(s)) that this pod should be co-located (affinity) or not co-located (anti-affinity) with, where co-located is defined as running on a node whose value of the label with key <topologyKey> matches that of any node on which a pod of the set of pods is running
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            /**
             * A label query over a set of resources, in this case pods.
             */
            labelSelector?: outputs.acme.v1alpha2.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            /**
             * namespaces specifies which namespaces the labelSelector applies to (matches against); null or empty list means "this pod's namespace"
             */
            namespaces?: string[];
            /**
             * This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed.
             */
            topologyKey: string;
        }

        /**
         * A label query over a set of resources, in this case pods.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.acme.v1alpha2.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * The pod this Toleration is attached to tolerates any taint that matches the triple <key,value,effect> using the matching operator <operator>.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecTolerations {
            /**
             * Effect indicates the taint effect to match. Empty means match all taint effects. When specified, allowed values are NoSchedule, PreferNoSchedule and NoExecute.
             */
            effect?: string;
            /**
             * Key is the taint key that the toleration applies to. Empty means match all taint keys. If the key is empty, operator must be Exists; this combination means to match all values and all keys.
             */
            key?: string;
            /**
             * Operator represents a key's relationship to the value. Valid operators are Exists and Equal. Defaults to Equal. Exists is equivalent to wildcard for value, so that a pod can tolerate all taints of a particular category.
             */
            operator?: string;
            /**
             * TolerationSeconds represents the period of time the toleration (which must be of effect NoExecute, otherwise this field is ignored) tolerates the taint. By default, it is not set, which means tolerate the taint forever (do not evict). Zero and negative values will be treated as 0 (evict immediately) by the system.
             */
            tolerationSeconds?: number;
            /**
             * Value is the taint value the toleration matches to. If the operator is Exists, the value should be empty, otherwise just a regular string.
             */
            value?: string;
        }

        /**
         * Selector selects a set of DNSNames on the Certificate resource that should be solved using this challenge solver. If not specified, the solver will be treated as the 'default' solver with the lowest priority, i.e. if any other solver has a more specific match, it will be used instead.
         */
        export interface ChallengeSpecSolverSelector {
            /**
             * List of DNSNames that this solver will be used to solve. If specified and a match is found, a dnsNames selector will take precedence over a dnsZones selector. If multiple solvers match with the same dnsNames value, the solver with the most matching labels in matchLabels will be selected. If neither has more matches, the solver defined earlier in the list will be selected.
             */
            dnsNames?: string[];
            /**
             * List of DNSZones that this solver will be used to solve. The most specific DNS zone match specified here will take precedence over other DNS zone matches, so a solver specifying sys.example.com will be selected over one specifying example.com for the domain www.sys.example.com. If multiple solvers match with the same dnsZones value, the solver with the most matching labels in matchLabels will be selected. If neither has more matches, the solver defined earlier in the list will be selected.
             */
            dnsZones?: string[];
            /**
             * A label selector that is used to refine the set of certificate's that this challenge solver will apply to.
             */
            matchLabels?: {[key: string]: string};
        }

        export interface ChallengeStatus {
            /**
             * Presented will be set to true if the challenge values for this challenge are currently 'presented'. This *does not* imply the self check is passing. Only that the values have been 'submitted' for the appropriate challenge mechanism (i.e. the DNS01 TXT record has been presented, or the HTTP01 configuration has been configured).
             */
            presented?: boolean;
            /**
             * Processing is used to denote whether this challenge should be processed or not. This field will only be set to true by the 'scheduling' component. It will only be set to false by the 'challenges' controller, after the challenge has reached a final state or timed out. If this field is set to false, the challenge controller will not take any more action.
             */
            processing?: boolean;
            /**
             * Reason contains human readable information on why the Challenge is in the current state.
             */
            reason?: string;
            /**
             * State contains the current 'state' of the challenge. If not set, the state of the challenge is unknown.
             */
            state?: string;
        }

        export interface OrderSpec {
            /**
             * CommonName is the common name as specified on the DER encoded CSR. If specified, this value must also be present in `dnsNames` or `ipAddresses`. This field must match the corresponding field on the DER encoded CSR.
             */
            commonName?: string;
            /**
             * Certificate signing request bytes in DER encoding. This will be used when finalizing the order. This field must be set on the order.
             */
            csr: string;
            /**
             * DNSNames is a list of DNS names that should be included as part of the Order validation process. This field must match the corresponding field on the DER encoded CSR.
             */
            dnsNames?: string[];
            /**
             * Duration is the duration for the not after date for the requested certificate. this is set on order creation as pe the ACME spec.
             */
            duration?: string;
            /**
             * IPAddresses is a list of IP addresses that should be included as part of the Order validation process. This field must match the corresponding field on the DER encoded CSR.
             */
            ipAddresses?: string[];
            /**
             * IssuerRef references a properly configured ACME-type Issuer which should be used to create this Order. If the Issuer does not exist, processing will be retried. If the Issuer is not an 'ACME' Issuer, an error will be returned and the Order will be marked as failed.
             */
            issuerRef: outputs.acme.v1alpha2.OrderSpecIssuerRef;
        }

        /**
         * IssuerRef references a properly configured ACME-type Issuer which should be used to create this Order. If the Issuer does not exist, processing will be retried. If the Issuer is not an 'ACME' Issuer, an error will be returned and the Order will be marked as failed.
         */
        export interface OrderSpecIssuerRef {
            /**
             * Group of the resource being referred to.
             */
            group?: string;
            /**
             * Kind of the resource being referred to.
             */
            kind?: string;
            /**
             * Name of the resource being referred to.
             */
            name: string;
        }

        export interface OrderStatus {
            /**
             * Authorizations contains data returned from the ACME server on what authorizations must be completed in order to validate the DNS names specified on the Order.
             */
            authorizations?: outputs.acme.v1alpha2.OrderStatusAuthorizations[];
            /**
             * Certificate is a copy of the PEM encoded certificate for this Order. This field will be populated after the order has been successfully finalized with the ACME server, and the order has transitioned to the 'valid' state.
             */
            certificate?: string;
            /**
             * FailureTime stores the time that this order failed. This is used to influence garbage collection and back-off.
             */
            failureTime?: string;
            /**
             * FinalizeURL of the Order. This is used to obtain certificates for this order once it has been completed.
             */
            finalizeURL?: string;
            /**
             * Reason optionally provides more information about a why the order is in the current state.
             */
            reason?: string;
            /**
             * State contains the current state of this Order resource. States 'success' and 'expired' are 'final'
             */
            state?: string;
            /**
             * URL of the Order. This will initially be empty when the resource is first created. The Order controller will populate this field when the Order is first processed. This field will be immutable after it is initially set.
             */
            url?: string;
        }

        /**
         * ACMEAuthorization contains data returned from the ACME server on an authorization that must be completed in order validate a DNS name on an ACME Order resource.
         */
        export interface OrderStatusAuthorizations {
            /**
             * Challenges specifies the challenge types offered by the ACME server. One of these challenge types will be selected when validating the DNS name and an appropriate Challenge resource will be created to perform the ACME challenge process.
             */
            challenges?: outputs.acme.v1alpha2.OrderStatusAuthorizationsChallenges[];
            /**
             * Identifier is the DNS name to be validated as part of this authorization
             */
            identifier?: string;
            /**
             * InitialState is the initial state of the ACME authorization when first fetched from the ACME server. If an Authorization is already 'valid', the Order controller will not create a Challenge resource for the authorization. This will occur when working with an ACME server that enables 'authz reuse' (such as Let's Encrypt's production endpoint). If not set and 'identifier' is set, the state is assumed to be pending and a Challenge will be created.
             */
            initialState?: string;
            /**
             * URL is the URL of the Authorization that must be completed
             */
            url: string;
            /**
             * Wildcard will be true if this authorization is for a wildcard DNS name. If this is true, the identifier will be the *non-wildcard* version of the DNS name. For example, if '*.example.com' is the DNS name being validated, this field will be 'true' and the 'identifier' field will be 'example.com'.
             */
            wildcard?: boolean;
        }

        /**
         * Challenge specifies a challenge offered by the ACME server for an Order. An appropriate Challenge resource can be created to perform the ACME challenge process.
         */
        export interface OrderStatusAuthorizationsChallenges {
            /**
             * Token is the token that must be presented for this challenge. This is used to compute the 'key' that must also be presented.
             */
            token: string;
            /**
             * Type is the type of challenge being offered, e.g. 'http-01', 'dns-01', 'tls-sni-01', etc. This is the raw value retrieved from the ACME server. Only 'http-01' and 'dns-01' are supported by cert-manager, other values will be ignored.
             */
            type: string;
            /**
             * URL is the URL of this challenge. It can be used to retrieve additional metadata about the Challenge from the ACME server.
             */
            url: string;
        }
    }

    export namespace v1alpha3 {
        export interface ChallengeSpec {
            /**
             * AuthzURL is the URL to the ACME Authorization resource that this challenge is a part of.
             */
            authzURL: string;
            /**
             * DNSName is the identifier that this challenge is for, e.g. example.com. If the requested DNSName is a 'wildcard', this field MUST be set to the non-wildcard domain, e.g. for `*.example.com`, it must be `example.com`.
             */
            dnsName: string;
            /**
             * IssuerRef references a properly configured ACME-type Issuer which should be used to create this Challenge. If the Issuer does not exist, processing will be retried. If the Issuer is not an 'ACME' Issuer, an error will be returned and the Challenge will be marked as failed.
             */
            issuerRef: outputs.acme.v1alpha3.ChallengeSpecIssuerRef;
            /**
             * Key is the ACME challenge key for this challenge For HTTP01 challenges, this is the value that must be responded with to complete the HTTP01 challenge in the format: `<private key JWK thumbprint>.<key from acme server for challenge>`. For DNS01 challenges, this is the base64 encoded SHA256 sum of the `<private key JWK thumbprint>.<key from acme server for challenge>` text that must be set as the TXT record content.
             */
            key: string;
            /**
             * Solver contains the domain solving configuration that should be used to solve this challenge resource.
             */
            solver: outputs.acme.v1alpha3.ChallengeSpecSolver;
            /**
             * Token is the ACME challenge token for this challenge. This is the raw value returned from the ACME server.
             */
            token: string;
            /**
             * Type is the type of ACME challenge this resource represents. One of "http-01" or "dns-01".
             */
            type: string;
            /**
             * URL is the URL of the ACME Challenge resource for this challenge. This can be used to lookup details about the status of this challenge.
             */
            url: string;
            /**
             * Wildcard will be true if this challenge is for a wildcard identifier, for example '*.example.com'.
             */
            wildcard?: boolean;
        }

        /**
         * IssuerRef references a properly configured ACME-type Issuer which should be used to create this Challenge. If the Issuer does not exist, processing will be retried. If the Issuer is not an 'ACME' Issuer, an error will be returned and the Challenge will be marked as failed.
         */
        export interface ChallengeSpecIssuerRef {
            /**
             * Group of the resource being referred to.
             */
            group?: string;
            /**
             * Kind of the resource being referred to.
             */
            kind?: string;
            /**
             * Name of the resource being referred to.
             */
            name: string;
        }

        /**
         * Solver contains the domain solving configuration that should be used to solve this challenge resource.
         */
        export interface ChallengeSpecSolver {
            /**
             * Configures cert-manager to attempt to complete authorizations by performing the DNS01 challenge flow.
             */
            dns01?: outputs.acme.v1alpha3.ChallengeSpecSolverDns01;
            /**
             * Configures cert-manager to attempt to complete authorizations by performing the HTTP01 challenge flow. It is not possible to obtain certificates for wildcard domain names (e.g. `*.example.com`) using the HTTP01 challenge mechanism.
             */
            http01?: outputs.acme.v1alpha3.ChallengeSpecSolverHttp01;
            /**
             * Selector selects a set of DNSNames on the Certificate resource that should be solved using this challenge solver. If not specified, the solver will be treated as the 'default' solver with the lowest priority, i.e. if any other solver has a more specific match, it will be used instead.
             */
            selector?: outputs.acme.v1alpha3.ChallengeSpecSolverSelector;
        }

        /**
         * Configures cert-manager to attempt to complete authorizations by performing the DNS01 challenge flow.
         */
        export interface ChallengeSpecSolverDns01 {
            /**
             * Use the 'ACME DNS' (https://github.com/joohoi/acme-dns) API to manage DNS01 challenge records.
             */
            acmedns?: outputs.acme.v1alpha3.ChallengeSpecSolverDns01Acmedns;
            /**
             * Use the Akamai DNS zone management API to manage DNS01 challenge records.
             */
            akamai?: outputs.acme.v1alpha3.ChallengeSpecSolverDns01Akamai;
            /**
             * Use the Microsoft Azure DNS API to manage DNS01 challenge records.
             */
            azuredns?: outputs.acme.v1alpha3.ChallengeSpecSolverDns01Azuredns;
            /**
             * Use the Google Cloud DNS API to manage DNS01 challenge records.
             */
            clouddns?: outputs.acme.v1alpha3.ChallengeSpecSolverDns01Clouddns;
            /**
             * Use the Cloudflare API to manage DNS01 challenge records.
             */
            cloudflare?: outputs.acme.v1alpha3.ChallengeSpecSolverDns01Cloudflare;
            /**
             * CNAMEStrategy configures how the DNS01 provider should handle CNAME records when found in DNS zones.
             */
            cnameStrategy?: string;
            /**
             * Use the DigitalOcean DNS API to manage DNS01 challenge records.
             */
            digitalocean?: outputs.acme.v1alpha3.ChallengeSpecSolverDns01Digitalocean;
            /**
             * Use RFC2136 ("Dynamic Updates in the Domain Name System") (https://datatracker.ietf.org/doc/rfc2136/) to manage DNS01 challenge records.
             */
            rfc2136?: outputs.acme.v1alpha3.ChallengeSpecSolverDns01Rfc2136;
            /**
             * Use the AWS Route53 API to manage DNS01 challenge records.
             */
            route53?: outputs.acme.v1alpha3.ChallengeSpecSolverDns01Route53;
            /**
             * Configure an external webhook based DNS01 challenge solver to manage DNS01 challenge records.
             */
            webhook?: outputs.acme.v1alpha3.ChallengeSpecSolverDns01Webhook;
        }

        /**
         * Use the 'ACME DNS' (https://github.com/joohoi/acme-dns) API to manage DNS01 challenge records.
         */
        export interface ChallengeSpecSolverDns01Acmedns {
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            accountSecretRef: outputs.acme.v1alpha3.ChallengeSpecSolverDns01AcmednsAccountSecretRef;
            host: string;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface ChallengeSpecSolverDns01AcmednsAccountSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the Akamai DNS zone management API to manage DNS01 challenge records.
         */
        export interface ChallengeSpecSolverDns01Akamai {
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            accessTokenSecretRef: outputs.acme.v1alpha3.ChallengeSpecSolverDns01AkamaiAccessTokenSecretRef;
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            clientSecretSecretRef: outputs.acme.v1alpha3.ChallengeSpecSolverDns01AkamaiClientSecretSecretRef;
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            clientTokenSecretRef: outputs.acme.v1alpha3.ChallengeSpecSolverDns01AkamaiClientTokenSecretRef;
            serviceConsumerDomain: string;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface ChallengeSpecSolverDns01AkamaiAccessTokenSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface ChallengeSpecSolverDns01AkamaiClientSecretSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface ChallengeSpecSolverDns01AkamaiClientTokenSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the Microsoft Azure DNS API to manage DNS01 challenge records.
         */
        export interface ChallengeSpecSolverDns01Azuredns {
            /**
             * if both this and ClientSecret are left unset MSI will be used
             */
            clientID?: string;
            /**
             * if both this and ClientID are left unset MSI will be used
             */
            clientSecretSecretRef?: outputs.acme.v1alpha3.ChallengeSpecSolverDns01AzurednsClientSecretSecretRef;
            environment?: string;
            hostedZoneName?: string;
            resourceGroupName: string;
            subscriptionID: string;
            /**
             * when specifying ClientID and ClientSecret then this field is also needed
             */
            tenantID?: string;
        }

        /**
         * if both this and ClientID are left unset MSI will be used
         */
        export interface ChallengeSpecSolverDns01AzurednsClientSecretSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the Google Cloud DNS API to manage DNS01 challenge records.
         */
        export interface ChallengeSpecSolverDns01Clouddns {
            /**
             * HostedZoneName is an optional field that tells cert-manager in which Cloud DNS zone the challenge record has to be created. If left empty cert-manager will automatically choose a zone.
             */
            hostedZoneName?: string;
            project: string;
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            serviceAccountSecretRef?: outputs.acme.v1alpha3.ChallengeSpecSolverDns01ClouddnsServiceAccountSecretRef;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface ChallengeSpecSolverDns01ClouddnsServiceAccountSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the Cloudflare API to manage DNS01 challenge records.
         */
        export interface ChallengeSpecSolverDns01Cloudflare {
            /**
             * API key to use to authenticate with Cloudflare. Note: using an API token to authenticate is now the recommended method as it allows greater control of permissions.
             */
            apiKeySecretRef?: outputs.acme.v1alpha3.ChallengeSpecSolverDns01CloudflareApiKeySecretRef;
            /**
             * API token used to authenticate with Cloudflare.
             */
            apiTokenSecretRef?: outputs.acme.v1alpha3.ChallengeSpecSolverDns01CloudflareApiTokenSecretRef;
            /**
             * Email of the account, only required when using API key based authentication.
             */
            email?: string;
        }

        /**
         * API key to use to authenticate with Cloudflare. Note: using an API token to authenticate is now the recommended method as it allows greater control of permissions.
         */
        export interface ChallengeSpecSolverDns01CloudflareApiKeySecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * API token used to authenticate with Cloudflare.
         */
        export interface ChallengeSpecSolverDns01CloudflareApiTokenSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the DigitalOcean DNS API to manage DNS01 challenge records.
         */
        export interface ChallengeSpecSolverDns01Digitalocean {
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            tokenSecretRef: outputs.acme.v1alpha3.ChallengeSpecSolverDns01DigitaloceanTokenSecretRef;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface ChallengeSpecSolverDns01DigitaloceanTokenSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use RFC2136 ("Dynamic Updates in the Domain Name System") (https://datatracker.ietf.org/doc/rfc2136/) to manage DNS01 challenge records.
         */
        export interface ChallengeSpecSolverDns01Rfc2136 {
            /**
             * The IP address or hostname of an authoritative DNS server supporting RFC2136 in the form host:port. If the host is an IPv6 address it must be enclosed in square brackets (e.g [2001:db8::1]) ; port is optional. This field is required.
             */
            nameserver: string;
            /**
             * The TSIG Algorithm configured in the DNS supporting RFC2136. Used only when ``tsigSecretSecretRef`` and ``tsigKeyName`` are defined. Supported values are (case-insensitive): ``HMACMD5`` (default), ``HMACSHA1``, ``HMACSHA256`` or ``HMACSHA512``.
             */
            tsigAlgorithm?: string;
            /**
             * The TSIG Key name configured in the DNS. If ``tsigSecretSecretRef`` is defined, this field is required.
             */
            tsigKeyName?: string;
            /**
             * The name of the secret containing the TSIG value. If ``tsigKeyName`` is defined, this field is required.
             */
            tsigSecretSecretRef?: outputs.acme.v1alpha3.ChallengeSpecSolverDns01Rfc2136TsigSecretSecretRef;
        }

        /**
         * The name of the secret containing the TSIG value. If ``tsigKeyName`` is defined, this field is required.
         */
        export interface ChallengeSpecSolverDns01Rfc2136TsigSecretSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the AWS Route53 API to manage DNS01 challenge records.
         */
        export interface ChallengeSpecSolverDns01Route53 {
            /**
             * The AccessKeyID is used for authentication. If not set we fall-back to using env vars, shared credentials file or AWS Instance metadata see: https://docs.aws.amazon.com/sdk-for-go/v1/developer-guide/configuring-sdk.html#specifying-credentials
             */
            accessKeyID?: string;
            /**
             * If set, the provider will manage only this zone in Route53 and will not do an lookup using the route53:ListHostedZonesByName api call.
             */
            hostedZoneID?: string;
            /**
             * Always set the region when using AccessKeyID and SecretAccessKey
             */
            region: string;
            /**
             * Role is a Role ARN which the Route53 provider will assume using either the explicit credentials AccessKeyID/SecretAccessKey or the inferred credentials from environment variables, shared credentials file or AWS Instance metadata
             */
            role?: string;
            /**
             * The SecretAccessKey is used for authentication. If not set we fall-back to using env vars, shared credentials file or AWS Instance metadata https://docs.aws.amazon.com/sdk-for-go/v1/developer-guide/configuring-sdk.html#specifying-credentials
             */
            secretAccessKeySecretRef?: outputs.acme.v1alpha3.ChallengeSpecSolverDns01Route53SecretAccessKeySecretRef;
        }

        /**
         * The SecretAccessKey is used for authentication. If not set we fall-back to using env vars, shared credentials file or AWS Instance metadata https://docs.aws.amazon.com/sdk-for-go/v1/developer-guide/configuring-sdk.html#specifying-credentials
         */
        export interface ChallengeSpecSolverDns01Route53SecretAccessKeySecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Configure an external webhook based DNS01 challenge solver to manage DNS01 challenge records.
         */
        export interface ChallengeSpecSolverDns01Webhook {
            /**
             * Additional configuration that should be passed to the webhook apiserver when challenges are processed. This can contain arbitrary JSON data. Secret values should not be specified in this stanza. If secret values are needed (e.g. credentials for a DNS service), you should use a SecretKeySelector to reference a Secret resource. For details on the schema of this field, consult the webhook provider implementation's documentation.
             */
            config?: {[key: string]: any};
            /**
             * The API group name that should be used when POSTing ChallengePayload resources to the webhook apiserver. This should be the same as the GroupName specified in the webhook provider implementation.
             */
            groupName: string;
            /**
             * The name of the solver to use, as defined in the webhook provider implementation. This will typically be the name of the provider, e.g. 'cloudflare'.
             */
            solverName: string;
        }

        /**
         * Configures cert-manager to attempt to complete authorizations by performing the HTTP01 challenge flow. It is not possible to obtain certificates for wildcard domain names (e.g. `*.example.com`) using the HTTP01 challenge mechanism.
         */
        export interface ChallengeSpecSolverHttp01 {
            /**
             * The ingress based HTTP01 challenge solver will solve challenges by creating or modifying Ingress resources in order to route requests for '/.well-known/acme-challenge/XYZ' to 'challenge solver' pods that are provisioned by cert-manager for each Challenge to be completed.
             */
            ingress?: outputs.acme.v1alpha3.ChallengeSpecSolverHttp01Ingress;
        }

        /**
         * The ingress based HTTP01 challenge solver will solve challenges by creating or modifying Ingress resources in order to route requests for '/.well-known/acme-challenge/XYZ' to 'challenge solver' pods that are provisioned by cert-manager for each Challenge to be completed.
         */
        export interface ChallengeSpecSolverHttp01Ingress {
            /**
             * The ingress class to use when creating Ingress resources to solve ACME challenges that use this challenge solver. Only one of 'class' or 'name' may be specified.
             */
            class?: string;
            /**
             * Optional ingress template used to configure the ACME challenge solver ingress used for HTTP01 challenges
             */
            ingressTemplate?: outputs.acme.v1alpha3.ChallengeSpecSolverHttp01IngressIngressTemplate;
            /**
             * The name of the ingress resource that should have ACME challenge solving routes inserted into it in order to solve HTTP01 challenges. This is typically used in conjunction with ingress controllers like ingress-gce, which maintains a 1:1 mapping between external IPs and ingress resources.
             */
            name?: string;
            /**
             * Optional pod template used to configure the ACME challenge solver pods used for HTTP01 challenges
             */
            podTemplate?: outputs.acme.v1alpha3.ChallengeSpecSolverHttp01IngressPodTemplate;
            /**
             * Optional service type for Kubernetes solver service
             */
            serviceType?: string;
        }

        /**
         * Optional ingress template used to configure the ACME challenge solver ingress used for HTTP01 challenges
         */
        export interface ChallengeSpecSolverHttp01IngressIngressTemplate {
            /**
             * ObjectMeta overrides for the ingress used to solve HTTP01 challenges. Only the 'labels' and 'annotations' fields may be set. If labels or annotations overlap with in-built values, the values here will override the in-built values.
             */
            metadata?: outputs.acme.v1alpha3.ChallengeSpecSolverHttp01IngressIngressTemplateMetadata;
        }

        /**
         * ObjectMeta overrides for the ingress used to solve HTTP01 challenges. Only the 'labels' and 'annotations' fields may be set. If labels or annotations overlap with in-built values, the values here will override the in-built values.
         */
        export interface ChallengeSpecSolverHttp01IngressIngressTemplateMetadata {
            /**
             * Annotations that should be added to the created ACME HTTP01 solver ingress.
             */
            annotations?: {[key: string]: string};
            /**
             * Labels that should be added to the created ACME HTTP01 solver ingress.
             */
            labels?: {[key: string]: string};
        }

        /**
         * Optional pod template used to configure the ACME challenge solver pods used for HTTP01 challenges
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplate {
            /**
             * ObjectMeta overrides for the pod used to solve HTTP01 challenges. Only the 'labels' and 'annotations' fields may be set. If labels or annotations overlap with in-built values, the values here will override the in-built values.
             */
            metadata?: outputs.acme.v1alpha3.ChallengeSpecSolverHttp01IngressPodTemplateMetadata;
            /**
             * PodSpec defines overrides for the HTTP01 challenge solver pod. Only the 'priorityClassName', 'nodeSelector', 'affinity', 'serviceAccountName' and 'tolerations' fields are supported currently. All other fields will be ignored.
             */
            spec?: outputs.acme.v1alpha3.ChallengeSpecSolverHttp01IngressPodTemplateSpec;
        }

        /**
         * ObjectMeta overrides for the pod used to solve HTTP01 challenges. Only the 'labels' and 'annotations' fields may be set. If labels or annotations overlap with in-built values, the values here will override the in-built values.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateMetadata {
            /**
             * Annotations that should be added to the create ACME HTTP01 solver pods.
             */
            annotations?: {[key: string]: string};
            /**
             * Labels that should be added to the created ACME HTTP01 solver pods.
             */
            labels?: {[key: string]: string};
        }

        /**
         * PodSpec defines overrides for the HTTP01 challenge solver pod. Only the 'priorityClassName', 'nodeSelector', 'affinity', 'serviceAccountName' and 'tolerations' fields are supported currently. All other fields will be ignored.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpec {
            /**
             * If specified, the pod's scheduling constraints
             */
            affinity?: outputs.acme.v1alpha3.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinity;
            /**
             * NodeSelector is a selector which must be true for the pod to fit on a node. Selector which must match a node's labels for the pod to be scheduled on that node. More info: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/
             */
            nodeSelector?: {[key: string]: string};
            /**
             * If specified, the pod's priorityClassName.
             */
            priorityClassName?: string;
            /**
             * If specified, the pod's service account
             */
            serviceAccountName?: string;
            /**
             * If specified, the pod's tolerations.
             */
            tolerations?: outputs.acme.v1alpha3.ChallengeSpecSolverHttp01IngressPodTemplateSpecTolerations[];
        }

        /**
         * If specified, the pod's scheduling constraints
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinity {
            /**
             * Describes node affinity scheduling rules for the pod.
             */
            nodeAffinity?: outputs.acme.v1alpha3.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityNodeAffinity;
            /**
             * Describes pod affinity scheduling rules (e.g. co-locate this pod in the same node, zone, etc. as some other pod(s)).
             */
            podAffinity?: outputs.acme.v1alpha3.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAffinity;
            /**
             * Describes pod anti-affinity scheduling rules (e.g. avoid putting this pod in the same node, zone, etc. as some other pod(s)).
             */
            podAntiAffinity?: outputs.acme.v1alpha3.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAntiAffinity;
        }

        /**
         * Describes node affinity scheduling rules for the pod.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityNodeAffinity {
            /**
             * The scheduler will prefer to schedule pods to nodes that satisfy the affinity expressions specified by this field, but it may choose a node that violates one or more of the expressions. The node that is most preferred is the one with the greatest sum of weights, i.e. for each node that meets all of the scheduling requirements (resource request, requiredDuringScheduling affinity expressions, etc.), compute a sum by iterating through the elements of this field and adding "weight" to the sum if the node matches the corresponding matchExpressions; the node(s) with the highest sum are the most preferred.
             */
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.acme.v1alpha3.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            /**
             * If the affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to an update), the system may or may not try to eventually evict the pod from its node.
             */
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.acme.v1alpha3.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution;
        }

        /**
         * An empty preferred scheduling term matches all objects with implicit weight 0 (i.e. it's a no-op). A null preferred scheduling term matches no objects (i.e. is also a no-op).
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            /**
             * A node selector term, associated with the corresponding weight.
             */
            preference: outputs.acme.v1alpha3.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference;
            /**
             * Weight associated with matching the corresponding nodeSelectorTerm, in the range 1-100.
             */
            weight: number;
        }

        /**
         * A node selector term, associated with the corresponding weight.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference {
            /**
             * A list of node selector requirements by node's labels.
             */
            matchExpressions?: outputs.acme.v1alpha3.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions[];
            /**
             * A list of node selector requirements by node's fields.
             */
            matchFields?: outputs.acme.v1alpha3.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields[];
        }

        /**
         * A node selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions {
            /**
             * The label key that the selector applies to.
             */
            key: string;
            /**
             * Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
             */
            operator: string;
            /**
             * An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * A node selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields {
            /**
             * The label key that the selector applies to.
             */
            key: string;
            /**
             * Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
             */
            operator: string;
            /**
             * An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * If the affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to an update), the system may or may not try to eventually evict the pod from its node.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            /**
             * Required. A list of node selector terms. The terms are ORed.
             */
            nodeSelectorTerms: outputs.acme.v1alpha3.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms[];
        }

        /**
         * A null or empty node selector term matches no objects. The requirements of them are ANDed. The TopologySelectorTerm type implements a subset of the NodeSelectorTerm.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms {
            /**
             * A list of node selector requirements by node's labels.
             */
            matchExpressions?: outputs.acme.v1alpha3.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions[];
            /**
             * A list of node selector requirements by node's fields.
             */
            matchFields?: outputs.acme.v1alpha3.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields[];
        }

        /**
         * A node selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions {
            /**
             * The label key that the selector applies to.
             */
            key: string;
            /**
             * Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
             */
            operator: string;
            /**
             * An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * A node selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields {
            /**
             * The label key that the selector applies to.
             */
            key: string;
            /**
             * Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
             */
            operator: string;
            /**
             * An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Describes pod affinity scheduling rules (e.g. co-locate this pod in the same node, zone, etc. as some other pod(s)).
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAffinity {
            /**
             * The scheduler will prefer to schedule pods to nodes that satisfy the affinity expressions specified by this field, but it may choose a node that violates one or more of the expressions. The node that is most preferred is the one with the greatest sum of weights, i.e. for each node that meets all of the scheduling requirements (resource request, requiredDuringScheduling affinity expressions, etc.), compute a sum by iterating through the elements of this field and adding "weight" to the sum if the node has pods which matches the corresponding podAffinityTerm; the node(s) with the highest sum are the most preferred.
             */
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.acme.v1alpha3.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            /**
             * If the affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to a pod label update), the system may or may not try to eventually evict the pod from its node. When there are multiple elements, the lists of nodes corresponding to each podAffinityTerm are intersected, i.e. all terms must be satisfied.
             */
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.acme.v1alpha3.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        /**
         * The weights of all of the matched WeightedPodAffinityTerm fields are added per-node to find the most preferred node(s)
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            /**
             * Required. A pod affinity term, associated with the corresponding weight.
             */
            podAffinityTerm: outputs.acme.v1alpha3.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            /**
             * weight associated with matching the corresponding podAffinityTerm, in the range 1-100.
             */
            weight: number;
        }

        /**
         * Required. A pod affinity term, associated with the corresponding weight.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            /**
             * A label query over a set of resources, in this case pods.
             */
            labelSelector?: outputs.acme.v1alpha3.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            /**
             * namespaces specifies which namespaces the labelSelector applies to (matches against); null or empty list means "this pod's namespace"
             */
            namespaces?: string[];
            /**
             * This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed.
             */
            topologyKey: string;
        }

        /**
         * A label query over a set of resources, in this case pods.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.acme.v1alpha3.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Defines a set of pods (namely those matching the labelSelector relative to the given namespace(s)) that this pod should be co-located (affinity) or not co-located (anti-affinity) with, where co-located is defined as running on a node whose value of the label with key <topologyKey> matches that of any node on which a pod of the set of pods is running
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            /**
             * A label query over a set of resources, in this case pods.
             */
            labelSelector?: outputs.acme.v1alpha3.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            /**
             * namespaces specifies which namespaces the labelSelector applies to (matches against); null or empty list means "this pod's namespace"
             */
            namespaces?: string[];
            /**
             * This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed.
             */
            topologyKey: string;
        }

        /**
         * A label query over a set of resources, in this case pods.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.acme.v1alpha3.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Describes pod anti-affinity scheduling rules (e.g. avoid putting this pod in the same node, zone, etc. as some other pod(s)).
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAntiAffinity {
            /**
             * The scheduler will prefer to schedule pods to nodes that satisfy the anti-affinity expressions specified by this field, but it may choose a node that violates one or more of the expressions. The node that is most preferred is the one with the greatest sum of weights, i.e. for each node that meets all of the scheduling requirements (resource request, requiredDuringScheduling anti-affinity expressions, etc.), compute a sum by iterating through the elements of this field and adding "weight" to the sum if the node has pods which matches the corresponding podAffinityTerm; the node(s) with the highest sum are the most preferred.
             */
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.acme.v1alpha3.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            /**
             * If the anti-affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the anti-affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to a pod label update), the system may or may not try to eventually evict the pod from its node. When there are multiple elements, the lists of nodes corresponding to each podAffinityTerm are intersected, i.e. all terms must be satisfied.
             */
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.acme.v1alpha3.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        /**
         * The weights of all of the matched WeightedPodAffinityTerm fields are added per-node to find the most preferred node(s)
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            /**
             * Required. A pod affinity term, associated with the corresponding weight.
             */
            podAffinityTerm: outputs.acme.v1alpha3.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            /**
             * weight associated with matching the corresponding podAffinityTerm, in the range 1-100.
             */
            weight: number;
        }

        /**
         * Required. A pod affinity term, associated with the corresponding weight.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            /**
             * A label query over a set of resources, in this case pods.
             */
            labelSelector?: outputs.acme.v1alpha3.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            /**
             * namespaces specifies which namespaces the labelSelector applies to (matches against); null or empty list means "this pod's namespace"
             */
            namespaces?: string[];
            /**
             * This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed.
             */
            topologyKey: string;
        }

        /**
         * A label query over a set of resources, in this case pods.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.acme.v1alpha3.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Defines a set of pods (namely those matching the labelSelector relative to the given namespace(s)) that this pod should be co-located (affinity) or not co-located (anti-affinity) with, where co-located is defined as running on a node whose value of the label with key <topologyKey> matches that of any node on which a pod of the set of pods is running
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            /**
             * A label query over a set of resources, in this case pods.
             */
            labelSelector?: outputs.acme.v1alpha3.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            /**
             * namespaces specifies which namespaces the labelSelector applies to (matches against); null or empty list means "this pod's namespace"
             */
            namespaces?: string[];
            /**
             * This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed.
             */
            topologyKey: string;
        }

        /**
         * A label query over a set of resources, in this case pods.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.acme.v1alpha3.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * The pod this Toleration is attached to tolerates any taint that matches the triple <key,value,effect> using the matching operator <operator>.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecTolerations {
            /**
             * Effect indicates the taint effect to match. Empty means match all taint effects. When specified, allowed values are NoSchedule, PreferNoSchedule and NoExecute.
             */
            effect?: string;
            /**
             * Key is the taint key that the toleration applies to. Empty means match all taint keys. If the key is empty, operator must be Exists; this combination means to match all values and all keys.
             */
            key?: string;
            /**
             * Operator represents a key's relationship to the value. Valid operators are Exists and Equal. Defaults to Equal. Exists is equivalent to wildcard for value, so that a pod can tolerate all taints of a particular category.
             */
            operator?: string;
            /**
             * TolerationSeconds represents the period of time the toleration (which must be of effect NoExecute, otherwise this field is ignored) tolerates the taint. By default, it is not set, which means tolerate the taint forever (do not evict). Zero and negative values will be treated as 0 (evict immediately) by the system.
             */
            tolerationSeconds?: number;
            /**
             * Value is the taint value the toleration matches to. If the operator is Exists, the value should be empty, otherwise just a regular string.
             */
            value?: string;
        }

        /**
         * Selector selects a set of DNSNames on the Certificate resource that should be solved using this challenge solver. If not specified, the solver will be treated as the 'default' solver with the lowest priority, i.e. if any other solver has a more specific match, it will be used instead.
         */
        export interface ChallengeSpecSolverSelector {
            /**
             * List of DNSNames that this solver will be used to solve. If specified and a match is found, a dnsNames selector will take precedence over a dnsZones selector. If multiple solvers match with the same dnsNames value, the solver with the most matching labels in matchLabels will be selected. If neither has more matches, the solver defined earlier in the list will be selected.
             */
            dnsNames?: string[];
            /**
             * List of DNSZones that this solver will be used to solve. The most specific DNS zone match specified here will take precedence over other DNS zone matches, so a solver specifying sys.example.com will be selected over one specifying example.com for the domain www.sys.example.com. If multiple solvers match with the same dnsZones value, the solver with the most matching labels in matchLabels will be selected. If neither has more matches, the solver defined earlier in the list will be selected.
             */
            dnsZones?: string[];
            /**
             * A label selector that is used to refine the set of certificate's that this challenge solver will apply to.
             */
            matchLabels?: {[key: string]: string};
        }

        export interface ChallengeStatus {
            /**
             * Presented will be set to true if the challenge values for this challenge are currently 'presented'. This *does not* imply the self check is passing. Only that the values have been 'submitted' for the appropriate challenge mechanism (i.e. the DNS01 TXT record has been presented, or the HTTP01 configuration has been configured).
             */
            presented?: boolean;
            /**
             * Processing is used to denote whether this challenge should be processed or not. This field will only be set to true by the 'scheduling' component. It will only be set to false by the 'challenges' controller, after the challenge has reached a final state or timed out. If this field is set to false, the challenge controller will not take any more action.
             */
            processing?: boolean;
            /**
             * Reason contains human readable information on why the Challenge is in the current state.
             */
            reason?: string;
            /**
             * State contains the current 'state' of the challenge. If not set, the state of the challenge is unknown.
             */
            state?: string;
        }

        export interface OrderSpec {
            /**
             * CommonName is the common name as specified on the DER encoded CSR. If specified, this value must also be present in `dnsNames` or `ipAddresses`. This field must match the corresponding field on the DER encoded CSR.
             */
            commonName?: string;
            /**
             * Certificate signing request bytes in DER encoding. This will be used when finalizing the order. This field must be set on the order.
             */
            csr: string;
            /**
             * DNSNames is a list of DNS names that should be included as part of the Order validation process. This field must match the corresponding field on the DER encoded CSR.
             */
            dnsNames?: string[];
            /**
             * Duration is the duration for the not after date for the requested certificate. this is set on order creation as pe the ACME spec.
             */
            duration?: string;
            /**
             * IPAddresses is a list of IP addresses that should be included as part of the Order validation process. This field must match the corresponding field on the DER encoded CSR.
             */
            ipAddresses?: string[];
            /**
             * IssuerRef references a properly configured ACME-type Issuer which should be used to create this Order. If the Issuer does not exist, processing will be retried. If the Issuer is not an 'ACME' Issuer, an error will be returned and the Order will be marked as failed.
             */
            issuerRef: outputs.acme.v1alpha3.OrderSpecIssuerRef;
        }

        /**
         * IssuerRef references a properly configured ACME-type Issuer which should be used to create this Order. If the Issuer does not exist, processing will be retried. If the Issuer is not an 'ACME' Issuer, an error will be returned and the Order will be marked as failed.
         */
        export interface OrderSpecIssuerRef {
            /**
             * Group of the resource being referred to.
             */
            group?: string;
            /**
             * Kind of the resource being referred to.
             */
            kind?: string;
            /**
             * Name of the resource being referred to.
             */
            name: string;
        }

        export interface OrderStatus {
            /**
             * Authorizations contains data returned from the ACME server on what authorizations must be completed in order to validate the DNS names specified on the Order.
             */
            authorizations?: outputs.acme.v1alpha3.OrderStatusAuthorizations[];
            /**
             * Certificate is a copy of the PEM encoded certificate for this Order. This field will be populated after the order has been successfully finalized with the ACME server, and the order has transitioned to the 'valid' state.
             */
            certificate?: string;
            /**
             * FailureTime stores the time that this order failed. This is used to influence garbage collection and back-off.
             */
            failureTime?: string;
            /**
             * FinalizeURL of the Order. This is used to obtain certificates for this order once it has been completed.
             */
            finalizeURL?: string;
            /**
             * Reason optionally provides more information about a why the order is in the current state.
             */
            reason?: string;
            /**
             * State contains the current state of this Order resource. States 'success' and 'expired' are 'final'
             */
            state?: string;
            /**
             * URL of the Order. This will initially be empty when the resource is first created. The Order controller will populate this field when the Order is first processed. This field will be immutable after it is initially set.
             */
            url?: string;
        }

        /**
         * ACMEAuthorization contains data returned from the ACME server on an authorization that must be completed in order validate a DNS name on an ACME Order resource.
         */
        export interface OrderStatusAuthorizations {
            /**
             * Challenges specifies the challenge types offered by the ACME server. One of these challenge types will be selected when validating the DNS name and an appropriate Challenge resource will be created to perform the ACME challenge process.
             */
            challenges?: outputs.acme.v1alpha3.OrderStatusAuthorizationsChallenges[];
            /**
             * Identifier is the DNS name to be validated as part of this authorization
             */
            identifier?: string;
            /**
             * InitialState is the initial state of the ACME authorization when first fetched from the ACME server. If an Authorization is already 'valid', the Order controller will not create a Challenge resource for the authorization. This will occur when working with an ACME server that enables 'authz reuse' (such as Let's Encrypt's production endpoint). If not set and 'identifier' is set, the state is assumed to be pending and a Challenge will be created.
             */
            initialState?: string;
            /**
             * URL is the URL of the Authorization that must be completed
             */
            url: string;
            /**
             * Wildcard will be true if this authorization is for a wildcard DNS name. If this is true, the identifier will be the *non-wildcard* version of the DNS name. For example, if '*.example.com' is the DNS name being validated, this field will be 'true' and the 'identifier' field will be 'example.com'.
             */
            wildcard?: boolean;
        }

        /**
         * Challenge specifies a challenge offered by the ACME server for an Order. An appropriate Challenge resource can be created to perform the ACME challenge process.
         */
        export interface OrderStatusAuthorizationsChallenges {
            /**
             * Token is the token that must be presented for this challenge. This is used to compute the 'key' that must also be presented.
             */
            token: string;
            /**
             * Type is the type of challenge being offered, e.g. 'http-01', 'dns-01', 'tls-sni-01', etc. This is the raw value retrieved from the ACME server. Only 'http-01' and 'dns-01' are supported by cert-manager, other values will be ignored.
             */
            type: string;
            /**
             * URL is the URL of this challenge. It can be used to retrieve additional metadata about the Challenge from the ACME server.
             */
            url: string;
        }
    }

    export namespace v1beta1 {
        export interface ChallengeSpec {
            /**
             * The URL to the ACME Authorization resource that this challenge is a part of.
             */
            authorizationURL: string;
            /**
             * dnsName is the identifier that this challenge is for, e.g. example.com. If the requested DNSName is a 'wildcard', this field MUST be set to the non-wildcard domain, e.g. for `*.example.com`, it must be `example.com`.
             */
            dnsName: string;
            /**
             * References a properly configured ACME-type Issuer which should be used to create this Challenge. If the Issuer does not exist, processing will be retried. If the Issuer is not an 'ACME' Issuer, an error will be returned and the Challenge will be marked as failed.
             */
            issuerRef: outputs.acme.v1beta1.ChallengeSpecIssuerRef;
            /**
             * The ACME challenge key for this challenge For HTTP01 challenges, this is the value that must be responded with to complete the HTTP01 challenge in the format: `<private key JWK thumbprint>.<key from acme server for challenge>`. For DNS01 challenges, this is the base64 encoded SHA256 sum of the `<private key JWK thumbprint>.<key from acme server for challenge>` text that must be set as the TXT record content.
             */
            key: string;
            /**
             * Contains the domain solving configuration that should be used to solve this challenge resource.
             */
            solver: outputs.acme.v1beta1.ChallengeSpecSolver;
            /**
             * The ACME challenge token for this challenge. This is the raw value returned from the ACME server.
             */
            token: string;
            /**
             * The type of ACME challenge this resource represents. One of "HTTP-01" or "DNS-01".
             */
            type: string;
            /**
             * The URL of the ACME Challenge resource for this challenge. This can be used to lookup details about the status of this challenge.
             */
            url: string;
            /**
             * wildcard will be true if this challenge is for a wildcard identifier, for example '*.example.com'.
             */
            wildcard?: boolean;
        }

        /**
         * References a properly configured ACME-type Issuer which should be used to create this Challenge. If the Issuer does not exist, processing will be retried. If the Issuer is not an 'ACME' Issuer, an error will be returned and the Challenge will be marked as failed.
         */
        export interface ChallengeSpecIssuerRef {
            /**
             * Group of the resource being referred to.
             */
            group?: string;
            /**
             * Kind of the resource being referred to.
             */
            kind?: string;
            /**
             * Name of the resource being referred to.
             */
            name: string;
        }

        /**
         * Contains the domain solving configuration that should be used to solve this challenge resource.
         */
        export interface ChallengeSpecSolver {
            /**
             * Configures cert-manager to attempt to complete authorizations by performing the DNS01 challenge flow.
             */
            dns01?: outputs.acme.v1beta1.ChallengeSpecSolverDns01;
            /**
             * Configures cert-manager to attempt to complete authorizations by performing the HTTP01 challenge flow. It is not possible to obtain certificates for wildcard domain names (e.g. `*.example.com`) using the HTTP01 challenge mechanism.
             */
            http01?: outputs.acme.v1beta1.ChallengeSpecSolverHttp01;
            /**
             * Selector selects a set of DNSNames on the Certificate resource that should be solved using this challenge solver. If not specified, the solver will be treated as the 'default' solver with the lowest priority, i.e. if any other solver has a more specific match, it will be used instead.
             */
            selector?: outputs.acme.v1beta1.ChallengeSpecSolverSelector;
        }

        /**
         * Configures cert-manager to attempt to complete authorizations by performing the DNS01 challenge flow.
         */
        export interface ChallengeSpecSolverDns01 {
            /**
             * Use the 'ACME DNS' (https://github.com/joohoi/acme-dns) API to manage DNS01 challenge records.
             */
            acmeDNS?: outputs.acme.v1beta1.ChallengeSpecSolverDns01AcmeDNS;
            /**
             * Use the Akamai DNS zone management API to manage DNS01 challenge records.
             */
            akamai?: outputs.acme.v1beta1.ChallengeSpecSolverDns01Akamai;
            /**
             * Use the Microsoft Azure DNS API to manage DNS01 challenge records.
             */
            azureDNS?: outputs.acme.v1beta1.ChallengeSpecSolverDns01AzureDNS;
            /**
             * Use the Google Cloud DNS API to manage DNS01 challenge records.
             */
            cloudDNS?: outputs.acme.v1beta1.ChallengeSpecSolverDns01CloudDNS;
            /**
             * Use the Cloudflare API to manage DNS01 challenge records.
             */
            cloudflare?: outputs.acme.v1beta1.ChallengeSpecSolverDns01Cloudflare;
            /**
             * CNAMEStrategy configures how the DNS01 provider should handle CNAME records when found in DNS zones.
             */
            cnameStrategy?: string;
            /**
             * Use the DigitalOcean DNS API to manage DNS01 challenge records.
             */
            digitalocean?: outputs.acme.v1beta1.ChallengeSpecSolverDns01Digitalocean;
            /**
             * Use RFC2136 ("Dynamic Updates in the Domain Name System") (https://datatracker.ietf.org/doc/rfc2136/) to manage DNS01 challenge records.
             */
            rfc2136?: outputs.acme.v1beta1.ChallengeSpecSolverDns01Rfc2136;
            /**
             * Use the AWS Route53 API to manage DNS01 challenge records.
             */
            route53?: outputs.acme.v1beta1.ChallengeSpecSolverDns01Route53;
            /**
             * Configure an external webhook based DNS01 challenge solver to manage DNS01 challenge records.
             */
            webhook?: outputs.acme.v1beta1.ChallengeSpecSolverDns01Webhook;
        }

        /**
         * Use the 'ACME DNS' (https://github.com/joohoi/acme-dns) API to manage DNS01 challenge records.
         */
        export interface ChallengeSpecSolverDns01AcmeDNS {
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            accountSecretRef: outputs.acme.v1beta1.ChallengeSpecSolverDns01AcmeDNSAccountSecretRef;
            host: string;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface ChallengeSpecSolverDns01AcmeDNSAccountSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the Akamai DNS zone management API to manage DNS01 challenge records.
         */
        export interface ChallengeSpecSolverDns01Akamai {
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            accessTokenSecretRef: outputs.acme.v1beta1.ChallengeSpecSolverDns01AkamaiAccessTokenSecretRef;
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            clientSecretSecretRef: outputs.acme.v1beta1.ChallengeSpecSolverDns01AkamaiClientSecretSecretRef;
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            clientTokenSecretRef: outputs.acme.v1beta1.ChallengeSpecSolverDns01AkamaiClientTokenSecretRef;
            serviceConsumerDomain: string;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface ChallengeSpecSolverDns01AkamaiAccessTokenSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface ChallengeSpecSolverDns01AkamaiClientSecretSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface ChallengeSpecSolverDns01AkamaiClientTokenSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the Microsoft Azure DNS API to manage DNS01 challenge records.
         */
        export interface ChallengeSpecSolverDns01AzureDNS {
            /**
             * if both this and ClientSecret are left unset MSI will be used
             */
            clientID?: string;
            /**
             * if both this and ClientID are left unset MSI will be used
             */
            clientSecretSecretRef?: outputs.acme.v1beta1.ChallengeSpecSolverDns01AzureDNSClientSecretSecretRef;
            environment?: string;
            hostedZoneName?: string;
            resourceGroupName: string;
            subscriptionID: string;
            /**
             * when specifying ClientID and ClientSecret then this field is also needed
             */
            tenantID?: string;
        }

        /**
         * if both this and ClientID are left unset MSI will be used
         */
        export interface ChallengeSpecSolverDns01AzureDNSClientSecretSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the Google Cloud DNS API to manage DNS01 challenge records.
         */
        export interface ChallengeSpecSolverDns01CloudDNS {
            /**
             * HostedZoneName is an optional field that tells cert-manager in which Cloud DNS zone the challenge record has to be created. If left empty cert-manager will automatically choose a zone.
             */
            hostedZoneName?: string;
            project: string;
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            serviceAccountSecretRef?: outputs.acme.v1beta1.ChallengeSpecSolverDns01CloudDNSServiceAccountSecretRef;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface ChallengeSpecSolverDns01CloudDNSServiceAccountSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the Cloudflare API to manage DNS01 challenge records.
         */
        export interface ChallengeSpecSolverDns01Cloudflare {
            /**
             * API key to use to authenticate with Cloudflare. Note: using an API token to authenticate is now the recommended method as it allows greater control of permissions.
             */
            apiKeySecretRef?: outputs.acme.v1beta1.ChallengeSpecSolverDns01CloudflareApiKeySecretRef;
            /**
             * API token used to authenticate with Cloudflare.
             */
            apiTokenSecretRef?: outputs.acme.v1beta1.ChallengeSpecSolverDns01CloudflareApiTokenSecretRef;
            /**
             * Email of the account, only required when using API key based authentication.
             */
            email?: string;
        }

        /**
         * API key to use to authenticate with Cloudflare. Note: using an API token to authenticate is now the recommended method as it allows greater control of permissions.
         */
        export interface ChallengeSpecSolverDns01CloudflareApiKeySecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * API token used to authenticate with Cloudflare.
         */
        export interface ChallengeSpecSolverDns01CloudflareApiTokenSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the DigitalOcean DNS API to manage DNS01 challenge records.
         */
        export interface ChallengeSpecSolverDns01Digitalocean {
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            tokenSecretRef: outputs.acme.v1beta1.ChallengeSpecSolverDns01DigitaloceanTokenSecretRef;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface ChallengeSpecSolverDns01DigitaloceanTokenSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use RFC2136 ("Dynamic Updates in the Domain Name System") (https://datatracker.ietf.org/doc/rfc2136/) to manage DNS01 challenge records.
         */
        export interface ChallengeSpecSolverDns01Rfc2136 {
            /**
             * The IP address or hostname of an authoritative DNS server supporting RFC2136 in the form host:port. If the host is an IPv6 address it must be enclosed in square brackets (e.g [2001:db8::1]) ; port is optional. This field is required.
             */
            nameserver: string;
            /**
             * The TSIG Algorithm configured in the DNS supporting RFC2136. Used only when ``tsigSecretSecretRef`` and ``tsigKeyName`` are defined. Supported values are (case-insensitive): ``HMACMD5`` (default), ``HMACSHA1``, ``HMACSHA256`` or ``HMACSHA512``.
             */
            tsigAlgorithm?: string;
            /**
             * The TSIG Key name configured in the DNS. If ``tsigSecretSecretRef`` is defined, this field is required.
             */
            tsigKeyName?: string;
            /**
             * The name of the secret containing the TSIG value. If ``tsigKeyName`` is defined, this field is required.
             */
            tsigSecretSecretRef?: outputs.acme.v1beta1.ChallengeSpecSolverDns01Rfc2136TsigSecretSecretRef;
        }

        /**
         * The name of the secret containing the TSIG value. If ``tsigKeyName`` is defined, this field is required.
         */
        export interface ChallengeSpecSolverDns01Rfc2136TsigSecretSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the AWS Route53 API to manage DNS01 challenge records.
         */
        export interface ChallengeSpecSolverDns01Route53 {
            /**
             * The AccessKeyID is used for authentication. If not set we fall-back to using env vars, shared credentials file or AWS Instance metadata see: https://docs.aws.amazon.com/sdk-for-go/v1/developer-guide/configuring-sdk.html#specifying-credentials
             */
            accessKeyID?: string;
            /**
             * If set, the provider will manage only this zone in Route53 and will not do an lookup using the route53:ListHostedZonesByName api call.
             */
            hostedZoneID?: string;
            /**
             * Always set the region when using AccessKeyID and SecretAccessKey
             */
            region: string;
            /**
             * Role is a Role ARN which the Route53 provider will assume using either the explicit credentials AccessKeyID/SecretAccessKey or the inferred credentials from environment variables, shared credentials file or AWS Instance metadata
             */
            role?: string;
            /**
             * The SecretAccessKey is used for authentication. If not set we fall-back to using env vars, shared credentials file or AWS Instance metadata https://docs.aws.amazon.com/sdk-for-go/v1/developer-guide/configuring-sdk.html#specifying-credentials
             */
            secretAccessKeySecretRef?: outputs.acme.v1beta1.ChallengeSpecSolverDns01Route53SecretAccessKeySecretRef;
        }

        /**
         * The SecretAccessKey is used for authentication. If not set we fall-back to using env vars, shared credentials file or AWS Instance metadata https://docs.aws.amazon.com/sdk-for-go/v1/developer-guide/configuring-sdk.html#specifying-credentials
         */
        export interface ChallengeSpecSolverDns01Route53SecretAccessKeySecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Configure an external webhook based DNS01 challenge solver to manage DNS01 challenge records.
         */
        export interface ChallengeSpecSolverDns01Webhook {
            /**
             * Additional configuration that should be passed to the webhook apiserver when challenges are processed. This can contain arbitrary JSON data. Secret values should not be specified in this stanza. If secret values are needed (e.g. credentials for a DNS service), you should use a SecretKeySelector to reference a Secret resource. For details on the schema of this field, consult the webhook provider implementation's documentation.
             */
            config?: {[key: string]: any};
            /**
             * The API group name that should be used when POSTing ChallengePayload resources to the webhook apiserver. This should be the same as the GroupName specified in the webhook provider implementation.
             */
            groupName: string;
            /**
             * The name of the solver to use, as defined in the webhook provider implementation. This will typically be the name of the provider, e.g. 'cloudflare'.
             */
            solverName: string;
        }

        /**
         * Configures cert-manager to attempt to complete authorizations by performing the HTTP01 challenge flow. It is not possible to obtain certificates for wildcard domain names (e.g. `*.example.com`) using the HTTP01 challenge mechanism.
         */
        export interface ChallengeSpecSolverHttp01 {
            /**
             * The ingress based HTTP01 challenge solver will solve challenges by creating or modifying Ingress resources in order to route requests for '/.well-known/acme-challenge/XYZ' to 'challenge solver' pods that are provisioned by cert-manager for each Challenge to be completed.
             */
            ingress?: outputs.acme.v1beta1.ChallengeSpecSolverHttp01Ingress;
        }

        /**
         * The ingress based HTTP01 challenge solver will solve challenges by creating or modifying Ingress resources in order to route requests for '/.well-known/acme-challenge/XYZ' to 'challenge solver' pods that are provisioned by cert-manager for each Challenge to be completed.
         */
        export interface ChallengeSpecSolverHttp01Ingress {
            /**
             * The ingress class to use when creating Ingress resources to solve ACME challenges that use this challenge solver. Only one of 'class' or 'name' may be specified.
             */
            class?: string;
            /**
             * Optional ingress template used to configure the ACME challenge solver ingress used for HTTP01 challenges
             */
            ingressTemplate?: outputs.acme.v1beta1.ChallengeSpecSolverHttp01IngressIngressTemplate;
            /**
             * The name of the ingress resource that should have ACME challenge solving routes inserted into it in order to solve HTTP01 challenges. This is typically used in conjunction with ingress controllers like ingress-gce, which maintains a 1:1 mapping between external IPs and ingress resources.
             */
            name?: string;
            /**
             * Optional pod template used to configure the ACME challenge solver pods used for HTTP01 challenges
             */
            podTemplate?: outputs.acme.v1beta1.ChallengeSpecSolverHttp01IngressPodTemplate;
            /**
             * Optional service type for Kubernetes solver service
             */
            serviceType?: string;
        }

        /**
         * Optional ingress template used to configure the ACME challenge solver ingress used for HTTP01 challenges
         */
        export interface ChallengeSpecSolverHttp01IngressIngressTemplate {
            /**
             * ObjectMeta overrides for the ingress used to solve HTTP01 challenges. Only the 'labels' and 'annotations' fields may be set. If labels or annotations overlap with in-built values, the values here will override the in-built values.
             */
            metadata?: outputs.acme.v1beta1.ChallengeSpecSolverHttp01IngressIngressTemplateMetadata;
        }

        /**
         * ObjectMeta overrides for the ingress used to solve HTTP01 challenges. Only the 'labels' and 'annotations' fields may be set. If labels or annotations overlap with in-built values, the values here will override the in-built values.
         */
        export interface ChallengeSpecSolverHttp01IngressIngressTemplateMetadata {
            /**
             * Annotations that should be added to the created ACME HTTP01 solver ingress.
             */
            annotations?: {[key: string]: string};
            /**
             * Labels that should be added to the created ACME HTTP01 solver ingress.
             */
            labels?: {[key: string]: string};
        }

        /**
         * Optional pod template used to configure the ACME challenge solver pods used for HTTP01 challenges
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplate {
            /**
             * ObjectMeta overrides for the pod used to solve HTTP01 challenges. Only the 'labels' and 'annotations' fields may be set. If labels or annotations overlap with in-built values, the values here will override the in-built values.
             */
            metadata?: outputs.acme.v1beta1.ChallengeSpecSolverHttp01IngressPodTemplateMetadata;
            /**
             * PodSpec defines overrides for the HTTP01 challenge solver pod. Only the 'priorityClassName', 'nodeSelector', 'affinity', 'serviceAccountName' and 'tolerations' fields are supported currently. All other fields will be ignored.
             */
            spec?: outputs.acme.v1beta1.ChallengeSpecSolverHttp01IngressPodTemplateSpec;
        }

        /**
         * ObjectMeta overrides for the pod used to solve HTTP01 challenges. Only the 'labels' and 'annotations' fields may be set. If labels or annotations overlap with in-built values, the values here will override the in-built values.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateMetadata {
            /**
             * Annotations that should be added to the create ACME HTTP01 solver pods.
             */
            annotations?: {[key: string]: string};
            /**
             * Labels that should be added to the created ACME HTTP01 solver pods.
             */
            labels?: {[key: string]: string};
        }

        /**
         * PodSpec defines overrides for the HTTP01 challenge solver pod. Only the 'priorityClassName', 'nodeSelector', 'affinity', 'serviceAccountName' and 'tolerations' fields are supported currently. All other fields will be ignored.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpec {
            /**
             * If specified, the pod's scheduling constraints
             */
            affinity?: outputs.acme.v1beta1.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinity;
            /**
             * NodeSelector is a selector which must be true for the pod to fit on a node. Selector which must match a node's labels for the pod to be scheduled on that node. More info: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/
             */
            nodeSelector?: {[key: string]: string};
            /**
             * If specified, the pod's priorityClassName.
             */
            priorityClassName?: string;
            /**
             * If specified, the pod's service account
             */
            serviceAccountName?: string;
            /**
             * If specified, the pod's tolerations.
             */
            tolerations?: outputs.acme.v1beta1.ChallengeSpecSolverHttp01IngressPodTemplateSpecTolerations[];
        }

        /**
         * If specified, the pod's scheduling constraints
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinity {
            /**
             * Describes node affinity scheduling rules for the pod.
             */
            nodeAffinity?: outputs.acme.v1beta1.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityNodeAffinity;
            /**
             * Describes pod affinity scheduling rules (e.g. co-locate this pod in the same node, zone, etc. as some other pod(s)).
             */
            podAffinity?: outputs.acme.v1beta1.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAffinity;
            /**
             * Describes pod anti-affinity scheduling rules (e.g. avoid putting this pod in the same node, zone, etc. as some other pod(s)).
             */
            podAntiAffinity?: outputs.acme.v1beta1.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAntiAffinity;
        }

        /**
         * Describes node affinity scheduling rules for the pod.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityNodeAffinity {
            /**
             * The scheduler will prefer to schedule pods to nodes that satisfy the affinity expressions specified by this field, but it may choose a node that violates one or more of the expressions. The node that is most preferred is the one with the greatest sum of weights, i.e. for each node that meets all of the scheduling requirements (resource request, requiredDuringScheduling affinity expressions, etc.), compute a sum by iterating through the elements of this field and adding "weight" to the sum if the node matches the corresponding matchExpressions; the node(s) with the highest sum are the most preferred.
             */
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.acme.v1beta1.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            /**
             * If the affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to an update), the system may or may not try to eventually evict the pod from its node.
             */
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.acme.v1beta1.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution;
        }

        /**
         * An empty preferred scheduling term matches all objects with implicit weight 0 (i.e. it's a no-op). A null preferred scheduling term matches no objects (i.e. is also a no-op).
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            /**
             * A node selector term, associated with the corresponding weight.
             */
            preference: outputs.acme.v1beta1.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference;
            /**
             * Weight associated with matching the corresponding nodeSelectorTerm, in the range 1-100.
             */
            weight: number;
        }

        /**
         * A node selector term, associated with the corresponding weight.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference {
            /**
             * A list of node selector requirements by node's labels.
             */
            matchExpressions?: outputs.acme.v1beta1.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions[];
            /**
             * A list of node selector requirements by node's fields.
             */
            matchFields?: outputs.acme.v1beta1.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields[];
        }

        /**
         * A node selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions {
            /**
             * The label key that the selector applies to.
             */
            key: string;
            /**
             * Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
             */
            operator: string;
            /**
             * An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * A node selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields {
            /**
             * The label key that the selector applies to.
             */
            key: string;
            /**
             * Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
             */
            operator: string;
            /**
             * An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * If the affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to an update), the system may or may not try to eventually evict the pod from its node.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            /**
             * Required. A list of node selector terms. The terms are ORed.
             */
            nodeSelectorTerms: outputs.acme.v1beta1.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms[];
        }

        /**
         * A null or empty node selector term matches no objects. The requirements of them are ANDed. The TopologySelectorTerm type implements a subset of the NodeSelectorTerm.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms {
            /**
             * A list of node selector requirements by node's labels.
             */
            matchExpressions?: outputs.acme.v1beta1.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions[];
            /**
             * A list of node selector requirements by node's fields.
             */
            matchFields?: outputs.acme.v1beta1.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields[];
        }

        /**
         * A node selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions {
            /**
             * The label key that the selector applies to.
             */
            key: string;
            /**
             * Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
             */
            operator: string;
            /**
             * An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * A node selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields {
            /**
             * The label key that the selector applies to.
             */
            key: string;
            /**
             * Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
             */
            operator: string;
            /**
             * An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Describes pod affinity scheduling rules (e.g. co-locate this pod in the same node, zone, etc. as some other pod(s)).
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAffinity {
            /**
             * The scheduler will prefer to schedule pods to nodes that satisfy the affinity expressions specified by this field, but it may choose a node that violates one or more of the expressions. The node that is most preferred is the one with the greatest sum of weights, i.e. for each node that meets all of the scheduling requirements (resource request, requiredDuringScheduling affinity expressions, etc.), compute a sum by iterating through the elements of this field and adding "weight" to the sum if the node has pods which matches the corresponding podAffinityTerm; the node(s) with the highest sum are the most preferred.
             */
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.acme.v1beta1.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            /**
             * If the affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to a pod label update), the system may or may not try to eventually evict the pod from its node. When there are multiple elements, the lists of nodes corresponding to each podAffinityTerm are intersected, i.e. all terms must be satisfied.
             */
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.acme.v1beta1.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        /**
         * The weights of all of the matched WeightedPodAffinityTerm fields are added per-node to find the most preferred node(s)
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            /**
             * Required. A pod affinity term, associated with the corresponding weight.
             */
            podAffinityTerm: outputs.acme.v1beta1.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            /**
             * weight associated with matching the corresponding podAffinityTerm, in the range 1-100.
             */
            weight: number;
        }

        /**
         * Required. A pod affinity term, associated with the corresponding weight.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            /**
             * A label query over a set of resources, in this case pods.
             */
            labelSelector?: outputs.acme.v1beta1.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            /**
             * namespaces specifies which namespaces the labelSelector applies to (matches against); null or empty list means "this pod's namespace"
             */
            namespaces?: string[];
            /**
             * This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed.
             */
            topologyKey: string;
        }

        /**
         * A label query over a set of resources, in this case pods.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.acme.v1beta1.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Defines a set of pods (namely those matching the labelSelector relative to the given namespace(s)) that this pod should be co-located (affinity) or not co-located (anti-affinity) with, where co-located is defined as running on a node whose value of the label with key <topologyKey> matches that of any node on which a pod of the set of pods is running
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            /**
             * A label query over a set of resources, in this case pods.
             */
            labelSelector?: outputs.acme.v1beta1.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            /**
             * namespaces specifies which namespaces the labelSelector applies to (matches against); null or empty list means "this pod's namespace"
             */
            namespaces?: string[];
            /**
             * This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed.
             */
            topologyKey: string;
        }

        /**
         * A label query over a set of resources, in this case pods.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.acme.v1beta1.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Describes pod anti-affinity scheduling rules (e.g. avoid putting this pod in the same node, zone, etc. as some other pod(s)).
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAntiAffinity {
            /**
             * The scheduler will prefer to schedule pods to nodes that satisfy the anti-affinity expressions specified by this field, but it may choose a node that violates one or more of the expressions. The node that is most preferred is the one with the greatest sum of weights, i.e. for each node that meets all of the scheduling requirements (resource request, requiredDuringScheduling anti-affinity expressions, etc.), compute a sum by iterating through the elements of this field and adding "weight" to the sum if the node has pods which matches the corresponding podAffinityTerm; the node(s) with the highest sum are the most preferred.
             */
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.acme.v1beta1.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            /**
             * If the anti-affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the anti-affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to a pod label update), the system may or may not try to eventually evict the pod from its node. When there are multiple elements, the lists of nodes corresponding to each podAffinityTerm are intersected, i.e. all terms must be satisfied.
             */
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.acme.v1beta1.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        /**
         * The weights of all of the matched WeightedPodAffinityTerm fields are added per-node to find the most preferred node(s)
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            /**
             * Required. A pod affinity term, associated with the corresponding weight.
             */
            podAffinityTerm: outputs.acme.v1beta1.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            /**
             * weight associated with matching the corresponding podAffinityTerm, in the range 1-100.
             */
            weight: number;
        }

        /**
         * Required. A pod affinity term, associated with the corresponding weight.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            /**
             * A label query over a set of resources, in this case pods.
             */
            labelSelector?: outputs.acme.v1beta1.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            /**
             * namespaces specifies which namespaces the labelSelector applies to (matches against); null or empty list means "this pod's namespace"
             */
            namespaces?: string[];
            /**
             * This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed.
             */
            topologyKey: string;
        }

        /**
         * A label query over a set of resources, in this case pods.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.acme.v1beta1.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Defines a set of pods (namely those matching the labelSelector relative to the given namespace(s)) that this pod should be co-located (affinity) or not co-located (anti-affinity) with, where co-located is defined as running on a node whose value of the label with key <topologyKey> matches that of any node on which a pod of the set of pods is running
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            /**
             * A label query over a set of resources, in this case pods.
             */
            labelSelector?: outputs.acme.v1beta1.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            /**
             * namespaces specifies which namespaces the labelSelector applies to (matches against); null or empty list means "this pod's namespace"
             */
            namespaces?: string[];
            /**
             * This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed.
             */
            topologyKey: string;
        }

        /**
         * A label query over a set of resources, in this case pods.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.acme.v1beta1.ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * The pod this Toleration is attached to tolerates any taint that matches the triple <key,value,effect> using the matching operator <operator>.
         */
        export interface ChallengeSpecSolverHttp01IngressPodTemplateSpecTolerations {
            /**
             * Effect indicates the taint effect to match. Empty means match all taint effects. When specified, allowed values are NoSchedule, PreferNoSchedule and NoExecute.
             */
            effect?: string;
            /**
             * Key is the taint key that the toleration applies to. Empty means match all taint keys. If the key is empty, operator must be Exists; this combination means to match all values and all keys.
             */
            key?: string;
            /**
             * Operator represents a key's relationship to the value. Valid operators are Exists and Equal. Defaults to Equal. Exists is equivalent to wildcard for value, so that a pod can tolerate all taints of a particular category.
             */
            operator?: string;
            /**
             * TolerationSeconds represents the period of time the toleration (which must be of effect NoExecute, otherwise this field is ignored) tolerates the taint. By default, it is not set, which means tolerate the taint forever (do not evict). Zero and negative values will be treated as 0 (evict immediately) by the system.
             */
            tolerationSeconds?: number;
            /**
             * Value is the taint value the toleration matches to. If the operator is Exists, the value should be empty, otherwise just a regular string.
             */
            value?: string;
        }

        /**
         * Selector selects a set of DNSNames on the Certificate resource that should be solved using this challenge solver. If not specified, the solver will be treated as the 'default' solver with the lowest priority, i.e. if any other solver has a more specific match, it will be used instead.
         */
        export interface ChallengeSpecSolverSelector {
            /**
             * List of DNSNames that this solver will be used to solve. If specified and a match is found, a dnsNames selector will take precedence over a dnsZones selector. If multiple solvers match with the same dnsNames value, the solver with the most matching labels in matchLabels will be selected. If neither has more matches, the solver defined earlier in the list will be selected.
             */
            dnsNames?: string[];
            /**
             * List of DNSZones that this solver will be used to solve. The most specific DNS zone match specified here will take precedence over other DNS zone matches, so a solver specifying sys.example.com will be selected over one specifying example.com for the domain www.sys.example.com. If multiple solvers match with the same dnsZones value, the solver with the most matching labels in matchLabels will be selected. If neither has more matches, the solver defined earlier in the list will be selected.
             */
            dnsZones?: string[];
            /**
             * A label selector that is used to refine the set of certificate's that this challenge solver will apply to.
             */
            matchLabels?: {[key: string]: string};
        }

        export interface ChallengeStatus {
            /**
             * presented will be set to true if the challenge values for this challenge are currently 'presented'. This *does not* imply the self check is passing. Only that the values have been 'submitted' for the appropriate challenge mechanism (i.e. the DNS01 TXT record has been presented, or the HTTP01 configuration has been configured).
             */
            presented?: boolean;
            /**
             * Used to denote whether this challenge should be processed or not. This field will only be set to true by the 'scheduling' component. It will only be set to false by the 'challenges' controller, after the challenge has reached a final state or timed out. If this field is set to false, the challenge controller will not take any more action.
             */
            processing?: boolean;
            /**
             * Contains human readable information on why the Challenge is in the current state.
             */
            reason?: string;
            /**
             * Contains the current 'state' of the challenge. If not set, the state of the challenge is unknown.
             */
            state?: string;
        }

        export interface OrderSpec {
            /**
             * CommonName is the common name as specified on the DER encoded CSR. If specified, this value must also be present in `dnsNames` or `ipAddresses`. This field must match the corresponding field on the DER encoded CSR.
             */
            commonName?: string;
            /**
             * DNSNames is a list of DNS names that should be included as part of the Order validation process. This field must match the corresponding field on the DER encoded CSR.
             */
            dnsNames?: string[];
            /**
             * Duration is the duration for the not after date for the requested certificate. this is set on order creation as pe the ACME spec.
             */
            duration?: string;
            /**
             * IPAddresses is a list of IP addresses that should be included as part of the Order validation process. This field must match the corresponding field on the DER encoded CSR.
             */
            ipAddresses?: string[];
            /**
             * IssuerRef references a properly configured ACME-type Issuer which should be used to create this Order. If the Issuer does not exist, processing will be retried. If the Issuer is not an 'ACME' Issuer, an error will be returned and the Order will be marked as failed.
             */
            issuerRef: outputs.acme.v1beta1.OrderSpecIssuerRef;
            /**
             * Certificate signing request bytes in DER encoding. This will be used when finalizing the order. This field must be set on the order.
             */
            request: string;
        }

        /**
         * IssuerRef references a properly configured ACME-type Issuer which should be used to create this Order. If the Issuer does not exist, processing will be retried. If the Issuer is not an 'ACME' Issuer, an error will be returned and the Order will be marked as failed.
         */
        export interface OrderSpecIssuerRef {
            /**
             * Group of the resource being referred to.
             */
            group?: string;
            /**
             * Kind of the resource being referred to.
             */
            kind?: string;
            /**
             * Name of the resource being referred to.
             */
            name: string;
        }

        export interface OrderStatus {
            /**
             * Authorizations contains data returned from the ACME server on what authorizations must be completed in order to validate the DNS names specified on the Order.
             */
            authorizations?: outputs.acme.v1beta1.OrderStatusAuthorizations[];
            /**
             * Certificate is a copy of the PEM encoded certificate for this Order. This field will be populated after the order has been successfully finalized with the ACME server, and the order has transitioned to the 'valid' state.
             */
            certificate?: string;
            /**
             * FailureTime stores the time that this order failed. This is used to influence garbage collection and back-off.
             */
            failureTime?: string;
            /**
             * FinalizeURL of the Order. This is used to obtain certificates for this order once it has been completed.
             */
            finalizeURL?: string;
            /**
             * Reason optionally provides more information about a why the order is in the current state.
             */
            reason?: string;
            /**
             * State contains the current state of this Order resource. States 'success' and 'expired' are 'final'
             */
            state?: string;
            /**
             * URL of the Order. This will initially be empty when the resource is first created. The Order controller will populate this field when the Order is first processed. This field will be immutable after it is initially set.
             */
            url?: string;
        }

        /**
         * ACMEAuthorization contains data returned from the ACME server on an authorization that must be completed in order validate a DNS name on an ACME Order resource.
         */
        export interface OrderStatusAuthorizations {
            /**
             * Challenges specifies the challenge types offered by the ACME server. One of these challenge types will be selected when validating the DNS name and an appropriate Challenge resource will be created to perform the ACME challenge process.
             */
            challenges?: outputs.acme.v1beta1.OrderStatusAuthorizationsChallenges[];
            /**
             * Identifier is the DNS name to be validated as part of this authorization
             */
            identifier?: string;
            /**
             * InitialState is the initial state of the ACME authorization when first fetched from the ACME server. If an Authorization is already 'valid', the Order controller will not create a Challenge resource for the authorization. This will occur when working with an ACME server that enables 'authz reuse' (such as Let's Encrypt's production endpoint). If not set and 'identifier' is set, the state is assumed to be pending and a Challenge will be created.
             */
            initialState?: string;
            /**
             * URL is the URL of the Authorization that must be completed
             */
            url: string;
            /**
             * Wildcard will be true if this authorization is for a wildcard DNS name. If this is true, the identifier will be the *non-wildcard* version of the DNS name. For example, if '*.example.com' is the DNS name being validated, this field will be 'true' and the 'identifier' field will be 'example.com'.
             */
            wildcard?: boolean;
        }

        /**
         * Challenge specifies a challenge offered by the ACME server for an Order. An appropriate Challenge resource can be created to perform the ACME challenge process.
         */
        export interface OrderStatusAuthorizationsChallenges {
            /**
             * Token is the token that must be presented for this challenge. This is used to compute the 'key' that must also be presented.
             */
            token: string;
            /**
             * Type is the type of challenge being offered, e.g. 'http-01', 'dns-01', 'tls-sni-01', etc. This is the raw value retrieved from the ACME server. Only 'http-01' and 'dns-01' are supported by cert-manager, other values will be ignored.
             */
            type: string;
            /**
             * URL is the URL of this challenge. It can be used to retrieve additional metadata about the Challenge from the ACME server.
             */
            url: string;
        }
    }
}

export namespace certmanager {
    export namespace v1 {
        /**
         * Desired state of the CertificateRequest resource.
         */
        export interface CertificateRequestSpec {
            /**
             * The requested 'duration' (i.e. lifetime) of the Certificate. This option may be ignored/overridden by some issuer types.
             */
            duration?: string;
            /**
             * IsCA will request to mark the certificate as valid for certificate signing when submitting to the issuer. This will automatically add the `cert sign` usage to the list of `usages`.
             */
            isCA?: boolean;
            /**
             * IssuerRef is a reference to the issuer for this CertificateRequest.  If the 'kind' field is not set, or set to 'Issuer', an Issuer resource with the given name in the same namespace as the CertificateRequest will be used.  If the 'kind' field is set to 'ClusterIssuer', a ClusterIssuer with the provided name will be used. The 'name' field in this stanza is required at all times. The group field refers to the API group of the issuer which defaults to 'cert-manager.io' if empty.
             */
            issuerRef: outputs.certmanager.v1.CertificateRequestSpecIssuerRef;
            /**
             * The PEM-encoded x509 certificate signing request to be submitted to the CA for signing.
             */
            request: string;
            /**
             * Usages is the set of x509 usages that are requested for the certificate. If usages are set they SHOULD be encoded inside the CSR spec Defaults to `digital signature` and `key encipherment` if not specified.
             */
            usages?: string[];
        }

        /**
         * IssuerRef is a reference to the issuer for this CertificateRequest.  If the 'kind' field is not set, or set to 'Issuer', an Issuer resource with the given name in the same namespace as the CertificateRequest will be used.  If the 'kind' field is set to 'ClusterIssuer', a ClusterIssuer with the provided name will be used. The 'name' field in this stanza is required at all times. The group field refers to the API group of the issuer which defaults to 'cert-manager.io' if empty.
         */
        export interface CertificateRequestSpecIssuerRef {
            /**
             * Group of the resource being referred to.
             */
            group?: string;
            /**
             * Kind of the resource being referred to.
             */
            kind?: string;
            /**
             * Name of the resource being referred to.
             */
            name: string;
        }

        /**
         * Status of the CertificateRequest. This is set and managed automatically.
         */
        export interface CertificateRequestStatus {
            /**
             * The PEM encoded x509 certificate of the signer, also known as the CA (Certificate Authority). This is set on a best-effort basis by different issuers. If not set, the CA is assumed to be unknown/not available.
             */
            ca?: string;
            /**
             * The PEM encoded x509 certificate resulting from the certificate signing request. If not set, the CertificateRequest has either not been completed or has failed. More information on failure can be found by checking the `conditions` field.
             */
            certificate?: string;
            /**
             * List of status conditions to indicate the status of a CertificateRequest. Known condition types are `Ready` and `InvalidRequest`.
             */
            conditions?: outputs.certmanager.v1.CertificateRequestStatusConditions[];
            /**
             * FailureTime stores the time that this CertificateRequest failed. This is used to influence garbage collection and back-off.
             */
            failureTime?: string;
        }

        /**
         * CertificateRequestCondition contains condition information for a CertificateRequest.
         */
        export interface CertificateRequestStatusConditions {
            /**
             * LastTransitionTime is the timestamp corresponding to the last status change of this condition.
             */
            lastTransitionTime?: string;
            /**
             * Message is a human readable description of the details of the last transition, complementing reason.
             */
            message?: string;
            /**
             * Reason is a brief machine readable explanation for the condition's last transition.
             */
            reason?: string;
            /**
             * Status of the condition, one of ('True', 'False', 'Unknown').
             */
            status: string;
            /**
             * Type of the condition, known values are ('Ready', 'InvalidRequest').
             */
            type: string;
        }

        /**
         * Desired state of the Certificate resource.
         */
        export interface CertificateSpec {
            /**
             * CommonName is a common name to be used on the Certificate. The CommonName should have a length of 64 characters or fewer to avoid generating invalid CSRs. This value is ignored by TLS clients when any subject alt name is set. This is x509 behaviour: https://tools.ietf.org/html/rfc6125#section-6.4.4
             */
            commonName?: string;
            /**
             * DNSNames is a list of DNS subjectAltNames to be set on the Certificate.
             */
            dnsNames?: string[];
            /**
             * The requested 'duration' (i.e. lifetime) of the Certificate. This option may be ignored/overridden by some issuer types. If overridden and `renewBefore` is greater than the actual certificate duration, the certificate will be automatically renewed 2/3rds of the way through the certificate's duration.
             */
            duration?: string;
            /**
             * EmailAddresses is a list of email subjectAltNames to be set on the Certificate.
             */
            emailAddresses?: string[];
            /**
             * EncodeUsagesInRequest controls whether key usages should be present in the CertificateRequest
             */
            encodeUsagesInRequest?: boolean;
            /**
             * IPAddresses is a list of IP address subjectAltNames to be set on the Certificate.
             */
            ipAddresses?: string[];
            /**
             * IsCA will mark this Certificate as valid for certificate signing. This will automatically add the `cert sign` usage to the list of `usages`.
             */
            isCA?: boolean;
            /**
             * IssuerRef is a reference to the issuer for this certificate. If the 'kind' field is not set, or set to 'Issuer', an Issuer resource with the given name in the same namespace as the Certificate will be used. If the 'kind' field is set to 'ClusterIssuer', a ClusterIssuer with the provided name will be used. The 'name' field in this stanza is required at all times.
             */
            issuerRef: outputs.certmanager.v1.CertificateSpecIssuerRef;
            /**
             * Keystores configures additional keystore output formats stored in the `secretName` Secret resource.
             */
            keystores?: outputs.certmanager.v1.CertificateSpecKeystores;
            /**
             * Options to control private keys used for the Certificate.
             */
            privateKey?: outputs.certmanager.v1.CertificateSpecPrivateKey;
            /**
             * The amount of time before the currently issued certificate's `notAfter` time that cert-manager will begin to attempt to renew the certificate. If this value is greater than the total duration of the certificate (i.e. notAfter - notBefore), it will be automatically renewed 2/3rds of the way through the certificate's duration.
             */
            renewBefore?: string;
            /**
             * SecretName is the name of the secret resource that will be automatically created and managed by this Certificate resource. It will be populated with a private key and certificate, signed by the denoted issuer.
             */
            secretName: string;
            /**
             * Full X509 name specification (https://golang.org/pkg/crypto/x509/pkix/#Name).
             */
            subject?: outputs.certmanager.v1.CertificateSpecSubject;
            /**
             * URIs is a list of URI subjectAltNames to be set on the Certificate.
             */
            uris?: string[];
            /**
             * Usages is the set of x509 usages that are requested for the certificate. Defaults to `digital signature` and `key encipherment` if not specified.
             */
            usages?: string[];
        }

        /**
         * IssuerRef is a reference to the issuer for this certificate. If the 'kind' field is not set, or set to 'Issuer', an Issuer resource with the given name in the same namespace as the Certificate will be used. If the 'kind' field is set to 'ClusterIssuer', a ClusterIssuer with the provided name will be used. The 'name' field in this stanza is required at all times.
         */
        export interface CertificateSpecIssuerRef {
            /**
             * Group of the resource being referred to.
             */
            group?: string;
            /**
             * Kind of the resource being referred to.
             */
            kind?: string;
            /**
             * Name of the resource being referred to.
             */
            name: string;
        }

        /**
         * Keystores configures additional keystore output formats stored in the `secretName` Secret resource.
         */
        export interface CertificateSpecKeystores {
            /**
             * JKS configures options for storing a JKS keystore in the `spec.secretName` Secret resource.
             */
            jks?: outputs.certmanager.v1.CertificateSpecKeystoresJks;
            /**
             * PKCS12 configures options for storing a PKCS12 keystore in the `spec.secretName` Secret resource.
             */
            pkcs12?: outputs.certmanager.v1.CertificateSpecKeystoresPkcs12;
        }

        /**
         * JKS configures options for storing a JKS keystore in the `spec.secretName` Secret resource.
         */
        export interface CertificateSpecKeystoresJks {
            /**
             * Create enables JKS keystore creation for the Certificate. If true, a file named `keystore.jks` will be created in the target Secret resource, encrypted using the password stored in `passwordSecretRef`. The keystore file will only be updated upon re-issuance.
             */
            create: boolean;
            /**
             * PasswordSecretRef is a reference to a key in a Secret resource containing the password used to encrypt the JKS keystore.
             */
            passwordSecretRef: outputs.certmanager.v1.CertificateSpecKeystoresJksPasswordSecretRef;
        }

        /**
         * PasswordSecretRef is a reference to a key in a Secret resource containing the password used to encrypt the JKS keystore.
         */
        export interface CertificateSpecKeystoresJksPasswordSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * PKCS12 configures options for storing a PKCS12 keystore in the `spec.secretName` Secret resource.
         */
        export interface CertificateSpecKeystoresPkcs12 {
            /**
             * Create enables PKCS12 keystore creation for the Certificate. If true, a file named `keystore.p12` will be created in the target Secret resource, encrypted using the password stored in `passwordSecretRef`. The keystore file will only be updated upon re-issuance.
             */
            create: boolean;
            /**
             * PasswordSecretRef is a reference to a key in a Secret resource containing the password used to encrypt the PKCS12 keystore.
             */
            passwordSecretRef: outputs.certmanager.v1.CertificateSpecKeystoresPkcs12PasswordSecretRef;
        }

        /**
         * PasswordSecretRef is a reference to a key in a Secret resource containing the password used to encrypt the PKCS12 keystore.
         */
        export interface CertificateSpecKeystoresPkcs12PasswordSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Options to control private keys used for the Certificate.
         */
        export interface CertificateSpecPrivateKey {
            /**
             * Algorithm is the private key algorithm of the corresponding private key for this certificate. If provided, allowed values are either "rsa" or "ecdsa" If `algorithm` is specified and `size` is not provided, key size of 256 will be used for "ecdsa" key algorithm and key size of 2048 will be used for "rsa" key algorithm.
             */
            algorithm?: string;
            /**
             * The private key cryptography standards (PKCS) encoding for this certificate's private key to be encoded in. If provided, allowed values are "pkcs1" and "pkcs8" standing for PKCS#1 and PKCS#8, respectively. Defaults to PKCS#1 if not specified.
             */
            encoding?: string;
            /**
             * RotationPolicy controls how private keys should be regenerated when a re-issuance is being processed. If set to Never, a private key will only be generated if one does not already exist in the target `spec.secretName`. If one does exists but it does not have the correct algorithm or size, a warning will be raised to await user intervention. If set to Always, a private key matching the specified requirements will be generated whenever a re-issuance occurs. Default is 'Never' for backward compatibility.
             */
            rotationPolicy?: string;
            /**
             * Size is the key bit size of the corresponding private key for this certificate. If `algorithm` is set to `RSA`, valid values are `2048`, `4096` or `8192`, and will default to `2048` if not specified. If `algorithm` is set to `ECDSA`, valid values are `256`, `384` or `521`, and will default to `256` if not specified. No other values are allowed.
             */
            size?: number;
        }

        /**
         * Full X509 name specification (https://golang.org/pkg/crypto/x509/pkix/#Name).
         */
        export interface CertificateSpecSubject {
            /**
             * Countries to be used on the Certificate.
             */
            countries?: string[];
            /**
             * Cities to be used on the Certificate.
             */
            localities?: string[];
            /**
             * Organizational Units to be used on the Certificate.
             */
            organizationalUnits?: string[];
            /**
             * Organizations to be used on the Certificate.
             */
            organizations?: string[];
            /**
             * Postal codes to be used on the Certificate.
             */
            postalCodes?: string[];
            /**
             * State/Provinces to be used on the Certificate.
             */
            provinces?: string[];
            /**
             * Serial number to be used on the Certificate.
             */
            serialNumber?: string;
            /**
             * Street addresses to be used on the Certificate.
             */
            streetAddresses?: string[];
        }

        /**
         * Status of the Certificate. This is set and managed automatically.
         */
        export interface CertificateStatus {
            /**
             * List of status conditions to indicate the status of certificates. Known condition types are `Ready` and `Issuing`.
             */
            conditions?: outputs.certmanager.v1.CertificateStatusConditions[];
            /**
             * LastFailureTime is the time as recorded by the Certificate controller of the most recent failure to complete a CertificateRequest for this Certificate resource. If set, cert-manager will not re-request another Certificate until 1 hour has elapsed from this time.
             */
            lastFailureTime?: string;
            /**
             * The name of the Secret resource containing the private key to be used for the next certificate iteration. The keymanager controller will automatically set this field if the `Issuing` condition is set to `True`. It will automatically unset this field when the Issuing condition is not set or False.
             */
            nextPrivateKeySecretName?: string;
            /**
             * The expiration time of the certificate stored in the secret named by this resource in `spec.secretName`.
             */
            notAfter?: string;
            /**
             * The time after which the certificate stored in the secret named by this resource in spec.secretName is valid.
             */
            notBefore?: string;
            /**
             * RenewalTime is the time at which the certificate will be next renewed. If not set, no upcoming renewal is scheduled.
             */
            renewalTime?: string;
            /**
             * The current 'revision' of the certificate as issued. 
             *  When a CertificateRequest resource is created, it will have the `cert-manager.io/certificate-revision` set to one greater than the current value of this field. 
             *  Upon issuance, this field will be set to the value of the annotation on the CertificateRequest resource used to issue the certificate. 
             *  Persisting the value on the CertificateRequest resource allows the certificates controller to know whether a request is part of an old issuance or if it is part of the ongoing revision's issuance by checking if the revision value in the annotation is greater than this field.
             */
            revision?: number;
        }

        /**
         * CertificateCondition contains condition information for an Certificate.
         */
        export interface CertificateStatusConditions {
            /**
             * LastTransitionTime is the timestamp corresponding to the last status change of this condition.
             */
            lastTransitionTime?: string;
            /**
             * Message is a human readable description of the details of the last transition, complementing reason.
             */
            message?: string;
            /**
             * Reason is a brief machine readable explanation for the condition's last transition.
             */
            reason?: string;
            /**
             * Status of the condition, one of ('True', 'False', 'Unknown').
             */
            status: string;
            /**
             * Type of the condition, known values are ('Ready', `Issuing`).
             */
            type: string;
        }

        /**
         * Desired state of the ClusterIssuer resource.
         */
        export interface ClusterIssuerSpec {
            /**
             * ACME configures this issuer to communicate with a RFC8555 (ACME) server to obtain signed x509 certificates.
             */
            acme?: outputs.certmanager.v1.ClusterIssuerSpecAcme;
            /**
             * CA configures this issuer to sign certificates using a signing CA keypair stored in a Secret resource. This is used to build internal PKIs that are managed by cert-manager.
             */
            ca?: outputs.certmanager.v1.ClusterIssuerSpecCa;
            /**
             * SelfSigned configures this issuer to 'self sign' certificates using the private key used to create the CertificateRequest object.
             */
            selfSigned?: outputs.certmanager.v1.ClusterIssuerSpecSelfSigned;
            /**
             * Vault configures this issuer to sign certificates using a HashiCorp Vault PKI backend.
             */
            vault?: outputs.certmanager.v1.ClusterIssuerSpecVault;
            /**
             * Venafi configures this issuer to sign certificates using a Venafi TPP or Venafi Cloud policy zone.
             */
            venafi?: outputs.certmanager.v1.ClusterIssuerSpecVenafi;
        }

        /**
         * ACME configures this issuer to communicate with a RFC8555 (ACME) server to obtain signed x509 certificates.
         */
        export interface ClusterIssuerSpecAcme {
            /**
             * Enables or disables generating a new ACME account key. If true, the Issuer resource will *not* request a new account but will expect the account key to be supplied via an existing secret. If false, the cert-manager system will generate a new ACME account key for the Issuer. Defaults to false.
             */
            disableAccountKeyGeneration?: boolean;
            /**
             * Email is the email address to be associated with the ACME account. This field is optional, but it is strongly recommended to be set. It will be used to contact you in case of issues with your account or certificates, including expiry notification emails. This field may be updated after the account is initially registered.
             */
            email?: string;
            /**
             * Enables requesting a Not After date on certificates that matches the duration of the certificate. This is not supported by all ACME servers like Let's Encrypt. If set to true when the ACME server does not support it it will create an error on the Order. Defaults to false.
             */
            enableDurationFeature?: boolean;
            /**
             * ExternalAccountBinding is a reference to a CA external account of the ACME server. If set, upon registration cert-manager will attempt to associate the given external account credentials with the registered ACME account.
             */
            externalAccountBinding?: outputs.certmanager.v1.ClusterIssuerSpecAcmeExternalAccountBinding;
            /**
             * PreferredChain is the chain to use if the ACME server outputs multiple. PreferredChain is no guarantee that this one gets delivered by the ACME endpoint. For example, for Let's Encrypt's DST crosssign you would use: "DST Root CA X3" or "ISRG Root X1" for the newer Let's Encrypt root CA. This value picks the first certificate bundle in the ACME alternative chains that has a certificate with this value as its issuer's CN
             */
            preferredChain?: string;
            /**
             * PrivateKey is the name of a Kubernetes Secret resource that will be used to store the automatically generated ACME account private key. Optionally, a `key` may be specified to select a specific entry within the named Secret resource. If `key` is not specified, a default of `tls.key` will be used.
             */
            privateKeySecretRef: outputs.certmanager.v1.ClusterIssuerSpecAcmePrivateKeySecretRef;
            /**
             * Server is the URL used to access the ACME server's 'directory' endpoint. For example, for Let's Encrypt's staging endpoint, you would use: "https://acme-staging-v02.api.letsencrypt.org/directory". Only ACME v2 endpoints (i.e. RFC 8555) are supported.
             */
            server: string;
            /**
             * Enables or disables validation of the ACME server TLS certificate. If true, requests to the ACME server will not have their TLS certificate validated (i.e. insecure connections will be allowed). Only enable this option in development environments. The cert-manager system installed roots will be used to verify connections to the ACME server if this is false. Defaults to false.
             */
            skipTLSVerify?: boolean;
            /**
             * Solvers is a list of challenge solvers that will be used to solve ACME challenges for the matching domains. Solver configurations must be provided in order to obtain certificates from an ACME server. For more information, see: https://cert-manager.io/docs/configuration/acme/
             */
            solvers?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolvers[];
        }

        /**
         * ExternalAccountBinding is a reference to a CA external account of the ACME server. If set, upon registration cert-manager will attempt to associate the given external account credentials with the registered ACME account.
         */
        export interface ClusterIssuerSpecAcmeExternalAccountBinding {
            /**
             * keyAlgorithm is the MAC key algorithm that the key is used for. Valid values are "HS256", "HS384" and "HS512".
             */
            keyAlgorithm: string;
            /**
             * keyID is the ID of the CA key that the External Account is bound to.
             */
            keyID: string;
            /**
             * keySecretRef is a Secret Key Selector referencing a data item in a Kubernetes Secret which holds the symmetric MAC key of the External Account Binding. The `key` is the index string that is paired with the key data in the Secret and should not be confused with the key data itself, or indeed with the External Account Binding keyID above. The secret key stored in the Secret **must** be un-padded, base64 URL encoded data.
             */
            keySecretRef: outputs.certmanager.v1.ClusterIssuerSpecAcmeExternalAccountBindingKeySecretRef;
        }

        /**
         * keySecretRef is a Secret Key Selector referencing a data item in a Kubernetes Secret which holds the symmetric MAC key of the External Account Binding. The `key` is the index string that is paired with the key data in the Secret and should not be confused with the key data itself, or indeed with the External Account Binding keyID above. The secret key stored in the Secret **must** be un-padded, base64 URL encoded data.
         */
        export interface ClusterIssuerSpecAcmeExternalAccountBindingKeySecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * PrivateKey is the name of a Kubernetes Secret resource that will be used to store the automatically generated ACME account private key. Optionally, a `key` may be specified to select a specific entry within the named Secret resource. If `key` is not specified, a default of `tls.key` will be used.
         */
        export interface ClusterIssuerSpecAcmePrivateKeySecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Configures an issuer to solve challenges using the specified options. Only one of HTTP01 or DNS01 may be provided.
         */
        export interface ClusterIssuerSpecAcmeSolvers {
            /**
             * Configures cert-manager to attempt to complete authorizations by performing the DNS01 challenge flow.
             */
            dns01?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversDns01;
            /**
             * Configures cert-manager to attempt to complete authorizations by performing the HTTP01 challenge flow. It is not possible to obtain certificates for wildcard domain names (e.g. `*.example.com`) using the HTTP01 challenge mechanism.
             */
            http01?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversHttp01;
            /**
             * Selector selects a set of DNSNames on the Certificate resource that should be solved using this challenge solver. If not specified, the solver will be treated as the 'default' solver with the lowest priority, i.e. if any other solver has a more specific match, it will be used instead.
             */
            selector?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversSelector;
        }

        /**
         * Configures cert-manager to attempt to complete authorizations by performing the DNS01 challenge flow.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01 {
            /**
             * Use the 'ACME DNS' (https://github.com/joohoi/acme-dns) API to manage DNS01 challenge records.
             */
            acmeDNS?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversDns01AcmeDNS;
            /**
             * Use the Akamai DNS zone management API to manage DNS01 challenge records.
             */
            akamai?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversDns01Akamai;
            /**
             * Use the Microsoft Azure DNS API to manage DNS01 challenge records.
             */
            azureDNS?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversDns01AzureDNS;
            /**
             * Use the Google Cloud DNS API to manage DNS01 challenge records.
             */
            cloudDNS?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversDns01CloudDNS;
            /**
             * Use the Cloudflare API to manage DNS01 challenge records.
             */
            cloudflare?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversDns01Cloudflare;
            /**
             * CNAMEStrategy configures how the DNS01 provider should handle CNAME records when found in DNS zones.
             */
            cnameStrategy?: string;
            /**
             * Use the DigitalOcean DNS API to manage DNS01 challenge records.
             */
            digitalocean?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversDns01Digitalocean;
            /**
             * Use RFC2136 ("Dynamic Updates in the Domain Name System") (https://datatracker.ietf.org/doc/rfc2136/) to manage DNS01 challenge records.
             */
            rfc2136?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversDns01Rfc2136;
            /**
             * Use the AWS Route53 API to manage DNS01 challenge records.
             */
            route53?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversDns01Route53;
            /**
             * Configure an external webhook based DNS01 challenge solver to manage DNS01 challenge records.
             */
            webhook?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversDns01Webhook;
        }

        /**
         * Use the 'ACME DNS' (https://github.com/joohoi/acme-dns) API to manage DNS01 challenge records.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01AcmeDNS {
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            accountSecretRef: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversDns01AcmeDNSAccountSecretRef;
            host: string;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01AcmeDNSAccountSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the Akamai DNS zone management API to manage DNS01 challenge records.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01Akamai {
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            accessTokenSecretRef: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversDns01AkamaiAccessTokenSecretRef;
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            clientSecretSecretRef: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversDns01AkamaiClientSecretSecretRef;
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            clientTokenSecretRef: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversDns01AkamaiClientTokenSecretRef;
            serviceConsumerDomain: string;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01AkamaiAccessTokenSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01AkamaiClientSecretSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01AkamaiClientTokenSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the Microsoft Azure DNS API to manage DNS01 challenge records.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01AzureDNS {
            /**
             * if both this and ClientSecret are left unset MSI will be used
             */
            clientID?: string;
            /**
             * if both this and ClientID are left unset MSI will be used
             */
            clientSecretSecretRef?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversDns01AzureDNSClientSecretSecretRef;
            environment?: string;
            hostedZoneName?: string;
            resourceGroupName: string;
            subscriptionID: string;
            /**
             * when specifying ClientID and ClientSecret then this field is also needed
             */
            tenantID?: string;
        }

        /**
         * if both this and ClientID are left unset MSI will be used
         */
        export interface ClusterIssuerSpecAcmeSolversDns01AzureDNSClientSecretSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the Google Cloud DNS API to manage DNS01 challenge records.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01CloudDNS {
            /**
             * HostedZoneName is an optional field that tells cert-manager in which Cloud DNS zone the challenge record has to be created. If left empty cert-manager will automatically choose a zone.
             */
            hostedZoneName?: string;
            project: string;
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            serviceAccountSecretRef?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversDns01CloudDNSServiceAccountSecretRef;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01CloudDNSServiceAccountSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the Cloudflare API to manage DNS01 challenge records.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01Cloudflare {
            /**
             * API key to use to authenticate with Cloudflare. Note: using an API token to authenticate is now the recommended method as it allows greater control of permissions.
             */
            apiKeySecretRef?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversDns01CloudflareApiKeySecretRef;
            /**
             * API token used to authenticate with Cloudflare.
             */
            apiTokenSecretRef?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversDns01CloudflareApiTokenSecretRef;
            /**
             * Email of the account, only required when using API key based authentication.
             */
            email?: string;
        }

        /**
         * API key to use to authenticate with Cloudflare. Note: using an API token to authenticate is now the recommended method as it allows greater control of permissions.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01CloudflareApiKeySecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * API token used to authenticate with Cloudflare.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01CloudflareApiTokenSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the DigitalOcean DNS API to manage DNS01 challenge records.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01Digitalocean {
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            tokenSecretRef: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversDns01DigitaloceanTokenSecretRef;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01DigitaloceanTokenSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use RFC2136 ("Dynamic Updates in the Domain Name System") (https://datatracker.ietf.org/doc/rfc2136/) to manage DNS01 challenge records.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01Rfc2136 {
            /**
             * The IP address or hostname of an authoritative DNS server supporting RFC2136 in the form host:port. If the host is an IPv6 address it must be enclosed in square brackets (e.g [2001:db8::1]) ; port is optional. This field is required.
             */
            nameserver: string;
            /**
             * The TSIG Algorithm configured in the DNS supporting RFC2136. Used only when ``tsigSecretSecretRef`` and ``tsigKeyName`` are defined. Supported values are (case-insensitive): ``HMACMD5`` (default), ``HMACSHA1``, ``HMACSHA256`` or ``HMACSHA512``.
             */
            tsigAlgorithm?: string;
            /**
             * The TSIG Key name configured in the DNS. If ``tsigSecretSecretRef`` is defined, this field is required.
             */
            tsigKeyName?: string;
            /**
             * The name of the secret containing the TSIG value. If ``tsigKeyName`` is defined, this field is required.
             */
            tsigSecretSecretRef?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversDns01Rfc2136TsigSecretSecretRef;
        }

        /**
         * The name of the secret containing the TSIG value. If ``tsigKeyName`` is defined, this field is required.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01Rfc2136TsigSecretSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the AWS Route53 API to manage DNS01 challenge records.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01Route53 {
            /**
             * The AccessKeyID is used for authentication. If not set we fall-back to using env vars, shared credentials file or AWS Instance metadata see: https://docs.aws.amazon.com/sdk-for-go/v1/developer-guide/configuring-sdk.html#specifying-credentials
             */
            accessKeyID?: string;
            /**
             * If set, the provider will manage only this zone in Route53 and will not do an lookup using the route53:ListHostedZonesByName api call.
             */
            hostedZoneID?: string;
            /**
             * Always set the region when using AccessKeyID and SecretAccessKey
             */
            region: string;
            /**
             * Role is a Role ARN which the Route53 provider will assume using either the explicit credentials AccessKeyID/SecretAccessKey or the inferred credentials from environment variables, shared credentials file or AWS Instance metadata
             */
            role?: string;
            /**
             * The SecretAccessKey is used for authentication. If not set we fall-back to using env vars, shared credentials file or AWS Instance metadata https://docs.aws.amazon.com/sdk-for-go/v1/developer-guide/configuring-sdk.html#specifying-credentials
             */
            secretAccessKeySecretRef?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversDns01Route53SecretAccessKeySecretRef;
        }

        /**
         * The SecretAccessKey is used for authentication. If not set we fall-back to using env vars, shared credentials file or AWS Instance metadata https://docs.aws.amazon.com/sdk-for-go/v1/developer-guide/configuring-sdk.html#specifying-credentials
         */
        export interface ClusterIssuerSpecAcmeSolversDns01Route53SecretAccessKeySecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Configure an external webhook based DNS01 challenge solver to manage DNS01 challenge records.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01Webhook {
            /**
             * Additional configuration that should be passed to the webhook apiserver when challenges are processed. This can contain arbitrary JSON data. Secret values should not be specified in this stanza. If secret values are needed (e.g. credentials for a DNS service), you should use a SecretKeySelector to reference a Secret resource. For details on the schema of this field, consult the webhook provider implementation's documentation.
             */
            config?: {[key: string]: any};
            /**
             * The API group name that should be used when POSTing ChallengePayload resources to the webhook apiserver. This should be the same as the GroupName specified in the webhook provider implementation.
             */
            groupName: string;
            /**
             * The name of the solver to use, as defined in the webhook provider implementation. This will typically be the name of the provider, e.g. 'cloudflare'.
             */
            solverName: string;
        }

        /**
         * Configures cert-manager to attempt to complete authorizations by performing the HTTP01 challenge flow. It is not possible to obtain certificates for wildcard domain names (e.g. `*.example.com`) using the HTTP01 challenge mechanism.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01 {
            /**
             * The ingress based HTTP01 challenge solver will solve challenges by creating or modifying Ingress resources in order to route requests for '/.well-known/acme-challenge/XYZ' to 'challenge solver' pods that are provisioned by cert-manager for each Challenge to be completed.
             */
            ingress?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversHttp01Ingress;
        }

        /**
         * The ingress based HTTP01 challenge solver will solve challenges by creating or modifying Ingress resources in order to route requests for '/.well-known/acme-challenge/XYZ' to 'challenge solver' pods that are provisioned by cert-manager for each Challenge to be completed.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01Ingress {
            /**
             * The ingress class to use when creating Ingress resources to solve ACME challenges that use this challenge solver. Only one of 'class' or 'name' may be specified.
             */
            class?: string;
            /**
             * Optional ingress template used to configure the ACME challenge solver ingress used for HTTP01 challenges
             */
            ingressTemplate?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversHttp01IngressIngressTemplate;
            /**
             * The name of the ingress resource that should have ACME challenge solving routes inserted into it in order to solve HTTP01 challenges. This is typically used in conjunction with ingress controllers like ingress-gce, which maintains a 1:1 mapping between external IPs and ingress resources.
             */
            name?: string;
            /**
             * Optional pod template used to configure the ACME challenge solver pods used for HTTP01 challenges
             */
            podTemplate?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplate;
            /**
             * Optional service type for Kubernetes solver service
             */
            serviceType?: string;
        }

        /**
         * Optional ingress template used to configure the ACME challenge solver ingress used for HTTP01 challenges
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressIngressTemplate {
            /**
             * ObjectMeta overrides for the ingress used to solve HTTP01 challenges. Only the 'labels' and 'annotations' fields may be set. If labels or annotations overlap with in-built values, the values here will override the in-built values.
             */
            metadata?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversHttp01IngressIngressTemplateMetadata;
        }

        /**
         * ObjectMeta overrides for the ingress used to solve HTTP01 challenges. Only the 'labels' and 'annotations' fields may be set. If labels or annotations overlap with in-built values, the values here will override the in-built values.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressIngressTemplateMetadata {
            /**
             * Annotations that should be added to the created ACME HTTP01 solver ingress.
             */
            annotations?: {[key: string]: string};
            /**
             * Labels that should be added to the created ACME HTTP01 solver ingress.
             */
            labels?: {[key: string]: string};
        }

        /**
         * Optional pod template used to configure the ACME challenge solver pods used for HTTP01 challenges
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplate {
            /**
             * ObjectMeta overrides for the pod used to solve HTTP01 challenges. Only the 'labels' and 'annotations' fields may be set. If labels or annotations overlap with in-built values, the values here will override the in-built values.
             */
            metadata?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateMetadata;
            /**
             * PodSpec defines overrides for the HTTP01 challenge solver pod. Only the 'priorityClassName', 'nodeSelector', 'affinity', 'serviceAccountName' and 'tolerations' fields are supported currently. All other fields will be ignored.
             */
            spec?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpec;
        }

        /**
         * ObjectMeta overrides for the pod used to solve HTTP01 challenges. Only the 'labels' and 'annotations' fields may be set. If labels or annotations overlap with in-built values, the values here will override the in-built values.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateMetadata {
            /**
             * Annotations that should be added to the create ACME HTTP01 solver pods.
             */
            annotations?: {[key: string]: string};
            /**
             * Labels that should be added to the created ACME HTTP01 solver pods.
             */
            labels?: {[key: string]: string};
        }

        /**
         * PodSpec defines overrides for the HTTP01 challenge solver pod. Only the 'priorityClassName', 'nodeSelector', 'affinity', 'serviceAccountName' and 'tolerations' fields are supported currently. All other fields will be ignored.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpec {
            /**
             * If specified, the pod's scheduling constraints
             */
            affinity?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinity;
            /**
             * NodeSelector is a selector which must be true for the pod to fit on a node. Selector which must match a node's labels for the pod to be scheduled on that node. More info: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/
             */
            nodeSelector?: {[key: string]: string};
            /**
             * If specified, the pod's priorityClassName.
             */
            priorityClassName?: string;
            /**
             * If specified, the pod's service account
             */
            serviceAccountName?: string;
            /**
             * If specified, the pod's tolerations.
             */
            tolerations?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecTolerations[];
        }

        /**
         * If specified, the pod's scheduling constraints
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinity {
            /**
             * Describes node affinity scheduling rules for the pod.
             */
            nodeAffinity?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinity;
            /**
             * Describes pod affinity scheduling rules (e.g. co-locate this pod in the same node, zone, etc. as some other pod(s)).
             */
            podAffinity?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinity;
            /**
             * Describes pod anti-affinity scheduling rules (e.g. avoid putting this pod in the same node, zone, etc. as some other pod(s)).
             */
            podAntiAffinity?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinity;
        }

        /**
         * Describes node affinity scheduling rules for the pod.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinity {
            /**
             * The scheduler will prefer to schedule pods to nodes that satisfy the affinity expressions specified by this field, but it may choose a node that violates one or more of the expressions. The node that is most preferred is the one with the greatest sum of weights, i.e. for each node that meets all of the scheduling requirements (resource request, requiredDuringScheduling affinity expressions, etc.), compute a sum by iterating through the elements of this field and adding "weight" to the sum if the node matches the corresponding matchExpressions; the node(s) with the highest sum are the most preferred.
             */
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            /**
             * If the affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to an update), the system may or may not try to eventually evict the pod from its node.
             */
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution;
        }

        /**
         * An empty preferred scheduling term matches all objects with implicit weight 0 (i.e. it's a no-op). A null preferred scheduling term matches no objects (i.e. is also a no-op).
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            /**
             * A node selector term, associated with the corresponding weight.
             */
            preference: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference;
            /**
             * Weight associated with matching the corresponding nodeSelectorTerm, in the range 1-100.
             */
            weight: number;
        }

        /**
         * A node selector term, associated with the corresponding weight.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference {
            /**
             * A list of node selector requirements by node's labels.
             */
            matchExpressions?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions[];
            /**
             * A list of node selector requirements by node's fields.
             */
            matchFields?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields[];
        }

        /**
         * A node selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions {
            /**
             * The label key that the selector applies to.
             */
            key: string;
            /**
             * Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
             */
            operator: string;
            /**
             * An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * A node selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields {
            /**
             * The label key that the selector applies to.
             */
            key: string;
            /**
             * Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
             */
            operator: string;
            /**
             * An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * If the affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to an update), the system may or may not try to eventually evict the pod from its node.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            /**
             * Required. A list of node selector terms. The terms are ORed.
             */
            nodeSelectorTerms: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms[];
        }

        /**
         * A null or empty node selector term matches no objects. The requirements of them are ANDed. The TopologySelectorTerm type implements a subset of the NodeSelectorTerm.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms {
            /**
             * A list of node selector requirements by node's labels.
             */
            matchExpressions?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions[];
            /**
             * A list of node selector requirements by node's fields.
             */
            matchFields?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields[];
        }

        /**
         * A node selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions {
            /**
             * The label key that the selector applies to.
             */
            key: string;
            /**
             * Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
             */
            operator: string;
            /**
             * An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * A node selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields {
            /**
             * The label key that the selector applies to.
             */
            key: string;
            /**
             * Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
             */
            operator: string;
            /**
             * An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Describes pod affinity scheduling rules (e.g. co-locate this pod in the same node, zone, etc. as some other pod(s)).
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinity {
            /**
             * The scheduler will prefer to schedule pods to nodes that satisfy the affinity expressions specified by this field, but it may choose a node that violates one or more of the expressions. The node that is most preferred is the one with the greatest sum of weights, i.e. for each node that meets all of the scheduling requirements (resource request, requiredDuringScheduling affinity expressions, etc.), compute a sum by iterating through the elements of this field and adding "weight" to the sum if the node has pods which matches the corresponding podAffinityTerm; the node(s) with the highest sum are the most preferred.
             */
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            /**
             * If the affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to a pod label update), the system may or may not try to eventually evict the pod from its node. When there are multiple elements, the lists of nodes corresponding to each podAffinityTerm are intersected, i.e. all terms must be satisfied.
             */
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        /**
         * The weights of all of the matched WeightedPodAffinityTerm fields are added per-node to find the most preferred node(s)
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            /**
             * Required. A pod affinity term, associated with the corresponding weight.
             */
            podAffinityTerm: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            /**
             * weight associated with matching the corresponding podAffinityTerm, in the range 1-100.
             */
            weight: number;
        }

        /**
         * Required. A pod affinity term, associated with the corresponding weight.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            /**
             * A label query over a set of resources, in this case pods.
             */
            labelSelector?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            /**
             * namespaces specifies which namespaces the labelSelector applies to (matches against); null or empty list means "this pod's namespace"
             */
            namespaces?: string[];
            /**
             * This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed.
             */
            topologyKey: string;
        }

        /**
         * A label query over a set of resources, in this case pods.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Defines a set of pods (namely those matching the labelSelector relative to the given namespace(s)) that this pod should be co-located (affinity) or not co-located (anti-affinity) with, where co-located is defined as running on a node whose value of the label with key <topologyKey> matches that of any node on which a pod of the set of pods is running
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            /**
             * A label query over a set of resources, in this case pods.
             */
            labelSelector?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            /**
             * namespaces specifies which namespaces the labelSelector applies to (matches against); null or empty list means "this pod's namespace"
             */
            namespaces?: string[];
            /**
             * This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed.
             */
            topologyKey: string;
        }

        /**
         * A label query over a set of resources, in this case pods.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Describes pod anti-affinity scheduling rules (e.g. avoid putting this pod in the same node, zone, etc. as some other pod(s)).
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinity {
            /**
             * The scheduler will prefer to schedule pods to nodes that satisfy the anti-affinity expressions specified by this field, but it may choose a node that violates one or more of the expressions. The node that is most preferred is the one with the greatest sum of weights, i.e. for each node that meets all of the scheduling requirements (resource request, requiredDuringScheduling anti-affinity expressions, etc.), compute a sum by iterating through the elements of this field and adding "weight" to the sum if the node has pods which matches the corresponding podAffinityTerm; the node(s) with the highest sum are the most preferred.
             */
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            /**
             * If the anti-affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the anti-affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to a pod label update), the system may or may not try to eventually evict the pod from its node. When there are multiple elements, the lists of nodes corresponding to each podAffinityTerm are intersected, i.e. all terms must be satisfied.
             */
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        /**
         * The weights of all of the matched WeightedPodAffinityTerm fields are added per-node to find the most preferred node(s)
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            /**
             * Required. A pod affinity term, associated with the corresponding weight.
             */
            podAffinityTerm: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            /**
             * weight associated with matching the corresponding podAffinityTerm, in the range 1-100.
             */
            weight: number;
        }

        /**
         * Required. A pod affinity term, associated with the corresponding weight.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            /**
             * A label query over a set of resources, in this case pods.
             */
            labelSelector?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            /**
             * namespaces specifies which namespaces the labelSelector applies to (matches against); null or empty list means "this pod's namespace"
             */
            namespaces?: string[];
            /**
             * This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed.
             */
            topologyKey: string;
        }

        /**
         * A label query over a set of resources, in this case pods.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Defines a set of pods (namely those matching the labelSelector relative to the given namespace(s)) that this pod should be co-located (affinity) or not co-located (anti-affinity) with, where co-located is defined as running on a node whose value of the label with key <topologyKey> matches that of any node on which a pod of the set of pods is running
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            /**
             * A label query over a set of resources, in this case pods.
             */
            labelSelector?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            /**
             * namespaces specifies which namespaces the labelSelector applies to (matches against); null or empty list means "this pod's namespace"
             */
            namespaces?: string[];
            /**
             * This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed.
             */
            topologyKey: string;
        }

        /**
         * A label query over a set of resources, in this case pods.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.certmanager.v1.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * The pod this Toleration is attached to tolerates any taint that matches the triple <key,value,effect> using the matching operator <operator>.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecTolerations {
            /**
             * Effect indicates the taint effect to match. Empty means match all taint effects. When specified, allowed values are NoSchedule, PreferNoSchedule and NoExecute.
             */
            effect?: string;
            /**
             * Key is the taint key that the toleration applies to. Empty means match all taint keys. If the key is empty, operator must be Exists; this combination means to match all values and all keys.
             */
            key?: string;
            /**
             * Operator represents a key's relationship to the value. Valid operators are Exists and Equal. Defaults to Equal. Exists is equivalent to wildcard for value, so that a pod can tolerate all taints of a particular category.
             */
            operator?: string;
            /**
             * TolerationSeconds represents the period of time the toleration (which must be of effect NoExecute, otherwise this field is ignored) tolerates the taint. By default, it is not set, which means tolerate the taint forever (do not evict). Zero and negative values will be treated as 0 (evict immediately) by the system.
             */
            tolerationSeconds?: number;
            /**
             * Value is the taint value the toleration matches to. If the operator is Exists, the value should be empty, otherwise just a regular string.
             */
            value?: string;
        }

        /**
         * Selector selects a set of DNSNames on the Certificate resource that should be solved using this challenge solver. If not specified, the solver will be treated as the 'default' solver with the lowest priority, i.e. if any other solver has a more specific match, it will be used instead.
         */
        export interface ClusterIssuerSpecAcmeSolversSelector {
            /**
             * List of DNSNames that this solver will be used to solve. If specified and a match is found, a dnsNames selector will take precedence over a dnsZones selector. If multiple solvers match with the same dnsNames value, the solver with the most matching labels in matchLabels will be selected. If neither has more matches, the solver defined earlier in the list will be selected.
             */
            dnsNames?: string[];
            /**
             * List of DNSZones that this solver will be used to solve. The most specific DNS zone match specified here will take precedence over other DNS zone matches, so a solver specifying sys.example.com will be selected over one specifying example.com for the domain www.sys.example.com. If multiple solvers match with the same dnsZones value, the solver with the most matching labels in matchLabels will be selected. If neither has more matches, the solver defined earlier in the list will be selected.
             */
            dnsZones?: string[];
            /**
             * A label selector that is used to refine the set of certificate's that this challenge solver will apply to.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * CA configures this issuer to sign certificates using a signing CA keypair stored in a Secret resource. This is used to build internal PKIs that are managed by cert-manager.
         */
        export interface ClusterIssuerSpecCa {
            /**
             * The CRL distribution points is an X.509 v3 certificate extension which identifies the location of the CRL from which the revocation of this certificate can be checked. If not set, certificates will be issued without distribution points set.
             */
            crlDistributionPoints?: string[];
            /**
             * SecretName is the name of the secret used to sign Certificates issued by this Issuer.
             */
            secretName: string;
        }

        /**
         * SelfSigned configures this issuer to 'self sign' certificates using the private key used to create the CertificateRequest object.
         */
        export interface ClusterIssuerSpecSelfSigned {
            /**
             * The CRL distribution points is an X.509 v3 certificate extension which identifies the location of the CRL from which the revocation of this certificate can be checked. If not set certificate will be issued without CDP. Values are strings.
             */
            crlDistributionPoints?: string[];
        }

        /**
         * Vault configures this issuer to sign certificates using a HashiCorp Vault PKI backend.
         */
        export interface ClusterIssuerSpecVault {
            /**
             * Auth configures how cert-manager authenticates with the Vault server.
             */
            auth: outputs.certmanager.v1.ClusterIssuerSpecVaultAuth;
            /**
             * PEM encoded CA bundle used to validate Vault server certificate. Only used if the Server URL is using HTTPS protocol. This parameter is ignored for plain HTTP protocol connection. If not set the system root certificates are used to validate the TLS connection.
             */
            caBundle?: string;
            /**
             * Name of the vault namespace. Namespaces is a set of features within Vault Enterprise that allows Vault environments to support Secure Multi-tenancy. e.g: "ns1" More about namespaces can be found here https://www.vaultproject.io/docs/enterprise/namespaces
             */
            namespace?: string;
            /**
             * Path is the mount path of the Vault PKI backend's `sign` endpoint, e.g: "my_pki_mount/sign/my-role-name".
             */
            path: string;
            /**
             * Server is the connection address for the Vault server, e.g: "https://vault.example.com:8200".
             */
            server: string;
        }

        /**
         * Auth configures how cert-manager authenticates with the Vault server.
         */
        export interface ClusterIssuerSpecVaultAuth {
            /**
             * AppRole authenticates with Vault using the App Role auth mechanism, with the role and secret stored in a Kubernetes Secret resource.
             */
            appRole?: outputs.certmanager.v1.ClusterIssuerSpecVaultAuthAppRole;
            /**
             * Kubernetes authenticates with Vault by passing the ServiceAccount token stored in the named Secret resource to the Vault server.
             */
            kubernetes?: outputs.certmanager.v1.ClusterIssuerSpecVaultAuthKubernetes;
            /**
             * TokenSecretRef authenticates with Vault by presenting a token.
             */
            tokenSecretRef?: outputs.certmanager.v1.ClusterIssuerSpecVaultAuthTokenSecretRef;
        }

        /**
         * AppRole authenticates with Vault using the App Role auth mechanism, with the role and secret stored in a Kubernetes Secret resource.
         */
        export interface ClusterIssuerSpecVaultAuthAppRole {
            /**
             * Path where the App Role authentication backend is mounted in Vault, e.g: "approle"
             */
            path: string;
            /**
             * RoleID configured in the App Role authentication backend when setting up the authentication backend in Vault.
             */
            roleId: string;
            /**
             * Reference to a key in a Secret that contains the App Role secret used to authenticate with Vault. The `key` field must be specified and denotes which entry within the Secret resource is used as the app role secret.
             */
            secretRef: outputs.certmanager.v1.ClusterIssuerSpecVaultAuthAppRoleSecretRef;
        }

        /**
         * Reference to a key in a Secret that contains the App Role secret used to authenticate with Vault. The `key` field must be specified and denotes which entry within the Secret resource is used as the app role secret.
         */
        export interface ClusterIssuerSpecVaultAuthAppRoleSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Kubernetes authenticates with Vault by passing the ServiceAccount token stored in the named Secret resource to the Vault server.
         */
        export interface ClusterIssuerSpecVaultAuthKubernetes {
            /**
             * The Vault mountPath here is the mount path to use when authenticating with Vault. For example, setting a value to `/v1/auth/foo`, will use the path `/v1/auth/foo/login` to authenticate with Vault. If unspecified, the default value "/v1/auth/kubernetes" will be used.
             */
            mountPath?: string;
            /**
             * A required field containing the Vault Role to assume. A Role binds a Kubernetes ServiceAccount with a set of Vault policies.
             */
            role: string;
            /**
             * The required Secret field containing a Kubernetes ServiceAccount JWT used for authenticating with Vault. Use of 'ambient credentials' is not supported.
             */
            secretRef: outputs.certmanager.v1.ClusterIssuerSpecVaultAuthKubernetesSecretRef;
        }

        /**
         * The required Secret field containing a Kubernetes ServiceAccount JWT used for authenticating with Vault. Use of 'ambient credentials' is not supported.
         */
        export interface ClusterIssuerSpecVaultAuthKubernetesSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * TokenSecretRef authenticates with Vault by presenting a token.
         */
        export interface ClusterIssuerSpecVaultAuthTokenSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Venafi configures this issuer to sign certificates using a Venafi TPP or Venafi Cloud policy zone.
         */
        export interface ClusterIssuerSpecVenafi {
            /**
             * Cloud specifies the Venafi cloud configuration settings. Only one of TPP or Cloud may be specified.
             */
            cloud?: outputs.certmanager.v1.ClusterIssuerSpecVenafiCloud;
            /**
             * TPP specifies Trust Protection Platform configuration settings. Only one of TPP or Cloud may be specified.
             */
            tpp?: outputs.certmanager.v1.ClusterIssuerSpecVenafiTpp;
            /**
             * Zone is the Venafi Policy Zone to use for this issuer. All requests made to the Venafi platform will be restricted by the named zone policy. This field is required.
             */
            zone: string;
        }

        /**
         * Cloud specifies the Venafi cloud configuration settings. Only one of TPP or Cloud may be specified.
         */
        export interface ClusterIssuerSpecVenafiCloud {
            /**
             * APITokenSecretRef is a secret key selector for the Venafi Cloud API token.
             */
            apiTokenSecretRef: outputs.certmanager.v1.ClusterIssuerSpecVenafiCloudApiTokenSecretRef;
            /**
             * URL is the base URL for Venafi Cloud. Defaults to "https://api.venafi.cloud/v1".
             */
            url?: string;
        }

        /**
         * APITokenSecretRef is a secret key selector for the Venafi Cloud API token.
         */
        export interface ClusterIssuerSpecVenafiCloudApiTokenSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * TPP specifies Trust Protection Platform configuration settings. Only one of TPP or Cloud may be specified.
         */
        export interface ClusterIssuerSpecVenafiTpp {
            /**
             * CABundle is a PEM encoded TLS certificate to use to verify connections to the TPP instance. If specified, system roots will not be used and the issuing CA for the TPP instance must be verifiable using the provided root. If not specified, the connection will be verified using the cert-manager system root certificates.
             */
            caBundle?: string;
            /**
             * CredentialsRef is a reference to a Secret containing the username and password for the TPP server. The secret must contain two keys, 'username' and 'password'.
             */
            credentialsRef: outputs.certmanager.v1.ClusterIssuerSpecVenafiTppCredentialsRef;
            /**
             * URL is the base URL for the vedsdk endpoint of the Venafi TPP instance, for example: "https://tpp.example.com/vedsdk".
             */
            url: string;
        }

        /**
         * CredentialsRef is a reference to a Secret containing the username and password for the TPP server. The secret must contain two keys, 'username' and 'password'.
         */
        export interface ClusterIssuerSpecVenafiTppCredentialsRef {
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Status of the ClusterIssuer. This is set and managed automatically.
         */
        export interface ClusterIssuerStatus {
            /**
             * ACME specific status options. This field should only be set if the Issuer is configured to use an ACME server to issue certificates.
             */
            acme?: outputs.certmanager.v1.ClusterIssuerStatusAcme;
            /**
             * List of status conditions to indicate the status of a CertificateRequest. Known condition types are `Ready`.
             */
            conditions?: outputs.certmanager.v1.ClusterIssuerStatusConditions[];
        }

        /**
         * ACME specific status options. This field should only be set if the Issuer is configured to use an ACME server to issue certificates.
         */
        export interface ClusterIssuerStatusAcme {
            /**
             * LastRegisteredEmail is the email associated with the latest registered ACME account, in order to track changes made to registered account associated with the  Issuer
             */
            lastRegisteredEmail?: string;
            /**
             * URI is the unique account identifier, which can also be used to retrieve account details from the CA
             */
            uri?: string;
        }

        /**
         * IssuerCondition contains condition information for an Issuer.
         */
        export interface ClusterIssuerStatusConditions {
            /**
             * LastTransitionTime is the timestamp corresponding to the last status change of this condition.
             */
            lastTransitionTime?: string;
            /**
             * Message is a human readable description of the details of the last transition, complementing reason.
             */
            message?: string;
            /**
             * Reason is a brief machine readable explanation for the condition's last transition.
             */
            reason?: string;
            /**
             * Status of the condition, one of ('True', 'False', 'Unknown').
             */
            status: string;
            /**
             * Type of the condition, known values are ('Ready').
             */
            type: string;
        }

        /**
         * Desired state of the Issuer resource.
         */
        export interface IssuerSpec {
            /**
             * ACME configures this issuer to communicate with a RFC8555 (ACME) server to obtain signed x509 certificates.
             */
            acme?: outputs.certmanager.v1.IssuerSpecAcme;
            /**
             * CA configures this issuer to sign certificates using a signing CA keypair stored in a Secret resource. This is used to build internal PKIs that are managed by cert-manager.
             */
            ca?: outputs.certmanager.v1.IssuerSpecCa;
            /**
             * SelfSigned configures this issuer to 'self sign' certificates using the private key used to create the CertificateRequest object.
             */
            selfSigned?: outputs.certmanager.v1.IssuerSpecSelfSigned;
            /**
             * Vault configures this issuer to sign certificates using a HashiCorp Vault PKI backend.
             */
            vault?: outputs.certmanager.v1.IssuerSpecVault;
            /**
             * Venafi configures this issuer to sign certificates using a Venafi TPP or Venafi Cloud policy zone.
             */
            venafi?: outputs.certmanager.v1.IssuerSpecVenafi;
        }

        /**
         * ACME configures this issuer to communicate with a RFC8555 (ACME) server to obtain signed x509 certificates.
         */
        export interface IssuerSpecAcme {
            /**
             * Enables or disables generating a new ACME account key. If true, the Issuer resource will *not* request a new account but will expect the account key to be supplied via an existing secret. If false, the cert-manager system will generate a new ACME account key for the Issuer. Defaults to false.
             */
            disableAccountKeyGeneration?: boolean;
            /**
             * Email is the email address to be associated with the ACME account. This field is optional, but it is strongly recommended to be set. It will be used to contact you in case of issues with your account or certificates, including expiry notification emails. This field may be updated after the account is initially registered.
             */
            email?: string;
            /**
             * Enables requesting a Not After date on certificates that matches the duration of the certificate. This is not supported by all ACME servers like Let's Encrypt. If set to true when the ACME server does not support it it will create an error on the Order. Defaults to false.
             */
            enableDurationFeature?: boolean;
            /**
             * ExternalAccountBinding is a reference to a CA external account of the ACME server. If set, upon registration cert-manager will attempt to associate the given external account credentials with the registered ACME account.
             */
            externalAccountBinding?: outputs.certmanager.v1.IssuerSpecAcmeExternalAccountBinding;
            /**
             * PreferredChain is the chain to use if the ACME server outputs multiple. PreferredChain is no guarantee that this one gets delivered by the ACME endpoint. For example, for Let's Encrypt's DST crosssign you would use: "DST Root CA X3" or "ISRG Root X1" for the newer Let's Encrypt root CA. This value picks the first certificate bundle in the ACME alternative chains that has a certificate with this value as its issuer's CN
             */
            preferredChain?: string;
            /**
             * PrivateKey is the name of a Kubernetes Secret resource that will be used to store the automatically generated ACME account private key. Optionally, a `key` may be specified to select a specific entry within the named Secret resource. If `key` is not specified, a default of `tls.key` will be used.
             */
            privateKeySecretRef: outputs.certmanager.v1.IssuerSpecAcmePrivateKeySecretRef;
            /**
             * Server is the URL used to access the ACME server's 'directory' endpoint. For example, for Let's Encrypt's staging endpoint, you would use: "https://acme-staging-v02.api.letsencrypt.org/directory". Only ACME v2 endpoints (i.e. RFC 8555) are supported.
             */
            server: string;
            /**
             * Enables or disables validation of the ACME server TLS certificate. If true, requests to the ACME server will not have their TLS certificate validated (i.e. insecure connections will be allowed). Only enable this option in development environments. The cert-manager system installed roots will be used to verify connections to the ACME server if this is false. Defaults to false.
             */
            skipTLSVerify?: boolean;
            /**
             * Solvers is a list of challenge solvers that will be used to solve ACME challenges for the matching domains. Solver configurations must be provided in order to obtain certificates from an ACME server. For more information, see: https://cert-manager.io/docs/configuration/acme/
             */
            solvers?: outputs.certmanager.v1.IssuerSpecAcmeSolvers[];
        }

        /**
         * ExternalAccountBinding is a reference to a CA external account of the ACME server. If set, upon registration cert-manager will attempt to associate the given external account credentials with the registered ACME account.
         */
        export interface IssuerSpecAcmeExternalAccountBinding {
            /**
             * keyAlgorithm is the MAC key algorithm that the key is used for. Valid values are "HS256", "HS384" and "HS512".
             */
            keyAlgorithm: string;
            /**
             * keyID is the ID of the CA key that the External Account is bound to.
             */
            keyID: string;
            /**
             * keySecretRef is a Secret Key Selector referencing a data item in a Kubernetes Secret which holds the symmetric MAC key of the External Account Binding. The `key` is the index string that is paired with the key data in the Secret and should not be confused with the key data itself, or indeed with the External Account Binding keyID above. The secret key stored in the Secret **must** be un-padded, base64 URL encoded data.
             */
            keySecretRef: outputs.certmanager.v1.IssuerSpecAcmeExternalAccountBindingKeySecretRef;
        }

        /**
         * keySecretRef is a Secret Key Selector referencing a data item in a Kubernetes Secret which holds the symmetric MAC key of the External Account Binding. The `key` is the index string that is paired with the key data in the Secret and should not be confused with the key data itself, or indeed with the External Account Binding keyID above. The secret key stored in the Secret **must** be un-padded, base64 URL encoded data.
         */
        export interface IssuerSpecAcmeExternalAccountBindingKeySecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * PrivateKey is the name of a Kubernetes Secret resource that will be used to store the automatically generated ACME account private key. Optionally, a `key` may be specified to select a specific entry within the named Secret resource. If `key` is not specified, a default of `tls.key` will be used.
         */
        export interface IssuerSpecAcmePrivateKeySecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Configures an issuer to solve challenges using the specified options. Only one of HTTP01 or DNS01 may be provided.
         */
        export interface IssuerSpecAcmeSolvers {
            /**
             * Configures cert-manager to attempt to complete authorizations by performing the DNS01 challenge flow.
             */
            dns01?: outputs.certmanager.v1.IssuerSpecAcmeSolversDns01;
            /**
             * Configures cert-manager to attempt to complete authorizations by performing the HTTP01 challenge flow. It is not possible to obtain certificates for wildcard domain names (e.g. `*.example.com`) using the HTTP01 challenge mechanism.
             */
            http01?: outputs.certmanager.v1.IssuerSpecAcmeSolversHttp01;
            /**
             * Selector selects a set of DNSNames on the Certificate resource that should be solved using this challenge solver. If not specified, the solver will be treated as the 'default' solver with the lowest priority, i.e. if any other solver has a more specific match, it will be used instead.
             */
            selector?: outputs.certmanager.v1.IssuerSpecAcmeSolversSelector;
        }

        /**
         * Configures cert-manager to attempt to complete authorizations by performing the DNS01 challenge flow.
         */
        export interface IssuerSpecAcmeSolversDns01 {
            /**
             * Use the 'ACME DNS' (https://github.com/joohoi/acme-dns) API to manage DNS01 challenge records.
             */
            acmeDNS?: outputs.certmanager.v1.IssuerSpecAcmeSolversDns01AcmeDNS;
            /**
             * Use the Akamai DNS zone management API to manage DNS01 challenge records.
             */
            akamai?: outputs.certmanager.v1.IssuerSpecAcmeSolversDns01Akamai;
            /**
             * Use the Microsoft Azure DNS API to manage DNS01 challenge records.
             */
            azureDNS?: outputs.certmanager.v1.IssuerSpecAcmeSolversDns01AzureDNS;
            /**
             * Use the Google Cloud DNS API to manage DNS01 challenge records.
             */
            cloudDNS?: outputs.certmanager.v1.IssuerSpecAcmeSolversDns01CloudDNS;
            /**
             * Use the Cloudflare API to manage DNS01 challenge records.
             */
            cloudflare?: outputs.certmanager.v1.IssuerSpecAcmeSolversDns01Cloudflare;
            /**
             * CNAMEStrategy configures how the DNS01 provider should handle CNAME records when found in DNS zones.
             */
            cnameStrategy?: string;
            /**
             * Use the DigitalOcean DNS API to manage DNS01 challenge records.
             */
            digitalocean?: outputs.certmanager.v1.IssuerSpecAcmeSolversDns01Digitalocean;
            /**
             * Use RFC2136 ("Dynamic Updates in the Domain Name System") (https://datatracker.ietf.org/doc/rfc2136/) to manage DNS01 challenge records.
             */
            rfc2136?: outputs.certmanager.v1.IssuerSpecAcmeSolversDns01Rfc2136;
            /**
             * Use the AWS Route53 API to manage DNS01 challenge records.
             */
            route53?: outputs.certmanager.v1.IssuerSpecAcmeSolversDns01Route53;
            /**
             * Configure an external webhook based DNS01 challenge solver to manage DNS01 challenge records.
             */
            webhook?: outputs.certmanager.v1.IssuerSpecAcmeSolversDns01Webhook;
        }

        /**
         * Use the 'ACME DNS' (https://github.com/joohoi/acme-dns) API to manage DNS01 challenge records.
         */
        export interface IssuerSpecAcmeSolversDns01AcmeDNS {
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            accountSecretRef: outputs.certmanager.v1.IssuerSpecAcmeSolversDns01AcmeDNSAccountSecretRef;
            host: string;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface IssuerSpecAcmeSolversDns01AcmeDNSAccountSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the Akamai DNS zone management API to manage DNS01 challenge records.
         */
        export interface IssuerSpecAcmeSolversDns01Akamai {
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            accessTokenSecretRef: outputs.certmanager.v1.IssuerSpecAcmeSolversDns01AkamaiAccessTokenSecretRef;
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            clientSecretSecretRef: outputs.certmanager.v1.IssuerSpecAcmeSolversDns01AkamaiClientSecretSecretRef;
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            clientTokenSecretRef: outputs.certmanager.v1.IssuerSpecAcmeSolversDns01AkamaiClientTokenSecretRef;
            serviceConsumerDomain: string;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface IssuerSpecAcmeSolversDns01AkamaiAccessTokenSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface IssuerSpecAcmeSolversDns01AkamaiClientSecretSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface IssuerSpecAcmeSolversDns01AkamaiClientTokenSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the Microsoft Azure DNS API to manage DNS01 challenge records.
         */
        export interface IssuerSpecAcmeSolversDns01AzureDNS {
            /**
             * if both this and ClientSecret are left unset MSI will be used
             */
            clientID?: string;
            /**
             * if both this and ClientID are left unset MSI will be used
             */
            clientSecretSecretRef?: outputs.certmanager.v1.IssuerSpecAcmeSolversDns01AzureDNSClientSecretSecretRef;
            environment?: string;
            hostedZoneName?: string;
            resourceGroupName: string;
            subscriptionID: string;
            /**
             * when specifying ClientID and ClientSecret then this field is also needed
             */
            tenantID?: string;
        }

        /**
         * if both this and ClientID are left unset MSI will be used
         */
        export interface IssuerSpecAcmeSolversDns01AzureDNSClientSecretSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the Google Cloud DNS API to manage DNS01 challenge records.
         */
        export interface IssuerSpecAcmeSolversDns01CloudDNS {
            /**
             * HostedZoneName is an optional field that tells cert-manager in which Cloud DNS zone the challenge record has to be created. If left empty cert-manager will automatically choose a zone.
             */
            hostedZoneName?: string;
            project: string;
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            serviceAccountSecretRef?: outputs.certmanager.v1.IssuerSpecAcmeSolversDns01CloudDNSServiceAccountSecretRef;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface IssuerSpecAcmeSolversDns01CloudDNSServiceAccountSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the Cloudflare API to manage DNS01 challenge records.
         */
        export interface IssuerSpecAcmeSolversDns01Cloudflare {
            /**
             * API key to use to authenticate with Cloudflare. Note: using an API token to authenticate is now the recommended method as it allows greater control of permissions.
             */
            apiKeySecretRef?: outputs.certmanager.v1.IssuerSpecAcmeSolversDns01CloudflareApiKeySecretRef;
            /**
             * API token used to authenticate with Cloudflare.
             */
            apiTokenSecretRef?: outputs.certmanager.v1.IssuerSpecAcmeSolversDns01CloudflareApiTokenSecretRef;
            /**
             * Email of the account, only required when using API key based authentication.
             */
            email?: string;
        }

        /**
         * API key to use to authenticate with Cloudflare. Note: using an API token to authenticate is now the recommended method as it allows greater control of permissions.
         */
        export interface IssuerSpecAcmeSolversDns01CloudflareApiKeySecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * API token used to authenticate with Cloudflare.
         */
        export interface IssuerSpecAcmeSolversDns01CloudflareApiTokenSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the DigitalOcean DNS API to manage DNS01 challenge records.
         */
        export interface IssuerSpecAcmeSolversDns01Digitalocean {
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            tokenSecretRef: outputs.certmanager.v1.IssuerSpecAcmeSolversDns01DigitaloceanTokenSecretRef;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface IssuerSpecAcmeSolversDns01DigitaloceanTokenSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use RFC2136 ("Dynamic Updates in the Domain Name System") (https://datatracker.ietf.org/doc/rfc2136/) to manage DNS01 challenge records.
         */
        export interface IssuerSpecAcmeSolversDns01Rfc2136 {
            /**
             * The IP address or hostname of an authoritative DNS server supporting RFC2136 in the form host:port. If the host is an IPv6 address it must be enclosed in square brackets (e.g [2001:db8::1]) ; port is optional. This field is required.
             */
            nameserver: string;
            /**
             * The TSIG Algorithm configured in the DNS supporting RFC2136. Used only when ``tsigSecretSecretRef`` and ``tsigKeyName`` are defined. Supported values are (case-insensitive): ``HMACMD5`` (default), ``HMACSHA1``, ``HMACSHA256`` or ``HMACSHA512``.
             */
            tsigAlgorithm?: string;
            /**
             * The TSIG Key name configured in the DNS. If ``tsigSecretSecretRef`` is defined, this field is required.
             */
            tsigKeyName?: string;
            /**
             * The name of the secret containing the TSIG value. If ``tsigKeyName`` is defined, this field is required.
             */
            tsigSecretSecretRef?: outputs.certmanager.v1.IssuerSpecAcmeSolversDns01Rfc2136TsigSecretSecretRef;
        }

        /**
         * The name of the secret containing the TSIG value. If ``tsigKeyName`` is defined, this field is required.
         */
        export interface IssuerSpecAcmeSolversDns01Rfc2136TsigSecretSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the AWS Route53 API to manage DNS01 challenge records.
         */
        export interface IssuerSpecAcmeSolversDns01Route53 {
            /**
             * The AccessKeyID is used for authentication. If not set we fall-back to using env vars, shared credentials file or AWS Instance metadata see: https://docs.aws.amazon.com/sdk-for-go/v1/developer-guide/configuring-sdk.html#specifying-credentials
             */
            accessKeyID?: string;
            /**
             * If set, the provider will manage only this zone in Route53 and will not do an lookup using the route53:ListHostedZonesByName api call.
             */
            hostedZoneID?: string;
            /**
             * Always set the region when using AccessKeyID and SecretAccessKey
             */
            region: string;
            /**
             * Role is a Role ARN which the Route53 provider will assume using either the explicit credentials AccessKeyID/SecretAccessKey or the inferred credentials from environment variables, shared credentials file or AWS Instance metadata
             */
            role?: string;
            /**
             * The SecretAccessKey is used for authentication. If not set we fall-back to using env vars, shared credentials file or AWS Instance metadata https://docs.aws.amazon.com/sdk-for-go/v1/developer-guide/configuring-sdk.html#specifying-credentials
             */
            secretAccessKeySecretRef?: outputs.certmanager.v1.IssuerSpecAcmeSolversDns01Route53SecretAccessKeySecretRef;
        }

        /**
         * The SecretAccessKey is used for authentication. If not set we fall-back to using env vars, shared credentials file or AWS Instance metadata https://docs.aws.amazon.com/sdk-for-go/v1/developer-guide/configuring-sdk.html#specifying-credentials
         */
        export interface IssuerSpecAcmeSolversDns01Route53SecretAccessKeySecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Configure an external webhook based DNS01 challenge solver to manage DNS01 challenge records.
         */
        export interface IssuerSpecAcmeSolversDns01Webhook {
            /**
             * Additional configuration that should be passed to the webhook apiserver when challenges are processed. This can contain arbitrary JSON data. Secret values should not be specified in this stanza. If secret values are needed (e.g. credentials for a DNS service), you should use a SecretKeySelector to reference a Secret resource. For details on the schema of this field, consult the webhook provider implementation's documentation.
             */
            config?: {[key: string]: any};
            /**
             * The API group name that should be used when POSTing ChallengePayload resources to the webhook apiserver. This should be the same as the GroupName specified in the webhook provider implementation.
             */
            groupName: string;
            /**
             * The name of the solver to use, as defined in the webhook provider implementation. This will typically be the name of the provider, e.g. 'cloudflare'.
             */
            solverName: string;
        }

        /**
         * Configures cert-manager to attempt to complete authorizations by performing the HTTP01 challenge flow. It is not possible to obtain certificates for wildcard domain names (e.g. `*.example.com`) using the HTTP01 challenge mechanism.
         */
        export interface IssuerSpecAcmeSolversHttp01 {
            /**
             * The ingress based HTTP01 challenge solver will solve challenges by creating or modifying Ingress resources in order to route requests for '/.well-known/acme-challenge/XYZ' to 'challenge solver' pods that are provisioned by cert-manager for each Challenge to be completed.
             */
            ingress?: outputs.certmanager.v1.IssuerSpecAcmeSolversHttp01Ingress;
        }

        /**
         * The ingress based HTTP01 challenge solver will solve challenges by creating or modifying Ingress resources in order to route requests for '/.well-known/acme-challenge/XYZ' to 'challenge solver' pods that are provisioned by cert-manager for each Challenge to be completed.
         */
        export interface IssuerSpecAcmeSolversHttp01Ingress {
            /**
             * The ingress class to use when creating Ingress resources to solve ACME challenges that use this challenge solver. Only one of 'class' or 'name' may be specified.
             */
            class?: string;
            /**
             * Optional ingress template used to configure the ACME challenge solver ingress used for HTTP01 challenges
             */
            ingressTemplate?: outputs.certmanager.v1.IssuerSpecAcmeSolversHttp01IngressIngressTemplate;
            /**
             * The name of the ingress resource that should have ACME challenge solving routes inserted into it in order to solve HTTP01 challenges. This is typically used in conjunction with ingress controllers like ingress-gce, which maintains a 1:1 mapping between external IPs and ingress resources.
             */
            name?: string;
            /**
             * Optional pod template used to configure the ACME challenge solver pods used for HTTP01 challenges
             */
            podTemplate?: outputs.certmanager.v1.IssuerSpecAcmeSolversHttp01IngressPodTemplate;
            /**
             * Optional service type for Kubernetes solver service
             */
            serviceType?: string;
        }

        /**
         * Optional ingress template used to configure the ACME challenge solver ingress used for HTTP01 challenges
         */
        export interface IssuerSpecAcmeSolversHttp01IngressIngressTemplate {
            /**
             * ObjectMeta overrides for the ingress used to solve HTTP01 challenges. Only the 'labels' and 'annotations' fields may be set. If labels or annotations overlap with in-built values, the values here will override the in-built values.
             */
            metadata?: outputs.certmanager.v1.IssuerSpecAcmeSolversHttp01IngressIngressTemplateMetadata;
        }

        /**
         * ObjectMeta overrides for the ingress used to solve HTTP01 challenges. Only the 'labels' and 'annotations' fields may be set. If labels or annotations overlap with in-built values, the values here will override the in-built values.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressIngressTemplateMetadata {
            /**
             * Annotations that should be added to the created ACME HTTP01 solver ingress.
             */
            annotations?: {[key: string]: string};
            /**
             * Labels that should be added to the created ACME HTTP01 solver ingress.
             */
            labels?: {[key: string]: string};
        }

        /**
         * Optional pod template used to configure the ACME challenge solver pods used for HTTP01 challenges
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplate {
            /**
             * ObjectMeta overrides for the pod used to solve HTTP01 challenges. Only the 'labels' and 'annotations' fields may be set. If labels or annotations overlap with in-built values, the values here will override the in-built values.
             */
            metadata?: outputs.certmanager.v1.IssuerSpecAcmeSolversHttp01IngressPodTemplateMetadata;
            /**
             * PodSpec defines overrides for the HTTP01 challenge solver pod. Only the 'priorityClassName', 'nodeSelector', 'affinity', 'serviceAccountName' and 'tolerations' fields are supported currently. All other fields will be ignored.
             */
            spec?: outputs.certmanager.v1.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpec;
        }

        /**
         * ObjectMeta overrides for the pod used to solve HTTP01 challenges. Only the 'labels' and 'annotations' fields may be set. If labels or annotations overlap with in-built values, the values here will override the in-built values.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateMetadata {
            /**
             * Annotations that should be added to the create ACME HTTP01 solver pods.
             */
            annotations?: {[key: string]: string};
            /**
             * Labels that should be added to the created ACME HTTP01 solver pods.
             */
            labels?: {[key: string]: string};
        }

        /**
         * PodSpec defines overrides for the HTTP01 challenge solver pod. Only the 'priorityClassName', 'nodeSelector', 'affinity', 'serviceAccountName' and 'tolerations' fields are supported currently. All other fields will be ignored.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpec {
            /**
             * If specified, the pod's scheduling constraints
             */
            affinity?: outputs.certmanager.v1.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinity;
            /**
             * NodeSelector is a selector which must be true for the pod to fit on a node. Selector which must match a node's labels for the pod to be scheduled on that node. More info: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/
             */
            nodeSelector?: {[key: string]: string};
            /**
             * If specified, the pod's priorityClassName.
             */
            priorityClassName?: string;
            /**
             * If specified, the pod's service account
             */
            serviceAccountName?: string;
            /**
             * If specified, the pod's tolerations.
             */
            tolerations?: outputs.certmanager.v1.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecTolerations[];
        }

        /**
         * If specified, the pod's scheduling constraints
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinity {
            /**
             * Describes node affinity scheduling rules for the pod.
             */
            nodeAffinity?: outputs.certmanager.v1.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinity;
            /**
             * Describes pod affinity scheduling rules (e.g. co-locate this pod in the same node, zone, etc. as some other pod(s)).
             */
            podAffinity?: outputs.certmanager.v1.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinity;
            /**
             * Describes pod anti-affinity scheduling rules (e.g. avoid putting this pod in the same node, zone, etc. as some other pod(s)).
             */
            podAntiAffinity?: outputs.certmanager.v1.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinity;
        }

        /**
         * Describes node affinity scheduling rules for the pod.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinity {
            /**
             * The scheduler will prefer to schedule pods to nodes that satisfy the affinity expressions specified by this field, but it may choose a node that violates one or more of the expressions. The node that is most preferred is the one with the greatest sum of weights, i.e. for each node that meets all of the scheduling requirements (resource request, requiredDuringScheduling affinity expressions, etc.), compute a sum by iterating through the elements of this field and adding "weight" to the sum if the node matches the corresponding matchExpressions; the node(s) with the highest sum are the most preferred.
             */
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.certmanager.v1.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            /**
             * If the affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to an update), the system may or may not try to eventually evict the pod from its node.
             */
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.certmanager.v1.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution;
        }

        /**
         * An empty preferred scheduling term matches all objects with implicit weight 0 (i.e. it's a no-op). A null preferred scheduling term matches no objects (i.e. is also a no-op).
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            /**
             * A node selector term, associated with the corresponding weight.
             */
            preference: outputs.certmanager.v1.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference;
            /**
             * Weight associated with matching the corresponding nodeSelectorTerm, in the range 1-100.
             */
            weight: number;
        }

        /**
         * A node selector term, associated with the corresponding weight.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference {
            /**
             * A list of node selector requirements by node's labels.
             */
            matchExpressions?: outputs.certmanager.v1.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions[];
            /**
             * A list of node selector requirements by node's fields.
             */
            matchFields?: outputs.certmanager.v1.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields[];
        }

        /**
         * A node selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions {
            /**
             * The label key that the selector applies to.
             */
            key: string;
            /**
             * Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
             */
            operator: string;
            /**
             * An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * A node selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields {
            /**
             * The label key that the selector applies to.
             */
            key: string;
            /**
             * Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
             */
            operator: string;
            /**
             * An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * If the affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to an update), the system may or may not try to eventually evict the pod from its node.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            /**
             * Required. A list of node selector terms. The terms are ORed.
             */
            nodeSelectorTerms: outputs.certmanager.v1.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms[];
        }

        /**
         * A null or empty node selector term matches no objects. The requirements of them are ANDed. The TopologySelectorTerm type implements a subset of the NodeSelectorTerm.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms {
            /**
             * A list of node selector requirements by node's labels.
             */
            matchExpressions?: outputs.certmanager.v1.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions[];
            /**
             * A list of node selector requirements by node's fields.
             */
            matchFields?: outputs.certmanager.v1.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields[];
        }

        /**
         * A node selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions {
            /**
             * The label key that the selector applies to.
             */
            key: string;
            /**
             * Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
             */
            operator: string;
            /**
             * An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * A node selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields {
            /**
             * The label key that the selector applies to.
             */
            key: string;
            /**
             * Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
             */
            operator: string;
            /**
             * An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Describes pod affinity scheduling rules (e.g. co-locate this pod in the same node, zone, etc. as some other pod(s)).
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinity {
            /**
             * The scheduler will prefer to schedule pods to nodes that satisfy the affinity expressions specified by this field, but it may choose a node that violates one or more of the expressions. The node that is most preferred is the one with the greatest sum of weights, i.e. for each node that meets all of the scheduling requirements (resource request, requiredDuringScheduling affinity expressions, etc.), compute a sum by iterating through the elements of this field and adding "weight" to the sum if the node has pods which matches the corresponding podAffinityTerm; the node(s) with the highest sum are the most preferred.
             */
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.certmanager.v1.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            /**
             * If the affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to a pod label update), the system may or may not try to eventually evict the pod from its node. When there are multiple elements, the lists of nodes corresponding to each podAffinityTerm are intersected, i.e. all terms must be satisfied.
             */
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.certmanager.v1.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        /**
         * The weights of all of the matched WeightedPodAffinityTerm fields are added per-node to find the most preferred node(s)
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            /**
             * Required. A pod affinity term, associated with the corresponding weight.
             */
            podAffinityTerm: outputs.certmanager.v1.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            /**
             * weight associated with matching the corresponding podAffinityTerm, in the range 1-100.
             */
            weight: number;
        }

        /**
         * Required. A pod affinity term, associated with the corresponding weight.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            /**
             * A label query over a set of resources, in this case pods.
             */
            labelSelector?: outputs.certmanager.v1.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            /**
             * namespaces specifies which namespaces the labelSelector applies to (matches against); null or empty list means "this pod's namespace"
             */
            namespaces?: string[];
            /**
             * This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed.
             */
            topologyKey: string;
        }

        /**
         * A label query over a set of resources, in this case pods.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.certmanager.v1.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Defines a set of pods (namely those matching the labelSelector relative to the given namespace(s)) that this pod should be co-located (affinity) or not co-located (anti-affinity) with, where co-located is defined as running on a node whose value of the label with key <topologyKey> matches that of any node on which a pod of the set of pods is running
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            /**
             * A label query over a set of resources, in this case pods.
             */
            labelSelector?: outputs.certmanager.v1.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            /**
             * namespaces specifies which namespaces the labelSelector applies to (matches against); null or empty list means "this pod's namespace"
             */
            namespaces?: string[];
            /**
             * This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed.
             */
            topologyKey: string;
        }

        /**
         * A label query over a set of resources, in this case pods.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.certmanager.v1.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Describes pod anti-affinity scheduling rules (e.g. avoid putting this pod in the same node, zone, etc. as some other pod(s)).
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinity {
            /**
             * The scheduler will prefer to schedule pods to nodes that satisfy the anti-affinity expressions specified by this field, but it may choose a node that violates one or more of the expressions. The node that is most preferred is the one with the greatest sum of weights, i.e. for each node that meets all of the scheduling requirements (resource request, requiredDuringScheduling anti-affinity expressions, etc.), compute a sum by iterating through the elements of this field and adding "weight" to the sum if the node has pods which matches the corresponding podAffinityTerm; the node(s) with the highest sum are the most preferred.
             */
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.certmanager.v1.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            /**
             * If the anti-affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the anti-affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to a pod label update), the system may or may not try to eventually evict the pod from its node. When there are multiple elements, the lists of nodes corresponding to each podAffinityTerm are intersected, i.e. all terms must be satisfied.
             */
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.certmanager.v1.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        /**
         * The weights of all of the matched WeightedPodAffinityTerm fields are added per-node to find the most preferred node(s)
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            /**
             * Required. A pod affinity term, associated with the corresponding weight.
             */
            podAffinityTerm: outputs.certmanager.v1.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            /**
             * weight associated with matching the corresponding podAffinityTerm, in the range 1-100.
             */
            weight: number;
        }

        /**
         * Required. A pod affinity term, associated with the corresponding weight.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            /**
             * A label query over a set of resources, in this case pods.
             */
            labelSelector?: outputs.certmanager.v1.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            /**
             * namespaces specifies which namespaces the labelSelector applies to (matches against); null or empty list means "this pod's namespace"
             */
            namespaces?: string[];
            /**
             * This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed.
             */
            topologyKey: string;
        }

        /**
         * A label query over a set of resources, in this case pods.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.certmanager.v1.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Defines a set of pods (namely those matching the labelSelector relative to the given namespace(s)) that this pod should be co-located (affinity) or not co-located (anti-affinity) with, where co-located is defined as running on a node whose value of the label with key <topologyKey> matches that of any node on which a pod of the set of pods is running
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            /**
             * A label query over a set of resources, in this case pods.
             */
            labelSelector?: outputs.certmanager.v1.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            /**
             * namespaces specifies which namespaces the labelSelector applies to (matches against); null or empty list means "this pod's namespace"
             */
            namespaces?: string[];
            /**
             * This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed.
             */
            topologyKey: string;
        }

        /**
         * A label query over a set of resources, in this case pods.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.certmanager.v1.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * The pod this Toleration is attached to tolerates any taint that matches the triple <key,value,effect> using the matching operator <operator>.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecTolerations {
            /**
             * Effect indicates the taint effect to match. Empty means match all taint effects. When specified, allowed values are NoSchedule, PreferNoSchedule and NoExecute.
             */
            effect?: string;
            /**
             * Key is the taint key that the toleration applies to. Empty means match all taint keys. If the key is empty, operator must be Exists; this combination means to match all values and all keys.
             */
            key?: string;
            /**
             * Operator represents a key's relationship to the value. Valid operators are Exists and Equal. Defaults to Equal. Exists is equivalent to wildcard for value, so that a pod can tolerate all taints of a particular category.
             */
            operator?: string;
            /**
             * TolerationSeconds represents the period of time the toleration (which must be of effect NoExecute, otherwise this field is ignored) tolerates the taint. By default, it is not set, which means tolerate the taint forever (do not evict). Zero and negative values will be treated as 0 (evict immediately) by the system.
             */
            tolerationSeconds?: number;
            /**
             * Value is the taint value the toleration matches to. If the operator is Exists, the value should be empty, otherwise just a regular string.
             */
            value?: string;
        }

        /**
         * Selector selects a set of DNSNames on the Certificate resource that should be solved using this challenge solver. If not specified, the solver will be treated as the 'default' solver with the lowest priority, i.e. if any other solver has a more specific match, it will be used instead.
         */
        export interface IssuerSpecAcmeSolversSelector {
            /**
             * List of DNSNames that this solver will be used to solve. If specified and a match is found, a dnsNames selector will take precedence over a dnsZones selector. If multiple solvers match with the same dnsNames value, the solver with the most matching labels in matchLabels will be selected. If neither has more matches, the solver defined earlier in the list will be selected.
             */
            dnsNames?: string[];
            /**
             * List of DNSZones that this solver will be used to solve. The most specific DNS zone match specified here will take precedence over other DNS zone matches, so a solver specifying sys.example.com will be selected over one specifying example.com for the domain www.sys.example.com. If multiple solvers match with the same dnsZones value, the solver with the most matching labels in matchLabels will be selected. If neither has more matches, the solver defined earlier in the list will be selected.
             */
            dnsZones?: string[];
            /**
             * A label selector that is used to refine the set of certificate's that this challenge solver will apply to.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * CA configures this issuer to sign certificates using a signing CA keypair stored in a Secret resource. This is used to build internal PKIs that are managed by cert-manager.
         */
        export interface IssuerSpecCa {
            /**
             * The CRL distribution points is an X.509 v3 certificate extension which identifies the location of the CRL from which the revocation of this certificate can be checked. If not set, certificates will be issued without distribution points set.
             */
            crlDistributionPoints?: string[];
            /**
             * SecretName is the name of the secret used to sign Certificates issued by this Issuer.
             */
            secretName: string;
        }

        /**
         * SelfSigned configures this issuer to 'self sign' certificates using the private key used to create the CertificateRequest object.
         */
        export interface IssuerSpecSelfSigned {
            /**
             * The CRL distribution points is an X.509 v3 certificate extension which identifies the location of the CRL from which the revocation of this certificate can be checked. If not set certificate will be issued without CDP. Values are strings.
             */
            crlDistributionPoints?: string[];
        }

        /**
         * Vault configures this issuer to sign certificates using a HashiCorp Vault PKI backend.
         */
        export interface IssuerSpecVault {
            /**
             * Auth configures how cert-manager authenticates with the Vault server.
             */
            auth: outputs.certmanager.v1.IssuerSpecVaultAuth;
            /**
             * PEM encoded CA bundle used to validate Vault server certificate. Only used if the Server URL is using HTTPS protocol. This parameter is ignored for plain HTTP protocol connection. If not set the system root certificates are used to validate the TLS connection.
             */
            caBundle?: string;
            /**
             * Name of the vault namespace. Namespaces is a set of features within Vault Enterprise that allows Vault environments to support Secure Multi-tenancy. e.g: "ns1" More about namespaces can be found here https://www.vaultproject.io/docs/enterprise/namespaces
             */
            namespace?: string;
            /**
             * Path is the mount path of the Vault PKI backend's `sign` endpoint, e.g: "my_pki_mount/sign/my-role-name".
             */
            path: string;
            /**
             * Server is the connection address for the Vault server, e.g: "https://vault.example.com:8200".
             */
            server: string;
        }

        /**
         * Auth configures how cert-manager authenticates with the Vault server.
         */
        export interface IssuerSpecVaultAuth {
            /**
             * AppRole authenticates with Vault using the App Role auth mechanism, with the role and secret stored in a Kubernetes Secret resource.
             */
            appRole?: outputs.certmanager.v1.IssuerSpecVaultAuthAppRole;
            /**
             * Kubernetes authenticates with Vault by passing the ServiceAccount token stored in the named Secret resource to the Vault server.
             */
            kubernetes?: outputs.certmanager.v1.IssuerSpecVaultAuthKubernetes;
            /**
             * TokenSecretRef authenticates with Vault by presenting a token.
             */
            tokenSecretRef?: outputs.certmanager.v1.IssuerSpecVaultAuthTokenSecretRef;
        }

        /**
         * AppRole authenticates with Vault using the App Role auth mechanism, with the role and secret stored in a Kubernetes Secret resource.
         */
        export interface IssuerSpecVaultAuthAppRole {
            /**
             * Path where the App Role authentication backend is mounted in Vault, e.g: "approle"
             */
            path: string;
            /**
             * RoleID configured in the App Role authentication backend when setting up the authentication backend in Vault.
             */
            roleId: string;
            /**
             * Reference to a key in a Secret that contains the App Role secret used to authenticate with Vault. The `key` field must be specified and denotes which entry within the Secret resource is used as the app role secret.
             */
            secretRef: outputs.certmanager.v1.IssuerSpecVaultAuthAppRoleSecretRef;
        }

        /**
         * Reference to a key in a Secret that contains the App Role secret used to authenticate with Vault. The `key` field must be specified and denotes which entry within the Secret resource is used as the app role secret.
         */
        export interface IssuerSpecVaultAuthAppRoleSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Kubernetes authenticates with Vault by passing the ServiceAccount token stored in the named Secret resource to the Vault server.
         */
        export interface IssuerSpecVaultAuthKubernetes {
            /**
             * The Vault mountPath here is the mount path to use when authenticating with Vault. For example, setting a value to `/v1/auth/foo`, will use the path `/v1/auth/foo/login` to authenticate with Vault. If unspecified, the default value "/v1/auth/kubernetes" will be used.
             */
            mountPath?: string;
            /**
             * A required field containing the Vault Role to assume. A Role binds a Kubernetes ServiceAccount with a set of Vault policies.
             */
            role: string;
            /**
             * The required Secret field containing a Kubernetes ServiceAccount JWT used for authenticating with Vault. Use of 'ambient credentials' is not supported.
             */
            secretRef: outputs.certmanager.v1.IssuerSpecVaultAuthKubernetesSecretRef;
        }

        /**
         * The required Secret field containing a Kubernetes ServiceAccount JWT used for authenticating with Vault. Use of 'ambient credentials' is not supported.
         */
        export interface IssuerSpecVaultAuthKubernetesSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * TokenSecretRef authenticates with Vault by presenting a token.
         */
        export interface IssuerSpecVaultAuthTokenSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Venafi configures this issuer to sign certificates using a Venafi TPP or Venafi Cloud policy zone.
         */
        export interface IssuerSpecVenafi {
            /**
             * Cloud specifies the Venafi cloud configuration settings. Only one of TPP or Cloud may be specified.
             */
            cloud?: outputs.certmanager.v1.IssuerSpecVenafiCloud;
            /**
             * TPP specifies Trust Protection Platform configuration settings. Only one of TPP or Cloud may be specified.
             */
            tpp?: outputs.certmanager.v1.IssuerSpecVenafiTpp;
            /**
             * Zone is the Venafi Policy Zone to use for this issuer. All requests made to the Venafi platform will be restricted by the named zone policy. This field is required.
             */
            zone: string;
        }

        /**
         * Cloud specifies the Venafi cloud configuration settings. Only one of TPP or Cloud may be specified.
         */
        export interface IssuerSpecVenafiCloud {
            /**
             * APITokenSecretRef is a secret key selector for the Venafi Cloud API token.
             */
            apiTokenSecretRef: outputs.certmanager.v1.IssuerSpecVenafiCloudApiTokenSecretRef;
            /**
             * URL is the base URL for Venafi Cloud. Defaults to "https://api.venafi.cloud/v1".
             */
            url?: string;
        }

        /**
         * APITokenSecretRef is a secret key selector for the Venafi Cloud API token.
         */
        export interface IssuerSpecVenafiCloudApiTokenSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * TPP specifies Trust Protection Platform configuration settings. Only one of TPP or Cloud may be specified.
         */
        export interface IssuerSpecVenafiTpp {
            /**
             * CABundle is a PEM encoded TLS certificate to use to verify connections to the TPP instance. If specified, system roots will not be used and the issuing CA for the TPP instance must be verifiable using the provided root. If not specified, the connection will be verified using the cert-manager system root certificates.
             */
            caBundle?: string;
            /**
             * CredentialsRef is a reference to a Secret containing the username and password for the TPP server. The secret must contain two keys, 'username' and 'password'.
             */
            credentialsRef: outputs.certmanager.v1.IssuerSpecVenafiTppCredentialsRef;
            /**
             * URL is the base URL for the vedsdk endpoint of the Venafi TPP instance, for example: "https://tpp.example.com/vedsdk".
             */
            url: string;
        }

        /**
         * CredentialsRef is a reference to a Secret containing the username and password for the TPP server. The secret must contain two keys, 'username' and 'password'.
         */
        export interface IssuerSpecVenafiTppCredentialsRef {
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Status of the Issuer. This is set and managed automatically.
         */
        export interface IssuerStatus {
            /**
             * ACME specific status options. This field should only be set if the Issuer is configured to use an ACME server to issue certificates.
             */
            acme?: outputs.certmanager.v1.IssuerStatusAcme;
            /**
             * List of status conditions to indicate the status of a CertificateRequest. Known condition types are `Ready`.
             */
            conditions?: outputs.certmanager.v1.IssuerStatusConditions[];
        }

        /**
         * ACME specific status options. This field should only be set if the Issuer is configured to use an ACME server to issue certificates.
         */
        export interface IssuerStatusAcme {
            /**
             * LastRegisteredEmail is the email associated with the latest registered ACME account, in order to track changes made to registered account associated with the  Issuer
             */
            lastRegisteredEmail?: string;
            /**
             * URI is the unique account identifier, which can also be used to retrieve account details from the CA
             */
            uri?: string;
        }

        /**
         * IssuerCondition contains condition information for an Issuer.
         */
        export interface IssuerStatusConditions {
            /**
             * LastTransitionTime is the timestamp corresponding to the last status change of this condition.
             */
            lastTransitionTime?: string;
            /**
             * Message is a human readable description of the details of the last transition, complementing reason.
             */
            message?: string;
            /**
             * Reason is a brief machine readable explanation for the condition's last transition.
             */
            reason?: string;
            /**
             * Status of the condition, one of ('True', 'False', 'Unknown').
             */
            status: string;
            /**
             * Type of the condition, known values are ('Ready').
             */
            type: string;
        }
    }

    export namespace v1alpha2 {
        /**
         * Desired state of the CertificateRequest resource.
         */
        export interface CertificateRequestSpec {
            /**
             * The PEM-encoded x509 certificate signing request to be submitted to the CA for signing.
             */
            csr: string;
            /**
             * The requested 'duration' (i.e. lifetime) of the Certificate. This option may be ignored/overridden by some issuer types.
             */
            duration?: string;
            /**
             * IsCA will request to mark the certificate as valid for certificate signing when submitting to the issuer. This will automatically add the `cert sign` usage to the list of `usages`.
             */
            isCA?: boolean;
            /**
             * IssuerRef is a reference to the issuer for this CertificateRequest.  If the 'kind' field is not set, or set to 'Issuer', an Issuer resource with the given name in the same namespace as the CertificateRequest will be used.  If the 'kind' field is set to 'ClusterIssuer', a ClusterIssuer with the provided name will be used. The 'name' field in this stanza is required at all times. The group field refers to the API group of the issuer which defaults to 'cert-manager.io' if empty.
             */
            issuerRef: outputs.certmanager.v1alpha2.CertificateRequestSpecIssuerRef;
            /**
             * Usages is the set of x509 usages that are requested for the certificate. Defaults to `digital signature` and `key encipherment` if not specified.
             */
            usages?: string[];
        }

        /**
         * IssuerRef is a reference to the issuer for this CertificateRequest.  If the 'kind' field is not set, or set to 'Issuer', an Issuer resource with the given name in the same namespace as the CertificateRequest will be used.  If the 'kind' field is set to 'ClusterIssuer', a ClusterIssuer with the provided name will be used. The 'name' field in this stanza is required at all times. The group field refers to the API group of the issuer which defaults to 'cert-manager.io' if empty.
         */
        export interface CertificateRequestSpecIssuerRef {
            /**
             * Group of the resource being referred to.
             */
            group?: string;
            /**
             * Kind of the resource being referred to.
             */
            kind?: string;
            /**
             * Name of the resource being referred to.
             */
            name: string;
        }

        /**
         * Status of the CertificateRequest. This is set and managed automatically.
         */
        export interface CertificateRequestStatus {
            /**
             * The PEM encoded x509 certificate of the signer, also known as the CA (Certificate Authority). This is set on a best-effort basis by different issuers. If not set, the CA is assumed to be unknown/not available.
             */
            ca?: string;
            /**
             * The PEM encoded x509 certificate resulting from the certificate signing request. If not set, the CertificateRequest has either not been completed or has failed. More information on failure can be found by checking the `conditions` field.
             */
            certificate?: string;
            /**
             * List of status conditions to indicate the status of a CertificateRequest. Known condition types are `Ready` and `InvalidRequest`.
             */
            conditions?: outputs.certmanager.v1alpha2.CertificateRequestStatusConditions[];
            /**
             * FailureTime stores the time that this CertificateRequest failed. This is used to influence garbage collection and back-off.
             */
            failureTime?: string;
        }

        /**
         * CertificateRequestCondition contains condition information for a CertificateRequest.
         */
        export interface CertificateRequestStatusConditions {
            /**
             * LastTransitionTime is the timestamp corresponding to the last status change of this condition.
             */
            lastTransitionTime?: string;
            /**
             * Message is a human readable description of the details of the last transition, complementing reason.
             */
            message?: string;
            /**
             * Reason is a brief machine readable explanation for the condition's last transition.
             */
            reason?: string;
            /**
             * Status of the condition, one of ('True', 'False', 'Unknown').
             */
            status: string;
            /**
             * Type of the condition, known values are ('Ready', 'InvalidRequest').
             */
            type: string;
        }

        /**
         * Desired state of the Certificate resource.
         */
        export interface CertificateSpec {
            /**
             * CommonName is a common name to be used on the Certificate. The CommonName should have a length of 64 characters or fewer to avoid generating invalid CSRs. This value is ignored by TLS clients when any subject alt name is set. This is x509 behaviour: https://tools.ietf.org/html/rfc6125#section-6.4.4
             */
            commonName?: string;
            /**
             * DNSNames is a list of DNS subjectAltNames to be set on the Certificate.
             */
            dnsNames?: string[];
            /**
             * The requested 'duration' (i.e. lifetime) of the Certificate. This option may be ignored/overridden by some issuer types. If overridden and `renewBefore` is greater than the actual certificate duration, the certificate will be automatically renewed 2/3rds of the way through the certificate's duration.
             */
            duration?: string;
            /**
             * EmailSANs is a list of email subjectAltNames to be set on the Certificate.
             */
            emailSANs?: string[];
            /**
             * EncodeUsagesInRequest controls whether key usages should be present in the CertificateRequest
             */
            encodeUsagesInRequest?: boolean;
            /**
             * IPAddresses is a list of IP address subjectAltNames to be set on the Certificate.
             */
            ipAddresses?: string[];
            /**
             * IsCA will mark this Certificate as valid for certificate signing. This will automatically add the `cert sign` usage to the list of `usages`.
             */
            isCA?: boolean;
            /**
             * IssuerRef is a reference to the issuer for this certificate. If the 'kind' field is not set, or set to 'Issuer', an Issuer resource with the given name in the same namespace as the Certificate will be used. If the 'kind' field is set to 'ClusterIssuer', a ClusterIssuer with the provided name will be used. The 'name' field in this stanza is required at all times.
             */
            issuerRef: outputs.certmanager.v1alpha2.CertificateSpecIssuerRef;
            /**
             * KeyAlgorithm is the private key algorithm of the corresponding private key for this certificate. If provided, allowed values are either "rsa" or "ecdsa" If `keyAlgorithm` is specified and `keySize` is not provided, key size of 256 will be used for "ecdsa" key algorithm and key size of 2048 will be used for "rsa" key algorithm.
             */
            keyAlgorithm?: string;
            /**
             * KeyEncoding is the private key cryptography standards (PKCS) for this certificate's private key to be encoded in. If provided, allowed values are "pkcs1" and "pkcs8" standing for PKCS#1 and PKCS#8, respectively. If KeyEncoding is not specified, then PKCS#1 will be used by default.
             */
            keyEncoding?: string;
            /**
             * KeySize is the key bit size of the corresponding private key for this certificate. If `keyAlgorithm` is set to `RSA`, valid values are `2048`, `4096` or `8192`, and will default to `2048` if not specified. If `keyAlgorithm` is set to `ECDSA`, valid values are `256`, `384` or `521`, and will default to `256` if not specified. No other values are allowed.
             */
            keySize?: number;
            /**
             * Keystores configures additional keystore output formats stored in the `secretName` Secret resource.
             */
            keystores?: outputs.certmanager.v1alpha2.CertificateSpecKeystores;
            /**
             * Organization is a list of organizations to be used on the Certificate.
             */
            organization?: string[];
            /**
             * Options to control private keys used for the Certificate.
             */
            privateKey?: outputs.certmanager.v1alpha2.CertificateSpecPrivateKey;
            /**
             * The amount of time before the currently issued certificate's `notAfter` time that cert-manager will begin to attempt to renew the certificate. If this value is greater than the total duration of the certificate (i.e. notAfter - notBefore), it will be automatically renewed 2/3rds of the way through the certificate's duration.
             */
            renewBefore?: string;
            /**
             * SecretName is the name of the secret resource that will be automatically created and managed by this Certificate resource. It will be populated with a private key and certificate, signed by the denoted issuer.
             */
            secretName: string;
            /**
             * Full X509 name specification (https://golang.org/pkg/crypto/x509/pkix/#Name).
             */
            subject?: outputs.certmanager.v1alpha2.CertificateSpecSubject;
            /**
             * URISANs is a list of URI subjectAltNames to be set on the Certificate.
             */
            uriSANs?: string[];
            /**
             * Usages is the set of x509 usages that are requested for the certificate. Defaults to `digital signature` and `key encipherment` if not specified.
             */
            usages?: string[];
        }

        /**
         * IssuerRef is a reference to the issuer for this certificate. If the 'kind' field is not set, or set to 'Issuer', an Issuer resource with the given name in the same namespace as the Certificate will be used. If the 'kind' field is set to 'ClusterIssuer', a ClusterIssuer with the provided name will be used. The 'name' field in this stanza is required at all times.
         */
        export interface CertificateSpecIssuerRef {
            /**
             * Group of the resource being referred to.
             */
            group?: string;
            /**
             * Kind of the resource being referred to.
             */
            kind?: string;
            /**
             * Name of the resource being referred to.
             */
            name: string;
        }

        /**
         * Keystores configures additional keystore output formats stored in the `secretName` Secret resource.
         */
        export interface CertificateSpecKeystores {
            /**
             * JKS configures options for storing a JKS keystore in the `spec.secretName` Secret resource.
             */
            jks?: outputs.certmanager.v1alpha2.CertificateSpecKeystoresJks;
            /**
             * PKCS12 configures options for storing a PKCS12 keystore in the `spec.secretName` Secret resource.
             */
            pkcs12?: outputs.certmanager.v1alpha2.CertificateSpecKeystoresPkcs12;
        }

        /**
         * JKS configures options for storing a JKS keystore in the `spec.secretName` Secret resource.
         */
        export interface CertificateSpecKeystoresJks {
            /**
             * Create enables JKS keystore creation for the Certificate. If true, a file named `keystore.jks` will be created in the target Secret resource, encrypted using the password stored in `passwordSecretRef`. The keystore file will only be updated upon re-issuance.
             */
            create: boolean;
            /**
             * PasswordSecretRef is a reference to a key in a Secret resource containing the password used to encrypt the JKS keystore.
             */
            passwordSecretRef: outputs.certmanager.v1alpha2.CertificateSpecKeystoresJksPasswordSecretRef;
        }

        /**
         * PasswordSecretRef is a reference to a key in a Secret resource containing the password used to encrypt the JKS keystore.
         */
        export interface CertificateSpecKeystoresJksPasswordSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * PKCS12 configures options for storing a PKCS12 keystore in the `spec.secretName` Secret resource.
         */
        export interface CertificateSpecKeystoresPkcs12 {
            /**
             * Create enables PKCS12 keystore creation for the Certificate. If true, a file named `keystore.p12` will be created in the target Secret resource, encrypted using the password stored in `passwordSecretRef`. The keystore file will only be updated upon re-issuance.
             */
            create: boolean;
            /**
             * PasswordSecretRef is a reference to a key in a Secret resource containing the password used to encrypt the PKCS12 keystore.
             */
            passwordSecretRef: outputs.certmanager.v1alpha2.CertificateSpecKeystoresPkcs12PasswordSecretRef;
        }

        /**
         * PasswordSecretRef is a reference to a key in a Secret resource containing the password used to encrypt the PKCS12 keystore.
         */
        export interface CertificateSpecKeystoresPkcs12PasswordSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Options to control private keys used for the Certificate.
         */
        export interface CertificateSpecPrivateKey {
            /**
             * RotationPolicy controls how private keys should be regenerated when a re-issuance is being processed. If set to Never, a private key will only be generated if one does not already exist in the target `spec.secretName`. If one does exists but it does not have the correct algorithm or size, a warning will be raised to await user intervention. If set to Always, a private key matching the specified requirements will be generated whenever a re-issuance occurs. Default is 'Never' for backward compatibility.
             */
            rotationPolicy?: string;
        }

        /**
         * Full X509 name specification (https://golang.org/pkg/crypto/x509/pkix/#Name).
         */
        export interface CertificateSpecSubject {
            /**
             * Countries to be used on the Certificate.
             */
            countries?: string[];
            /**
             * Cities to be used on the Certificate.
             */
            localities?: string[];
            /**
             * Organizational Units to be used on the Certificate.
             */
            organizationalUnits?: string[];
            /**
             * Postal codes to be used on the Certificate.
             */
            postalCodes?: string[];
            /**
             * State/Provinces to be used on the Certificate.
             */
            provinces?: string[];
            /**
             * Serial number to be used on the Certificate.
             */
            serialNumber?: string;
            /**
             * Street addresses to be used on the Certificate.
             */
            streetAddresses?: string[];
        }

        /**
         * Status of the Certificate. This is set and managed automatically.
         */
        export interface CertificateStatus {
            /**
             * List of status conditions to indicate the status of certificates. Known condition types are `Ready` and `Issuing`.
             */
            conditions?: outputs.certmanager.v1alpha2.CertificateStatusConditions[];
            /**
             * LastFailureTime is the time as recorded by the Certificate controller of the most recent failure to complete a CertificateRequest for this Certificate resource. If set, cert-manager will not re-request another Certificate until 1 hour has elapsed from this time.
             */
            lastFailureTime?: string;
            /**
             * The name of the Secret resource containing the private key to be used for the next certificate iteration. The keymanager controller will automatically set this field if the `Issuing` condition is set to `True`. It will automatically unset this field when the Issuing condition is not set or False.
             */
            nextPrivateKeySecretName?: string;
            /**
             * The expiration time of the certificate stored in the secret named by this resource in `spec.secretName`.
             */
            notAfter?: string;
            /**
             * The time after which the certificate stored in the secret named by this resource in spec.secretName is valid.
             */
            notBefore?: string;
            /**
             * RenewalTime is the time at which the certificate will be next renewed. If not set, no upcoming renewal is scheduled.
             */
            renewalTime?: string;
            /**
             * The current 'revision' of the certificate as issued. 
             *  When a CertificateRequest resource is created, it will have the `cert-manager.io/certificate-revision` set to one greater than the current value of this field. 
             *  Upon issuance, this field will be set to the value of the annotation on the CertificateRequest resource used to issue the certificate. 
             *  Persisting the value on the CertificateRequest resource allows the certificates controller to know whether a request is part of an old issuance or if it is part of the ongoing revision's issuance by checking if the revision value in the annotation is greater than this field.
             */
            revision?: number;
        }

        /**
         * CertificateCondition contains condition information for an Certificate.
         */
        export interface CertificateStatusConditions {
            /**
             * LastTransitionTime is the timestamp corresponding to the last status change of this condition.
             */
            lastTransitionTime?: string;
            /**
             * Message is a human readable description of the details of the last transition, complementing reason.
             */
            message?: string;
            /**
             * Reason is a brief machine readable explanation for the condition's last transition.
             */
            reason?: string;
            /**
             * Status of the condition, one of ('True', 'False', 'Unknown').
             */
            status: string;
            /**
             * Type of the condition, known values are ('Ready', `Issuing`).
             */
            type: string;
        }

        /**
         * Desired state of the ClusterIssuer resource.
         */
        export interface ClusterIssuerSpec {
            /**
             * ACME configures this issuer to communicate with a RFC8555 (ACME) server to obtain signed x509 certificates.
             */
            acme?: outputs.certmanager.v1alpha2.ClusterIssuerSpecAcme;
            /**
             * CA configures this issuer to sign certificates using a signing CA keypair stored in a Secret resource. This is used to build internal PKIs that are managed by cert-manager.
             */
            ca?: outputs.certmanager.v1alpha2.ClusterIssuerSpecCa;
            /**
             * SelfSigned configures this issuer to 'self sign' certificates using the private key used to create the CertificateRequest object.
             */
            selfSigned?: outputs.certmanager.v1alpha2.ClusterIssuerSpecSelfSigned;
            /**
             * Vault configures this issuer to sign certificates using a HashiCorp Vault PKI backend.
             */
            vault?: outputs.certmanager.v1alpha2.ClusterIssuerSpecVault;
            /**
             * Venafi configures this issuer to sign certificates using a Venafi TPP or Venafi Cloud policy zone.
             */
            venafi?: outputs.certmanager.v1alpha2.ClusterIssuerSpecVenafi;
        }

        /**
         * ACME configures this issuer to communicate with a RFC8555 (ACME) server to obtain signed x509 certificates.
         */
        export interface ClusterIssuerSpecAcme {
            /**
             * Enables or disables generating a new ACME account key. If true, the Issuer resource will *not* request a new account but will expect the account key to be supplied via an existing secret. If false, the cert-manager system will generate a new ACME account key for the Issuer. Defaults to false.
             */
            disableAccountKeyGeneration?: boolean;
            /**
             * Email is the email address to be associated with the ACME account. This field is optional, but it is strongly recommended to be set. It will be used to contact you in case of issues with your account or certificates, including expiry notification emails. This field may be updated after the account is initially registered.
             */
            email?: string;
            /**
             * Enables requesting a Not After date on certificates that matches the duration of the certificate. This is not supported by all ACME servers like Let's Encrypt. If set to true when the ACME server does not support it it will create an error on the Order. Defaults to false.
             */
            enableDurationFeature?: boolean;
            /**
             * ExternalAccountBinding is a reference to a CA external account of the ACME server. If set, upon registration cert-manager will attempt to associate the given external account credentials with the registered ACME account.
             */
            externalAccountBinding?: outputs.certmanager.v1alpha2.ClusterIssuerSpecAcmeExternalAccountBinding;
            /**
             * PreferredChain is the chain to use if the ACME server outputs multiple. PreferredChain is no guarantee that this one gets delivered by the ACME endpoint. For example, for Let's Encrypt's DST crosssign you would use: "DST Root CA X3" or "ISRG Root X1" for the newer Let's Encrypt root CA. This value picks the first certificate bundle in the ACME alternative chains that has a certificate with this value as its issuer's CN
             */
            preferredChain?: string;
            /**
             * PrivateKey is the name of a Kubernetes Secret resource that will be used to store the automatically generated ACME account private key. Optionally, a `key` may be specified to select a specific entry within the named Secret resource. If `key` is not specified, a default of `tls.key` will be used.
             */
            privateKeySecretRef: outputs.certmanager.v1alpha2.ClusterIssuerSpecAcmePrivateKeySecretRef;
            /**
             * Server is the URL used to access the ACME server's 'directory' endpoint. For example, for Let's Encrypt's staging endpoint, you would use: "https://acme-staging-v02.api.letsencrypt.org/directory". Only ACME v2 endpoints (i.e. RFC 8555) are supported.
             */
            server: string;
            /**
             * Enables or disables validation of the ACME server TLS certificate. If true, requests to the ACME server will not have their TLS certificate validated (i.e. insecure connections will be allowed). Only enable this option in development environments. The cert-manager system installed roots will be used to verify connections to the ACME server if this is false. Defaults to false.
             */
            skipTLSVerify?: boolean;
            /**
             * Solvers is a list of challenge solvers that will be used to solve ACME challenges for the matching domains. Solver configurations must be provided in order to obtain certificates from an ACME server. For more information, see: https://cert-manager.io/docs/configuration/acme/
             */
            solvers?: outputs.certmanager.v1alpha2.ClusterIssuerSpecAcmeSolvers[];
        }

        /**
         * ExternalAccountBinding is a reference to a CA external account of the ACME server. If set, upon registration cert-manager will attempt to associate the given external account credentials with the registered ACME account.
         */
        export interface ClusterIssuerSpecAcmeExternalAccountBinding {
            /**
             * keyAlgorithm is the MAC key algorithm that the key is used for. Valid values are "HS256", "HS384" and "HS512".
             */
            keyAlgorithm: string;
            /**
             * keyID is the ID of the CA key that the External Account is bound to.
             */
            keyID: string;
            /**
             * keySecretRef is a Secret Key Selector referencing a data item in a Kubernetes Secret which holds the symmetric MAC key of the External Account Binding. The `key` is the index string that is paired with the key data in the Secret and should not be confused with the key data itself, or indeed with the External Account Binding keyID above. The secret key stored in the Secret **must** be un-padded, base64 URL encoded data.
             */
            keySecretRef: outputs.certmanager.v1alpha2.ClusterIssuerSpecAcmeExternalAccountBindingKeySecretRef;
        }

        /**
         * keySecretRef is a Secret Key Selector referencing a data item in a Kubernetes Secret which holds the symmetric MAC key of the External Account Binding. The `key` is the index string that is paired with the key data in the Secret and should not be confused with the key data itself, or indeed with the External Account Binding keyID above. The secret key stored in the Secret **must** be un-padded, base64 URL encoded data.
         */
        export interface ClusterIssuerSpecAcmeExternalAccountBindingKeySecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * PrivateKey is the name of a Kubernetes Secret resource that will be used to store the automatically generated ACME account private key. Optionally, a `key` may be specified to select a specific entry within the named Secret resource. If `key` is not specified, a default of `tls.key` will be used.
         */
        export interface ClusterIssuerSpecAcmePrivateKeySecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Configures an issuer to solve challenges using the specified options. Only one of HTTP01 or DNS01 may be provided.
         */
        export interface ClusterIssuerSpecAcmeSolvers {
            /**
             * Configures cert-manager to attempt to complete authorizations by performing the DNS01 challenge flow.
             */
            dns01?: outputs.certmanager.v1alpha2.ClusterIssuerSpecAcmeSolversDns01;
            /**
             * Configures cert-manager to attempt to complete authorizations by performing the HTTP01 challenge flow. It is not possible to obtain certificates for wildcard domain names (e.g. `*.example.com`) using the HTTP01 challenge mechanism.
             */
            http01?: outputs.certmanager.v1alpha2.ClusterIssuerSpecAcmeSolversHttp01;
            /**
             * Selector selects a set of DNSNames on the Certificate resource that should be solved using this challenge solver. If not specified, the solver will be treated as the 'default' solver with the lowest priority, i.e. if any other solver has a more specific match, it will be used instead.
             */
            selector?: outputs.certmanager.v1alpha2.ClusterIssuerSpecAcmeSolversSelector;
        }

        /**
         * Configures cert-manager to attempt to complete authorizations by performing the DNS01 challenge flow.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01 {
            /**
             * Use the 'ACME DNS' (https://github.com/joohoi/acme-dns) API to manage DNS01 challenge records.
             */
            acmedns?: outputs.certmanager.v1alpha2.ClusterIssuerSpecAcmeSolversDns01Acmedns;
            /**
             * Use the Akamai DNS zone management API to manage DNS01 challenge records.
             */
            akamai?: outputs.certmanager.v1alpha2.ClusterIssuerSpecAcmeSolversDns01Akamai;
            /**
             * Use the Microsoft Azure DNS API to manage DNS01 challenge records.
             */
            azuredns?: outputs.certmanager.v1alpha2.ClusterIssuerSpecAcmeSolversDns01Azuredns;
            /**
             * Use the Google Cloud DNS API to manage DNS01 challenge records.
             */
            clouddns?: outputs.certmanager.v1alpha2.ClusterIssuerSpecAcmeSolversDns01Clouddns;
            /**
             * Use the Cloudflare API to manage DNS01 challenge records.
             */
            cloudflare?: outputs.certmanager.v1alpha2.ClusterIssuerSpecAcmeSolversDns01Cloudflare;
            /**
             * CNAMEStrategy configures how the DNS01 provider should handle CNAME records when found in DNS zones.
             */
            cnameStrategy?: string;
            /**
             * Use the DigitalOcean DNS API to manage DNS01 challenge records.
             */
            digitalocean?: outputs.certmanager.v1alpha2.ClusterIssuerSpecAcmeSolversDns01Digitalocean;
            /**
             * Use RFC2136 ("Dynamic Updates in the Domain Name System") (https://datatracker.ietf.org/doc/rfc2136/) to manage DNS01 challenge records.
             */
            rfc2136?: outputs.certmanager.v1alpha2.ClusterIssuerSpecAcmeSolversDns01Rfc2136;
            /**
             * Use the AWS Route53 API to manage DNS01 challenge records.
             */
            route53?: outputs.certmanager.v1alpha2.ClusterIssuerSpecAcmeSolversDns01Route53;
            /**
             * Configure an external webhook based DNS01 challenge solver to manage DNS01 challenge records.
             */
            webhook?: outputs.certmanager.v1alpha2.ClusterIssuerSpecAcmeSolversDns01Webhook;
        }

        /**
         * Use the 'ACME DNS' (https://github.com/joohoi/acme-dns) API to manage DNS01 challenge records.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01Acmedns {
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            accountSecretRef: outputs.certmanager.v1alpha2.ClusterIssuerSpecAcmeSolversDns01AcmednsAccountSecretRef;
            host: string;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01AcmednsAccountSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the Akamai DNS zone management API to manage DNS01 challenge records.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01Akamai {
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            accessTokenSecretRef: outputs.certmanager.v1alpha2.ClusterIssuerSpecAcmeSolversDns01AkamaiAccessTokenSecretRef;
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            clientSecretSecretRef: outputs.certmanager.v1alpha2.ClusterIssuerSpecAcmeSolversDns01AkamaiClientSecretSecretRef;
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            clientTokenSecretRef: outputs.certmanager.v1alpha2.ClusterIssuerSpecAcmeSolversDns01AkamaiClientTokenSecretRef;
            serviceConsumerDomain: string;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01AkamaiAccessTokenSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01AkamaiClientSecretSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01AkamaiClientTokenSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the Microsoft Azure DNS API to manage DNS01 challenge records.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01Azuredns {
            /**
             * if both this and ClientSecret are left unset MSI will be used
             */
            clientID?: string;
            /**
             * if both this and ClientID are left unset MSI will be used
             */
            clientSecretSecretRef?: outputs.certmanager.v1alpha2.ClusterIssuerSpecAcmeSolversDns01AzurednsClientSecretSecretRef;
            environment?: string;
            hostedZoneName?: string;
            resourceGroupName: string;
            subscriptionID: string;
            /**
             * when specifying ClientID and ClientSecret then this field is also needed
             */
            tenantID?: string;
        }

        /**
         * if both this and ClientID are left unset MSI will be used
         */
        export interface ClusterIssuerSpecAcmeSolversDns01AzurednsClientSecretSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the Google Cloud DNS API to manage DNS01 challenge records.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01Clouddns {
            /**
             * HostedZoneName is an optional field that tells cert-manager in which Cloud DNS zone the challenge record has to be created. If left empty cert-manager will automatically choose a zone.
             */
            hostedZoneName?: string;
            project: string;
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            serviceAccountSecretRef?: outputs.certmanager.v1alpha2.ClusterIssuerSpecAcmeSolversDns01ClouddnsServiceAccountSecretRef;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01ClouddnsServiceAccountSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the Cloudflare API to manage DNS01 challenge records.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01Cloudflare {
            /**
             * API key to use to authenticate with Cloudflare. Note: using an API token to authenticate is now the recommended method as it allows greater control of permissions.
             */
            apiKeySecretRef?: outputs.certmanager.v1alpha2.ClusterIssuerSpecAcmeSolversDns01CloudflareApiKeySecretRef;
            /**
             * API token used to authenticate with Cloudflare.
             */
            apiTokenSecretRef?: outputs.certmanager.v1alpha2.ClusterIssuerSpecAcmeSolversDns01CloudflareApiTokenSecretRef;
            /**
             * Email of the account, only required when using API key based authentication.
             */
            email?: string;
        }

        /**
         * API key to use to authenticate with Cloudflare. Note: using an API token to authenticate is now the recommended method as it allows greater control of permissions.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01CloudflareApiKeySecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * API token used to authenticate with Cloudflare.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01CloudflareApiTokenSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the DigitalOcean DNS API to manage DNS01 challenge records.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01Digitalocean {
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            tokenSecretRef: outputs.certmanager.v1alpha2.ClusterIssuerSpecAcmeSolversDns01DigitaloceanTokenSecretRef;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01DigitaloceanTokenSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use RFC2136 ("Dynamic Updates in the Domain Name System") (https://datatracker.ietf.org/doc/rfc2136/) to manage DNS01 challenge records.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01Rfc2136 {
            /**
             * The IP address or hostname of an authoritative DNS server supporting RFC2136 in the form host:port. If the host is an IPv6 address it must be enclosed in square brackets (e.g [2001:db8::1]) ; port is optional. This field is required.
             */
            nameserver: string;
            /**
             * The TSIG Algorithm configured in the DNS supporting RFC2136. Used only when ``tsigSecretSecretRef`` and ``tsigKeyName`` are defined. Supported values are (case-insensitive): ``HMACMD5`` (default), ``HMACSHA1``, ``HMACSHA256`` or ``HMACSHA512``.
             */
            tsigAlgorithm?: string;
            /**
             * The TSIG Key name configured in the DNS. If ``tsigSecretSecretRef`` is defined, this field is required.
             */
            tsigKeyName?: string;
            /**
             * The name of the secret containing the TSIG value. If ``tsigKeyName`` is defined, this field is required.
             */
            tsigSecretSecretRef?: outputs.certmanager.v1alpha2.ClusterIssuerSpecAcmeSolversDns01Rfc2136TsigSecretSecretRef;
        }

        /**
         * The name of the secret containing the TSIG value. If ``tsigKeyName`` is defined, this field is required.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01Rfc2136TsigSecretSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the AWS Route53 API to manage DNS01 challenge records.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01Route53 {
            /**
             * The AccessKeyID is used for authentication. If not set we fall-back to using env vars, shared credentials file or AWS Instance metadata see: https://docs.aws.amazon.com/sdk-for-go/v1/developer-guide/configuring-sdk.html#specifying-credentials
             */
            accessKeyID?: string;
            /**
             * If set, the provider will manage only this zone in Route53 and will not do an lookup using the route53:ListHostedZonesByName api call.
             */
            hostedZoneID?: string;
            /**
             * Always set the region when using AccessKeyID and SecretAccessKey
             */
            region: string;
            /**
             * Role is a Role ARN which the Route53 provider will assume using either the explicit credentials AccessKeyID/SecretAccessKey or the inferred credentials from environment variables, shared credentials file or AWS Instance metadata
             */
            role?: string;
            /**
             * The SecretAccessKey is used for authentication. If not set we fall-back to using env vars, shared credentials file or AWS Instance metadata https://docs.aws.amazon.com/sdk-for-go/v1/developer-guide/configuring-sdk.html#specifying-credentials
             */
            secretAccessKeySecretRef?: outputs.certmanager.v1alpha2.ClusterIssuerSpecAcmeSolversDns01Route53SecretAccessKeySecretRef;
        }

        /**
         * The SecretAccessKey is used for authentication. If not set we fall-back to using env vars, shared credentials file or AWS Instance metadata https://docs.aws.amazon.com/sdk-for-go/v1/developer-guide/configuring-sdk.html#specifying-credentials
         */
        export interface ClusterIssuerSpecAcmeSolversDns01Route53SecretAccessKeySecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Configure an external webhook based DNS01 challenge solver to manage DNS01 challenge records.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01Webhook {
            /**
             * Additional configuration that should be passed to the webhook apiserver when challenges are processed. This can contain arbitrary JSON data. Secret values should not be specified in this stanza. If secret values are needed (e.g. credentials for a DNS service), you should use a SecretKeySelector to reference a Secret resource. For details on the schema of this field, consult the webhook provider implementation's documentation.
             */
            config?: {[key: string]: any};
            /**
             * The API group name that should be used when POSTing ChallengePayload resources to the webhook apiserver. This should be the same as the GroupName specified in the webhook provider implementation.
             */
            groupName: string;
            /**
             * The name of the solver to use, as defined in the webhook provider implementation. This will typically be the name of the provider, e.g. 'cloudflare'.
             */
            solverName: string;
        }

        /**
         * Configures cert-manager to attempt to complete authorizations by performing the HTTP01 challenge flow. It is not possible to obtain certificates for wildcard domain names (e.g. `*.example.com`) using the HTTP01 challenge mechanism.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01 {
            /**
             * The ingress based HTTP01 challenge solver will solve challenges by creating or modifying Ingress resources in order to route requests for '/.well-known/acme-challenge/XYZ' to 'challenge solver' pods that are provisioned by cert-manager for each Challenge to be completed.
             */
            ingress?: outputs.certmanager.v1alpha2.ClusterIssuerSpecAcmeSolversHttp01Ingress;
        }

        /**
         * The ingress based HTTP01 challenge solver will solve challenges by creating or modifying Ingress resources in order to route requests for '/.well-known/acme-challenge/XYZ' to 'challenge solver' pods that are provisioned by cert-manager for each Challenge to be completed.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01Ingress {
            /**
             * The ingress class to use when creating Ingress resources to solve ACME challenges that use this challenge solver. Only one of 'class' or 'name' may be specified.
             */
            class?: string;
            /**
             * Optional ingress template used to configure the ACME challenge solver ingress used for HTTP01 challenges
             */
            ingressTemplate?: outputs.certmanager.v1alpha2.ClusterIssuerSpecAcmeSolversHttp01IngressIngressTemplate;
            /**
             * The name of the ingress resource that should have ACME challenge solving routes inserted into it in order to solve HTTP01 challenges. This is typically used in conjunction with ingress controllers like ingress-gce, which maintains a 1:1 mapping between external IPs and ingress resources.
             */
            name?: string;
            /**
             * Optional pod template used to configure the ACME challenge solver pods used for HTTP01 challenges
             */
            podTemplate?: outputs.certmanager.v1alpha2.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplate;
            /**
             * Optional service type for Kubernetes solver service
             */
            serviceType?: string;
        }

        /**
         * Optional ingress template used to configure the ACME challenge solver ingress used for HTTP01 challenges
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressIngressTemplate {
            /**
             * ObjectMeta overrides for the ingress used to solve HTTP01 challenges. Only the 'labels' and 'annotations' fields may be set. If labels or annotations overlap with in-built values, the values here will override the in-built values.
             */
            metadata?: outputs.certmanager.v1alpha2.ClusterIssuerSpecAcmeSolversHttp01IngressIngressTemplateMetadata;
        }

        /**
         * ObjectMeta overrides for the ingress used to solve HTTP01 challenges. Only the 'labels' and 'annotations' fields may be set. If labels or annotations overlap with in-built values, the values here will override the in-built values.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressIngressTemplateMetadata {
            /**
             * Annotations that should be added to the created ACME HTTP01 solver ingress.
             */
            annotations?: {[key: string]: string};
            /**
             * Labels that should be added to the created ACME HTTP01 solver ingress.
             */
            labels?: {[key: string]: string};
        }

        /**
         * Optional pod template used to configure the ACME challenge solver pods used for HTTP01 challenges
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplate {
            /**
             * ObjectMeta overrides for the pod used to solve HTTP01 challenges. Only the 'labels' and 'annotations' fields may be set. If labels or annotations overlap with in-built values, the values here will override the in-built values.
             */
            metadata?: outputs.certmanager.v1alpha2.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateMetadata;
            /**
             * PodSpec defines overrides for the HTTP01 challenge solver pod. Only the 'priorityClassName', 'nodeSelector', 'affinity', 'serviceAccountName' and 'tolerations' fields are supported currently. All other fields will be ignored.
             */
            spec?: outputs.certmanager.v1alpha2.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpec;
        }

        /**
         * ObjectMeta overrides for the pod used to solve HTTP01 challenges. Only the 'labels' and 'annotations' fields may be set. If labels or annotations overlap with in-built values, the values here will override the in-built values.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateMetadata {
            /**
             * Annotations that should be added to the create ACME HTTP01 solver pods.
             */
            annotations?: {[key: string]: string};
            /**
             * Labels that should be added to the created ACME HTTP01 solver pods.
             */
            labels?: {[key: string]: string};
        }

        /**
         * PodSpec defines overrides for the HTTP01 challenge solver pod. Only the 'priorityClassName', 'nodeSelector', 'affinity', 'serviceAccountName' and 'tolerations' fields are supported currently. All other fields will be ignored.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpec {
            /**
             * If specified, the pod's scheduling constraints
             */
            affinity?: outputs.certmanager.v1alpha2.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinity;
            /**
             * NodeSelector is a selector which must be true for the pod to fit on a node. Selector which must match a node's labels for the pod to be scheduled on that node. More info: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/
             */
            nodeSelector?: {[key: string]: string};
            /**
             * If specified, the pod's priorityClassName.
             */
            priorityClassName?: string;
            /**
             * If specified, the pod's service account
             */
            serviceAccountName?: string;
            /**
             * If specified, the pod's tolerations.
             */
            tolerations?: outputs.certmanager.v1alpha2.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecTolerations[];
        }

        /**
         * If specified, the pod's scheduling constraints
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinity {
            /**
             * Describes node affinity scheduling rules for the pod.
             */
            nodeAffinity?: outputs.certmanager.v1alpha2.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinity;
            /**
             * Describes pod affinity scheduling rules (e.g. co-locate this pod in the same node, zone, etc. as some other pod(s)).
             */
            podAffinity?: outputs.certmanager.v1alpha2.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinity;
            /**
             * Describes pod anti-affinity scheduling rules (e.g. avoid putting this pod in the same node, zone, etc. as some other pod(s)).
             */
            podAntiAffinity?: outputs.certmanager.v1alpha2.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinity;
        }

        /**
         * Describes node affinity scheduling rules for the pod.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinity {
            /**
             * The scheduler will prefer to schedule pods to nodes that satisfy the affinity expressions specified by this field, but it may choose a node that violates one or more of the expressions. The node that is most preferred is the one with the greatest sum of weights, i.e. for each node that meets all of the scheduling requirements (resource request, requiredDuringScheduling affinity expressions, etc.), compute a sum by iterating through the elements of this field and adding "weight" to the sum if the node matches the corresponding matchExpressions; the node(s) with the highest sum are the most preferred.
             */
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.certmanager.v1alpha2.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            /**
             * If the affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to an update), the system may or may not try to eventually evict the pod from its node.
             */
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.certmanager.v1alpha2.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution;
        }

        /**
         * An empty preferred scheduling term matches all objects with implicit weight 0 (i.e. it's a no-op). A null preferred scheduling term matches no objects (i.e. is also a no-op).
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            /**
             * A node selector term, associated with the corresponding weight.
             */
            preference: outputs.certmanager.v1alpha2.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference;
            /**
             * Weight associated with matching the corresponding nodeSelectorTerm, in the range 1-100.
             */
            weight: number;
        }

        /**
         * A node selector term, associated with the corresponding weight.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference {
            /**
             * A list of node selector requirements by node's labels.
             */
            matchExpressions?: outputs.certmanager.v1alpha2.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions[];
            /**
             * A list of node selector requirements by node's fields.
             */
            matchFields?: outputs.certmanager.v1alpha2.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields[];
        }

        /**
         * A node selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions {
            /**
             * The label key that the selector applies to.
             */
            key: string;
            /**
             * Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
             */
            operator: string;
            /**
             * An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * A node selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields {
            /**
             * The label key that the selector applies to.
             */
            key: string;
            /**
             * Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
             */
            operator: string;
            /**
             * An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * If the affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to an update), the system may or may not try to eventually evict the pod from its node.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            /**
             * Required. A list of node selector terms. The terms are ORed.
             */
            nodeSelectorTerms: outputs.certmanager.v1alpha2.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms[];
        }

        /**
         * A null or empty node selector term matches no objects. The requirements of them are ANDed. The TopologySelectorTerm type implements a subset of the NodeSelectorTerm.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms {
            /**
             * A list of node selector requirements by node's labels.
             */
            matchExpressions?: outputs.certmanager.v1alpha2.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions[];
            /**
             * A list of node selector requirements by node's fields.
             */
            matchFields?: outputs.certmanager.v1alpha2.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields[];
        }

        /**
         * A node selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions {
            /**
             * The label key that the selector applies to.
             */
            key: string;
            /**
             * Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
             */
            operator: string;
            /**
             * An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * A node selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields {
            /**
             * The label key that the selector applies to.
             */
            key: string;
            /**
             * Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
             */
            operator: string;
            /**
             * An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Describes pod affinity scheduling rules (e.g. co-locate this pod in the same node, zone, etc. as some other pod(s)).
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinity {
            /**
             * The scheduler will prefer to schedule pods to nodes that satisfy the affinity expressions specified by this field, but it may choose a node that violates one or more of the expressions. The node that is most preferred is the one with the greatest sum of weights, i.e. for each node that meets all of the scheduling requirements (resource request, requiredDuringScheduling affinity expressions, etc.), compute a sum by iterating through the elements of this field and adding "weight" to the sum if the node has pods which matches the corresponding podAffinityTerm; the node(s) with the highest sum are the most preferred.
             */
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.certmanager.v1alpha2.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            /**
             * If the affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to a pod label update), the system may or may not try to eventually evict the pod from its node. When there are multiple elements, the lists of nodes corresponding to each podAffinityTerm are intersected, i.e. all terms must be satisfied.
             */
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.certmanager.v1alpha2.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        /**
         * The weights of all of the matched WeightedPodAffinityTerm fields are added per-node to find the most preferred node(s)
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            /**
             * Required. A pod affinity term, associated with the corresponding weight.
             */
            podAffinityTerm: outputs.certmanager.v1alpha2.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            /**
             * weight associated with matching the corresponding podAffinityTerm, in the range 1-100.
             */
            weight: number;
        }

        /**
         * Required. A pod affinity term, associated with the corresponding weight.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            /**
             * A label query over a set of resources, in this case pods.
             */
            labelSelector?: outputs.certmanager.v1alpha2.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            /**
             * namespaces specifies which namespaces the labelSelector applies to (matches against); null or empty list means "this pod's namespace"
             */
            namespaces?: string[];
            /**
             * This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed.
             */
            topologyKey: string;
        }

        /**
         * A label query over a set of resources, in this case pods.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.certmanager.v1alpha2.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Defines a set of pods (namely those matching the labelSelector relative to the given namespace(s)) that this pod should be co-located (affinity) or not co-located (anti-affinity) with, where co-located is defined as running on a node whose value of the label with key <topologyKey> matches that of any node on which a pod of the set of pods is running
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            /**
             * A label query over a set of resources, in this case pods.
             */
            labelSelector?: outputs.certmanager.v1alpha2.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            /**
             * namespaces specifies which namespaces the labelSelector applies to (matches against); null or empty list means "this pod's namespace"
             */
            namespaces?: string[];
            /**
             * This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed.
             */
            topologyKey: string;
        }

        /**
         * A label query over a set of resources, in this case pods.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.certmanager.v1alpha2.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Describes pod anti-affinity scheduling rules (e.g. avoid putting this pod in the same node, zone, etc. as some other pod(s)).
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinity {
            /**
             * The scheduler will prefer to schedule pods to nodes that satisfy the anti-affinity expressions specified by this field, but it may choose a node that violates one or more of the expressions. The node that is most preferred is the one with the greatest sum of weights, i.e. for each node that meets all of the scheduling requirements (resource request, requiredDuringScheduling anti-affinity expressions, etc.), compute a sum by iterating through the elements of this field and adding "weight" to the sum if the node has pods which matches the corresponding podAffinityTerm; the node(s) with the highest sum are the most preferred.
             */
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.certmanager.v1alpha2.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            /**
             * If the anti-affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the anti-affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to a pod label update), the system may or may not try to eventually evict the pod from its node. When there are multiple elements, the lists of nodes corresponding to each podAffinityTerm are intersected, i.e. all terms must be satisfied.
             */
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.certmanager.v1alpha2.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        /**
         * The weights of all of the matched WeightedPodAffinityTerm fields are added per-node to find the most preferred node(s)
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            /**
             * Required. A pod affinity term, associated with the corresponding weight.
             */
            podAffinityTerm: outputs.certmanager.v1alpha2.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            /**
             * weight associated with matching the corresponding podAffinityTerm, in the range 1-100.
             */
            weight: number;
        }

        /**
         * Required. A pod affinity term, associated with the corresponding weight.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            /**
             * A label query over a set of resources, in this case pods.
             */
            labelSelector?: outputs.certmanager.v1alpha2.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            /**
             * namespaces specifies which namespaces the labelSelector applies to (matches against); null or empty list means "this pod's namespace"
             */
            namespaces?: string[];
            /**
             * This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed.
             */
            topologyKey: string;
        }

        /**
         * A label query over a set of resources, in this case pods.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.certmanager.v1alpha2.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Defines a set of pods (namely those matching the labelSelector relative to the given namespace(s)) that this pod should be co-located (affinity) or not co-located (anti-affinity) with, where co-located is defined as running on a node whose value of the label with key <topologyKey> matches that of any node on which a pod of the set of pods is running
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            /**
             * A label query over a set of resources, in this case pods.
             */
            labelSelector?: outputs.certmanager.v1alpha2.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            /**
             * namespaces specifies which namespaces the labelSelector applies to (matches against); null or empty list means "this pod's namespace"
             */
            namespaces?: string[];
            /**
             * This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed.
             */
            topologyKey: string;
        }

        /**
         * A label query over a set of resources, in this case pods.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.certmanager.v1alpha2.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * The pod this Toleration is attached to tolerates any taint that matches the triple <key,value,effect> using the matching operator <operator>.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecTolerations {
            /**
             * Effect indicates the taint effect to match. Empty means match all taint effects. When specified, allowed values are NoSchedule, PreferNoSchedule and NoExecute.
             */
            effect?: string;
            /**
             * Key is the taint key that the toleration applies to. Empty means match all taint keys. If the key is empty, operator must be Exists; this combination means to match all values and all keys.
             */
            key?: string;
            /**
             * Operator represents a key's relationship to the value. Valid operators are Exists and Equal. Defaults to Equal. Exists is equivalent to wildcard for value, so that a pod can tolerate all taints of a particular category.
             */
            operator?: string;
            /**
             * TolerationSeconds represents the period of time the toleration (which must be of effect NoExecute, otherwise this field is ignored) tolerates the taint. By default, it is not set, which means tolerate the taint forever (do not evict). Zero and negative values will be treated as 0 (evict immediately) by the system.
             */
            tolerationSeconds?: number;
            /**
             * Value is the taint value the toleration matches to. If the operator is Exists, the value should be empty, otherwise just a regular string.
             */
            value?: string;
        }

        /**
         * Selector selects a set of DNSNames on the Certificate resource that should be solved using this challenge solver. If not specified, the solver will be treated as the 'default' solver with the lowest priority, i.e. if any other solver has a more specific match, it will be used instead.
         */
        export interface ClusterIssuerSpecAcmeSolversSelector {
            /**
             * List of DNSNames that this solver will be used to solve. If specified and a match is found, a dnsNames selector will take precedence over a dnsZones selector. If multiple solvers match with the same dnsNames value, the solver with the most matching labels in matchLabels will be selected. If neither has more matches, the solver defined earlier in the list will be selected.
             */
            dnsNames?: string[];
            /**
             * List of DNSZones that this solver will be used to solve. The most specific DNS zone match specified here will take precedence over other DNS zone matches, so a solver specifying sys.example.com will be selected over one specifying example.com for the domain www.sys.example.com. If multiple solvers match with the same dnsZones value, the solver with the most matching labels in matchLabels will be selected. If neither has more matches, the solver defined earlier in the list will be selected.
             */
            dnsZones?: string[];
            /**
             * A label selector that is used to refine the set of certificate's that this challenge solver will apply to.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * CA configures this issuer to sign certificates using a signing CA keypair stored in a Secret resource. This is used to build internal PKIs that are managed by cert-manager.
         */
        export interface ClusterIssuerSpecCa {
            /**
             * The CRL distribution points is an X.509 v3 certificate extension which identifies the location of the CRL from which the revocation of this certificate can be checked. If not set, certificates will be issued without distribution points set.
             */
            crlDistributionPoints?: string[];
            /**
             * SecretName is the name of the secret used to sign Certificates issued by this Issuer.
             */
            secretName: string;
        }

        /**
         * SelfSigned configures this issuer to 'self sign' certificates using the private key used to create the CertificateRequest object.
         */
        export interface ClusterIssuerSpecSelfSigned {
            /**
             * The CRL distribution points is an X.509 v3 certificate extension which identifies the location of the CRL from which the revocation of this certificate can be checked. If not set certificate will be issued without CDP. Values are strings.
             */
            crlDistributionPoints?: string[];
        }

        /**
         * Vault configures this issuer to sign certificates using a HashiCorp Vault PKI backend.
         */
        export interface ClusterIssuerSpecVault {
            /**
             * Auth configures how cert-manager authenticates with the Vault server.
             */
            auth: outputs.certmanager.v1alpha2.ClusterIssuerSpecVaultAuth;
            /**
             * PEM encoded CA bundle used to validate Vault server certificate. Only used if the Server URL is using HTTPS protocol. This parameter is ignored for plain HTTP protocol connection. If not set the system root certificates are used to validate the TLS connection.
             */
            caBundle?: string;
            /**
             * Name of the vault namespace. Namespaces is a set of features within Vault Enterprise that allows Vault environments to support Secure Multi-tenancy. e.g: "ns1" More about namespaces can be found here https://www.vaultproject.io/docs/enterprise/namespaces
             */
            namespace?: string;
            /**
             * Path is the mount path of the Vault PKI backend's `sign` endpoint, e.g: "my_pki_mount/sign/my-role-name".
             */
            path: string;
            /**
             * Server is the connection address for the Vault server, e.g: "https://vault.example.com:8200".
             */
            server: string;
        }

        /**
         * Auth configures how cert-manager authenticates with the Vault server.
         */
        export interface ClusterIssuerSpecVaultAuth {
            /**
             * AppRole authenticates with Vault using the App Role auth mechanism, with the role and secret stored in a Kubernetes Secret resource.
             */
            appRole?: outputs.certmanager.v1alpha2.ClusterIssuerSpecVaultAuthAppRole;
            /**
             * Kubernetes authenticates with Vault by passing the ServiceAccount token stored in the named Secret resource to the Vault server.
             */
            kubernetes?: outputs.certmanager.v1alpha2.ClusterIssuerSpecVaultAuthKubernetes;
            /**
             * TokenSecretRef authenticates with Vault by presenting a token.
             */
            tokenSecretRef?: outputs.certmanager.v1alpha2.ClusterIssuerSpecVaultAuthTokenSecretRef;
        }

        /**
         * AppRole authenticates with Vault using the App Role auth mechanism, with the role and secret stored in a Kubernetes Secret resource.
         */
        export interface ClusterIssuerSpecVaultAuthAppRole {
            /**
             * Path where the App Role authentication backend is mounted in Vault, e.g: "approle"
             */
            path: string;
            /**
             * RoleID configured in the App Role authentication backend when setting up the authentication backend in Vault.
             */
            roleId: string;
            /**
             * Reference to a key in a Secret that contains the App Role secret used to authenticate with Vault. The `key` field must be specified and denotes which entry within the Secret resource is used as the app role secret.
             */
            secretRef: outputs.certmanager.v1alpha2.ClusterIssuerSpecVaultAuthAppRoleSecretRef;
        }

        /**
         * Reference to a key in a Secret that contains the App Role secret used to authenticate with Vault. The `key` field must be specified and denotes which entry within the Secret resource is used as the app role secret.
         */
        export interface ClusterIssuerSpecVaultAuthAppRoleSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Kubernetes authenticates with Vault by passing the ServiceAccount token stored in the named Secret resource to the Vault server.
         */
        export interface ClusterIssuerSpecVaultAuthKubernetes {
            /**
             * The Vault mountPath here is the mount path to use when authenticating with Vault. For example, setting a value to `/v1/auth/foo`, will use the path `/v1/auth/foo/login` to authenticate with Vault. If unspecified, the default value "/v1/auth/kubernetes" will be used.
             */
            mountPath?: string;
            /**
             * A required field containing the Vault Role to assume. A Role binds a Kubernetes ServiceAccount with a set of Vault policies.
             */
            role: string;
            /**
             * The required Secret field containing a Kubernetes ServiceAccount JWT used for authenticating with Vault. Use of 'ambient credentials' is not supported.
             */
            secretRef: outputs.certmanager.v1alpha2.ClusterIssuerSpecVaultAuthKubernetesSecretRef;
        }

        /**
         * The required Secret field containing a Kubernetes ServiceAccount JWT used for authenticating with Vault. Use of 'ambient credentials' is not supported.
         */
        export interface ClusterIssuerSpecVaultAuthKubernetesSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * TokenSecretRef authenticates with Vault by presenting a token.
         */
        export interface ClusterIssuerSpecVaultAuthTokenSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Venafi configures this issuer to sign certificates using a Venafi TPP or Venafi Cloud policy zone.
         */
        export interface ClusterIssuerSpecVenafi {
            /**
             * Cloud specifies the Venafi cloud configuration settings. Only one of TPP or Cloud may be specified.
             */
            cloud?: outputs.certmanager.v1alpha2.ClusterIssuerSpecVenafiCloud;
            /**
             * TPP specifies Trust Protection Platform configuration settings. Only one of TPP or Cloud may be specified.
             */
            tpp?: outputs.certmanager.v1alpha2.ClusterIssuerSpecVenafiTpp;
            /**
             * Zone is the Venafi Policy Zone to use for this issuer. All requests made to the Venafi platform will be restricted by the named zone policy. This field is required.
             */
            zone: string;
        }

        /**
         * Cloud specifies the Venafi cloud configuration settings. Only one of TPP or Cloud may be specified.
         */
        export interface ClusterIssuerSpecVenafiCloud {
            /**
             * APITokenSecretRef is a secret key selector for the Venafi Cloud API token.
             */
            apiTokenSecretRef: outputs.certmanager.v1alpha2.ClusterIssuerSpecVenafiCloudApiTokenSecretRef;
            /**
             * URL is the base URL for Venafi Cloud. Defaults to "https://api.venafi.cloud/v1".
             */
            url?: string;
        }

        /**
         * APITokenSecretRef is a secret key selector for the Venafi Cloud API token.
         */
        export interface ClusterIssuerSpecVenafiCloudApiTokenSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * TPP specifies Trust Protection Platform configuration settings. Only one of TPP or Cloud may be specified.
         */
        export interface ClusterIssuerSpecVenafiTpp {
            /**
             * CABundle is a PEM encoded TLS certificate to use to verify connections to the TPP instance. If specified, system roots will not be used and the issuing CA for the TPP instance must be verifiable using the provided root. If not specified, the connection will be verified using the cert-manager system root certificates.
             */
            caBundle?: string;
            /**
             * CredentialsRef is a reference to a Secret containing the username and password for the TPP server. The secret must contain two keys, 'username' and 'password'.
             */
            credentialsRef: outputs.certmanager.v1alpha2.ClusterIssuerSpecVenafiTppCredentialsRef;
            /**
             * URL is the base URL for the vedsdk endpoint of the Venafi TPP instance, for example: "https://tpp.example.com/vedsdk".
             */
            url: string;
        }

        /**
         * CredentialsRef is a reference to a Secret containing the username and password for the TPP server. The secret must contain two keys, 'username' and 'password'.
         */
        export interface ClusterIssuerSpecVenafiTppCredentialsRef {
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Status of the ClusterIssuer. This is set and managed automatically.
         */
        export interface ClusterIssuerStatus {
            /**
             * ACME specific status options. This field should only be set if the Issuer is configured to use an ACME server to issue certificates.
             */
            acme?: outputs.certmanager.v1alpha2.ClusterIssuerStatusAcme;
            /**
             * List of status conditions to indicate the status of a CertificateRequest. Known condition types are `Ready`.
             */
            conditions?: outputs.certmanager.v1alpha2.ClusterIssuerStatusConditions[];
        }

        /**
         * ACME specific status options. This field should only be set if the Issuer is configured to use an ACME server to issue certificates.
         */
        export interface ClusterIssuerStatusAcme {
            /**
             * LastRegisteredEmail is the email associated with the latest registered ACME account, in order to track changes made to registered account associated with the  Issuer
             */
            lastRegisteredEmail?: string;
            /**
             * URI is the unique account identifier, which can also be used to retrieve account details from the CA
             */
            uri?: string;
        }

        /**
         * IssuerCondition contains condition information for an Issuer.
         */
        export interface ClusterIssuerStatusConditions {
            /**
             * LastTransitionTime is the timestamp corresponding to the last status change of this condition.
             */
            lastTransitionTime?: string;
            /**
             * Message is a human readable description of the details of the last transition, complementing reason.
             */
            message?: string;
            /**
             * Reason is a brief machine readable explanation for the condition's last transition.
             */
            reason?: string;
            /**
             * Status of the condition, one of ('True', 'False', 'Unknown').
             */
            status: string;
            /**
             * Type of the condition, known values are ('Ready').
             */
            type: string;
        }

        /**
         * Desired state of the Issuer resource.
         */
        export interface IssuerSpec {
            /**
             * ACME configures this issuer to communicate with a RFC8555 (ACME) server to obtain signed x509 certificates.
             */
            acme?: outputs.certmanager.v1alpha2.IssuerSpecAcme;
            /**
             * CA configures this issuer to sign certificates using a signing CA keypair stored in a Secret resource. This is used to build internal PKIs that are managed by cert-manager.
             */
            ca?: outputs.certmanager.v1alpha2.IssuerSpecCa;
            /**
             * SelfSigned configures this issuer to 'self sign' certificates using the private key used to create the CertificateRequest object.
             */
            selfSigned?: outputs.certmanager.v1alpha2.IssuerSpecSelfSigned;
            /**
             * Vault configures this issuer to sign certificates using a HashiCorp Vault PKI backend.
             */
            vault?: outputs.certmanager.v1alpha2.IssuerSpecVault;
            /**
             * Venafi configures this issuer to sign certificates using a Venafi TPP or Venafi Cloud policy zone.
             */
            venafi?: outputs.certmanager.v1alpha2.IssuerSpecVenafi;
        }

        /**
         * ACME configures this issuer to communicate with a RFC8555 (ACME) server to obtain signed x509 certificates.
         */
        export interface IssuerSpecAcme {
            /**
             * Enables or disables generating a new ACME account key. If true, the Issuer resource will *not* request a new account but will expect the account key to be supplied via an existing secret. If false, the cert-manager system will generate a new ACME account key for the Issuer. Defaults to false.
             */
            disableAccountKeyGeneration?: boolean;
            /**
             * Email is the email address to be associated with the ACME account. This field is optional, but it is strongly recommended to be set. It will be used to contact you in case of issues with your account or certificates, including expiry notification emails. This field may be updated after the account is initially registered.
             */
            email?: string;
            /**
             * Enables requesting a Not After date on certificates that matches the duration of the certificate. This is not supported by all ACME servers like Let's Encrypt. If set to true when the ACME server does not support it it will create an error on the Order. Defaults to false.
             */
            enableDurationFeature?: boolean;
            /**
             * ExternalAccountBinding is a reference to a CA external account of the ACME server. If set, upon registration cert-manager will attempt to associate the given external account credentials with the registered ACME account.
             */
            externalAccountBinding?: outputs.certmanager.v1alpha2.IssuerSpecAcmeExternalAccountBinding;
            /**
             * PreferredChain is the chain to use if the ACME server outputs multiple. PreferredChain is no guarantee that this one gets delivered by the ACME endpoint. For example, for Let's Encrypt's DST crosssign you would use: "DST Root CA X3" or "ISRG Root X1" for the newer Let's Encrypt root CA. This value picks the first certificate bundle in the ACME alternative chains that has a certificate with this value as its issuer's CN
             */
            preferredChain?: string;
            /**
             * PrivateKey is the name of a Kubernetes Secret resource that will be used to store the automatically generated ACME account private key. Optionally, a `key` may be specified to select a specific entry within the named Secret resource. If `key` is not specified, a default of `tls.key` will be used.
             */
            privateKeySecretRef: outputs.certmanager.v1alpha2.IssuerSpecAcmePrivateKeySecretRef;
            /**
             * Server is the URL used to access the ACME server's 'directory' endpoint. For example, for Let's Encrypt's staging endpoint, you would use: "https://acme-staging-v02.api.letsencrypt.org/directory". Only ACME v2 endpoints (i.e. RFC 8555) are supported.
             */
            server: string;
            /**
             * Enables or disables validation of the ACME server TLS certificate. If true, requests to the ACME server will not have their TLS certificate validated (i.e. insecure connections will be allowed). Only enable this option in development environments. The cert-manager system installed roots will be used to verify connections to the ACME server if this is false. Defaults to false.
             */
            skipTLSVerify?: boolean;
            /**
             * Solvers is a list of challenge solvers that will be used to solve ACME challenges for the matching domains. Solver configurations must be provided in order to obtain certificates from an ACME server. For more information, see: https://cert-manager.io/docs/configuration/acme/
             */
            solvers?: outputs.certmanager.v1alpha2.IssuerSpecAcmeSolvers[];
        }

        /**
         * ExternalAccountBinding is a reference to a CA external account of the ACME server. If set, upon registration cert-manager will attempt to associate the given external account credentials with the registered ACME account.
         */
        export interface IssuerSpecAcmeExternalAccountBinding {
            /**
             * keyAlgorithm is the MAC key algorithm that the key is used for. Valid values are "HS256", "HS384" and "HS512".
             */
            keyAlgorithm: string;
            /**
             * keyID is the ID of the CA key that the External Account is bound to.
             */
            keyID: string;
            /**
             * keySecretRef is a Secret Key Selector referencing a data item in a Kubernetes Secret which holds the symmetric MAC key of the External Account Binding. The `key` is the index string that is paired with the key data in the Secret and should not be confused with the key data itself, or indeed with the External Account Binding keyID above. The secret key stored in the Secret **must** be un-padded, base64 URL encoded data.
             */
            keySecretRef: outputs.certmanager.v1alpha2.IssuerSpecAcmeExternalAccountBindingKeySecretRef;
        }

        /**
         * keySecretRef is a Secret Key Selector referencing a data item in a Kubernetes Secret which holds the symmetric MAC key of the External Account Binding. The `key` is the index string that is paired with the key data in the Secret and should not be confused with the key data itself, or indeed with the External Account Binding keyID above. The secret key stored in the Secret **must** be un-padded, base64 URL encoded data.
         */
        export interface IssuerSpecAcmeExternalAccountBindingKeySecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * PrivateKey is the name of a Kubernetes Secret resource that will be used to store the automatically generated ACME account private key. Optionally, a `key` may be specified to select a specific entry within the named Secret resource. If `key` is not specified, a default of `tls.key` will be used.
         */
        export interface IssuerSpecAcmePrivateKeySecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Configures an issuer to solve challenges using the specified options. Only one of HTTP01 or DNS01 may be provided.
         */
        export interface IssuerSpecAcmeSolvers {
            /**
             * Configures cert-manager to attempt to complete authorizations by performing the DNS01 challenge flow.
             */
            dns01?: outputs.certmanager.v1alpha2.IssuerSpecAcmeSolversDns01;
            /**
             * Configures cert-manager to attempt to complete authorizations by performing the HTTP01 challenge flow. It is not possible to obtain certificates for wildcard domain names (e.g. `*.example.com`) using the HTTP01 challenge mechanism.
             */
            http01?: outputs.certmanager.v1alpha2.IssuerSpecAcmeSolversHttp01;
            /**
             * Selector selects a set of DNSNames on the Certificate resource that should be solved using this challenge solver. If not specified, the solver will be treated as the 'default' solver with the lowest priority, i.e. if any other solver has a more specific match, it will be used instead.
             */
            selector?: outputs.certmanager.v1alpha2.IssuerSpecAcmeSolversSelector;
        }

        /**
         * Configures cert-manager to attempt to complete authorizations by performing the DNS01 challenge flow.
         */
        export interface IssuerSpecAcmeSolversDns01 {
            /**
             * Use the 'ACME DNS' (https://github.com/joohoi/acme-dns) API to manage DNS01 challenge records.
             */
            acmedns?: outputs.certmanager.v1alpha2.IssuerSpecAcmeSolversDns01Acmedns;
            /**
             * Use the Akamai DNS zone management API to manage DNS01 challenge records.
             */
            akamai?: outputs.certmanager.v1alpha2.IssuerSpecAcmeSolversDns01Akamai;
            /**
             * Use the Microsoft Azure DNS API to manage DNS01 challenge records.
             */
            azuredns?: outputs.certmanager.v1alpha2.IssuerSpecAcmeSolversDns01Azuredns;
            /**
             * Use the Google Cloud DNS API to manage DNS01 challenge records.
             */
            clouddns?: outputs.certmanager.v1alpha2.IssuerSpecAcmeSolversDns01Clouddns;
            /**
             * Use the Cloudflare API to manage DNS01 challenge records.
             */
            cloudflare?: outputs.certmanager.v1alpha2.IssuerSpecAcmeSolversDns01Cloudflare;
            /**
             * CNAMEStrategy configures how the DNS01 provider should handle CNAME records when found in DNS zones.
             */
            cnameStrategy?: string;
            /**
             * Use the DigitalOcean DNS API to manage DNS01 challenge records.
             */
            digitalocean?: outputs.certmanager.v1alpha2.IssuerSpecAcmeSolversDns01Digitalocean;
            /**
             * Use RFC2136 ("Dynamic Updates in the Domain Name System") (https://datatracker.ietf.org/doc/rfc2136/) to manage DNS01 challenge records.
             */
            rfc2136?: outputs.certmanager.v1alpha2.IssuerSpecAcmeSolversDns01Rfc2136;
            /**
             * Use the AWS Route53 API to manage DNS01 challenge records.
             */
            route53?: outputs.certmanager.v1alpha2.IssuerSpecAcmeSolversDns01Route53;
            /**
             * Configure an external webhook based DNS01 challenge solver to manage DNS01 challenge records.
             */
            webhook?: outputs.certmanager.v1alpha2.IssuerSpecAcmeSolversDns01Webhook;
        }

        /**
         * Use the 'ACME DNS' (https://github.com/joohoi/acme-dns) API to manage DNS01 challenge records.
         */
        export interface IssuerSpecAcmeSolversDns01Acmedns {
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            accountSecretRef: outputs.certmanager.v1alpha2.IssuerSpecAcmeSolversDns01AcmednsAccountSecretRef;
            host: string;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface IssuerSpecAcmeSolversDns01AcmednsAccountSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the Akamai DNS zone management API to manage DNS01 challenge records.
         */
        export interface IssuerSpecAcmeSolversDns01Akamai {
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            accessTokenSecretRef: outputs.certmanager.v1alpha2.IssuerSpecAcmeSolversDns01AkamaiAccessTokenSecretRef;
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            clientSecretSecretRef: outputs.certmanager.v1alpha2.IssuerSpecAcmeSolversDns01AkamaiClientSecretSecretRef;
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            clientTokenSecretRef: outputs.certmanager.v1alpha2.IssuerSpecAcmeSolversDns01AkamaiClientTokenSecretRef;
            serviceConsumerDomain: string;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface IssuerSpecAcmeSolversDns01AkamaiAccessTokenSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface IssuerSpecAcmeSolversDns01AkamaiClientSecretSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface IssuerSpecAcmeSolversDns01AkamaiClientTokenSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the Microsoft Azure DNS API to manage DNS01 challenge records.
         */
        export interface IssuerSpecAcmeSolversDns01Azuredns {
            /**
             * if both this and ClientSecret are left unset MSI will be used
             */
            clientID?: string;
            /**
             * if both this and ClientID are left unset MSI will be used
             */
            clientSecretSecretRef?: outputs.certmanager.v1alpha2.IssuerSpecAcmeSolversDns01AzurednsClientSecretSecretRef;
            environment?: string;
            hostedZoneName?: string;
            resourceGroupName: string;
            subscriptionID: string;
            /**
             * when specifying ClientID and ClientSecret then this field is also needed
             */
            tenantID?: string;
        }

        /**
         * if both this and ClientID are left unset MSI will be used
         */
        export interface IssuerSpecAcmeSolversDns01AzurednsClientSecretSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the Google Cloud DNS API to manage DNS01 challenge records.
         */
        export interface IssuerSpecAcmeSolversDns01Clouddns {
            /**
             * HostedZoneName is an optional field that tells cert-manager in which Cloud DNS zone the challenge record has to be created. If left empty cert-manager will automatically choose a zone.
             */
            hostedZoneName?: string;
            project: string;
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            serviceAccountSecretRef?: outputs.certmanager.v1alpha2.IssuerSpecAcmeSolversDns01ClouddnsServiceAccountSecretRef;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface IssuerSpecAcmeSolversDns01ClouddnsServiceAccountSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the Cloudflare API to manage DNS01 challenge records.
         */
        export interface IssuerSpecAcmeSolversDns01Cloudflare {
            /**
             * API key to use to authenticate with Cloudflare. Note: using an API token to authenticate is now the recommended method as it allows greater control of permissions.
             */
            apiKeySecretRef?: outputs.certmanager.v1alpha2.IssuerSpecAcmeSolversDns01CloudflareApiKeySecretRef;
            /**
             * API token used to authenticate with Cloudflare.
             */
            apiTokenSecretRef?: outputs.certmanager.v1alpha2.IssuerSpecAcmeSolversDns01CloudflareApiTokenSecretRef;
            /**
             * Email of the account, only required when using API key based authentication.
             */
            email?: string;
        }

        /**
         * API key to use to authenticate with Cloudflare. Note: using an API token to authenticate is now the recommended method as it allows greater control of permissions.
         */
        export interface IssuerSpecAcmeSolversDns01CloudflareApiKeySecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * API token used to authenticate with Cloudflare.
         */
        export interface IssuerSpecAcmeSolversDns01CloudflareApiTokenSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the DigitalOcean DNS API to manage DNS01 challenge records.
         */
        export interface IssuerSpecAcmeSolversDns01Digitalocean {
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            tokenSecretRef: outputs.certmanager.v1alpha2.IssuerSpecAcmeSolversDns01DigitaloceanTokenSecretRef;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface IssuerSpecAcmeSolversDns01DigitaloceanTokenSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use RFC2136 ("Dynamic Updates in the Domain Name System") (https://datatracker.ietf.org/doc/rfc2136/) to manage DNS01 challenge records.
         */
        export interface IssuerSpecAcmeSolversDns01Rfc2136 {
            /**
             * The IP address or hostname of an authoritative DNS server supporting RFC2136 in the form host:port. If the host is an IPv6 address it must be enclosed in square brackets (e.g [2001:db8::1]) ; port is optional. This field is required.
             */
            nameserver: string;
            /**
             * The TSIG Algorithm configured in the DNS supporting RFC2136. Used only when ``tsigSecretSecretRef`` and ``tsigKeyName`` are defined. Supported values are (case-insensitive): ``HMACMD5`` (default), ``HMACSHA1``, ``HMACSHA256`` or ``HMACSHA512``.
             */
            tsigAlgorithm?: string;
            /**
             * The TSIG Key name configured in the DNS. If ``tsigSecretSecretRef`` is defined, this field is required.
             */
            tsigKeyName?: string;
            /**
             * The name of the secret containing the TSIG value. If ``tsigKeyName`` is defined, this field is required.
             */
            tsigSecretSecretRef?: outputs.certmanager.v1alpha2.IssuerSpecAcmeSolversDns01Rfc2136TsigSecretSecretRef;
        }

        /**
         * The name of the secret containing the TSIG value. If ``tsigKeyName`` is defined, this field is required.
         */
        export interface IssuerSpecAcmeSolversDns01Rfc2136TsigSecretSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the AWS Route53 API to manage DNS01 challenge records.
         */
        export interface IssuerSpecAcmeSolversDns01Route53 {
            /**
             * The AccessKeyID is used for authentication. If not set we fall-back to using env vars, shared credentials file or AWS Instance metadata see: https://docs.aws.amazon.com/sdk-for-go/v1/developer-guide/configuring-sdk.html#specifying-credentials
             */
            accessKeyID?: string;
            /**
             * If set, the provider will manage only this zone in Route53 and will not do an lookup using the route53:ListHostedZonesByName api call.
             */
            hostedZoneID?: string;
            /**
             * Always set the region when using AccessKeyID and SecretAccessKey
             */
            region: string;
            /**
             * Role is a Role ARN which the Route53 provider will assume using either the explicit credentials AccessKeyID/SecretAccessKey or the inferred credentials from environment variables, shared credentials file or AWS Instance metadata
             */
            role?: string;
            /**
             * The SecretAccessKey is used for authentication. If not set we fall-back to using env vars, shared credentials file or AWS Instance metadata https://docs.aws.amazon.com/sdk-for-go/v1/developer-guide/configuring-sdk.html#specifying-credentials
             */
            secretAccessKeySecretRef?: outputs.certmanager.v1alpha2.IssuerSpecAcmeSolversDns01Route53SecretAccessKeySecretRef;
        }

        /**
         * The SecretAccessKey is used for authentication. If not set we fall-back to using env vars, shared credentials file or AWS Instance metadata https://docs.aws.amazon.com/sdk-for-go/v1/developer-guide/configuring-sdk.html#specifying-credentials
         */
        export interface IssuerSpecAcmeSolversDns01Route53SecretAccessKeySecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Configure an external webhook based DNS01 challenge solver to manage DNS01 challenge records.
         */
        export interface IssuerSpecAcmeSolversDns01Webhook {
            /**
             * Additional configuration that should be passed to the webhook apiserver when challenges are processed. This can contain arbitrary JSON data. Secret values should not be specified in this stanza. If secret values are needed (e.g. credentials for a DNS service), you should use a SecretKeySelector to reference a Secret resource. For details on the schema of this field, consult the webhook provider implementation's documentation.
             */
            config?: {[key: string]: any};
            /**
             * The API group name that should be used when POSTing ChallengePayload resources to the webhook apiserver. This should be the same as the GroupName specified in the webhook provider implementation.
             */
            groupName: string;
            /**
             * The name of the solver to use, as defined in the webhook provider implementation. This will typically be the name of the provider, e.g. 'cloudflare'.
             */
            solverName: string;
        }

        /**
         * Configures cert-manager to attempt to complete authorizations by performing the HTTP01 challenge flow. It is not possible to obtain certificates for wildcard domain names (e.g. `*.example.com`) using the HTTP01 challenge mechanism.
         */
        export interface IssuerSpecAcmeSolversHttp01 {
            /**
             * The ingress based HTTP01 challenge solver will solve challenges by creating or modifying Ingress resources in order to route requests for '/.well-known/acme-challenge/XYZ' to 'challenge solver' pods that are provisioned by cert-manager for each Challenge to be completed.
             */
            ingress?: outputs.certmanager.v1alpha2.IssuerSpecAcmeSolversHttp01Ingress;
        }

        /**
         * The ingress based HTTP01 challenge solver will solve challenges by creating or modifying Ingress resources in order to route requests for '/.well-known/acme-challenge/XYZ' to 'challenge solver' pods that are provisioned by cert-manager for each Challenge to be completed.
         */
        export interface IssuerSpecAcmeSolversHttp01Ingress {
            /**
             * The ingress class to use when creating Ingress resources to solve ACME challenges that use this challenge solver. Only one of 'class' or 'name' may be specified.
             */
            class?: string;
            /**
             * Optional ingress template used to configure the ACME challenge solver ingress used for HTTP01 challenges
             */
            ingressTemplate?: outputs.certmanager.v1alpha2.IssuerSpecAcmeSolversHttp01IngressIngressTemplate;
            /**
             * The name of the ingress resource that should have ACME challenge solving routes inserted into it in order to solve HTTP01 challenges. This is typically used in conjunction with ingress controllers like ingress-gce, which maintains a 1:1 mapping between external IPs and ingress resources.
             */
            name?: string;
            /**
             * Optional pod template used to configure the ACME challenge solver pods used for HTTP01 challenges
             */
            podTemplate?: outputs.certmanager.v1alpha2.IssuerSpecAcmeSolversHttp01IngressPodTemplate;
            /**
             * Optional service type for Kubernetes solver service
             */
            serviceType?: string;
        }

        /**
         * Optional ingress template used to configure the ACME challenge solver ingress used for HTTP01 challenges
         */
        export interface IssuerSpecAcmeSolversHttp01IngressIngressTemplate {
            /**
             * ObjectMeta overrides for the ingress used to solve HTTP01 challenges. Only the 'labels' and 'annotations' fields may be set. If labels or annotations overlap with in-built values, the values here will override the in-built values.
             */
            metadata?: outputs.certmanager.v1alpha2.IssuerSpecAcmeSolversHttp01IngressIngressTemplateMetadata;
        }

        /**
         * ObjectMeta overrides for the ingress used to solve HTTP01 challenges. Only the 'labels' and 'annotations' fields may be set. If labels or annotations overlap with in-built values, the values here will override the in-built values.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressIngressTemplateMetadata {
            /**
             * Annotations that should be added to the created ACME HTTP01 solver ingress.
             */
            annotations?: {[key: string]: string};
            /**
             * Labels that should be added to the created ACME HTTP01 solver ingress.
             */
            labels?: {[key: string]: string};
        }

        /**
         * Optional pod template used to configure the ACME challenge solver pods used for HTTP01 challenges
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplate {
            /**
             * ObjectMeta overrides for the pod used to solve HTTP01 challenges. Only the 'labels' and 'annotations' fields may be set. If labels or annotations overlap with in-built values, the values here will override the in-built values.
             */
            metadata?: outputs.certmanager.v1alpha2.IssuerSpecAcmeSolversHttp01IngressPodTemplateMetadata;
            /**
             * PodSpec defines overrides for the HTTP01 challenge solver pod. Only the 'priorityClassName', 'nodeSelector', 'affinity', 'serviceAccountName' and 'tolerations' fields are supported currently. All other fields will be ignored.
             */
            spec?: outputs.certmanager.v1alpha2.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpec;
        }

        /**
         * ObjectMeta overrides for the pod used to solve HTTP01 challenges. Only the 'labels' and 'annotations' fields may be set. If labels or annotations overlap with in-built values, the values here will override the in-built values.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateMetadata {
            /**
             * Annotations that should be added to the create ACME HTTP01 solver pods.
             */
            annotations?: {[key: string]: string};
            /**
             * Labels that should be added to the created ACME HTTP01 solver pods.
             */
            labels?: {[key: string]: string};
        }

        /**
         * PodSpec defines overrides for the HTTP01 challenge solver pod. Only the 'priorityClassName', 'nodeSelector', 'affinity', 'serviceAccountName' and 'tolerations' fields are supported currently. All other fields will be ignored.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpec {
            /**
             * If specified, the pod's scheduling constraints
             */
            affinity?: outputs.certmanager.v1alpha2.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinity;
            /**
             * NodeSelector is a selector which must be true for the pod to fit on a node. Selector which must match a node's labels for the pod to be scheduled on that node. More info: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/
             */
            nodeSelector?: {[key: string]: string};
            /**
             * If specified, the pod's priorityClassName.
             */
            priorityClassName?: string;
            /**
             * If specified, the pod's service account
             */
            serviceAccountName?: string;
            /**
             * If specified, the pod's tolerations.
             */
            tolerations?: outputs.certmanager.v1alpha2.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecTolerations[];
        }

        /**
         * If specified, the pod's scheduling constraints
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinity {
            /**
             * Describes node affinity scheduling rules for the pod.
             */
            nodeAffinity?: outputs.certmanager.v1alpha2.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinity;
            /**
             * Describes pod affinity scheduling rules (e.g. co-locate this pod in the same node, zone, etc. as some other pod(s)).
             */
            podAffinity?: outputs.certmanager.v1alpha2.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinity;
            /**
             * Describes pod anti-affinity scheduling rules (e.g. avoid putting this pod in the same node, zone, etc. as some other pod(s)).
             */
            podAntiAffinity?: outputs.certmanager.v1alpha2.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinity;
        }

        /**
         * Describes node affinity scheduling rules for the pod.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinity {
            /**
             * The scheduler will prefer to schedule pods to nodes that satisfy the affinity expressions specified by this field, but it may choose a node that violates one or more of the expressions. The node that is most preferred is the one with the greatest sum of weights, i.e. for each node that meets all of the scheduling requirements (resource request, requiredDuringScheduling affinity expressions, etc.), compute a sum by iterating through the elements of this field and adding "weight" to the sum if the node matches the corresponding matchExpressions; the node(s) with the highest sum are the most preferred.
             */
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.certmanager.v1alpha2.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            /**
             * If the affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to an update), the system may or may not try to eventually evict the pod from its node.
             */
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.certmanager.v1alpha2.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution;
        }

        /**
         * An empty preferred scheduling term matches all objects with implicit weight 0 (i.e. it's a no-op). A null preferred scheduling term matches no objects (i.e. is also a no-op).
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            /**
             * A node selector term, associated with the corresponding weight.
             */
            preference: outputs.certmanager.v1alpha2.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference;
            /**
             * Weight associated with matching the corresponding nodeSelectorTerm, in the range 1-100.
             */
            weight: number;
        }

        /**
         * A node selector term, associated with the corresponding weight.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference {
            /**
             * A list of node selector requirements by node's labels.
             */
            matchExpressions?: outputs.certmanager.v1alpha2.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions[];
            /**
             * A list of node selector requirements by node's fields.
             */
            matchFields?: outputs.certmanager.v1alpha2.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields[];
        }

        /**
         * A node selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions {
            /**
             * The label key that the selector applies to.
             */
            key: string;
            /**
             * Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
             */
            operator: string;
            /**
             * An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * A node selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields {
            /**
             * The label key that the selector applies to.
             */
            key: string;
            /**
             * Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
             */
            operator: string;
            /**
             * An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * If the affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to an update), the system may or may not try to eventually evict the pod from its node.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            /**
             * Required. A list of node selector terms. The terms are ORed.
             */
            nodeSelectorTerms: outputs.certmanager.v1alpha2.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms[];
        }

        /**
         * A null or empty node selector term matches no objects. The requirements of them are ANDed. The TopologySelectorTerm type implements a subset of the NodeSelectorTerm.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms {
            /**
             * A list of node selector requirements by node's labels.
             */
            matchExpressions?: outputs.certmanager.v1alpha2.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions[];
            /**
             * A list of node selector requirements by node's fields.
             */
            matchFields?: outputs.certmanager.v1alpha2.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields[];
        }

        /**
         * A node selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions {
            /**
             * The label key that the selector applies to.
             */
            key: string;
            /**
             * Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
             */
            operator: string;
            /**
             * An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * A node selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields {
            /**
             * The label key that the selector applies to.
             */
            key: string;
            /**
             * Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
             */
            operator: string;
            /**
             * An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Describes pod affinity scheduling rules (e.g. co-locate this pod in the same node, zone, etc. as some other pod(s)).
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinity {
            /**
             * The scheduler will prefer to schedule pods to nodes that satisfy the affinity expressions specified by this field, but it may choose a node that violates one or more of the expressions. The node that is most preferred is the one with the greatest sum of weights, i.e. for each node that meets all of the scheduling requirements (resource request, requiredDuringScheduling affinity expressions, etc.), compute a sum by iterating through the elements of this field and adding "weight" to the sum if the node has pods which matches the corresponding podAffinityTerm; the node(s) with the highest sum are the most preferred.
             */
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.certmanager.v1alpha2.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            /**
             * If the affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to a pod label update), the system may or may not try to eventually evict the pod from its node. When there are multiple elements, the lists of nodes corresponding to each podAffinityTerm are intersected, i.e. all terms must be satisfied.
             */
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.certmanager.v1alpha2.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        /**
         * The weights of all of the matched WeightedPodAffinityTerm fields are added per-node to find the most preferred node(s)
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            /**
             * Required. A pod affinity term, associated with the corresponding weight.
             */
            podAffinityTerm: outputs.certmanager.v1alpha2.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            /**
             * weight associated with matching the corresponding podAffinityTerm, in the range 1-100.
             */
            weight: number;
        }

        /**
         * Required. A pod affinity term, associated with the corresponding weight.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            /**
             * A label query over a set of resources, in this case pods.
             */
            labelSelector?: outputs.certmanager.v1alpha2.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            /**
             * namespaces specifies which namespaces the labelSelector applies to (matches against); null or empty list means "this pod's namespace"
             */
            namespaces?: string[];
            /**
             * This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed.
             */
            topologyKey: string;
        }

        /**
         * A label query over a set of resources, in this case pods.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.certmanager.v1alpha2.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Defines a set of pods (namely those matching the labelSelector relative to the given namespace(s)) that this pod should be co-located (affinity) or not co-located (anti-affinity) with, where co-located is defined as running on a node whose value of the label with key <topologyKey> matches that of any node on which a pod of the set of pods is running
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            /**
             * A label query over a set of resources, in this case pods.
             */
            labelSelector?: outputs.certmanager.v1alpha2.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            /**
             * namespaces specifies which namespaces the labelSelector applies to (matches against); null or empty list means "this pod's namespace"
             */
            namespaces?: string[];
            /**
             * This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed.
             */
            topologyKey: string;
        }

        /**
         * A label query over a set of resources, in this case pods.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.certmanager.v1alpha2.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Describes pod anti-affinity scheduling rules (e.g. avoid putting this pod in the same node, zone, etc. as some other pod(s)).
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinity {
            /**
             * The scheduler will prefer to schedule pods to nodes that satisfy the anti-affinity expressions specified by this field, but it may choose a node that violates one or more of the expressions. The node that is most preferred is the one with the greatest sum of weights, i.e. for each node that meets all of the scheduling requirements (resource request, requiredDuringScheduling anti-affinity expressions, etc.), compute a sum by iterating through the elements of this field and adding "weight" to the sum if the node has pods which matches the corresponding podAffinityTerm; the node(s) with the highest sum are the most preferred.
             */
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.certmanager.v1alpha2.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            /**
             * If the anti-affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the anti-affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to a pod label update), the system may or may not try to eventually evict the pod from its node. When there are multiple elements, the lists of nodes corresponding to each podAffinityTerm are intersected, i.e. all terms must be satisfied.
             */
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.certmanager.v1alpha2.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        /**
         * The weights of all of the matched WeightedPodAffinityTerm fields are added per-node to find the most preferred node(s)
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            /**
             * Required. A pod affinity term, associated with the corresponding weight.
             */
            podAffinityTerm: outputs.certmanager.v1alpha2.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            /**
             * weight associated with matching the corresponding podAffinityTerm, in the range 1-100.
             */
            weight: number;
        }

        /**
         * Required. A pod affinity term, associated with the corresponding weight.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            /**
             * A label query over a set of resources, in this case pods.
             */
            labelSelector?: outputs.certmanager.v1alpha2.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            /**
             * namespaces specifies which namespaces the labelSelector applies to (matches against); null or empty list means "this pod's namespace"
             */
            namespaces?: string[];
            /**
             * This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed.
             */
            topologyKey: string;
        }

        /**
         * A label query over a set of resources, in this case pods.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.certmanager.v1alpha2.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Defines a set of pods (namely those matching the labelSelector relative to the given namespace(s)) that this pod should be co-located (affinity) or not co-located (anti-affinity) with, where co-located is defined as running on a node whose value of the label with key <topologyKey> matches that of any node on which a pod of the set of pods is running
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            /**
             * A label query over a set of resources, in this case pods.
             */
            labelSelector?: outputs.certmanager.v1alpha2.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            /**
             * namespaces specifies which namespaces the labelSelector applies to (matches against); null or empty list means "this pod's namespace"
             */
            namespaces?: string[];
            /**
             * This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed.
             */
            topologyKey: string;
        }

        /**
         * A label query over a set of resources, in this case pods.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.certmanager.v1alpha2.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * The pod this Toleration is attached to tolerates any taint that matches the triple <key,value,effect> using the matching operator <operator>.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecTolerations {
            /**
             * Effect indicates the taint effect to match. Empty means match all taint effects. When specified, allowed values are NoSchedule, PreferNoSchedule and NoExecute.
             */
            effect?: string;
            /**
             * Key is the taint key that the toleration applies to. Empty means match all taint keys. If the key is empty, operator must be Exists; this combination means to match all values and all keys.
             */
            key?: string;
            /**
             * Operator represents a key's relationship to the value. Valid operators are Exists and Equal. Defaults to Equal. Exists is equivalent to wildcard for value, so that a pod can tolerate all taints of a particular category.
             */
            operator?: string;
            /**
             * TolerationSeconds represents the period of time the toleration (which must be of effect NoExecute, otherwise this field is ignored) tolerates the taint. By default, it is not set, which means tolerate the taint forever (do not evict). Zero and negative values will be treated as 0 (evict immediately) by the system.
             */
            tolerationSeconds?: number;
            /**
             * Value is the taint value the toleration matches to. If the operator is Exists, the value should be empty, otherwise just a regular string.
             */
            value?: string;
        }

        /**
         * Selector selects a set of DNSNames on the Certificate resource that should be solved using this challenge solver. If not specified, the solver will be treated as the 'default' solver with the lowest priority, i.e. if any other solver has a more specific match, it will be used instead.
         */
        export interface IssuerSpecAcmeSolversSelector {
            /**
             * List of DNSNames that this solver will be used to solve. If specified and a match is found, a dnsNames selector will take precedence over a dnsZones selector. If multiple solvers match with the same dnsNames value, the solver with the most matching labels in matchLabels will be selected. If neither has more matches, the solver defined earlier in the list will be selected.
             */
            dnsNames?: string[];
            /**
             * List of DNSZones that this solver will be used to solve. The most specific DNS zone match specified here will take precedence over other DNS zone matches, so a solver specifying sys.example.com will be selected over one specifying example.com for the domain www.sys.example.com. If multiple solvers match with the same dnsZones value, the solver with the most matching labels in matchLabels will be selected. If neither has more matches, the solver defined earlier in the list will be selected.
             */
            dnsZones?: string[];
            /**
             * A label selector that is used to refine the set of certificate's that this challenge solver will apply to.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * CA configures this issuer to sign certificates using a signing CA keypair stored in a Secret resource. This is used to build internal PKIs that are managed by cert-manager.
         */
        export interface IssuerSpecCa {
            /**
             * The CRL distribution points is an X.509 v3 certificate extension which identifies the location of the CRL from which the revocation of this certificate can be checked. If not set, certificates will be issued without distribution points set.
             */
            crlDistributionPoints?: string[];
            /**
             * SecretName is the name of the secret used to sign Certificates issued by this Issuer.
             */
            secretName: string;
        }

        /**
         * SelfSigned configures this issuer to 'self sign' certificates using the private key used to create the CertificateRequest object.
         */
        export interface IssuerSpecSelfSigned {
            /**
             * The CRL distribution points is an X.509 v3 certificate extension which identifies the location of the CRL from which the revocation of this certificate can be checked. If not set certificate will be issued without CDP. Values are strings.
             */
            crlDistributionPoints?: string[];
        }

        /**
         * Vault configures this issuer to sign certificates using a HashiCorp Vault PKI backend.
         */
        export interface IssuerSpecVault {
            /**
             * Auth configures how cert-manager authenticates with the Vault server.
             */
            auth: outputs.certmanager.v1alpha2.IssuerSpecVaultAuth;
            /**
             * PEM encoded CA bundle used to validate Vault server certificate. Only used if the Server URL is using HTTPS protocol. This parameter is ignored for plain HTTP protocol connection. If not set the system root certificates are used to validate the TLS connection.
             */
            caBundle?: string;
            /**
             * Name of the vault namespace. Namespaces is a set of features within Vault Enterprise that allows Vault environments to support Secure Multi-tenancy. e.g: "ns1" More about namespaces can be found here https://www.vaultproject.io/docs/enterprise/namespaces
             */
            namespace?: string;
            /**
             * Path is the mount path of the Vault PKI backend's `sign` endpoint, e.g: "my_pki_mount/sign/my-role-name".
             */
            path: string;
            /**
             * Server is the connection address for the Vault server, e.g: "https://vault.example.com:8200".
             */
            server: string;
        }

        /**
         * Auth configures how cert-manager authenticates with the Vault server.
         */
        export interface IssuerSpecVaultAuth {
            /**
             * AppRole authenticates with Vault using the App Role auth mechanism, with the role and secret stored in a Kubernetes Secret resource.
             */
            appRole?: outputs.certmanager.v1alpha2.IssuerSpecVaultAuthAppRole;
            /**
             * Kubernetes authenticates with Vault by passing the ServiceAccount token stored in the named Secret resource to the Vault server.
             */
            kubernetes?: outputs.certmanager.v1alpha2.IssuerSpecVaultAuthKubernetes;
            /**
             * TokenSecretRef authenticates with Vault by presenting a token.
             */
            tokenSecretRef?: outputs.certmanager.v1alpha2.IssuerSpecVaultAuthTokenSecretRef;
        }

        /**
         * AppRole authenticates with Vault using the App Role auth mechanism, with the role and secret stored in a Kubernetes Secret resource.
         */
        export interface IssuerSpecVaultAuthAppRole {
            /**
             * Path where the App Role authentication backend is mounted in Vault, e.g: "approle"
             */
            path: string;
            /**
             * RoleID configured in the App Role authentication backend when setting up the authentication backend in Vault.
             */
            roleId: string;
            /**
             * Reference to a key in a Secret that contains the App Role secret used to authenticate with Vault. The `key` field must be specified and denotes which entry within the Secret resource is used as the app role secret.
             */
            secretRef: outputs.certmanager.v1alpha2.IssuerSpecVaultAuthAppRoleSecretRef;
        }

        /**
         * Reference to a key in a Secret that contains the App Role secret used to authenticate with Vault. The `key` field must be specified and denotes which entry within the Secret resource is used as the app role secret.
         */
        export interface IssuerSpecVaultAuthAppRoleSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Kubernetes authenticates with Vault by passing the ServiceAccount token stored in the named Secret resource to the Vault server.
         */
        export interface IssuerSpecVaultAuthKubernetes {
            /**
             * The Vault mountPath here is the mount path to use when authenticating with Vault. For example, setting a value to `/v1/auth/foo`, will use the path `/v1/auth/foo/login` to authenticate with Vault. If unspecified, the default value "/v1/auth/kubernetes" will be used.
             */
            mountPath?: string;
            /**
             * A required field containing the Vault Role to assume. A Role binds a Kubernetes ServiceAccount with a set of Vault policies.
             */
            role: string;
            /**
             * The required Secret field containing a Kubernetes ServiceAccount JWT used for authenticating with Vault. Use of 'ambient credentials' is not supported.
             */
            secretRef: outputs.certmanager.v1alpha2.IssuerSpecVaultAuthKubernetesSecretRef;
        }

        /**
         * The required Secret field containing a Kubernetes ServiceAccount JWT used for authenticating with Vault. Use of 'ambient credentials' is not supported.
         */
        export interface IssuerSpecVaultAuthKubernetesSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * TokenSecretRef authenticates with Vault by presenting a token.
         */
        export interface IssuerSpecVaultAuthTokenSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Venafi configures this issuer to sign certificates using a Venafi TPP or Venafi Cloud policy zone.
         */
        export interface IssuerSpecVenafi {
            /**
             * Cloud specifies the Venafi cloud configuration settings. Only one of TPP or Cloud may be specified.
             */
            cloud?: outputs.certmanager.v1alpha2.IssuerSpecVenafiCloud;
            /**
             * TPP specifies Trust Protection Platform configuration settings. Only one of TPP or Cloud may be specified.
             */
            tpp?: outputs.certmanager.v1alpha2.IssuerSpecVenafiTpp;
            /**
             * Zone is the Venafi Policy Zone to use for this issuer. All requests made to the Venafi platform will be restricted by the named zone policy. This field is required.
             */
            zone: string;
        }

        /**
         * Cloud specifies the Venafi cloud configuration settings. Only one of TPP or Cloud may be specified.
         */
        export interface IssuerSpecVenafiCloud {
            /**
             * APITokenSecretRef is a secret key selector for the Venafi Cloud API token.
             */
            apiTokenSecretRef: outputs.certmanager.v1alpha2.IssuerSpecVenafiCloudApiTokenSecretRef;
            /**
             * URL is the base URL for Venafi Cloud. Defaults to "https://api.venafi.cloud/v1".
             */
            url?: string;
        }

        /**
         * APITokenSecretRef is a secret key selector for the Venafi Cloud API token.
         */
        export interface IssuerSpecVenafiCloudApiTokenSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * TPP specifies Trust Protection Platform configuration settings. Only one of TPP or Cloud may be specified.
         */
        export interface IssuerSpecVenafiTpp {
            /**
             * CABundle is a PEM encoded TLS certificate to use to verify connections to the TPP instance. If specified, system roots will not be used and the issuing CA for the TPP instance must be verifiable using the provided root. If not specified, the connection will be verified using the cert-manager system root certificates.
             */
            caBundle?: string;
            /**
             * CredentialsRef is a reference to a Secret containing the username and password for the TPP server. The secret must contain two keys, 'username' and 'password'.
             */
            credentialsRef: outputs.certmanager.v1alpha2.IssuerSpecVenafiTppCredentialsRef;
            /**
             * URL is the base URL for the vedsdk endpoint of the Venafi TPP instance, for example: "https://tpp.example.com/vedsdk".
             */
            url: string;
        }

        /**
         * CredentialsRef is a reference to a Secret containing the username and password for the TPP server. The secret must contain two keys, 'username' and 'password'.
         */
        export interface IssuerSpecVenafiTppCredentialsRef {
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Status of the Issuer. This is set and managed automatically.
         */
        export interface IssuerStatus {
            /**
             * ACME specific status options. This field should only be set if the Issuer is configured to use an ACME server to issue certificates.
             */
            acme?: outputs.certmanager.v1alpha2.IssuerStatusAcme;
            /**
             * List of status conditions to indicate the status of a CertificateRequest. Known condition types are `Ready`.
             */
            conditions?: outputs.certmanager.v1alpha2.IssuerStatusConditions[];
        }

        /**
         * ACME specific status options. This field should only be set if the Issuer is configured to use an ACME server to issue certificates.
         */
        export interface IssuerStatusAcme {
            /**
             * LastRegisteredEmail is the email associated with the latest registered ACME account, in order to track changes made to registered account associated with the  Issuer
             */
            lastRegisteredEmail?: string;
            /**
             * URI is the unique account identifier, which can also be used to retrieve account details from the CA
             */
            uri?: string;
        }

        /**
         * IssuerCondition contains condition information for an Issuer.
         */
        export interface IssuerStatusConditions {
            /**
             * LastTransitionTime is the timestamp corresponding to the last status change of this condition.
             */
            lastTransitionTime?: string;
            /**
             * Message is a human readable description of the details of the last transition, complementing reason.
             */
            message?: string;
            /**
             * Reason is a brief machine readable explanation for the condition's last transition.
             */
            reason?: string;
            /**
             * Status of the condition, one of ('True', 'False', 'Unknown').
             */
            status: string;
            /**
             * Type of the condition, known values are ('Ready').
             */
            type: string;
        }
    }

    export namespace v1alpha3 {
        /**
         * Desired state of the CertificateRequest resource.
         */
        export interface CertificateRequestSpec {
            /**
             * The PEM-encoded x509 certificate signing request to be submitted to the CA for signing.
             */
            csr: string;
            /**
             * The requested 'duration' (i.e. lifetime) of the Certificate. This option may be ignored/overridden by some issuer types.
             */
            duration?: string;
            /**
             * IsCA will request to mark the certificate as valid for certificate signing when submitting to the issuer. This will automatically add the `cert sign` usage to the list of `usages`.
             */
            isCA?: boolean;
            /**
             * IssuerRef is a reference to the issuer for this CertificateRequest.  If the 'kind' field is not set, or set to 'Issuer', an Issuer resource with the given name in the same namespace as the CertificateRequest will be used.  If the 'kind' field is set to 'ClusterIssuer', a ClusterIssuer with the provided name will be used. The 'name' field in this stanza is required at all times. The group field refers to the API group of the issuer which defaults to 'cert-manager.io' if empty.
             */
            issuerRef: outputs.certmanager.v1alpha3.CertificateRequestSpecIssuerRef;
            /**
             * Usages is the set of x509 usages that are requested for the certificate. Defaults to `digital signature` and `key encipherment` if not specified.
             */
            usages?: string[];
        }

        /**
         * IssuerRef is a reference to the issuer for this CertificateRequest.  If the 'kind' field is not set, or set to 'Issuer', an Issuer resource with the given name in the same namespace as the CertificateRequest will be used.  If the 'kind' field is set to 'ClusterIssuer', a ClusterIssuer with the provided name will be used. The 'name' field in this stanza is required at all times. The group field refers to the API group of the issuer which defaults to 'cert-manager.io' if empty.
         */
        export interface CertificateRequestSpecIssuerRef {
            /**
             * Group of the resource being referred to.
             */
            group?: string;
            /**
             * Kind of the resource being referred to.
             */
            kind?: string;
            /**
             * Name of the resource being referred to.
             */
            name: string;
        }

        /**
         * Status of the CertificateRequest. This is set and managed automatically.
         */
        export interface CertificateRequestStatus {
            /**
             * The PEM encoded x509 certificate of the signer, also known as the CA (Certificate Authority). This is set on a best-effort basis by different issuers. If not set, the CA is assumed to be unknown/not available.
             */
            ca?: string;
            /**
             * The PEM encoded x509 certificate resulting from the certificate signing request. If not set, the CertificateRequest has either not been completed or has failed. More information on failure can be found by checking the `conditions` field.
             */
            certificate?: string;
            /**
             * List of status conditions to indicate the status of a CertificateRequest. Known condition types are `Ready` and `InvalidRequest`.
             */
            conditions?: outputs.certmanager.v1alpha3.CertificateRequestStatusConditions[];
            /**
             * FailureTime stores the time that this CertificateRequest failed. This is used to influence garbage collection and back-off.
             */
            failureTime?: string;
        }

        /**
         * CertificateRequestCondition contains condition information for a CertificateRequest.
         */
        export interface CertificateRequestStatusConditions {
            /**
             * LastTransitionTime is the timestamp corresponding to the last status change of this condition.
             */
            lastTransitionTime?: string;
            /**
             * Message is a human readable description of the details of the last transition, complementing reason.
             */
            message?: string;
            /**
             * Reason is a brief machine readable explanation for the condition's last transition.
             */
            reason?: string;
            /**
             * Status of the condition, one of ('True', 'False', 'Unknown').
             */
            status: string;
            /**
             * Type of the condition, known values are ('Ready', 'InvalidRequest').
             */
            type: string;
        }

        /**
         * Desired state of the Certificate resource.
         */
        export interface CertificateSpec {
            /**
             * CommonName is a common name to be used on the Certificate. The CommonName should have a length of 64 characters or fewer to avoid generating invalid CSRs. This value is ignored by TLS clients when any subject alt name is set. This is x509 behaviour: https://tools.ietf.org/html/rfc6125#section-6.4.4
             */
            commonName?: string;
            /**
             * DNSNames is a list of DNS subjectAltNames to be set on the Certificate.
             */
            dnsNames?: string[];
            /**
             * The requested 'duration' (i.e. lifetime) of the Certificate. This option may be ignored/overridden by some issuer types. If overridden and `renewBefore` is greater than the actual certificate duration, the certificate will be automatically renewed 2/3rds of the way through the certificate's duration.
             */
            duration?: string;
            /**
             * EmailSANs is a list of email subjectAltNames to be set on the Certificate.
             */
            emailSANs?: string[];
            /**
             * EncodeUsagesInRequest controls whether key usages should be present in the CertificateRequest
             */
            encodeUsagesInRequest?: boolean;
            /**
             * IPAddresses is a list of IP address subjectAltNames to be set on the Certificate.
             */
            ipAddresses?: string[];
            /**
             * IsCA will mark this Certificate as valid for certificate signing. This will automatically add the `cert sign` usage to the list of `usages`.
             */
            isCA?: boolean;
            /**
             * IssuerRef is a reference to the issuer for this certificate. If the 'kind' field is not set, or set to 'Issuer', an Issuer resource with the given name in the same namespace as the Certificate will be used. If the 'kind' field is set to 'ClusterIssuer', a ClusterIssuer with the provided name will be used. The 'name' field in this stanza is required at all times.
             */
            issuerRef: outputs.certmanager.v1alpha3.CertificateSpecIssuerRef;
            /**
             * KeyAlgorithm is the private key algorithm of the corresponding private key for this certificate. If provided, allowed values are either "rsa" or "ecdsa" If `keyAlgorithm` is specified and `keySize` is not provided, key size of 256 will be used for "ecdsa" key algorithm and key size of 2048 will be used for "rsa" key algorithm.
             */
            keyAlgorithm?: string;
            /**
             * KeyEncoding is the private key cryptography standards (PKCS) for this certificate's private key to be encoded in. If provided, allowed values are "pkcs1" and "pkcs8" standing for PKCS#1 and PKCS#8, respectively. If KeyEncoding is not specified, then PKCS#1 will be used by default.
             */
            keyEncoding?: string;
            /**
             * KeySize is the key bit size of the corresponding private key for this certificate. If `keyAlgorithm` is set to `RSA`, valid values are `2048`, `4096` or `8192`, and will default to `2048` if not specified. If `keyAlgorithm` is set to `ECDSA`, valid values are `256`, `384` or `521`, and will default to `256` if not specified. No other values are allowed.
             */
            keySize?: number;
            /**
             * Keystores configures additional keystore output formats stored in the `secretName` Secret resource.
             */
            keystores?: outputs.certmanager.v1alpha3.CertificateSpecKeystores;
            /**
             * Options to control private keys used for the Certificate.
             */
            privateKey?: outputs.certmanager.v1alpha3.CertificateSpecPrivateKey;
            /**
             * The amount of time before the currently issued certificate's `notAfter` time that cert-manager will begin to attempt to renew the certificate. If this value is greater than the total duration of the certificate (i.e. notAfter - notBefore), it will be automatically renewed 2/3rds of the way through the certificate's duration.
             */
            renewBefore?: string;
            /**
             * SecretName is the name of the secret resource that will be automatically created and managed by this Certificate resource. It will be populated with a private key and certificate, signed by the denoted issuer.
             */
            secretName: string;
            /**
             * Full X509 name specification (https://golang.org/pkg/crypto/x509/pkix/#Name).
             */
            subject?: outputs.certmanager.v1alpha3.CertificateSpecSubject;
            /**
             * URISANs is a list of URI subjectAltNames to be set on the Certificate.
             */
            uriSANs?: string[];
            /**
             * Usages is the set of x509 usages that are requested for the certificate. Defaults to `digital signature` and `key encipherment` if not specified.
             */
            usages?: string[];
        }

        /**
         * IssuerRef is a reference to the issuer for this certificate. If the 'kind' field is not set, or set to 'Issuer', an Issuer resource with the given name in the same namespace as the Certificate will be used. If the 'kind' field is set to 'ClusterIssuer', a ClusterIssuer with the provided name will be used. The 'name' field in this stanza is required at all times.
         */
        export interface CertificateSpecIssuerRef {
            /**
             * Group of the resource being referred to.
             */
            group?: string;
            /**
             * Kind of the resource being referred to.
             */
            kind?: string;
            /**
             * Name of the resource being referred to.
             */
            name: string;
        }

        /**
         * Keystores configures additional keystore output formats stored in the `secretName` Secret resource.
         */
        export interface CertificateSpecKeystores {
            /**
             * JKS configures options for storing a JKS keystore in the `spec.secretName` Secret resource.
             */
            jks?: outputs.certmanager.v1alpha3.CertificateSpecKeystoresJks;
            /**
             * PKCS12 configures options for storing a PKCS12 keystore in the `spec.secretName` Secret resource.
             */
            pkcs12?: outputs.certmanager.v1alpha3.CertificateSpecKeystoresPkcs12;
        }

        /**
         * JKS configures options for storing a JKS keystore in the `spec.secretName` Secret resource.
         */
        export interface CertificateSpecKeystoresJks {
            /**
             * Create enables JKS keystore creation for the Certificate. If true, a file named `keystore.jks` will be created in the target Secret resource, encrypted using the password stored in `passwordSecretRef`. The keystore file will only be updated upon re-issuance.
             */
            create: boolean;
            /**
             * PasswordSecretRef is a reference to a key in a Secret resource containing the password used to encrypt the JKS keystore.
             */
            passwordSecretRef: outputs.certmanager.v1alpha3.CertificateSpecKeystoresJksPasswordSecretRef;
        }

        /**
         * PasswordSecretRef is a reference to a key in a Secret resource containing the password used to encrypt the JKS keystore.
         */
        export interface CertificateSpecKeystoresJksPasswordSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * PKCS12 configures options for storing a PKCS12 keystore in the `spec.secretName` Secret resource.
         */
        export interface CertificateSpecKeystoresPkcs12 {
            /**
             * Create enables PKCS12 keystore creation for the Certificate. If true, a file named `keystore.p12` will be created in the target Secret resource, encrypted using the password stored in `passwordSecretRef`. The keystore file will only be updated upon re-issuance.
             */
            create: boolean;
            /**
             * PasswordSecretRef is a reference to a key in a Secret resource containing the password used to encrypt the PKCS12 keystore.
             */
            passwordSecretRef: outputs.certmanager.v1alpha3.CertificateSpecKeystoresPkcs12PasswordSecretRef;
        }

        /**
         * PasswordSecretRef is a reference to a key in a Secret resource containing the password used to encrypt the PKCS12 keystore.
         */
        export interface CertificateSpecKeystoresPkcs12PasswordSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Options to control private keys used for the Certificate.
         */
        export interface CertificateSpecPrivateKey {
            /**
             * RotationPolicy controls how private keys should be regenerated when a re-issuance is being processed. If set to Never, a private key will only be generated if one does not already exist in the target `spec.secretName`. If one does exists but it does not have the correct algorithm or size, a warning will be raised to await user intervention. If set to Always, a private key matching the specified requirements will be generated whenever a re-issuance occurs. Default is 'Never' for backward compatibility.
             */
            rotationPolicy?: string;
        }

        /**
         * Full X509 name specification (https://golang.org/pkg/crypto/x509/pkix/#Name).
         */
        export interface CertificateSpecSubject {
            /**
             * Countries to be used on the Certificate.
             */
            countries?: string[];
            /**
             * Cities to be used on the Certificate.
             */
            localities?: string[];
            /**
             * Organizational Units to be used on the Certificate.
             */
            organizationalUnits?: string[];
            /**
             * Organizations to be used on the Certificate.
             */
            organizations?: string[];
            /**
             * Postal codes to be used on the Certificate.
             */
            postalCodes?: string[];
            /**
             * State/Provinces to be used on the Certificate.
             */
            provinces?: string[];
            /**
             * Serial number to be used on the Certificate.
             */
            serialNumber?: string;
            /**
             * Street addresses to be used on the Certificate.
             */
            streetAddresses?: string[];
        }

        /**
         * Status of the Certificate. This is set and managed automatically.
         */
        export interface CertificateStatus {
            /**
             * List of status conditions to indicate the status of certificates. Known condition types are `Ready` and `Issuing`.
             */
            conditions?: outputs.certmanager.v1alpha3.CertificateStatusConditions[];
            /**
             * LastFailureTime is the time as recorded by the Certificate controller of the most recent failure to complete a CertificateRequest for this Certificate resource. If set, cert-manager will not re-request another Certificate until 1 hour has elapsed from this time.
             */
            lastFailureTime?: string;
            /**
             * The name of the Secret resource containing the private key to be used for the next certificate iteration. The keymanager controller will automatically set this field if the `Issuing` condition is set to `True`. It will automatically unset this field when the Issuing condition is not set or False.
             */
            nextPrivateKeySecretName?: string;
            /**
             * The expiration time of the certificate stored in the secret named by this resource in `spec.secretName`.
             */
            notAfter?: string;
            /**
             * The time after which the certificate stored in the secret named by this resource in spec.secretName is valid.
             */
            notBefore?: string;
            /**
             * RenewalTime is the time at which the certificate will be next renewed. If not set, no upcoming renewal is scheduled.
             */
            renewalTime?: string;
            /**
             * The current 'revision' of the certificate as issued. 
             *  When a CertificateRequest resource is created, it will have the `cert-manager.io/certificate-revision` set to one greater than the current value of this field. 
             *  Upon issuance, this field will be set to the value of the annotation on the CertificateRequest resource used to issue the certificate. 
             *  Persisting the value on the CertificateRequest resource allows the certificates controller to know whether a request is part of an old issuance or if it is part of the ongoing revision's issuance by checking if the revision value in the annotation is greater than this field.
             */
            revision?: number;
        }

        /**
         * CertificateCondition contains condition information for an Certificate.
         */
        export interface CertificateStatusConditions {
            /**
             * LastTransitionTime is the timestamp corresponding to the last status change of this condition.
             */
            lastTransitionTime?: string;
            /**
             * Message is a human readable description of the details of the last transition, complementing reason.
             */
            message?: string;
            /**
             * Reason is a brief machine readable explanation for the condition's last transition.
             */
            reason?: string;
            /**
             * Status of the condition, one of ('True', 'False', 'Unknown').
             */
            status: string;
            /**
             * Type of the condition, known values are ('Ready', `Issuing`).
             */
            type: string;
        }

        /**
         * Desired state of the ClusterIssuer resource.
         */
        export interface ClusterIssuerSpec {
            /**
             * ACME configures this issuer to communicate with a RFC8555 (ACME) server to obtain signed x509 certificates.
             */
            acme?: outputs.certmanager.v1alpha3.ClusterIssuerSpecAcme;
            /**
             * CA configures this issuer to sign certificates using a signing CA keypair stored in a Secret resource. This is used to build internal PKIs that are managed by cert-manager.
             */
            ca?: outputs.certmanager.v1alpha3.ClusterIssuerSpecCa;
            /**
             * SelfSigned configures this issuer to 'self sign' certificates using the private key used to create the CertificateRequest object.
             */
            selfSigned?: outputs.certmanager.v1alpha3.ClusterIssuerSpecSelfSigned;
            /**
             * Vault configures this issuer to sign certificates using a HashiCorp Vault PKI backend.
             */
            vault?: outputs.certmanager.v1alpha3.ClusterIssuerSpecVault;
            /**
             * Venafi configures this issuer to sign certificates using a Venafi TPP or Venafi Cloud policy zone.
             */
            venafi?: outputs.certmanager.v1alpha3.ClusterIssuerSpecVenafi;
        }

        /**
         * ACME configures this issuer to communicate with a RFC8555 (ACME) server to obtain signed x509 certificates.
         */
        export interface ClusterIssuerSpecAcme {
            /**
             * Enables or disables generating a new ACME account key. If true, the Issuer resource will *not* request a new account but will expect the account key to be supplied via an existing secret. If false, the cert-manager system will generate a new ACME account key for the Issuer. Defaults to false.
             */
            disableAccountKeyGeneration?: boolean;
            /**
             * Email is the email address to be associated with the ACME account. This field is optional, but it is strongly recommended to be set. It will be used to contact you in case of issues with your account or certificates, including expiry notification emails. This field may be updated after the account is initially registered.
             */
            email?: string;
            /**
             * Enables requesting a Not After date on certificates that matches the duration of the certificate. This is not supported by all ACME servers like Let's Encrypt. If set to true when the ACME server does not support it it will create an error on the Order. Defaults to false.
             */
            enableDurationFeature?: boolean;
            /**
             * ExternalAccountBinding is a reference to a CA external account of the ACME server. If set, upon registration cert-manager will attempt to associate the given external account credentials with the registered ACME account.
             */
            externalAccountBinding?: outputs.certmanager.v1alpha3.ClusterIssuerSpecAcmeExternalAccountBinding;
            /**
             * PreferredChain is the chain to use if the ACME server outputs multiple. PreferredChain is no guarantee that this one gets delivered by the ACME endpoint. For example, for Let's Encrypt's DST crosssign you would use: "DST Root CA X3" or "ISRG Root X1" for the newer Let's Encrypt root CA. This value picks the first certificate bundle in the ACME alternative chains that has a certificate with this value as its issuer's CN
             */
            preferredChain?: string;
            /**
             * PrivateKey is the name of a Kubernetes Secret resource that will be used to store the automatically generated ACME account private key. Optionally, a `key` may be specified to select a specific entry within the named Secret resource. If `key` is not specified, a default of `tls.key` will be used.
             */
            privateKeySecretRef: outputs.certmanager.v1alpha3.ClusterIssuerSpecAcmePrivateKeySecretRef;
            /**
             * Server is the URL used to access the ACME server's 'directory' endpoint. For example, for Let's Encrypt's staging endpoint, you would use: "https://acme-staging-v02.api.letsencrypt.org/directory". Only ACME v2 endpoints (i.e. RFC 8555) are supported.
             */
            server: string;
            /**
             * Enables or disables validation of the ACME server TLS certificate. If true, requests to the ACME server will not have their TLS certificate validated (i.e. insecure connections will be allowed). Only enable this option in development environments. The cert-manager system installed roots will be used to verify connections to the ACME server if this is false. Defaults to false.
             */
            skipTLSVerify?: boolean;
            /**
             * Solvers is a list of challenge solvers that will be used to solve ACME challenges for the matching domains. Solver configurations must be provided in order to obtain certificates from an ACME server. For more information, see: https://cert-manager.io/docs/configuration/acme/
             */
            solvers?: outputs.certmanager.v1alpha3.ClusterIssuerSpecAcmeSolvers[];
        }

        /**
         * ExternalAccountBinding is a reference to a CA external account of the ACME server. If set, upon registration cert-manager will attempt to associate the given external account credentials with the registered ACME account.
         */
        export interface ClusterIssuerSpecAcmeExternalAccountBinding {
            /**
             * keyAlgorithm is the MAC key algorithm that the key is used for. Valid values are "HS256", "HS384" and "HS512".
             */
            keyAlgorithm: string;
            /**
             * keyID is the ID of the CA key that the External Account is bound to.
             */
            keyID: string;
            /**
             * keySecretRef is a Secret Key Selector referencing a data item in a Kubernetes Secret which holds the symmetric MAC key of the External Account Binding. The `key` is the index string that is paired with the key data in the Secret and should not be confused with the key data itself, or indeed with the External Account Binding keyID above. The secret key stored in the Secret **must** be un-padded, base64 URL encoded data.
             */
            keySecretRef: outputs.certmanager.v1alpha3.ClusterIssuerSpecAcmeExternalAccountBindingKeySecretRef;
        }

        /**
         * keySecretRef is a Secret Key Selector referencing a data item in a Kubernetes Secret which holds the symmetric MAC key of the External Account Binding. The `key` is the index string that is paired with the key data in the Secret and should not be confused with the key data itself, or indeed with the External Account Binding keyID above. The secret key stored in the Secret **must** be un-padded, base64 URL encoded data.
         */
        export interface ClusterIssuerSpecAcmeExternalAccountBindingKeySecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * PrivateKey is the name of a Kubernetes Secret resource that will be used to store the automatically generated ACME account private key. Optionally, a `key` may be specified to select a specific entry within the named Secret resource. If `key` is not specified, a default of `tls.key` will be used.
         */
        export interface ClusterIssuerSpecAcmePrivateKeySecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Configures an issuer to solve challenges using the specified options. Only one of HTTP01 or DNS01 may be provided.
         */
        export interface ClusterIssuerSpecAcmeSolvers {
            /**
             * Configures cert-manager to attempt to complete authorizations by performing the DNS01 challenge flow.
             */
            dns01?: outputs.certmanager.v1alpha3.ClusterIssuerSpecAcmeSolversDns01;
            /**
             * Configures cert-manager to attempt to complete authorizations by performing the HTTP01 challenge flow. It is not possible to obtain certificates for wildcard domain names (e.g. `*.example.com`) using the HTTP01 challenge mechanism.
             */
            http01?: outputs.certmanager.v1alpha3.ClusterIssuerSpecAcmeSolversHttp01;
            /**
             * Selector selects a set of DNSNames on the Certificate resource that should be solved using this challenge solver. If not specified, the solver will be treated as the 'default' solver with the lowest priority, i.e. if any other solver has a more specific match, it will be used instead.
             */
            selector?: outputs.certmanager.v1alpha3.ClusterIssuerSpecAcmeSolversSelector;
        }

        /**
         * Configures cert-manager to attempt to complete authorizations by performing the DNS01 challenge flow.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01 {
            /**
             * Use the 'ACME DNS' (https://github.com/joohoi/acme-dns) API to manage DNS01 challenge records.
             */
            acmedns?: outputs.certmanager.v1alpha3.ClusterIssuerSpecAcmeSolversDns01Acmedns;
            /**
             * Use the Akamai DNS zone management API to manage DNS01 challenge records.
             */
            akamai?: outputs.certmanager.v1alpha3.ClusterIssuerSpecAcmeSolversDns01Akamai;
            /**
             * Use the Microsoft Azure DNS API to manage DNS01 challenge records.
             */
            azuredns?: outputs.certmanager.v1alpha3.ClusterIssuerSpecAcmeSolversDns01Azuredns;
            /**
             * Use the Google Cloud DNS API to manage DNS01 challenge records.
             */
            clouddns?: outputs.certmanager.v1alpha3.ClusterIssuerSpecAcmeSolversDns01Clouddns;
            /**
             * Use the Cloudflare API to manage DNS01 challenge records.
             */
            cloudflare?: outputs.certmanager.v1alpha3.ClusterIssuerSpecAcmeSolversDns01Cloudflare;
            /**
             * CNAMEStrategy configures how the DNS01 provider should handle CNAME records when found in DNS zones.
             */
            cnameStrategy?: string;
            /**
             * Use the DigitalOcean DNS API to manage DNS01 challenge records.
             */
            digitalocean?: outputs.certmanager.v1alpha3.ClusterIssuerSpecAcmeSolversDns01Digitalocean;
            /**
             * Use RFC2136 ("Dynamic Updates in the Domain Name System") (https://datatracker.ietf.org/doc/rfc2136/) to manage DNS01 challenge records.
             */
            rfc2136?: outputs.certmanager.v1alpha3.ClusterIssuerSpecAcmeSolversDns01Rfc2136;
            /**
             * Use the AWS Route53 API to manage DNS01 challenge records.
             */
            route53?: outputs.certmanager.v1alpha3.ClusterIssuerSpecAcmeSolversDns01Route53;
            /**
             * Configure an external webhook based DNS01 challenge solver to manage DNS01 challenge records.
             */
            webhook?: outputs.certmanager.v1alpha3.ClusterIssuerSpecAcmeSolversDns01Webhook;
        }

        /**
         * Use the 'ACME DNS' (https://github.com/joohoi/acme-dns) API to manage DNS01 challenge records.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01Acmedns {
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            accountSecretRef: outputs.certmanager.v1alpha3.ClusterIssuerSpecAcmeSolversDns01AcmednsAccountSecretRef;
            host: string;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01AcmednsAccountSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the Akamai DNS zone management API to manage DNS01 challenge records.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01Akamai {
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            accessTokenSecretRef: outputs.certmanager.v1alpha3.ClusterIssuerSpecAcmeSolversDns01AkamaiAccessTokenSecretRef;
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            clientSecretSecretRef: outputs.certmanager.v1alpha3.ClusterIssuerSpecAcmeSolversDns01AkamaiClientSecretSecretRef;
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            clientTokenSecretRef: outputs.certmanager.v1alpha3.ClusterIssuerSpecAcmeSolversDns01AkamaiClientTokenSecretRef;
            serviceConsumerDomain: string;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01AkamaiAccessTokenSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01AkamaiClientSecretSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01AkamaiClientTokenSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the Microsoft Azure DNS API to manage DNS01 challenge records.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01Azuredns {
            /**
             * if both this and ClientSecret are left unset MSI will be used
             */
            clientID?: string;
            /**
             * if both this and ClientID are left unset MSI will be used
             */
            clientSecretSecretRef?: outputs.certmanager.v1alpha3.ClusterIssuerSpecAcmeSolversDns01AzurednsClientSecretSecretRef;
            environment?: string;
            hostedZoneName?: string;
            resourceGroupName: string;
            subscriptionID: string;
            /**
             * when specifying ClientID and ClientSecret then this field is also needed
             */
            tenantID?: string;
        }

        /**
         * if both this and ClientID are left unset MSI will be used
         */
        export interface ClusterIssuerSpecAcmeSolversDns01AzurednsClientSecretSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the Google Cloud DNS API to manage DNS01 challenge records.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01Clouddns {
            /**
             * HostedZoneName is an optional field that tells cert-manager in which Cloud DNS zone the challenge record has to be created. If left empty cert-manager will automatically choose a zone.
             */
            hostedZoneName?: string;
            project: string;
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            serviceAccountSecretRef?: outputs.certmanager.v1alpha3.ClusterIssuerSpecAcmeSolversDns01ClouddnsServiceAccountSecretRef;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01ClouddnsServiceAccountSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the Cloudflare API to manage DNS01 challenge records.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01Cloudflare {
            /**
             * API key to use to authenticate with Cloudflare. Note: using an API token to authenticate is now the recommended method as it allows greater control of permissions.
             */
            apiKeySecretRef?: outputs.certmanager.v1alpha3.ClusterIssuerSpecAcmeSolversDns01CloudflareApiKeySecretRef;
            /**
             * API token used to authenticate with Cloudflare.
             */
            apiTokenSecretRef?: outputs.certmanager.v1alpha3.ClusterIssuerSpecAcmeSolversDns01CloudflareApiTokenSecretRef;
            /**
             * Email of the account, only required when using API key based authentication.
             */
            email?: string;
        }

        /**
         * API key to use to authenticate with Cloudflare. Note: using an API token to authenticate is now the recommended method as it allows greater control of permissions.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01CloudflareApiKeySecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * API token used to authenticate with Cloudflare.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01CloudflareApiTokenSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the DigitalOcean DNS API to manage DNS01 challenge records.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01Digitalocean {
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            tokenSecretRef: outputs.certmanager.v1alpha3.ClusterIssuerSpecAcmeSolversDns01DigitaloceanTokenSecretRef;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01DigitaloceanTokenSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use RFC2136 ("Dynamic Updates in the Domain Name System") (https://datatracker.ietf.org/doc/rfc2136/) to manage DNS01 challenge records.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01Rfc2136 {
            /**
             * The IP address or hostname of an authoritative DNS server supporting RFC2136 in the form host:port. If the host is an IPv6 address it must be enclosed in square brackets (e.g [2001:db8::1]) ; port is optional. This field is required.
             */
            nameserver: string;
            /**
             * The TSIG Algorithm configured in the DNS supporting RFC2136. Used only when ``tsigSecretSecretRef`` and ``tsigKeyName`` are defined. Supported values are (case-insensitive): ``HMACMD5`` (default), ``HMACSHA1``, ``HMACSHA256`` or ``HMACSHA512``.
             */
            tsigAlgorithm?: string;
            /**
             * The TSIG Key name configured in the DNS. If ``tsigSecretSecretRef`` is defined, this field is required.
             */
            tsigKeyName?: string;
            /**
             * The name of the secret containing the TSIG value. If ``tsigKeyName`` is defined, this field is required.
             */
            tsigSecretSecretRef?: outputs.certmanager.v1alpha3.ClusterIssuerSpecAcmeSolversDns01Rfc2136TsigSecretSecretRef;
        }

        /**
         * The name of the secret containing the TSIG value. If ``tsigKeyName`` is defined, this field is required.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01Rfc2136TsigSecretSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the AWS Route53 API to manage DNS01 challenge records.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01Route53 {
            /**
             * The AccessKeyID is used for authentication. If not set we fall-back to using env vars, shared credentials file or AWS Instance metadata see: https://docs.aws.amazon.com/sdk-for-go/v1/developer-guide/configuring-sdk.html#specifying-credentials
             */
            accessKeyID?: string;
            /**
             * If set, the provider will manage only this zone in Route53 and will not do an lookup using the route53:ListHostedZonesByName api call.
             */
            hostedZoneID?: string;
            /**
             * Always set the region when using AccessKeyID and SecretAccessKey
             */
            region: string;
            /**
             * Role is a Role ARN which the Route53 provider will assume using either the explicit credentials AccessKeyID/SecretAccessKey or the inferred credentials from environment variables, shared credentials file or AWS Instance metadata
             */
            role?: string;
            /**
             * The SecretAccessKey is used for authentication. If not set we fall-back to using env vars, shared credentials file or AWS Instance metadata https://docs.aws.amazon.com/sdk-for-go/v1/developer-guide/configuring-sdk.html#specifying-credentials
             */
            secretAccessKeySecretRef?: outputs.certmanager.v1alpha3.ClusterIssuerSpecAcmeSolversDns01Route53SecretAccessKeySecretRef;
        }

        /**
         * The SecretAccessKey is used for authentication. If not set we fall-back to using env vars, shared credentials file or AWS Instance metadata https://docs.aws.amazon.com/sdk-for-go/v1/developer-guide/configuring-sdk.html#specifying-credentials
         */
        export interface ClusterIssuerSpecAcmeSolversDns01Route53SecretAccessKeySecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Configure an external webhook based DNS01 challenge solver to manage DNS01 challenge records.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01Webhook {
            /**
             * Additional configuration that should be passed to the webhook apiserver when challenges are processed. This can contain arbitrary JSON data. Secret values should not be specified in this stanza. If secret values are needed (e.g. credentials for a DNS service), you should use a SecretKeySelector to reference a Secret resource. For details on the schema of this field, consult the webhook provider implementation's documentation.
             */
            config?: {[key: string]: any};
            /**
             * The API group name that should be used when POSTing ChallengePayload resources to the webhook apiserver. This should be the same as the GroupName specified in the webhook provider implementation.
             */
            groupName: string;
            /**
             * The name of the solver to use, as defined in the webhook provider implementation. This will typically be the name of the provider, e.g. 'cloudflare'.
             */
            solverName: string;
        }

        /**
         * Configures cert-manager to attempt to complete authorizations by performing the HTTP01 challenge flow. It is not possible to obtain certificates for wildcard domain names (e.g. `*.example.com`) using the HTTP01 challenge mechanism.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01 {
            /**
             * The ingress based HTTP01 challenge solver will solve challenges by creating or modifying Ingress resources in order to route requests for '/.well-known/acme-challenge/XYZ' to 'challenge solver' pods that are provisioned by cert-manager for each Challenge to be completed.
             */
            ingress?: outputs.certmanager.v1alpha3.ClusterIssuerSpecAcmeSolversHttp01Ingress;
        }

        /**
         * The ingress based HTTP01 challenge solver will solve challenges by creating or modifying Ingress resources in order to route requests for '/.well-known/acme-challenge/XYZ' to 'challenge solver' pods that are provisioned by cert-manager for each Challenge to be completed.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01Ingress {
            /**
             * The ingress class to use when creating Ingress resources to solve ACME challenges that use this challenge solver. Only one of 'class' or 'name' may be specified.
             */
            class?: string;
            /**
             * Optional ingress template used to configure the ACME challenge solver ingress used for HTTP01 challenges
             */
            ingressTemplate?: outputs.certmanager.v1alpha3.ClusterIssuerSpecAcmeSolversHttp01IngressIngressTemplate;
            /**
             * The name of the ingress resource that should have ACME challenge solving routes inserted into it in order to solve HTTP01 challenges. This is typically used in conjunction with ingress controllers like ingress-gce, which maintains a 1:1 mapping between external IPs and ingress resources.
             */
            name?: string;
            /**
             * Optional pod template used to configure the ACME challenge solver pods used for HTTP01 challenges
             */
            podTemplate?: outputs.certmanager.v1alpha3.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplate;
            /**
             * Optional service type for Kubernetes solver service
             */
            serviceType?: string;
        }

        /**
         * Optional ingress template used to configure the ACME challenge solver ingress used for HTTP01 challenges
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressIngressTemplate {
            /**
             * ObjectMeta overrides for the ingress used to solve HTTP01 challenges. Only the 'labels' and 'annotations' fields may be set. If labels or annotations overlap with in-built values, the values here will override the in-built values.
             */
            metadata?: outputs.certmanager.v1alpha3.ClusterIssuerSpecAcmeSolversHttp01IngressIngressTemplateMetadata;
        }

        /**
         * ObjectMeta overrides for the ingress used to solve HTTP01 challenges. Only the 'labels' and 'annotations' fields may be set. If labels or annotations overlap with in-built values, the values here will override the in-built values.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressIngressTemplateMetadata {
            /**
             * Annotations that should be added to the created ACME HTTP01 solver ingress.
             */
            annotations?: {[key: string]: string};
            /**
             * Labels that should be added to the created ACME HTTP01 solver ingress.
             */
            labels?: {[key: string]: string};
        }

        /**
         * Optional pod template used to configure the ACME challenge solver pods used for HTTP01 challenges
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplate {
            /**
             * ObjectMeta overrides for the pod used to solve HTTP01 challenges. Only the 'labels' and 'annotations' fields may be set. If labels or annotations overlap with in-built values, the values here will override the in-built values.
             */
            metadata?: outputs.certmanager.v1alpha3.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateMetadata;
            /**
             * PodSpec defines overrides for the HTTP01 challenge solver pod. Only the 'priorityClassName', 'nodeSelector', 'affinity', 'serviceAccountName' and 'tolerations' fields are supported currently. All other fields will be ignored.
             */
            spec?: outputs.certmanager.v1alpha3.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpec;
        }

        /**
         * ObjectMeta overrides for the pod used to solve HTTP01 challenges. Only the 'labels' and 'annotations' fields may be set. If labels or annotations overlap with in-built values, the values here will override the in-built values.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateMetadata {
            /**
             * Annotations that should be added to the create ACME HTTP01 solver pods.
             */
            annotations?: {[key: string]: string};
            /**
             * Labels that should be added to the created ACME HTTP01 solver pods.
             */
            labels?: {[key: string]: string};
        }

        /**
         * PodSpec defines overrides for the HTTP01 challenge solver pod. Only the 'priorityClassName', 'nodeSelector', 'affinity', 'serviceAccountName' and 'tolerations' fields are supported currently. All other fields will be ignored.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpec {
            /**
             * If specified, the pod's scheduling constraints
             */
            affinity?: outputs.certmanager.v1alpha3.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinity;
            /**
             * NodeSelector is a selector which must be true for the pod to fit on a node. Selector which must match a node's labels for the pod to be scheduled on that node. More info: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/
             */
            nodeSelector?: {[key: string]: string};
            /**
             * If specified, the pod's priorityClassName.
             */
            priorityClassName?: string;
            /**
             * If specified, the pod's service account
             */
            serviceAccountName?: string;
            /**
             * If specified, the pod's tolerations.
             */
            tolerations?: outputs.certmanager.v1alpha3.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecTolerations[];
        }

        /**
         * If specified, the pod's scheduling constraints
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinity {
            /**
             * Describes node affinity scheduling rules for the pod.
             */
            nodeAffinity?: outputs.certmanager.v1alpha3.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinity;
            /**
             * Describes pod affinity scheduling rules (e.g. co-locate this pod in the same node, zone, etc. as some other pod(s)).
             */
            podAffinity?: outputs.certmanager.v1alpha3.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinity;
            /**
             * Describes pod anti-affinity scheduling rules (e.g. avoid putting this pod in the same node, zone, etc. as some other pod(s)).
             */
            podAntiAffinity?: outputs.certmanager.v1alpha3.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinity;
        }

        /**
         * Describes node affinity scheduling rules for the pod.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinity {
            /**
             * The scheduler will prefer to schedule pods to nodes that satisfy the affinity expressions specified by this field, but it may choose a node that violates one or more of the expressions. The node that is most preferred is the one with the greatest sum of weights, i.e. for each node that meets all of the scheduling requirements (resource request, requiredDuringScheduling affinity expressions, etc.), compute a sum by iterating through the elements of this field and adding "weight" to the sum if the node matches the corresponding matchExpressions; the node(s) with the highest sum are the most preferred.
             */
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.certmanager.v1alpha3.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            /**
             * If the affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to an update), the system may or may not try to eventually evict the pod from its node.
             */
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.certmanager.v1alpha3.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution;
        }

        /**
         * An empty preferred scheduling term matches all objects with implicit weight 0 (i.e. it's a no-op). A null preferred scheduling term matches no objects (i.e. is also a no-op).
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            /**
             * A node selector term, associated with the corresponding weight.
             */
            preference: outputs.certmanager.v1alpha3.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference;
            /**
             * Weight associated with matching the corresponding nodeSelectorTerm, in the range 1-100.
             */
            weight: number;
        }

        /**
         * A node selector term, associated with the corresponding weight.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference {
            /**
             * A list of node selector requirements by node's labels.
             */
            matchExpressions?: outputs.certmanager.v1alpha3.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions[];
            /**
             * A list of node selector requirements by node's fields.
             */
            matchFields?: outputs.certmanager.v1alpha3.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields[];
        }

        /**
         * A node selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions {
            /**
             * The label key that the selector applies to.
             */
            key: string;
            /**
             * Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
             */
            operator: string;
            /**
             * An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * A node selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields {
            /**
             * The label key that the selector applies to.
             */
            key: string;
            /**
             * Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
             */
            operator: string;
            /**
             * An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * If the affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to an update), the system may or may not try to eventually evict the pod from its node.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            /**
             * Required. A list of node selector terms. The terms are ORed.
             */
            nodeSelectorTerms: outputs.certmanager.v1alpha3.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms[];
        }

        /**
         * A null or empty node selector term matches no objects. The requirements of them are ANDed. The TopologySelectorTerm type implements a subset of the NodeSelectorTerm.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms {
            /**
             * A list of node selector requirements by node's labels.
             */
            matchExpressions?: outputs.certmanager.v1alpha3.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions[];
            /**
             * A list of node selector requirements by node's fields.
             */
            matchFields?: outputs.certmanager.v1alpha3.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields[];
        }

        /**
         * A node selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions {
            /**
             * The label key that the selector applies to.
             */
            key: string;
            /**
             * Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
             */
            operator: string;
            /**
             * An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * A node selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields {
            /**
             * The label key that the selector applies to.
             */
            key: string;
            /**
             * Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
             */
            operator: string;
            /**
             * An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Describes pod affinity scheduling rules (e.g. co-locate this pod in the same node, zone, etc. as some other pod(s)).
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinity {
            /**
             * The scheduler will prefer to schedule pods to nodes that satisfy the affinity expressions specified by this field, but it may choose a node that violates one or more of the expressions. The node that is most preferred is the one with the greatest sum of weights, i.e. for each node that meets all of the scheduling requirements (resource request, requiredDuringScheduling affinity expressions, etc.), compute a sum by iterating through the elements of this field and adding "weight" to the sum if the node has pods which matches the corresponding podAffinityTerm; the node(s) with the highest sum are the most preferred.
             */
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.certmanager.v1alpha3.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            /**
             * If the affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to a pod label update), the system may or may not try to eventually evict the pod from its node. When there are multiple elements, the lists of nodes corresponding to each podAffinityTerm are intersected, i.e. all terms must be satisfied.
             */
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.certmanager.v1alpha3.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        /**
         * The weights of all of the matched WeightedPodAffinityTerm fields are added per-node to find the most preferred node(s)
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            /**
             * Required. A pod affinity term, associated with the corresponding weight.
             */
            podAffinityTerm: outputs.certmanager.v1alpha3.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            /**
             * weight associated with matching the corresponding podAffinityTerm, in the range 1-100.
             */
            weight: number;
        }

        /**
         * Required. A pod affinity term, associated with the corresponding weight.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            /**
             * A label query over a set of resources, in this case pods.
             */
            labelSelector?: outputs.certmanager.v1alpha3.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            /**
             * namespaces specifies which namespaces the labelSelector applies to (matches against); null or empty list means "this pod's namespace"
             */
            namespaces?: string[];
            /**
             * This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed.
             */
            topologyKey: string;
        }

        /**
         * A label query over a set of resources, in this case pods.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.certmanager.v1alpha3.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Defines a set of pods (namely those matching the labelSelector relative to the given namespace(s)) that this pod should be co-located (affinity) or not co-located (anti-affinity) with, where co-located is defined as running on a node whose value of the label with key <topologyKey> matches that of any node on which a pod of the set of pods is running
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            /**
             * A label query over a set of resources, in this case pods.
             */
            labelSelector?: outputs.certmanager.v1alpha3.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            /**
             * namespaces specifies which namespaces the labelSelector applies to (matches against); null or empty list means "this pod's namespace"
             */
            namespaces?: string[];
            /**
             * This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed.
             */
            topologyKey: string;
        }

        /**
         * A label query over a set of resources, in this case pods.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.certmanager.v1alpha3.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Describes pod anti-affinity scheduling rules (e.g. avoid putting this pod in the same node, zone, etc. as some other pod(s)).
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinity {
            /**
             * The scheduler will prefer to schedule pods to nodes that satisfy the anti-affinity expressions specified by this field, but it may choose a node that violates one or more of the expressions. The node that is most preferred is the one with the greatest sum of weights, i.e. for each node that meets all of the scheduling requirements (resource request, requiredDuringScheduling anti-affinity expressions, etc.), compute a sum by iterating through the elements of this field and adding "weight" to the sum if the node has pods which matches the corresponding podAffinityTerm; the node(s) with the highest sum are the most preferred.
             */
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.certmanager.v1alpha3.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            /**
             * If the anti-affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the anti-affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to a pod label update), the system may or may not try to eventually evict the pod from its node. When there are multiple elements, the lists of nodes corresponding to each podAffinityTerm are intersected, i.e. all terms must be satisfied.
             */
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.certmanager.v1alpha3.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        /**
         * The weights of all of the matched WeightedPodAffinityTerm fields are added per-node to find the most preferred node(s)
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            /**
             * Required. A pod affinity term, associated with the corresponding weight.
             */
            podAffinityTerm: outputs.certmanager.v1alpha3.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            /**
             * weight associated with matching the corresponding podAffinityTerm, in the range 1-100.
             */
            weight: number;
        }

        /**
         * Required. A pod affinity term, associated with the corresponding weight.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            /**
             * A label query over a set of resources, in this case pods.
             */
            labelSelector?: outputs.certmanager.v1alpha3.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            /**
             * namespaces specifies which namespaces the labelSelector applies to (matches against); null or empty list means "this pod's namespace"
             */
            namespaces?: string[];
            /**
             * This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed.
             */
            topologyKey: string;
        }

        /**
         * A label query over a set of resources, in this case pods.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.certmanager.v1alpha3.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Defines a set of pods (namely those matching the labelSelector relative to the given namespace(s)) that this pod should be co-located (affinity) or not co-located (anti-affinity) with, where co-located is defined as running on a node whose value of the label with key <topologyKey> matches that of any node on which a pod of the set of pods is running
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            /**
             * A label query over a set of resources, in this case pods.
             */
            labelSelector?: outputs.certmanager.v1alpha3.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            /**
             * namespaces specifies which namespaces the labelSelector applies to (matches against); null or empty list means "this pod's namespace"
             */
            namespaces?: string[];
            /**
             * This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed.
             */
            topologyKey: string;
        }

        /**
         * A label query over a set of resources, in this case pods.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.certmanager.v1alpha3.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * The pod this Toleration is attached to tolerates any taint that matches the triple <key,value,effect> using the matching operator <operator>.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecTolerations {
            /**
             * Effect indicates the taint effect to match. Empty means match all taint effects. When specified, allowed values are NoSchedule, PreferNoSchedule and NoExecute.
             */
            effect?: string;
            /**
             * Key is the taint key that the toleration applies to. Empty means match all taint keys. If the key is empty, operator must be Exists; this combination means to match all values and all keys.
             */
            key?: string;
            /**
             * Operator represents a key's relationship to the value. Valid operators are Exists and Equal. Defaults to Equal. Exists is equivalent to wildcard for value, so that a pod can tolerate all taints of a particular category.
             */
            operator?: string;
            /**
             * TolerationSeconds represents the period of time the toleration (which must be of effect NoExecute, otherwise this field is ignored) tolerates the taint. By default, it is not set, which means tolerate the taint forever (do not evict). Zero and negative values will be treated as 0 (evict immediately) by the system.
             */
            tolerationSeconds?: number;
            /**
             * Value is the taint value the toleration matches to. If the operator is Exists, the value should be empty, otherwise just a regular string.
             */
            value?: string;
        }

        /**
         * Selector selects a set of DNSNames on the Certificate resource that should be solved using this challenge solver. If not specified, the solver will be treated as the 'default' solver with the lowest priority, i.e. if any other solver has a more specific match, it will be used instead.
         */
        export interface ClusterIssuerSpecAcmeSolversSelector {
            /**
             * List of DNSNames that this solver will be used to solve. If specified and a match is found, a dnsNames selector will take precedence over a dnsZones selector. If multiple solvers match with the same dnsNames value, the solver with the most matching labels in matchLabels will be selected. If neither has more matches, the solver defined earlier in the list will be selected.
             */
            dnsNames?: string[];
            /**
             * List of DNSZones that this solver will be used to solve. The most specific DNS zone match specified here will take precedence over other DNS zone matches, so a solver specifying sys.example.com will be selected over one specifying example.com for the domain www.sys.example.com. If multiple solvers match with the same dnsZones value, the solver with the most matching labels in matchLabels will be selected. If neither has more matches, the solver defined earlier in the list will be selected.
             */
            dnsZones?: string[];
            /**
             * A label selector that is used to refine the set of certificate's that this challenge solver will apply to.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * CA configures this issuer to sign certificates using a signing CA keypair stored in a Secret resource. This is used to build internal PKIs that are managed by cert-manager.
         */
        export interface ClusterIssuerSpecCa {
            /**
             * The CRL distribution points is an X.509 v3 certificate extension which identifies the location of the CRL from which the revocation of this certificate can be checked. If not set, certificates will be issued without distribution points set.
             */
            crlDistributionPoints?: string[];
            /**
             * SecretName is the name of the secret used to sign Certificates issued by this Issuer.
             */
            secretName: string;
        }

        /**
         * SelfSigned configures this issuer to 'self sign' certificates using the private key used to create the CertificateRequest object.
         */
        export interface ClusterIssuerSpecSelfSigned {
            /**
             * The CRL distribution points is an X.509 v3 certificate extension which identifies the location of the CRL from which the revocation of this certificate can be checked. If not set certificate will be issued without CDP. Values are strings.
             */
            crlDistributionPoints?: string[];
        }

        /**
         * Vault configures this issuer to sign certificates using a HashiCorp Vault PKI backend.
         */
        export interface ClusterIssuerSpecVault {
            /**
             * Auth configures how cert-manager authenticates with the Vault server.
             */
            auth: outputs.certmanager.v1alpha3.ClusterIssuerSpecVaultAuth;
            /**
             * PEM encoded CA bundle used to validate Vault server certificate. Only used if the Server URL is using HTTPS protocol. This parameter is ignored for plain HTTP protocol connection. If not set the system root certificates are used to validate the TLS connection.
             */
            caBundle?: string;
            /**
             * Name of the vault namespace. Namespaces is a set of features within Vault Enterprise that allows Vault environments to support Secure Multi-tenancy. e.g: "ns1" More about namespaces can be found here https://www.vaultproject.io/docs/enterprise/namespaces
             */
            namespace?: string;
            /**
             * Path is the mount path of the Vault PKI backend's `sign` endpoint, e.g: "my_pki_mount/sign/my-role-name".
             */
            path: string;
            /**
             * Server is the connection address for the Vault server, e.g: "https://vault.example.com:8200".
             */
            server: string;
        }

        /**
         * Auth configures how cert-manager authenticates with the Vault server.
         */
        export interface ClusterIssuerSpecVaultAuth {
            /**
             * AppRole authenticates with Vault using the App Role auth mechanism, with the role and secret stored in a Kubernetes Secret resource.
             */
            appRole?: outputs.certmanager.v1alpha3.ClusterIssuerSpecVaultAuthAppRole;
            /**
             * Kubernetes authenticates with Vault by passing the ServiceAccount token stored in the named Secret resource to the Vault server.
             */
            kubernetes?: outputs.certmanager.v1alpha3.ClusterIssuerSpecVaultAuthKubernetes;
            /**
             * TokenSecretRef authenticates with Vault by presenting a token.
             */
            tokenSecretRef?: outputs.certmanager.v1alpha3.ClusterIssuerSpecVaultAuthTokenSecretRef;
        }

        /**
         * AppRole authenticates with Vault using the App Role auth mechanism, with the role and secret stored in a Kubernetes Secret resource.
         */
        export interface ClusterIssuerSpecVaultAuthAppRole {
            /**
             * Path where the App Role authentication backend is mounted in Vault, e.g: "approle"
             */
            path: string;
            /**
             * RoleID configured in the App Role authentication backend when setting up the authentication backend in Vault.
             */
            roleId: string;
            /**
             * Reference to a key in a Secret that contains the App Role secret used to authenticate with Vault. The `key` field must be specified and denotes which entry within the Secret resource is used as the app role secret.
             */
            secretRef: outputs.certmanager.v1alpha3.ClusterIssuerSpecVaultAuthAppRoleSecretRef;
        }

        /**
         * Reference to a key in a Secret that contains the App Role secret used to authenticate with Vault. The `key` field must be specified and denotes which entry within the Secret resource is used as the app role secret.
         */
        export interface ClusterIssuerSpecVaultAuthAppRoleSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Kubernetes authenticates with Vault by passing the ServiceAccount token stored in the named Secret resource to the Vault server.
         */
        export interface ClusterIssuerSpecVaultAuthKubernetes {
            /**
             * The Vault mountPath here is the mount path to use when authenticating with Vault. For example, setting a value to `/v1/auth/foo`, will use the path `/v1/auth/foo/login` to authenticate with Vault. If unspecified, the default value "/v1/auth/kubernetes" will be used.
             */
            mountPath?: string;
            /**
             * A required field containing the Vault Role to assume. A Role binds a Kubernetes ServiceAccount with a set of Vault policies.
             */
            role: string;
            /**
             * The required Secret field containing a Kubernetes ServiceAccount JWT used for authenticating with Vault. Use of 'ambient credentials' is not supported.
             */
            secretRef: outputs.certmanager.v1alpha3.ClusterIssuerSpecVaultAuthKubernetesSecretRef;
        }

        /**
         * The required Secret field containing a Kubernetes ServiceAccount JWT used for authenticating with Vault. Use of 'ambient credentials' is not supported.
         */
        export interface ClusterIssuerSpecVaultAuthKubernetesSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * TokenSecretRef authenticates with Vault by presenting a token.
         */
        export interface ClusterIssuerSpecVaultAuthTokenSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Venafi configures this issuer to sign certificates using a Venafi TPP or Venafi Cloud policy zone.
         */
        export interface ClusterIssuerSpecVenafi {
            /**
             * Cloud specifies the Venafi cloud configuration settings. Only one of TPP or Cloud may be specified.
             */
            cloud?: outputs.certmanager.v1alpha3.ClusterIssuerSpecVenafiCloud;
            /**
             * TPP specifies Trust Protection Platform configuration settings. Only one of TPP or Cloud may be specified.
             */
            tpp?: outputs.certmanager.v1alpha3.ClusterIssuerSpecVenafiTpp;
            /**
             * Zone is the Venafi Policy Zone to use for this issuer. All requests made to the Venafi platform will be restricted by the named zone policy. This field is required.
             */
            zone: string;
        }

        /**
         * Cloud specifies the Venafi cloud configuration settings. Only one of TPP or Cloud may be specified.
         */
        export interface ClusterIssuerSpecVenafiCloud {
            /**
             * APITokenSecretRef is a secret key selector for the Venafi Cloud API token.
             */
            apiTokenSecretRef: outputs.certmanager.v1alpha3.ClusterIssuerSpecVenafiCloudApiTokenSecretRef;
            /**
             * URL is the base URL for Venafi Cloud. Defaults to "https://api.venafi.cloud/v1".
             */
            url?: string;
        }

        /**
         * APITokenSecretRef is a secret key selector for the Venafi Cloud API token.
         */
        export interface ClusterIssuerSpecVenafiCloudApiTokenSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * TPP specifies Trust Protection Platform configuration settings. Only one of TPP or Cloud may be specified.
         */
        export interface ClusterIssuerSpecVenafiTpp {
            /**
             * CABundle is a PEM encoded TLS certificate to use to verify connections to the TPP instance. If specified, system roots will not be used and the issuing CA for the TPP instance must be verifiable using the provided root. If not specified, the connection will be verified using the cert-manager system root certificates.
             */
            caBundle?: string;
            /**
             * CredentialsRef is a reference to a Secret containing the username and password for the TPP server. The secret must contain two keys, 'username' and 'password'.
             */
            credentialsRef: outputs.certmanager.v1alpha3.ClusterIssuerSpecVenafiTppCredentialsRef;
            /**
             * URL is the base URL for the vedsdk endpoint of the Venafi TPP instance, for example: "https://tpp.example.com/vedsdk".
             */
            url: string;
        }

        /**
         * CredentialsRef is a reference to a Secret containing the username and password for the TPP server. The secret must contain two keys, 'username' and 'password'.
         */
        export interface ClusterIssuerSpecVenafiTppCredentialsRef {
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Status of the ClusterIssuer. This is set and managed automatically.
         */
        export interface ClusterIssuerStatus {
            /**
             * ACME specific status options. This field should only be set if the Issuer is configured to use an ACME server to issue certificates.
             */
            acme?: outputs.certmanager.v1alpha3.ClusterIssuerStatusAcme;
            /**
             * List of status conditions to indicate the status of a CertificateRequest. Known condition types are `Ready`.
             */
            conditions?: outputs.certmanager.v1alpha3.ClusterIssuerStatusConditions[];
        }

        /**
         * ACME specific status options. This field should only be set if the Issuer is configured to use an ACME server to issue certificates.
         */
        export interface ClusterIssuerStatusAcme {
            /**
             * LastRegisteredEmail is the email associated with the latest registered ACME account, in order to track changes made to registered account associated with the  Issuer
             */
            lastRegisteredEmail?: string;
            /**
             * URI is the unique account identifier, which can also be used to retrieve account details from the CA
             */
            uri?: string;
        }

        /**
         * IssuerCondition contains condition information for an Issuer.
         */
        export interface ClusterIssuerStatusConditions {
            /**
             * LastTransitionTime is the timestamp corresponding to the last status change of this condition.
             */
            lastTransitionTime?: string;
            /**
             * Message is a human readable description of the details of the last transition, complementing reason.
             */
            message?: string;
            /**
             * Reason is a brief machine readable explanation for the condition's last transition.
             */
            reason?: string;
            /**
             * Status of the condition, one of ('True', 'False', 'Unknown').
             */
            status: string;
            /**
             * Type of the condition, known values are ('Ready').
             */
            type: string;
        }

        /**
         * Desired state of the Issuer resource.
         */
        export interface IssuerSpec {
            /**
             * ACME configures this issuer to communicate with a RFC8555 (ACME) server to obtain signed x509 certificates.
             */
            acme?: outputs.certmanager.v1alpha3.IssuerSpecAcme;
            /**
             * CA configures this issuer to sign certificates using a signing CA keypair stored in a Secret resource. This is used to build internal PKIs that are managed by cert-manager.
             */
            ca?: outputs.certmanager.v1alpha3.IssuerSpecCa;
            /**
             * SelfSigned configures this issuer to 'self sign' certificates using the private key used to create the CertificateRequest object.
             */
            selfSigned?: outputs.certmanager.v1alpha3.IssuerSpecSelfSigned;
            /**
             * Vault configures this issuer to sign certificates using a HashiCorp Vault PKI backend.
             */
            vault?: outputs.certmanager.v1alpha3.IssuerSpecVault;
            /**
             * Venafi configures this issuer to sign certificates using a Venafi TPP or Venafi Cloud policy zone.
             */
            venafi?: outputs.certmanager.v1alpha3.IssuerSpecVenafi;
        }

        /**
         * ACME configures this issuer to communicate with a RFC8555 (ACME) server to obtain signed x509 certificates.
         */
        export interface IssuerSpecAcme {
            /**
             * Enables or disables generating a new ACME account key. If true, the Issuer resource will *not* request a new account but will expect the account key to be supplied via an existing secret. If false, the cert-manager system will generate a new ACME account key for the Issuer. Defaults to false.
             */
            disableAccountKeyGeneration?: boolean;
            /**
             * Email is the email address to be associated with the ACME account. This field is optional, but it is strongly recommended to be set. It will be used to contact you in case of issues with your account or certificates, including expiry notification emails. This field may be updated after the account is initially registered.
             */
            email?: string;
            /**
             * Enables requesting a Not After date on certificates that matches the duration of the certificate. This is not supported by all ACME servers like Let's Encrypt. If set to true when the ACME server does not support it it will create an error on the Order. Defaults to false.
             */
            enableDurationFeature?: boolean;
            /**
             * ExternalAccountBinding is a reference to a CA external account of the ACME server. If set, upon registration cert-manager will attempt to associate the given external account credentials with the registered ACME account.
             */
            externalAccountBinding?: outputs.certmanager.v1alpha3.IssuerSpecAcmeExternalAccountBinding;
            /**
             * PreferredChain is the chain to use if the ACME server outputs multiple. PreferredChain is no guarantee that this one gets delivered by the ACME endpoint. For example, for Let's Encrypt's DST crosssign you would use: "DST Root CA X3" or "ISRG Root X1" for the newer Let's Encrypt root CA. This value picks the first certificate bundle in the ACME alternative chains that has a certificate with this value as its issuer's CN
             */
            preferredChain?: string;
            /**
             * PrivateKey is the name of a Kubernetes Secret resource that will be used to store the automatically generated ACME account private key. Optionally, a `key` may be specified to select a specific entry within the named Secret resource. If `key` is not specified, a default of `tls.key` will be used.
             */
            privateKeySecretRef: outputs.certmanager.v1alpha3.IssuerSpecAcmePrivateKeySecretRef;
            /**
             * Server is the URL used to access the ACME server's 'directory' endpoint. For example, for Let's Encrypt's staging endpoint, you would use: "https://acme-staging-v02.api.letsencrypt.org/directory". Only ACME v2 endpoints (i.e. RFC 8555) are supported.
             */
            server: string;
            /**
             * Enables or disables validation of the ACME server TLS certificate. If true, requests to the ACME server will not have their TLS certificate validated (i.e. insecure connections will be allowed). Only enable this option in development environments. The cert-manager system installed roots will be used to verify connections to the ACME server if this is false. Defaults to false.
             */
            skipTLSVerify?: boolean;
            /**
             * Solvers is a list of challenge solvers that will be used to solve ACME challenges for the matching domains. Solver configurations must be provided in order to obtain certificates from an ACME server. For more information, see: https://cert-manager.io/docs/configuration/acme/
             */
            solvers?: outputs.certmanager.v1alpha3.IssuerSpecAcmeSolvers[];
        }

        /**
         * ExternalAccountBinding is a reference to a CA external account of the ACME server. If set, upon registration cert-manager will attempt to associate the given external account credentials with the registered ACME account.
         */
        export interface IssuerSpecAcmeExternalAccountBinding {
            /**
             * keyAlgorithm is the MAC key algorithm that the key is used for. Valid values are "HS256", "HS384" and "HS512".
             */
            keyAlgorithm: string;
            /**
             * keyID is the ID of the CA key that the External Account is bound to.
             */
            keyID: string;
            /**
             * keySecretRef is a Secret Key Selector referencing a data item in a Kubernetes Secret which holds the symmetric MAC key of the External Account Binding. The `key` is the index string that is paired with the key data in the Secret and should not be confused with the key data itself, or indeed with the External Account Binding keyID above. The secret key stored in the Secret **must** be un-padded, base64 URL encoded data.
             */
            keySecretRef: outputs.certmanager.v1alpha3.IssuerSpecAcmeExternalAccountBindingKeySecretRef;
        }

        /**
         * keySecretRef is a Secret Key Selector referencing a data item in a Kubernetes Secret which holds the symmetric MAC key of the External Account Binding. The `key` is the index string that is paired with the key data in the Secret and should not be confused with the key data itself, or indeed with the External Account Binding keyID above. The secret key stored in the Secret **must** be un-padded, base64 URL encoded data.
         */
        export interface IssuerSpecAcmeExternalAccountBindingKeySecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * PrivateKey is the name of a Kubernetes Secret resource that will be used to store the automatically generated ACME account private key. Optionally, a `key` may be specified to select a specific entry within the named Secret resource. If `key` is not specified, a default of `tls.key` will be used.
         */
        export interface IssuerSpecAcmePrivateKeySecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Configures an issuer to solve challenges using the specified options. Only one of HTTP01 or DNS01 may be provided.
         */
        export interface IssuerSpecAcmeSolvers {
            /**
             * Configures cert-manager to attempt to complete authorizations by performing the DNS01 challenge flow.
             */
            dns01?: outputs.certmanager.v1alpha3.IssuerSpecAcmeSolversDns01;
            /**
             * Configures cert-manager to attempt to complete authorizations by performing the HTTP01 challenge flow. It is not possible to obtain certificates for wildcard domain names (e.g. `*.example.com`) using the HTTP01 challenge mechanism.
             */
            http01?: outputs.certmanager.v1alpha3.IssuerSpecAcmeSolversHttp01;
            /**
             * Selector selects a set of DNSNames on the Certificate resource that should be solved using this challenge solver. If not specified, the solver will be treated as the 'default' solver with the lowest priority, i.e. if any other solver has a more specific match, it will be used instead.
             */
            selector?: outputs.certmanager.v1alpha3.IssuerSpecAcmeSolversSelector;
        }

        /**
         * Configures cert-manager to attempt to complete authorizations by performing the DNS01 challenge flow.
         */
        export interface IssuerSpecAcmeSolversDns01 {
            /**
             * Use the 'ACME DNS' (https://github.com/joohoi/acme-dns) API to manage DNS01 challenge records.
             */
            acmedns?: outputs.certmanager.v1alpha3.IssuerSpecAcmeSolversDns01Acmedns;
            /**
             * Use the Akamai DNS zone management API to manage DNS01 challenge records.
             */
            akamai?: outputs.certmanager.v1alpha3.IssuerSpecAcmeSolversDns01Akamai;
            /**
             * Use the Microsoft Azure DNS API to manage DNS01 challenge records.
             */
            azuredns?: outputs.certmanager.v1alpha3.IssuerSpecAcmeSolversDns01Azuredns;
            /**
             * Use the Google Cloud DNS API to manage DNS01 challenge records.
             */
            clouddns?: outputs.certmanager.v1alpha3.IssuerSpecAcmeSolversDns01Clouddns;
            /**
             * Use the Cloudflare API to manage DNS01 challenge records.
             */
            cloudflare?: outputs.certmanager.v1alpha3.IssuerSpecAcmeSolversDns01Cloudflare;
            /**
             * CNAMEStrategy configures how the DNS01 provider should handle CNAME records when found in DNS zones.
             */
            cnameStrategy?: string;
            /**
             * Use the DigitalOcean DNS API to manage DNS01 challenge records.
             */
            digitalocean?: outputs.certmanager.v1alpha3.IssuerSpecAcmeSolversDns01Digitalocean;
            /**
             * Use RFC2136 ("Dynamic Updates in the Domain Name System") (https://datatracker.ietf.org/doc/rfc2136/) to manage DNS01 challenge records.
             */
            rfc2136?: outputs.certmanager.v1alpha3.IssuerSpecAcmeSolversDns01Rfc2136;
            /**
             * Use the AWS Route53 API to manage DNS01 challenge records.
             */
            route53?: outputs.certmanager.v1alpha3.IssuerSpecAcmeSolversDns01Route53;
            /**
             * Configure an external webhook based DNS01 challenge solver to manage DNS01 challenge records.
             */
            webhook?: outputs.certmanager.v1alpha3.IssuerSpecAcmeSolversDns01Webhook;
        }

        /**
         * Use the 'ACME DNS' (https://github.com/joohoi/acme-dns) API to manage DNS01 challenge records.
         */
        export interface IssuerSpecAcmeSolversDns01Acmedns {
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            accountSecretRef: outputs.certmanager.v1alpha3.IssuerSpecAcmeSolversDns01AcmednsAccountSecretRef;
            host: string;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface IssuerSpecAcmeSolversDns01AcmednsAccountSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the Akamai DNS zone management API to manage DNS01 challenge records.
         */
        export interface IssuerSpecAcmeSolversDns01Akamai {
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            accessTokenSecretRef: outputs.certmanager.v1alpha3.IssuerSpecAcmeSolversDns01AkamaiAccessTokenSecretRef;
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            clientSecretSecretRef: outputs.certmanager.v1alpha3.IssuerSpecAcmeSolversDns01AkamaiClientSecretSecretRef;
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            clientTokenSecretRef: outputs.certmanager.v1alpha3.IssuerSpecAcmeSolversDns01AkamaiClientTokenSecretRef;
            serviceConsumerDomain: string;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface IssuerSpecAcmeSolversDns01AkamaiAccessTokenSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface IssuerSpecAcmeSolversDns01AkamaiClientSecretSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface IssuerSpecAcmeSolversDns01AkamaiClientTokenSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the Microsoft Azure DNS API to manage DNS01 challenge records.
         */
        export interface IssuerSpecAcmeSolversDns01Azuredns {
            /**
             * if both this and ClientSecret are left unset MSI will be used
             */
            clientID?: string;
            /**
             * if both this and ClientID are left unset MSI will be used
             */
            clientSecretSecretRef?: outputs.certmanager.v1alpha3.IssuerSpecAcmeSolversDns01AzurednsClientSecretSecretRef;
            environment?: string;
            hostedZoneName?: string;
            resourceGroupName: string;
            subscriptionID: string;
            /**
             * when specifying ClientID and ClientSecret then this field is also needed
             */
            tenantID?: string;
        }

        /**
         * if both this and ClientID are left unset MSI will be used
         */
        export interface IssuerSpecAcmeSolversDns01AzurednsClientSecretSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the Google Cloud DNS API to manage DNS01 challenge records.
         */
        export interface IssuerSpecAcmeSolversDns01Clouddns {
            /**
             * HostedZoneName is an optional field that tells cert-manager in which Cloud DNS zone the challenge record has to be created. If left empty cert-manager will automatically choose a zone.
             */
            hostedZoneName?: string;
            project: string;
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            serviceAccountSecretRef?: outputs.certmanager.v1alpha3.IssuerSpecAcmeSolversDns01ClouddnsServiceAccountSecretRef;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface IssuerSpecAcmeSolversDns01ClouddnsServiceAccountSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the Cloudflare API to manage DNS01 challenge records.
         */
        export interface IssuerSpecAcmeSolversDns01Cloudflare {
            /**
             * API key to use to authenticate with Cloudflare. Note: using an API token to authenticate is now the recommended method as it allows greater control of permissions.
             */
            apiKeySecretRef?: outputs.certmanager.v1alpha3.IssuerSpecAcmeSolversDns01CloudflareApiKeySecretRef;
            /**
             * API token used to authenticate with Cloudflare.
             */
            apiTokenSecretRef?: outputs.certmanager.v1alpha3.IssuerSpecAcmeSolversDns01CloudflareApiTokenSecretRef;
            /**
             * Email of the account, only required when using API key based authentication.
             */
            email?: string;
        }

        /**
         * API key to use to authenticate with Cloudflare. Note: using an API token to authenticate is now the recommended method as it allows greater control of permissions.
         */
        export interface IssuerSpecAcmeSolversDns01CloudflareApiKeySecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * API token used to authenticate with Cloudflare.
         */
        export interface IssuerSpecAcmeSolversDns01CloudflareApiTokenSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the DigitalOcean DNS API to manage DNS01 challenge records.
         */
        export interface IssuerSpecAcmeSolversDns01Digitalocean {
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            tokenSecretRef: outputs.certmanager.v1alpha3.IssuerSpecAcmeSolversDns01DigitaloceanTokenSecretRef;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface IssuerSpecAcmeSolversDns01DigitaloceanTokenSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use RFC2136 ("Dynamic Updates in the Domain Name System") (https://datatracker.ietf.org/doc/rfc2136/) to manage DNS01 challenge records.
         */
        export interface IssuerSpecAcmeSolversDns01Rfc2136 {
            /**
             * The IP address or hostname of an authoritative DNS server supporting RFC2136 in the form host:port. If the host is an IPv6 address it must be enclosed in square brackets (e.g [2001:db8::1]) ; port is optional. This field is required.
             */
            nameserver: string;
            /**
             * The TSIG Algorithm configured in the DNS supporting RFC2136. Used only when ``tsigSecretSecretRef`` and ``tsigKeyName`` are defined. Supported values are (case-insensitive): ``HMACMD5`` (default), ``HMACSHA1``, ``HMACSHA256`` or ``HMACSHA512``.
             */
            tsigAlgorithm?: string;
            /**
             * The TSIG Key name configured in the DNS. If ``tsigSecretSecretRef`` is defined, this field is required.
             */
            tsigKeyName?: string;
            /**
             * The name of the secret containing the TSIG value. If ``tsigKeyName`` is defined, this field is required.
             */
            tsigSecretSecretRef?: outputs.certmanager.v1alpha3.IssuerSpecAcmeSolversDns01Rfc2136TsigSecretSecretRef;
        }

        /**
         * The name of the secret containing the TSIG value. If ``tsigKeyName`` is defined, this field is required.
         */
        export interface IssuerSpecAcmeSolversDns01Rfc2136TsigSecretSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the AWS Route53 API to manage DNS01 challenge records.
         */
        export interface IssuerSpecAcmeSolversDns01Route53 {
            /**
             * The AccessKeyID is used for authentication. If not set we fall-back to using env vars, shared credentials file or AWS Instance metadata see: https://docs.aws.amazon.com/sdk-for-go/v1/developer-guide/configuring-sdk.html#specifying-credentials
             */
            accessKeyID?: string;
            /**
             * If set, the provider will manage only this zone in Route53 and will not do an lookup using the route53:ListHostedZonesByName api call.
             */
            hostedZoneID?: string;
            /**
             * Always set the region when using AccessKeyID and SecretAccessKey
             */
            region: string;
            /**
             * Role is a Role ARN which the Route53 provider will assume using either the explicit credentials AccessKeyID/SecretAccessKey or the inferred credentials from environment variables, shared credentials file or AWS Instance metadata
             */
            role?: string;
            /**
             * The SecretAccessKey is used for authentication. If not set we fall-back to using env vars, shared credentials file or AWS Instance metadata https://docs.aws.amazon.com/sdk-for-go/v1/developer-guide/configuring-sdk.html#specifying-credentials
             */
            secretAccessKeySecretRef?: outputs.certmanager.v1alpha3.IssuerSpecAcmeSolversDns01Route53SecretAccessKeySecretRef;
        }

        /**
         * The SecretAccessKey is used for authentication. If not set we fall-back to using env vars, shared credentials file or AWS Instance metadata https://docs.aws.amazon.com/sdk-for-go/v1/developer-guide/configuring-sdk.html#specifying-credentials
         */
        export interface IssuerSpecAcmeSolversDns01Route53SecretAccessKeySecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Configure an external webhook based DNS01 challenge solver to manage DNS01 challenge records.
         */
        export interface IssuerSpecAcmeSolversDns01Webhook {
            /**
             * Additional configuration that should be passed to the webhook apiserver when challenges are processed. This can contain arbitrary JSON data. Secret values should not be specified in this stanza. If secret values are needed (e.g. credentials for a DNS service), you should use a SecretKeySelector to reference a Secret resource. For details on the schema of this field, consult the webhook provider implementation's documentation.
             */
            config?: {[key: string]: any};
            /**
             * The API group name that should be used when POSTing ChallengePayload resources to the webhook apiserver. This should be the same as the GroupName specified in the webhook provider implementation.
             */
            groupName: string;
            /**
             * The name of the solver to use, as defined in the webhook provider implementation. This will typically be the name of the provider, e.g. 'cloudflare'.
             */
            solverName: string;
        }

        /**
         * Configures cert-manager to attempt to complete authorizations by performing the HTTP01 challenge flow. It is not possible to obtain certificates for wildcard domain names (e.g. `*.example.com`) using the HTTP01 challenge mechanism.
         */
        export interface IssuerSpecAcmeSolversHttp01 {
            /**
             * The ingress based HTTP01 challenge solver will solve challenges by creating or modifying Ingress resources in order to route requests for '/.well-known/acme-challenge/XYZ' to 'challenge solver' pods that are provisioned by cert-manager for each Challenge to be completed.
             */
            ingress?: outputs.certmanager.v1alpha3.IssuerSpecAcmeSolversHttp01Ingress;
        }

        /**
         * The ingress based HTTP01 challenge solver will solve challenges by creating or modifying Ingress resources in order to route requests for '/.well-known/acme-challenge/XYZ' to 'challenge solver' pods that are provisioned by cert-manager for each Challenge to be completed.
         */
        export interface IssuerSpecAcmeSolversHttp01Ingress {
            /**
             * The ingress class to use when creating Ingress resources to solve ACME challenges that use this challenge solver. Only one of 'class' or 'name' may be specified.
             */
            class?: string;
            /**
             * Optional ingress template used to configure the ACME challenge solver ingress used for HTTP01 challenges
             */
            ingressTemplate?: outputs.certmanager.v1alpha3.IssuerSpecAcmeSolversHttp01IngressIngressTemplate;
            /**
             * The name of the ingress resource that should have ACME challenge solving routes inserted into it in order to solve HTTP01 challenges. This is typically used in conjunction with ingress controllers like ingress-gce, which maintains a 1:1 mapping between external IPs and ingress resources.
             */
            name?: string;
            /**
             * Optional pod template used to configure the ACME challenge solver pods used for HTTP01 challenges
             */
            podTemplate?: outputs.certmanager.v1alpha3.IssuerSpecAcmeSolversHttp01IngressPodTemplate;
            /**
             * Optional service type for Kubernetes solver service
             */
            serviceType?: string;
        }

        /**
         * Optional ingress template used to configure the ACME challenge solver ingress used for HTTP01 challenges
         */
        export interface IssuerSpecAcmeSolversHttp01IngressIngressTemplate {
            /**
             * ObjectMeta overrides for the ingress used to solve HTTP01 challenges. Only the 'labels' and 'annotations' fields may be set. If labels or annotations overlap with in-built values, the values here will override the in-built values.
             */
            metadata?: outputs.certmanager.v1alpha3.IssuerSpecAcmeSolversHttp01IngressIngressTemplateMetadata;
        }

        /**
         * ObjectMeta overrides for the ingress used to solve HTTP01 challenges. Only the 'labels' and 'annotations' fields may be set. If labels or annotations overlap with in-built values, the values here will override the in-built values.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressIngressTemplateMetadata {
            /**
             * Annotations that should be added to the created ACME HTTP01 solver ingress.
             */
            annotations?: {[key: string]: string};
            /**
             * Labels that should be added to the created ACME HTTP01 solver ingress.
             */
            labels?: {[key: string]: string};
        }

        /**
         * Optional pod template used to configure the ACME challenge solver pods used for HTTP01 challenges
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplate {
            /**
             * ObjectMeta overrides for the pod used to solve HTTP01 challenges. Only the 'labels' and 'annotations' fields may be set. If labels or annotations overlap with in-built values, the values here will override the in-built values.
             */
            metadata?: outputs.certmanager.v1alpha3.IssuerSpecAcmeSolversHttp01IngressPodTemplateMetadata;
            /**
             * PodSpec defines overrides for the HTTP01 challenge solver pod. Only the 'priorityClassName', 'nodeSelector', 'affinity', 'serviceAccountName' and 'tolerations' fields are supported currently. All other fields will be ignored.
             */
            spec?: outputs.certmanager.v1alpha3.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpec;
        }

        /**
         * ObjectMeta overrides for the pod used to solve HTTP01 challenges. Only the 'labels' and 'annotations' fields may be set. If labels or annotations overlap with in-built values, the values here will override the in-built values.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateMetadata {
            /**
             * Annotations that should be added to the create ACME HTTP01 solver pods.
             */
            annotations?: {[key: string]: string};
            /**
             * Labels that should be added to the created ACME HTTP01 solver pods.
             */
            labels?: {[key: string]: string};
        }

        /**
         * PodSpec defines overrides for the HTTP01 challenge solver pod. Only the 'priorityClassName', 'nodeSelector', 'affinity', 'serviceAccountName' and 'tolerations' fields are supported currently. All other fields will be ignored.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpec {
            /**
             * If specified, the pod's scheduling constraints
             */
            affinity?: outputs.certmanager.v1alpha3.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinity;
            /**
             * NodeSelector is a selector which must be true for the pod to fit on a node. Selector which must match a node's labels for the pod to be scheduled on that node. More info: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/
             */
            nodeSelector?: {[key: string]: string};
            /**
             * If specified, the pod's priorityClassName.
             */
            priorityClassName?: string;
            /**
             * If specified, the pod's service account
             */
            serviceAccountName?: string;
            /**
             * If specified, the pod's tolerations.
             */
            tolerations?: outputs.certmanager.v1alpha3.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecTolerations[];
        }

        /**
         * If specified, the pod's scheduling constraints
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinity {
            /**
             * Describes node affinity scheduling rules for the pod.
             */
            nodeAffinity?: outputs.certmanager.v1alpha3.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinity;
            /**
             * Describes pod affinity scheduling rules (e.g. co-locate this pod in the same node, zone, etc. as some other pod(s)).
             */
            podAffinity?: outputs.certmanager.v1alpha3.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinity;
            /**
             * Describes pod anti-affinity scheduling rules (e.g. avoid putting this pod in the same node, zone, etc. as some other pod(s)).
             */
            podAntiAffinity?: outputs.certmanager.v1alpha3.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinity;
        }

        /**
         * Describes node affinity scheduling rules for the pod.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinity {
            /**
             * The scheduler will prefer to schedule pods to nodes that satisfy the affinity expressions specified by this field, but it may choose a node that violates one or more of the expressions. The node that is most preferred is the one with the greatest sum of weights, i.e. for each node that meets all of the scheduling requirements (resource request, requiredDuringScheduling affinity expressions, etc.), compute a sum by iterating through the elements of this field and adding "weight" to the sum if the node matches the corresponding matchExpressions; the node(s) with the highest sum are the most preferred.
             */
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.certmanager.v1alpha3.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            /**
             * If the affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to an update), the system may or may not try to eventually evict the pod from its node.
             */
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.certmanager.v1alpha3.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution;
        }

        /**
         * An empty preferred scheduling term matches all objects with implicit weight 0 (i.e. it's a no-op). A null preferred scheduling term matches no objects (i.e. is also a no-op).
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            /**
             * A node selector term, associated with the corresponding weight.
             */
            preference: outputs.certmanager.v1alpha3.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference;
            /**
             * Weight associated with matching the corresponding nodeSelectorTerm, in the range 1-100.
             */
            weight: number;
        }

        /**
         * A node selector term, associated with the corresponding weight.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference {
            /**
             * A list of node selector requirements by node's labels.
             */
            matchExpressions?: outputs.certmanager.v1alpha3.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions[];
            /**
             * A list of node selector requirements by node's fields.
             */
            matchFields?: outputs.certmanager.v1alpha3.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields[];
        }

        /**
         * A node selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions {
            /**
             * The label key that the selector applies to.
             */
            key: string;
            /**
             * Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
             */
            operator: string;
            /**
             * An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * A node selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields {
            /**
             * The label key that the selector applies to.
             */
            key: string;
            /**
             * Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
             */
            operator: string;
            /**
             * An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * If the affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to an update), the system may or may not try to eventually evict the pod from its node.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            /**
             * Required. A list of node selector terms. The terms are ORed.
             */
            nodeSelectorTerms: outputs.certmanager.v1alpha3.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms[];
        }

        /**
         * A null or empty node selector term matches no objects. The requirements of them are ANDed. The TopologySelectorTerm type implements a subset of the NodeSelectorTerm.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms {
            /**
             * A list of node selector requirements by node's labels.
             */
            matchExpressions?: outputs.certmanager.v1alpha3.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions[];
            /**
             * A list of node selector requirements by node's fields.
             */
            matchFields?: outputs.certmanager.v1alpha3.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields[];
        }

        /**
         * A node selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions {
            /**
             * The label key that the selector applies to.
             */
            key: string;
            /**
             * Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
             */
            operator: string;
            /**
             * An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * A node selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields {
            /**
             * The label key that the selector applies to.
             */
            key: string;
            /**
             * Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
             */
            operator: string;
            /**
             * An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Describes pod affinity scheduling rules (e.g. co-locate this pod in the same node, zone, etc. as some other pod(s)).
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinity {
            /**
             * The scheduler will prefer to schedule pods to nodes that satisfy the affinity expressions specified by this field, but it may choose a node that violates one or more of the expressions. The node that is most preferred is the one with the greatest sum of weights, i.e. for each node that meets all of the scheduling requirements (resource request, requiredDuringScheduling affinity expressions, etc.), compute a sum by iterating through the elements of this field and adding "weight" to the sum if the node has pods which matches the corresponding podAffinityTerm; the node(s) with the highest sum are the most preferred.
             */
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.certmanager.v1alpha3.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            /**
             * If the affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to a pod label update), the system may or may not try to eventually evict the pod from its node. When there are multiple elements, the lists of nodes corresponding to each podAffinityTerm are intersected, i.e. all terms must be satisfied.
             */
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.certmanager.v1alpha3.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        /**
         * The weights of all of the matched WeightedPodAffinityTerm fields are added per-node to find the most preferred node(s)
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            /**
             * Required. A pod affinity term, associated with the corresponding weight.
             */
            podAffinityTerm: outputs.certmanager.v1alpha3.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            /**
             * weight associated with matching the corresponding podAffinityTerm, in the range 1-100.
             */
            weight: number;
        }

        /**
         * Required. A pod affinity term, associated with the corresponding weight.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            /**
             * A label query over a set of resources, in this case pods.
             */
            labelSelector?: outputs.certmanager.v1alpha3.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            /**
             * namespaces specifies which namespaces the labelSelector applies to (matches against); null or empty list means "this pod's namespace"
             */
            namespaces?: string[];
            /**
             * This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed.
             */
            topologyKey: string;
        }

        /**
         * A label query over a set of resources, in this case pods.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.certmanager.v1alpha3.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Defines a set of pods (namely those matching the labelSelector relative to the given namespace(s)) that this pod should be co-located (affinity) or not co-located (anti-affinity) with, where co-located is defined as running on a node whose value of the label with key <topologyKey> matches that of any node on which a pod of the set of pods is running
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            /**
             * A label query over a set of resources, in this case pods.
             */
            labelSelector?: outputs.certmanager.v1alpha3.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            /**
             * namespaces specifies which namespaces the labelSelector applies to (matches against); null or empty list means "this pod's namespace"
             */
            namespaces?: string[];
            /**
             * This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed.
             */
            topologyKey: string;
        }

        /**
         * A label query over a set of resources, in this case pods.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.certmanager.v1alpha3.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Describes pod anti-affinity scheduling rules (e.g. avoid putting this pod in the same node, zone, etc. as some other pod(s)).
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinity {
            /**
             * The scheduler will prefer to schedule pods to nodes that satisfy the anti-affinity expressions specified by this field, but it may choose a node that violates one or more of the expressions. The node that is most preferred is the one with the greatest sum of weights, i.e. for each node that meets all of the scheduling requirements (resource request, requiredDuringScheduling anti-affinity expressions, etc.), compute a sum by iterating through the elements of this field and adding "weight" to the sum if the node has pods which matches the corresponding podAffinityTerm; the node(s) with the highest sum are the most preferred.
             */
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.certmanager.v1alpha3.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            /**
             * If the anti-affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the anti-affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to a pod label update), the system may or may not try to eventually evict the pod from its node. When there are multiple elements, the lists of nodes corresponding to each podAffinityTerm are intersected, i.e. all terms must be satisfied.
             */
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.certmanager.v1alpha3.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        /**
         * The weights of all of the matched WeightedPodAffinityTerm fields are added per-node to find the most preferred node(s)
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            /**
             * Required. A pod affinity term, associated with the corresponding weight.
             */
            podAffinityTerm: outputs.certmanager.v1alpha3.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            /**
             * weight associated with matching the corresponding podAffinityTerm, in the range 1-100.
             */
            weight: number;
        }

        /**
         * Required. A pod affinity term, associated with the corresponding weight.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            /**
             * A label query over a set of resources, in this case pods.
             */
            labelSelector?: outputs.certmanager.v1alpha3.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            /**
             * namespaces specifies which namespaces the labelSelector applies to (matches against); null or empty list means "this pod's namespace"
             */
            namespaces?: string[];
            /**
             * This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed.
             */
            topologyKey: string;
        }

        /**
         * A label query over a set of resources, in this case pods.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.certmanager.v1alpha3.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Defines a set of pods (namely those matching the labelSelector relative to the given namespace(s)) that this pod should be co-located (affinity) or not co-located (anti-affinity) with, where co-located is defined as running on a node whose value of the label with key <topologyKey> matches that of any node on which a pod of the set of pods is running
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            /**
             * A label query over a set of resources, in this case pods.
             */
            labelSelector?: outputs.certmanager.v1alpha3.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            /**
             * namespaces specifies which namespaces the labelSelector applies to (matches against); null or empty list means "this pod's namespace"
             */
            namespaces?: string[];
            /**
             * This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed.
             */
            topologyKey: string;
        }

        /**
         * A label query over a set of resources, in this case pods.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.certmanager.v1alpha3.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * The pod this Toleration is attached to tolerates any taint that matches the triple <key,value,effect> using the matching operator <operator>.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecTolerations {
            /**
             * Effect indicates the taint effect to match. Empty means match all taint effects. When specified, allowed values are NoSchedule, PreferNoSchedule and NoExecute.
             */
            effect?: string;
            /**
             * Key is the taint key that the toleration applies to. Empty means match all taint keys. If the key is empty, operator must be Exists; this combination means to match all values and all keys.
             */
            key?: string;
            /**
             * Operator represents a key's relationship to the value. Valid operators are Exists and Equal. Defaults to Equal. Exists is equivalent to wildcard for value, so that a pod can tolerate all taints of a particular category.
             */
            operator?: string;
            /**
             * TolerationSeconds represents the period of time the toleration (which must be of effect NoExecute, otherwise this field is ignored) tolerates the taint. By default, it is not set, which means tolerate the taint forever (do not evict). Zero and negative values will be treated as 0 (evict immediately) by the system.
             */
            tolerationSeconds?: number;
            /**
             * Value is the taint value the toleration matches to. If the operator is Exists, the value should be empty, otherwise just a regular string.
             */
            value?: string;
        }

        /**
         * Selector selects a set of DNSNames on the Certificate resource that should be solved using this challenge solver. If not specified, the solver will be treated as the 'default' solver with the lowest priority, i.e. if any other solver has a more specific match, it will be used instead.
         */
        export interface IssuerSpecAcmeSolversSelector {
            /**
             * List of DNSNames that this solver will be used to solve. If specified and a match is found, a dnsNames selector will take precedence over a dnsZones selector. If multiple solvers match with the same dnsNames value, the solver with the most matching labels in matchLabels will be selected. If neither has more matches, the solver defined earlier in the list will be selected.
             */
            dnsNames?: string[];
            /**
             * List of DNSZones that this solver will be used to solve. The most specific DNS zone match specified here will take precedence over other DNS zone matches, so a solver specifying sys.example.com will be selected over one specifying example.com for the domain www.sys.example.com. If multiple solvers match with the same dnsZones value, the solver with the most matching labels in matchLabels will be selected. If neither has more matches, the solver defined earlier in the list will be selected.
             */
            dnsZones?: string[];
            /**
             * A label selector that is used to refine the set of certificate's that this challenge solver will apply to.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * CA configures this issuer to sign certificates using a signing CA keypair stored in a Secret resource. This is used to build internal PKIs that are managed by cert-manager.
         */
        export interface IssuerSpecCa {
            /**
             * The CRL distribution points is an X.509 v3 certificate extension which identifies the location of the CRL from which the revocation of this certificate can be checked. If not set, certificates will be issued without distribution points set.
             */
            crlDistributionPoints?: string[];
            /**
             * SecretName is the name of the secret used to sign Certificates issued by this Issuer.
             */
            secretName: string;
        }

        /**
         * SelfSigned configures this issuer to 'self sign' certificates using the private key used to create the CertificateRequest object.
         */
        export interface IssuerSpecSelfSigned {
            /**
             * The CRL distribution points is an X.509 v3 certificate extension which identifies the location of the CRL from which the revocation of this certificate can be checked. If not set certificate will be issued without CDP. Values are strings.
             */
            crlDistributionPoints?: string[];
        }

        /**
         * Vault configures this issuer to sign certificates using a HashiCorp Vault PKI backend.
         */
        export interface IssuerSpecVault {
            /**
             * Auth configures how cert-manager authenticates with the Vault server.
             */
            auth: outputs.certmanager.v1alpha3.IssuerSpecVaultAuth;
            /**
             * PEM encoded CA bundle used to validate Vault server certificate. Only used if the Server URL is using HTTPS protocol. This parameter is ignored for plain HTTP protocol connection. If not set the system root certificates are used to validate the TLS connection.
             */
            caBundle?: string;
            /**
             * Name of the vault namespace. Namespaces is a set of features within Vault Enterprise that allows Vault environments to support Secure Multi-tenancy. e.g: "ns1" More about namespaces can be found here https://www.vaultproject.io/docs/enterprise/namespaces
             */
            namespace?: string;
            /**
             * Path is the mount path of the Vault PKI backend's `sign` endpoint, e.g: "my_pki_mount/sign/my-role-name".
             */
            path: string;
            /**
             * Server is the connection address for the Vault server, e.g: "https://vault.example.com:8200".
             */
            server: string;
        }

        /**
         * Auth configures how cert-manager authenticates with the Vault server.
         */
        export interface IssuerSpecVaultAuth {
            /**
             * AppRole authenticates with Vault using the App Role auth mechanism, with the role and secret stored in a Kubernetes Secret resource.
             */
            appRole?: outputs.certmanager.v1alpha3.IssuerSpecVaultAuthAppRole;
            /**
             * Kubernetes authenticates with Vault by passing the ServiceAccount token stored in the named Secret resource to the Vault server.
             */
            kubernetes?: outputs.certmanager.v1alpha3.IssuerSpecVaultAuthKubernetes;
            /**
             * TokenSecretRef authenticates with Vault by presenting a token.
             */
            tokenSecretRef?: outputs.certmanager.v1alpha3.IssuerSpecVaultAuthTokenSecretRef;
        }

        /**
         * AppRole authenticates with Vault using the App Role auth mechanism, with the role and secret stored in a Kubernetes Secret resource.
         */
        export interface IssuerSpecVaultAuthAppRole {
            /**
             * Path where the App Role authentication backend is mounted in Vault, e.g: "approle"
             */
            path: string;
            /**
             * RoleID configured in the App Role authentication backend when setting up the authentication backend in Vault.
             */
            roleId: string;
            /**
             * Reference to a key in a Secret that contains the App Role secret used to authenticate with Vault. The `key` field must be specified and denotes which entry within the Secret resource is used as the app role secret.
             */
            secretRef: outputs.certmanager.v1alpha3.IssuerSpecVaultAuthAppRoleSecretRef;
        }

        /**
         * Reference to a key in a Secret that contains the App Role secret used to authenticate with Vault. The `key` field must be specified and denotes which entry within the Secret resource is used as the app role secret.
         */
        export interface IssuerSpecVaultAuthAppRoleSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Kubernetes authenticates with Vault by passing the ServiceAccount token stored in the named Secret resource to the Vault server.
         */
        export interface IssuerSpecVaultAuthKubernetes {
            /**
             * The Vault mountPath here is the mount path to use when authenticating with Vault. For example, setting a value to `/v1/auth/foo`, will use the path `/v1/auth/foo/login` to authenticate with Vault. If unspecified, the default value "/v1/auth/kubernetes" will be used.
             */
            mountPath?: string;
            /**
             * A required field containing the Vault Role to assume. A Role binds a Kubernetes ServiceAccount with a set of Vault policies.
             */
            role: string;
            /**
             * The required Secret field containing a Kubernetes ServiceAccount JWT used for authenticating with Vault. Use of 'ambient credentials' is not supported.
             */
            secretRef: outputs.certmanager.v1alpha3.IssuerSpecVaultAuthKubernetesSecretRef;
        }

        /**
         * The required Secret field containing a Kubernetes ServiceAccount JWT used for authenticating with Vault. Use of 'ambient credentials' is not supported.
         */
        export interface IssuerSpecVaultAuthKubernetesSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * TokenSecretRef authenticates with Vault by presenting a token.
         */
        export interface IssuerSpecVaultAuthTokenSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Venafi configures this issuer to sign certificates using a Venafi TPP or Venafi Cloud policy zone.
         */
        export interface IssuerSpecVenafi {
            /**
             * Cloud specifies the Venafi cloud configuration settings. Only one of TPP or Cloud may be specified.
             */
            cloud?: outputs.certmanager.v1alpha3.IssuerSpecVenafiCloud;
            /**
             * TPP specifies Trust Protection Platform configuration settings. Only one of TPP or Cloud may be specified.
             */
            tpp?: outputs.certmanager.v1alpha3.IssuerSpecVenafiTpp;
            /**
             * Zone is the Venafi Policy Zone to use for this issuer. All requests made to the Venafi platform will be restricted by the named zone policy. This field is required.
             */
            zone: string;
        }

        /**
         * Cloud specifies the Venafi cloud configuration settings. Only one of TPP or Cloud may be specified.
         */
        export interface IssuerSpecVenafiCloud {
            /**
             * APITokenSecretRef is a secret key selector for the Venafi Cloud API token.
             */
            apiTokenSecretRef: outputs.certmanager.v1alpha3.IssuerSpecVenafiCloudApiTokenSecretRef;
            /**
             * URL is the base URL for Venafi Cloud. Defaults to "https://api.venafi.cloud/v1".
             */
            url?: string;
        }

        /**
         * APITokenSecretRef is a secret key selector for the Venafi Cloud API token.
         */
        export interface IssuerSpecVenafiCloudApiTokenSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * TPP specifies Trust Protection Platform configuration settings. Only one of TPP or Cloud may be specified.
         */
        export interface IssuerSpecVenafiTpp {
            /**
             * CABundle is a PEM encoded TLS certificate to use to verify connections to the TPP instance. If specified, system roots will not be used and the issuing CA for the TPP instance must be verifiable using the provided root. If not specified, the connection will be verified using the cert-manager system root certificates.
             */
            caBundle?: string;
            /**
             * CredentialsRef is a reference to a Secret containing the username and password for the TPP server. The secret must contain two keys, 'username' and 'password'.
             */
            credentialsRef: outputs.certmanager.v1alpha3.IssuerSpecVenafiTppCredentialsRef;
            /**
             * URL is the base URL for the vedsdk endpoint of the Venafi TPP instance, for example: "https://tpp.example.com/vedsdk".
             */
            url: string;
        }

        /**
         * CredentialsRef is a reference to a Secret containing the username and password for the TPP server. The secret must contain two keys, 'username' and 'password'.
         */
        export interface IssuerSpecVenafiTppCredentialsRef {
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Status of the Issuer. This is set and managed automatically.
         */
        export interface IssuerStatus {
            /**
             * ACME specific status options. This field should only be set if the Issuer is configured to use an ACME server to issue certificates.
             */
            acme?: outputs.certmanager.v1alpha3.IssuerStatusAcme;
            /**
             * List of status conditions to indicate the status of a CertificateRequest. Known condition types are `Ready`.
             */
            conditions?: outputs.certmanager.v1alpha3.IssuerStatusConditions[];
        }

        /**
         * ACME specific status options. This field should only be set if the Issuer is configured to use an ACME server to issue certificates.
         */
        export interface IssuerStatusAcme {
            /**
             * LastRegisteredEmail is the email associated with the latest registered ACME account, in order to track changes made to registered account associated with the  Issuer
             */
            lastRegisteredEmail?: string;
            /**
             * URI is the unique account identifier, which can also be used to retrieve account details from the CA
             */
            uri?: string;
        }

        /**
         * IssuerCondition contains condition information for an Issuer.
         */
        export interface IssuerStatusConditions {
            /**
             * LastTransitionTime is the timestamp corresponding to the last status change of this condition.
             */
            lastTransitionTime?: string;
            /**
             * Message is a human readable description of the details of the last transition, complementing reason.
             */
            message?: string;
            /**
             * Reason is a brief machine readable explanation for the condition's last transition.
             */
            reason?: string;
            /**
             * Status of the condition, one of ('True', 'False', 'Unknown').
             */
            status: string;
            /**
             * Type of the condition, known values are ('Ready').
             */
            type: string;
        }
    }

    export namespace v1beta1 {
        /**
         * Desired state of the CertificateRequest resource.
         */
        export interface CertificateRequestSpec {
            /**
             * The requested 'duration' (i.e. lifetime) of the Certificate. This option may be ignored/overridden by some issuer types.
             */
            duration?: string;
            /**
             * IsCA will request to mark the certificate as valid for certificate signing when submitting to the issuer. This will automatically add the `cert sign` usage to the list of `usages`.
             */
            isCA?: boolean;
            /**
             * IssuerRef is a reference to the issuer for this CertificateRequest.  If the 'kind' field is not set, or set to 'Issuer', an Issuer resource with the given name in the same namespace as the CertificateRequest will be used.  If the 'kind' field is set to 'ClusterIssuer', a ClusterIssuer with the provided name will be used. The 'name' field in this stanza is required at all times. The group field refers to the API group of the issuer which defaults to 'cert-manager.io' if empty.
             */
            issuerRef: outputs.certmanager.v1beta1.CertificateRequestSpecIssuerRef;
            /**
             * The PEM-encoded x509 certificate signing request to be submitted to the CA for signing.
             */
            request: string;
            /**
             * Usages is the set of x509 usages that are requested for the certificate. Defaults to `digital signature` and `key encipherment` if not specified.
             */
            usages?: string[];
        }

        /**
         * IssuerRef is a reference to the issuer for this CertificateRequest.  If the 'kind' field is not set, or set to 'Issuer', an Issuer resource with the given name in the same namespace as the CertificateRequest will be used.  If the 'kind' field is set to 'ClusterIssuer', a ClusterIssuer with the provided name will be used. The 'name' field in this stanza is required at all times. The group field refers to the API group of the issuer which defaults to 'cert-manager.io' if empty.
         */
        export interface CertificateRequestSpecIssuerRef {
            /**
             * Group of the resource being referred to.
             */
            group?: string;
            /**
             * Kind of the resource being referred to.
             */
            kind?: string;
            /**
             * Name of the resource being referred to.
             */
            name: string;
        }

        /**
         * Status of the CertificateRequest. This is set and managed automatically.
         */
        export interface CertificateRequestStatus {
            /**
             * The PEM encoded x509 certificate of the signer, also known as the CA (Certificate Authority). This is set on a best-effort basis by different issuers. If not set, the CA is assumed to be unknown/not available.
             */
            ca?: string;
            /**
             * The PEM encoded x509 certificate resulting from the certificate signing request. If not set, the CertificateRequest has either not been completed or has failed. More information on failure can be found by checking the `conditions` field.
             */
            certificate?: string;
            /**
             * List of status conditions to indicate the status of a CertificateRequest. Known condition types are `Ready` and `InvalidRequest`.
             */
            conditions?: outputs.certmanager.v1beta1.CertificateRequestStatusConditions[];
            /**
             * FailureTime stores the time that this CertificateRequest failed. This is used to influence garbage collection and back-off.
             */
            failureTime?: string;
        }

        /**
         * CertificateRequestCondition contains condition information for a CertificateRequest.
         */
        export interface CertificateRequestStatusConditions {
            /**
             * LastTransitionTime is the timestamp corresponding to the last status change of this condition.
             */
            lastTransitionTime?: string;
            /**
             * Message is a human readable description of the details of the last transition, complementing reason.
             */
            message?: string;
            /**
             * Reason is a brief machine readable explanation for the condition's last transition.
             */
            reason?: string;
            /**
             * Status of the condition, one of ('True', 'False', 'Unknown').
             */
            status: string;
            /**
             * Type of the condition, known values are ('Ready', 'InvalidRequest').
             */
            type: string;
        }

        /**
         * Desired state of the Certificate resource.
         */
        export interface CertificateSpec {
            /**
             * CommonName is a common name to be used on the Certificate. The CommonName should have a length of 64 characters or fewer to avoid generating invalid CSRs. This value is ignored by TLS clients when any subject alt name is set. This is x509 behaviour: https://tools.ietf.org/html/rfc6125#section-6.4.4
             */
            commonName?: string;
            /**
             * DNSNames is a list of DNS subjectAltNames to be set on the Certificate.
             */
            dnsNames?: string[];
            /**
             * The requested 'duration' (i.e. lifetime) of the Certificate. This option may be ignored/overridden by some issuer types. If overridden and `renewBefore` is greater than the actual certificate duration, the certificate will be automatically renewed 2/3rds of the way through the certificate's duration.
             */
            duration?: string;
            /**
             * EmailSANs is a list of email subjectAltNames to be set on the Certificate.
             */
            emailSANs?: string[];
            /**
             * EncodeUsagesInRequest controls whether key usages should be present in the CertificateRequest
             */
            encodeUsagesInRequest?: boolean;
            /**
             * IPAddresses is a list of IP address subjectAltNames to be set on the Certificate.
             */
            ipAddresses?: string[];
            /**
             * IsCA will mark this Certificate as valid for certificate signing. This will automatically add the `cert sign` usage to the list of `usages`.
             */
            isCA?: boolean;
            /**
             * IssuerRef is a reference to the issuer for this certificate. If the 'kind' field is not set, or set to 'Issuer', an Issuer resource with the given name in the same namespace as the Certificate will be used. If the 'kind' field is set to 'ClusterIssuer', a ClusterIssuer with the provided name will be used. The 'name' field in this stanza is required at all times.
             */
            issuerRef: outputs.certmanager.v1beta1.CertificateSpecIssuerRef;
            /**
             * Keystores configures additional keystore output formats stored in the `secretName` Secret resource.
             */
            keystores?: outputs.certmanager.v1beta1.CertificateSpecKeystores;
            /**
             * Options to control private keys used for the Certificate.
             */
            privateKey?: outputs.certmanager.v1beta1.CertificateSpecPrivateKey;
            /**
             * The amount of time before the currently issued certificate's `notAfter` time that cert-manager will begin to attempt to renew the certificate. If this value is greater than the total duration of the certificate (i.e. notAfter - notBefore), it will be automatically renewed 2/3rds of the way through the certificate's duration.
             */
            renewBefore?: string;
            /**
             * SecretName is the name of the secret resource that will be automatically created and managed by this Certificate resource. It will be populated with a private key and certificate, signed by the denoted issuer.
             */
            secretName: string;
            /**
             * Full X509 name specification (https://golang.org/pkg/crypto/x509/pkix/#Name).
             */
            subject?: outputs.certmanager.v1beta1.CertificateSpecSubject;
            /**
             * URISANs is a list of URI subjectAltNames to be set on the Certificate.
             */
            uriSANs?: string[];
            /**
             * Usages is the set of x509 usages that are requested for the certificate. Defaults to `digital signature` and `key encipherment` if not specified.
             */
            usages?: string[];
        }

        /**
         * IssuerRef is a reference to the issuer for this certificate. If the 'kind' field is not set, or set to 'Issuer', an Issuer resource with the given name in the same namespace as the Certificate will be used. If the 'kind' field is set to 'ClusterIssuer', a ClusterIssuer with the provided name will be used. The 'name' field in this stanza is required at all times.
         */
        export interface CertificateSpecIssuerRef {
            /**
             * Group of the resource being referred to.
             */
            group?: string;
            /**
             * Kind of the resource being referred to.
             */
            kind?: string;
            /**
             * Name of the resource being referred to.
             */
            name: string;
        }

        /**
         * Keystores configures additional keystore output formats stored in the `secretName` Secret resource.
         */
        export interface CertificateSpecKeystores {
            /**
             * JKS configures options for storing a JKS keystore in the `spec.secretName` Secret resource.
             */
            jks?: outputs.certmanager.v1beta1.CertificateSpecKeystoresJks;
            /**
             * PKCS12 configures options for storing a PKCS12 keystore in the `spec.secretName` Secret resource.
             */
            pkcs12?: outputs.certmanager.v1beta1.CertificateSpecKeystoresPkcs12;
        }

        /**
         * JKS configures options for storing a JKS keystore in the `spec.secretName` Secret resource.
         */
        export interface CertificateSpecKeystoresJks {
            /**
             * Create enables JKS keystore creation for the Certificate. If true, a file named `keystore.jks` will be created in the target Secret resource, encrypted using the password stored in `passwordSecretRef`. The keystore file will only be updated upon re-issuance.
             */
            create: boolean;
            /**
             * PasswordSecretRef is a reference to a key in a Secret resource containing the password used to encrypt the JKS keystore.
             */
            passwordSecretRef: outputs.certmanager.v1beta1.CertificateSpecKeystoresJksPasswordSecretRef;
        }

        /**
         * PasswordSecretRef is a reference to a key in a Secret resource containing the password used to encrypt the JKS keystore.
         */
        export interface CertificateSpecKeystoresJksPasswordSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * PKCS12 configures options for storing a PKCS12 keystore in the `spec.secretName` Secret resource.
         */
        export interface CertificateSpecKeystoresPkcs12 {
            /**
             * Create enables PKCS12 keystore creation for the Certificate. If true, a file named `keystore.p12` will be created in the target Secret resource, encrypted using the password stored in `passwordSecretRef`. The keystore file will only be updated upon re-issuance.
             */
            create: boolean;
            /**
             * PasswordSecretRef is a reference to a key in a Secret resource containing the password used to encrypt the PKCS12 keystore.
             */
            passwordSecretRef: outputs.certmanager.v1beta1.CertificateSpecKeystoresPkcs12PasswordSecretRef;
        }

        /**
         * PasswordSecretRef is a reference to a key in a Secret resource containing the password used to encrypt the PKCS12 keystore.
         */
        export interface CertificateSpecKeystoresPkcs12PasswordSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Options to control private keys used for the Certificate.
         */
        export interface CertificateSpecPrivateKey {
            /**
             * Algorithm is the private key algorithm of the corresponding private key for this certificate. If provided, allowed values are either "rsa" or "ecdsa" If `algorithm` is specified and `size` is not provided, key size of 256 will be used for "ecdsa" key algorithm and key size of 2048 will be used for "rsa" key algorithm.
             */
            algorithm?: string;
            /**
             * The private key cryptography standards (PKCS) encoding for this certificate's private key to be encoded in. If provided, allowed values are "pkcs1" and "pkcs8" standing for PKCS#1 and PKCS#8, respectively. Defaults to PKCS#1 if not specified.
             */
            encoding?: string;
            /**
             * RotationPolicy controls how private keys should be regenerated when a re-issuance is being processed. If set to Never, a private key will only be generated if one does not already exist in the target `spec.secretName`. If one does exists but it does not have the correct algorithm or size, a warning will be raised to await user intervention. If set to Always, a private key matching the specified requirements will be generated whenever a re-issuance occurs. Default is 'Never' for backward compatibility.
             */
            rotationPolicy?: string;
            /**
             * Size is the key bit size of the corresponding private key for this certificate. If `algorithm` is set to `RSA`, valid values are `2048`, `4096` or `8192`, and will default to `2048` if not specified. If `algorithm` is set to `ECDSA`, valid values are `256`, `384` or `521`, and will default to `256` if not specified. No other values are allowed.
             */
            size?: number;
        }

        /**
         * Full X509 name specification (https://golang.org/pkg/crypto/x509/pkix/#Name).
         */
        export interface CertificateSpecSubject {
            /**
             * Countries to be used on the Certificate.
             */
            countries?: string[];
            /**
             * Cities to be used on the Certificate.
             */
            localities?: string[];
            /**
             * Organizational Units to be used on the Certificate.
             */
            organizationalUnits?: string[];
            /**
             * Organizations to be used on the Certificate.
             */
            organizations?: string[];
            /**
             * Postal codes to be used on the Certificate.
             */
            postalCodes?: string[];
            /**
             * State/Provinces to be used on the Certificate.
             */
            provinces?: string[];
            /**
             * Serial number to be used on the Certificate.
             */
            serialNumber?: string;
            /**
             * Street addresses to be used on the Certificate.
             */
            streetAddresses?: string[];
        }

        /**
         * Status of the Certificate. This is set and managed automatically.
         */
        export interface CertificateStatus {
            /**
             * List of status conditions to indicate the status of certificates. Known condition types are `Ready` and `Issuing`.
             */
            conditions?: outputs.certmanager.v1beta1.CertificateStatusConditions[];
            /**
             * LastFailureTime is the time as recorded by the Certificate controller of the most recent failure to complete a CertificateRequest for this Certificate resource. If set, cert-manager will not re-request another Certificate until 1 hour has elapsed from this time.
             */
            lastFailureTime?: string;
            /**
             * The name of the Secret resource containing the private key to be used for the next certificate iteration. The keymanager controller will automatically set this field if the `Issuing` condition is set to `True`. It will automatically unset this field when the Issuing condition is not set or False.
             */
            nextPrivateKeySecretName?: string;
            /**
             * The expiration time of the certificate stored in the secret named by this resource in `spec.secretName`.
             */
            notAfter?: string;
            /**
             * The time after which the certificate stored in the secret named by this resource in spec.secretName is valid.
             */
            notBefore?: string;
            /**
             * RenewalTime is the time at which the certificate will be next renewed. If not set, no upcoming renewal is scheduled.
             */
            renewalTime?: string;
            /**
             * The current 'revision' of the certificate as issued. 
             *  When a CertificateRequest resource is created, it will have the `cert-manager.io/certificate-revision` set to one greater than the current value of this field. 
             *  Upon issuance, this field will be set to the value of the annotation on the CertificateRequest resource used to issue the certificate. 
             *  Persisting the value on the CertificateRequest resource allows the certificates controller to know whether a request is part of an old issuance or if it is part of the ongoing revision's issuance by checking if the revision value in the annotation is greater than this field.
             */
            revision?: number;
        }

        /**
         * CertificateCondition contains condition information for an Certificate.
         */
        export interface CertificateStatusConditions {
            /**
             * LastTransitionTime is the timestamp corresponding to the last status change of this condition.
             */
            lastTransitionTime?: string;
            /**
             * Message is a human readable description of the details of the last transition, complementing reason.
             */
            message?: string;
            /**
             * Reason is a brief machine readable explanation for the condition's last transition.
             */
            reason?: string;
            /**
             * Status of the condition, one of ('True', 'False', 'Unknown').
             */
            status: string;
            /**
             * Type of the condition, known values are ('Ready', `Issuing`).
             */
            type: string;
        }

        /**
         * Desired state of the ClusterIssuer resource.
         */
        export interface ClusterIssuerSpec {
            /**
             * ACME configures this issuer to communicate with a RFC8555 (ACME) server to obtain signed x509 certificates.
             */
            acme?: outputs.certmanager.v1beta1.ClusterIssuerSpecAcme;
            /**
             * CA configures this issuer to sign certificates using a signing CA keypair stored in a Secret resource. This is used to build internal PKIs that are managed by cert-manager.
             */
            ca?: outputs.certmanager.v1beta1.ClusterIssuerSpecCa;
            /**
             * SelfSigned configures this issuer to 'self sign' certificates using the private key used to create the CertificateRequest object.
             */
            selfSigned?: outputs.certmanager.v1beta1.ClusterIssuerSpecSelfSigned;
            /**
             * Vault configures this issuer to sign certificates using a HashiCorp Vault PKI backend.
             */
            vault?: outputs.certmanager.v1beta1.ClusterIssuerSpecVault;
            /**
             * Venafi configures this issuer to sign certificates using a Venafi TPP or Venafi Cloud policy zone.
             */
            venafi?: outputs.certmanager.v1beta1.ClusterIssuerSpecVenafi;
        }

        /**
         * ACME configures this issuer to communicate with a RFC8555 (ACME) server to obtain signed x509 certificates.
         */
        export interface ClusterIssuerSpecAcme {
            /**
             * Enables or disables generating a new ACME account key. If true, the Issuer resource will *not* request a new account but will expect the account key to be supplied via an existing secret. If false, the cert-manager system will generate a new ACME account key for the Issuer. Defaults to false.
             */
            disableAccountKeyGeneration?: boolean;
            /**
             * Email is the email address to be associated with the ACME account. This field is optional, but it is strongly recommended to be set. It will be used to contact you in case of issues with your account or certificates, including expiry notification emails. This field may be updated after the account is initially registered.
             */
            email?: string;
            /**
             * Enables requesting a Not After date on certificates that matches the duration of the certificate. This is not supported by all ACME servers like Let's Encrypt. If set to true when the ACME server does not support it it will create an error on the Order. Defaults to false.
             */
            enableDurationFeature?: boolean;
            /**
             * ExternalAccountBinding is a reference to a CA external account of the ACME server. If set, upon registration cert-manager will attempt to associate the given external account credentials with the registered ACME account.
             */
            externalAccountBinding?: outputs.certmanager.v1beta1.ClusterIssuerSpecAcmeExternalAccountBinding;
            /**
             * PreferredChain is the chain to use if the ACME server outputs multiple. PreferredChain is no guarantee that this one gets delivered by the ACME endpoint. For example, for Let's Encrypt's DST crosssign you would use: "DST Root CA X3" or "ISRG Root X1" for the newer Let's Encrypt root CA. This value picks the first certificate bundle in the ACME alternative chains that has a certificate with this value as its issuer's CN
             */
            preferredChain?: string;
            /**
             * PrivateKey is the name of a Kubernetes Secret resource that will be used to store the automatically generated ACME account private key. Optionally, a `key` may be specified to select a specific entry within the named Secret resource. If `key` is not specified, a default of `tls.key` will be used.
             */
            privateKeySecretRef: outputs.certmanager.v1beta1.ClusterIssuerSpecAcmePrivateKeySecretRef;
            /**
             * Server is the URL used to access the ACME server's 'directory' endpoint. For example, for Let's Encrypt's staging endpoint, you would use: "https://acme-staging-v02.api.letsencrypt.org/directory". Only ACME v2 endpoints (i.e. RFC 8555) are supported.
             */
            server: string;
            /**
             * Enables or disables validation of the ACME server TLS certificate. If true, requests to the ACME server will not have their TLS certificate validated (i.e. insecure connections will be allowed). Only enable this option in development environments. The cert-manager system installed roots will be used to verify connections to the ACME server if this is false. Defaults to false.
             */
            skipTLSVerify?: boolean;
            /**
             * Solvers is a list of challenge solvers that will be used to solve ACME challenges for the matching domains. Solver configurations must be provided in order to obtain certificates from an ACME server. For more information, see: https://cert-manager.io/docs/configuration/acme/
             */
            solvers?: outputs.certmanager.v1beta1.ClusterIssuerSpecAcmeSolvers[];
        }

        /**
         * ExternalAccountBinding is a reference to a CA external account of the ACME server. If set, upon registration cert-manager will attempt to associate the given external account credentials with the registered ACME account.
         */
        export interface ClusterIssuerSpecAcmeExternalAccountBinding {
            /**
             * keyAlgorithm is the MAC key algorithm that the key is used for. Valid values are "HS256", "HS384" and "HS512".
             */
            keyAlgorithm: string;
            /**
             * keyID is the ID of the CA key that the External Account is bound to.
             */
            keyID: string;
            /**
             * keySecretRef is a Secret Key Selector referencing a data item in a Kubernetes Secret which holds the symmetric MAC key of the External Account Binding. The `key` is the index string that is paired with the key data in the Secret and should not be confused with the key data itself, or indeed with the External Account Binding keyID above. The secret key stored in the Secret **must** be un-padded, base64 URL encoded data.
             */
            keySecretRef: outputs.certmanager.v1beta1.ClusterIssuerSpecAcmeExternalAccountBindingKeySecretRef;
        }

        /**
         * keySecretRef is a Secret Key Selector referencing a data item in a Kubernetes Secret which holds the symmetric MAC key of the External Account Binding. The `key` is the index string that is paired with the key data in the Secret and should not be confused with the key data itself, or indeed with the External Account Binding keyID above. The secret key stored in the Secret **must** be un-padded, base64 URL encoded data.
         */
        export interface ClusterIssuerSpecAcmeExternalAccountBindingKeySecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * PrivateKey is the name of a Kubernetes Secret resource that will be used to store the automatically generated ACME account private key. Optionally, a `key` may be specified to select a specific entry within the named Secret resource. If `key` is not specified, a default of `tls.key` will be used.
         */
        export interface ClusterIssuerSpecAcmePrivateKeySecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Configures an issuer to solve challenges using the specified options. Only one of HTTP01 or DNS01 may be provided.
         */
        export interface ClusterIssuerSpecAcmeSolvers {
            /**
             * Configures cert-manager to attempt to complete authorizations by performing the DNS01 challenge flow.
             */
            dns01?: outputs.certmanager.v1beta1.ClusterIssuerSpecAcmeSolversDns01;
            /**
             * Configures cert-manager to attempt to complete authorizations by performing the HTTP01 challenge flow. It is not possible to obtain certificates for wildcard domain names (e.g. `*.example.com`) using the HTTP01 challenge mechanism.
             */
            http01?: outputs.certmanager.v1beta1.ClusterIssuerSpecAcmeSolversHttp01;
            /**
             * Selector selects a set of DNSNames on the Certificate resource that should be solved using this challenge solver. If not specified, the solver will be treated as the 'default' solver with the lowest priority, i.e. if any other solver has a more specific match, it will be used instead.
             */
            selector?: outputs.certmanager.v1beta1.ClusterIssuerSpecAcmeSolversSelector;
        }

        /**
         * Configures cert-manager to attempt to complete authorizations by performing the DNS01 challenge flow.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01 {
            /**
             * Use the 'ACME DNS' (https://github.com/joohoi/acme-dns) API to manage DNS01 challenge records.
             */
            acmeDNS?: outputs.certmanager.v1beta1.ClusterIssuerSpecAcmeSolversDns01AcmeDNS;
            /**
             * Use the Akamai DNS zone management API to manage DNS01 challenge records.
             */
            akamai?: outputs.certmanager.v1beta1.ClusterIssuerSpecAcmeSolversDns01Akamai;
            /**
             * Use the Microsoft Azure DNS API to manage DNS01 challenge records.
             */
            azureDNS?: outputs.certmanager.v1beta1.ClusterIssuerSpecAcmeSolversDns01AzureDNS;
            /**
             * Use the Google Cloud DNS API to manage DNS01 challenge records.
             */
            cloudDNS?: outputs.certmanager.v1beta1.ClusterIssuerSpecAcmeSolversDns01CloudDNS;
            /**
             * Use the Cloudflare API to manage DNS01 challenge records.
             */
            cloudflare?: outputs.certmanager.v1beta1.ClusterIssuerSpecAcmeSolversDns01Cloudflare;
            /**
             * CNAMEStrategy configures how the DNS01 provider should handle CNAME records when found in DNS zones.
             */
            cnameStrategy?: string;
            /**
             * Use the DigitalOcean DNS API to manage DNS01 challenge records.
             */
            digitalocean?: outputs.certmanager.v1beta1.ClusterIssuerSpecAcmeSolversDns01Digitalocean;
            /**
             * Use RFC2136 ("Dynamic Updates in the Domain Name System") (https://datatracker.ietf.org/doc/rfc2136/) to manage DNS01 challenge records.
             */
            rfc2136?: outputs.certmanager.v1beta1.ClusterIssuerSpecAcmeSolversDns01Rfc2136;
            /**
             * Use the AWS Route53 API to manage DNS01 challenge records.
             */
            route53?: outputs.certmanager.v1beta1.ClusterIssuerSpecAcmeSolversDns01Route53;
            /**
             * Configure an external webhook based DNS01 challenge solver to manage DNS01 challenge records.
             */
            webhook?: outputs.certmanager.v1beta1.ClusterIssuerSpecAcmeSolversDns01Webhook;
        }

        /**
         * Use the 'ACME DNS' (https://github.com/joohoi/acme-dns) API to manage DNS01 challenge records.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01AcmeDNS {
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            accountSecretRef: outputs.certmanager.v1beta1.ClusterIssuerSpecAcmeSolversDns01AcmeDNSAccountSecretRef;
            host: string;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01AcmeDNSAccountSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the Akamai DNS zone management API to manage DNS01 challenge records.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01Akamai {
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            accessTokenSecretRef: outputs.certmanager.v1beta1.ClusterIssuerSpecAcmeSolversDns01AkamaiAccessTokenSecretRef;
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            clientSecretSecretRef: outputs.certmanager.v1beta1.ClusterIssuerSpecAcmeSolversDns01AkamaiClientSecretSecretRef;
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            clientTokenSecretRef: outputs.certmanager.v1beta1.ClusterIssuerSpecAcmeSolversDns01AkamaiClientTokenSecretRef;
            serviceConsumerDomain: string;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01AkamaiAccessTokenSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01AkamaiClientSecretSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01AkamaiClientTokenSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the Microsoft Azure DNS API to manage DNS01 challenge records.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01AzureDNS {
            /**
             * if both this and ClientSecret are left unset MSI will be used
             */
            clientID?: string;
            /**
             * if both this and ClientID are left unset MSI will be used
             */
            clientSecretSecretRef?: outputs.certmanager.v1beta1.ClusterIssuerSpecAcmeSolversDns01AzureDNSClientSecretSecretRef;
            environment?: string;
            hostedZoneName?: string;
            resourceGroupName: string;
            subscriptionID: string;
            /**
             * when specifying ClientID and ClientSecret then this field is also needed
             */
            tenantID?: string;
        }

        /**
         * if both this and ClientID are left unset MSI will be used
         */
        export interface ClusterIssuerSpecAcmeSolversDns01AzureDNSClientSecretSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the Google Cloud DNS API to manage DNS01 challenge records.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01CloudDNS {
            /**
             * HostedZoneName is an optional field that tells cert-manager in which Cloud DNS zone the challenge record has to be created. If left empty cert-manager will automatically choose a zone.
             */
            hostedZoneName?: string;
            project: string;
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            serviceAccountSecretRef?: outputs.certmanager.v1beta1.ClusterIssuerSpecAcmeSolversDns01CloudDNSServiceAccountSecretRef;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01CloudDNSServiceAccountSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the Cloudflare API to manage DNS01 challenge records.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01Cloudflare {
            /**
             * API key to use to authenticate with Cloudflare. Note: using an API token to authenticate is now the recommended method as it allows greater control of permissions.
             */
            apiKeySecretRef?: outputs.certmanager.v1beta1.ClusterIssuerSpecAcmeSolversDns01CloudflareApiKeySecretRef;
            /**
             * API token used to authenticate with Cloudflare.
             */
            apiTokenSecretRef?: outputs.certmanager.v1beta1.ClusterIssuerSpecAcmeSolversDns01CloudflareApiTokenSecretRef;
            /**
             * Email of the account, only required when using API key based authentication.
             */
            email?: string;
        }

        /**
         * API key to use to authenticate with Cloudflare. Note: using an API token to authenticate is now the recommended method as it allows greater control of permissions.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01CloudflareApiKeySecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * API token used to authenticate with Cloudflare.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01CloudflareApiTokenSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the DigitalOcean DNS API to manage DNS01 challenge records.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01Digitalocean {
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            tokenSecretRef: outputs.certmanager.v1beta1.ClusterIssuerSpecAcmeSolversDns01DigitaloceanTokenSecretRef;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01DigitaloceanTokenSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use RFC2136 ("Dynamic Updates in the Domain Name System") (https://datatracker.ietf.org/doc/rfc2136/) to manage DNS01 challenge records.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01Rfc2136 {
            /**
             * The IP address or hostname of an authoritative DNS server supporting RFC2136 in the form host:port. If the host is an IPv6 address it must be enclosed in square brackets (e.g [2001:db8::1]) ; port is optional. This field is required.
             */
            nameserver: string;
            /**
             * The TSIG Algorithm configured in the DNS supporting RFC2136. Used only when ``tsigSecretSecretRef`` and ``tsigKeyName`` are defined. Supported values are (case-insensitive): ``HMACMD5`` (default), ``HMACSHA1``, ``HMACSHA256`` or ``HMACSHA512``.
             */
            tsigAlgorithm?: string;
            /**
             * The TSIG Key name configured in the DNS. If ``tsigSecretSecretRef`` is defined, this field is required.
             */
            tsigKeyName?: string;
            /**
             * The name of the secret containing the TSIG value. If ``tsigKeyName`` is defined, this field is required.
             */
            tsigSecretSecretRef?: outputs.certmanager.v1beta1.ClusterIssuerSpecAcmeSolversDns01Rfc2136TsigSecretSecretRef;
        }

        /**
         * The name of the secret containing the TSIG value. If ``tsigKeyName`` is defined, this field is required.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01Rfc2136TsigSecretSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the AWS Route53 API to manage DNS01 challenge records.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01Route53 {
            /**
             * The AccessKeyID is used for authentication. If not set we fall-back to using env vars, shared credentials file or AWS Instance metadata see: https://docs.aws.amazon.com/sdk-for-go/v1/developer-guide/configuring-sdk.html#specifying-credentials
             */
            accessKeyID?: string;
            /**
             * If set, the provider will manage only this zone in Route53 and will not do an lookup using the route53:ListHostedZonesByName api call.
             */
            hostedZoneID?: string;
            /**
             * Always set the region when using AccessKeyID and SecretAccessKey
             */
            region: string;
            /**
             * Role is a Role ARN which the Route53 provider will assume using either the explicit credentials AccessKeyID/SecretAccessKey or the inferred credentials from environment variables, shared credentials file or AWS Instance metadata
             */
            role?: string;
            /**
             * The SecretAccessKey is used for authentication. If not set we fall-back to using env vars, shared credentials file or AWS Instance metadata https://docs.aws.amazon.com/sdk-for-go/v1/developer-guide/configuring-sdk.html#specifying-credentials
             */
            secretAccessKeySecretRef?: outputs.certmanager.v1beta1.ClusterIssuerSpecAcmeSolversDns01Route53SecretAccessKeySecretRef;
        }

        /**
         * The SecretAccessKey is used for authentication. If not set we fall-back to using env vars, shared credentials file or AWS Instance metadata https://docs.aws.amazon.com/sdk-for-go/v1/developer-guide/configuring-sdk.html#specifying-credentials
         */
        export interface ClusterIssuerSpecAcmeSolversDns01Route53SecretAccessKeySecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Configure an external webhook based DNS01 challenge solver to manage DNS01 challenge records.
         */
        export interface ClusterIssuerSpecAcmeSolversDns01Webhook {
            /**
             * Additional configuration that should be passed to the webhook apiserver when challenges are processed. This can contain arbitrary JSON data. Secret values should not be specified in this stanza. If secret values are needed (e.g. credentials for a DNS service), you should use a SecretKeySelector to reference a Secret resource. For details on the schema of this field, consult the webhook provider implementation's documentation.
             */
            config?: {[key: string]: any};
            /**
             * The API group name that should be used when POSTing ChallengePayload resources to the webhook apiserver. This should be the same as the GroupName specified in the webhook provider implementation.
             */
            groupName: string;
            /**
             * The name of the solver to use, as defined in the webhook provider implementation. This will typically be the name of the provider, e.g. 'cloudflare'.
             */
            solverName: string;
        }

        /**
         * Configures cert-manager to attempt to complete authorizations by performing the HTTP01 challenge flow. It is not possible to obtain certificates for wildcard domain names (e.g. `*.example.com`) using the HTTP01 challenge mechanism.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01 {
            /**
             * The ingress based HTTP01 challenge solver will solve challenges by creating or modifying Ingress resources in order to route requests for '/.well-known/acme-challenge/XYZ' to 'challenge solver' pods that are provisioned by cert-manager for each Challenge to be completed.
             */
            ingress?: outputs.certmanager.v1beta1.ClusterIssuerSpecAcmeSolversHttp01Ingress;
        }

        /**
         * The ingress based HTTP01 challenge solver will solve challenges by creating or modifying Ingress resources in order to route requests for '/.well-known/acme-challenge/XYZ' to 'challenge solver' pods that are provisioned by cert-manager for each Challenge to be completed.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01Ingress {
            /**
             * The ingress class to use when creating Ingress resources to solve ACME challenges that use this challenge solver. Only one of 'class' or 'name' may be specified.
             */
            class?: string;
            /**
             * Optional ingress template used to configure the ACME challenge solver ingress used for HTTP01 challenges
             */
            ingressTemplate?: outputs.certmanager.v1beta1.ClusterIssuerSpecAcmeSolversHttp01IngressIngressTemplate;
            /**
             * The name of the ingress resource that should have ACME challenge solving routes inserted into it in order to solve HTTP01 challenges. This is typically used in conjunction with ingress controllers like ingress-gce, which maintains a 1:1 mapping between external IPs and ingress resources.
             */
            name?: string;
            /**
             * Optional pod template used to configure the ACME challenge solver pods used for HTTP01 challenges
             */
            podTemplate?: outputs.certmanager.v1beta1.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplate;
            /**
             * Optional service type for Kubernetes solver service
             */
            serviceType?: string;
        }

        /**
         * Optional ingress template used to configure the ACME challenge solver ingress used for HTTP01 challenges
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressIngressTemplate {
            /**
             * ObjectMeta overrides for the ingress used to solve HTTP01 challenges. Only the 'labels' and 'annotations' fields may be set. If labels or annotations overlap with in-built values, the values here will override the in-built values.
             */
            metadata?: outputs.certmanager.v1beta1.ClusterIssuerSpecAcmeSolversHttp01IngressIngressTemplateMetadata;
        }

        /**
         * ObjectMeta overrides for the ingress used to solve HTTP01 challenges. Only the 'labels' and 'annotations' fields may be set. If labels or annotations overlap with in-built values, the values here will override the in-built values.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressIngressTemplateMetadata {
            /**
             * Annotations that should be added to the created ACME HTTP01 solver ingress.
             */
            annotations?: {[key: string]: string};
            /**
             * Labels that should be added to the created ACME HTTP01 solver ingress.
             */
            labels?: {[key: string]: string};
        }

        /**
         * Optional pod template used to configure the ACME challenge solver pods used for HTTP01 challenges
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplate {
            /**
             * ObjectMeta overrides for the pod used to solve HTTP01 challenges. Only the 'labels' and 'annotations' fields may be set. If labels or annotations overlap with in-built values, the values here will override the in-built values.
             */
            metadata?: outputs.certmanager.v1beta1.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateMetadata;
            /**
             * PodSpec defines overrides for the HTTP01 challenge solver pod. Only the 'priorityClassName', 'nodeSelector', 'affinity', 'serviceAccountName' and 'tolerations' fields are supported currently. All other fields will be ignored.
             */
            spec?: outputs.certmanager.v1beta1.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpec;
        }

        /**
         * ObjectMeta overrides for the pod used to solve HTTP01 challenges. Only the 'labels' and 'annotations' fields may be set. If labels or annotations overlap with in-built values, the values here will override the in-built values.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateMetadata {
            /**
             * Annotations that should be added to the create ACME HTTP01 solver pods.
             */
            annotations?: {[key: string]: string};
            /**
             * Labels that should be added to the created ACME HTTP01 solver pods.
             */
            labels?: {[key: string]: string};
        }

        /**
         * PodSpec defines overrides for the HTTP01 challenge solver pod. Only the 'priorityClassName', 'nodeSelector', 'affinity', 'serviceAccountName' and 'tolerations' fields are supported currently. All other fields will be ignored.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpec {
            /**
             * If specified, the pod's scheduling constraints
             */
            affinity?: outputs.certmanager.v1beta1.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinity;
            /**
             * NodeSelector is a selector which must be true for the pod to fit on a node. Selector which must match a node's labels for the pod to be scheduled on that node. More info: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/
             */
            nodeSelector?: {[key: string]: string};
            /**
             * If specified, the pod's priorityClassName.
             */
            priorityClassName?: string;
            /**
             * If specified, the pod's service account
             */
            serviceAccountName?: string;
            /**
             * If specified, the pod's tolerations.
             */
            tolerations?: outputs.certmanager.v1beta1.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecTolerations[];
        }

        /**
         * If specified, the pod's scheduling constraints
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinity {
            /**
             * Describes node affinity scheduling rules for the pod.
             */
            nodeAffinity?: outputs.certmanager.v1beta1.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinity;
            /**
             * Describes pod affinity scheduling rules (e.g. co-locate this pod in the same node, zone, etc. as some other pod(s)).
             */
            podAffinity?: outputs.certmanager.v1beta1.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinity;
            /**
             * Describes pod anti-affinity scheduling rules (e.g. avoid putting this pod in the same node, zone, etc. as some other pod(s)).
             */
            podAntiAffinity?: outputs.certmanager.v1beta1.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinity;
        }

        /**
         * Describes node affinity scheduling rules for the pod.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinity {
            /**
             * The scheduler will prefer to schedule pods to nodes that satisfy the affinity expressions specified by this field, but it may choose a node that violates one or more of the expressions. The node that is most preferred is the one with the greatest sum of weights, i.e. for each node that meets all of the scheduling requirements (resource request, requiredDuringScheduling affinity expressions, etc.), compute a sum by iterating through the elements of this field and adding "weight" to the sum if the node matches the corresponding matchExpressions; the node(s) with the highest sum are the most preferred.
             */
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.certmanager.v1beta1.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            /**
             * If the affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to an update), the system may or may not try to eventually evict the pod from its node.
             */
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.certmanager.v1beta1.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution;
        }

        /**
         * An empty preferred scheduling term matches all objects with implicit weight 0 (i.e. it's a no-op). A null preferred scheduling term matches no objects (i.e. is also a no-op).
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            /**
             * A node selector term, associated with the corresponding weight.
             */
            preference: outputs.certmanager.v1beta1.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference;
            /**
             * Weight associated with matching the corresponding nodeSelectorTerm, in the range 1-100.
             */
            weight: number;
        }

        /**
         * A node selector term, associated with the corresponding weight.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference {
            /**
             * A list of node selector requirements by node's labels.
             */
            matchExpressions?: outputs.certmanager.v1beta1.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions[];
            /**
             * A list of node selector requirements by node's fields.
             */
            matchFields?: outputs.certmanager.v1beta1.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields[];
        }

        /**
         * A node selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions {
            /**
             * The label key that the selector applies to.
             */
            key: string;
            /**
             * Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
             */
            operator: string;
            /**
             * An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * A node selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields {
            /**
             * The label key that the selector applies to.
             */
            key: string;
            /**
             * Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
             */
            operator: string;
            /**
             * An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * If the affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to an update), the system may or may not try to eventually evict the pod from its node.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            /**
             * Required. A list of node selector terms. The terms are ORed.
             */
            nodeSelectorTerms: outputs.certmanager.v1beta1.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms[];
        }

        /**
         * A null or empty node selector term matches no objects. The requirements of them are ANDed. The TopologySelectorTerm type implements a subset of the NodeSelectorTerm.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms {
            /**
             * A list of node selector requirements by node's labels.
             */
            matchExpressions?: outputs.certmanager.v1beta1.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions[];
            /**
             * A list of node selector requirements by node's fields.
             */
            matchFields?: outputs.certmanager.v1beta1.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields[];
        }

        /**
         * A node selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions {
            /**
             * The label key that the selector applies to.
             */
            key: string;
            /**
             * Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
             */
            operator: string;
            /**
             * An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * A node selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields {
            /**
             * The label key that the selector applies to.
             */
            key: string;
            /**
             * Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
             */
            operator: string;
            /**
             * An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Describes pod affinity scheduling rules (e.g. co-locate this pod in the same node, zone, etc. as some other pod(s)).
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinity {
            /**
             * The scheduler will prefer to schedule pods to nodes that satisfy the affinity expressions specified by this field, but it may choose a node that violates one or more of the expressions. The node that is most preferred is the one with the greatest sum of weights, i.e. for each node that meets all of the scheduling requirements (resource request, requiredDuringScheduling affinity expressions, etc.), compute a sum by iterating through the elements of this field and adding "weight" to the sum if the node has pods which matches the corresponding podAffinityTerm; the node(s) with the highest sum are the most preferred.
             */
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.certmanager.v1beta1.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            /**
             * If the affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to a pod label update), the system may or may not try to eventually evict the pod from its node. When there are multiple elements, the lists of nodes corresponding to each podAffinityTerm are intersected, i.e. all terms must be satisfied.
             */
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.certmanager.v1beta1.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        /**
         * The weights of all of the matched WeightedPodAffinityTerm fields are added per-node to find the most preferred node(s)
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            /**
             * Required. A pod affinity term, associated with the corresponding weight.
             */
            podAffinityTerm: outputs.certmanager.v1beta1.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            /**
             * weight associated with matching the corresponding podAffinityTerm, in the range 1-100.
             */
            weight: number;
        }

        /**
         * Required. A pod affinity term, associated with the corresponding weight.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            /**
             * A label query over a set of resources, in this case pods.
             */
            labelSelector?: outputs.certmanager.v1beta1.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            /**
             * namespaces specifies which namespaces the labelSelector applies to (matches against); null or empty list means "this pod's namespace"
             */
            namespaces?: string[];
            /**
             * This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed.
             */
            topologyKey: string;
        }

        /**
         * A label query over a set of resources, in this case pods.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.certmanager.v1beta1.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Defines a set of pods (namely those matching the labelSelector relative to the given namespace(s)) that this pod should be co-located (affinity) or not co-located (anti-affinity) with, where co-located is defined as running on a node whose value of the label with key <topologyKey> matches that of any node on which a pod of the set of pods is running
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            /**
             * A label query over a set of resources, in this case pods.
             */
            labelSelector?: outputs.certmanager.v1beta1.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            /**
             * namespaces specifies which namespaces the labelSelector applies to (matches against); null or empty list means "this pod's namespace"
             */
            namespaces?: string[];
            /**
             * This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed.
             */
            topologyKey: string;
        }

        /**
         * A label query over a set of resources, in this case pods.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.certmanager.v1beta1.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Describes pod anti-affinity scheduling rules (e.g. avoid putting this pod in the same node, zone, etc. as some other pod(s)).
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinity {
            /**
             * The scheduler will prefer to schedule pods to nodes that satisfy the anti-affinity expressions specified by this field, but it may choose a node that violates one or more of the expressions. The node that is most preferred is the one with the greatest sum of weights, i.e. for each node that meets all of the scheduling requirements (resource request, requiredDuringScheduling anti-affinity expressions, etc.), compute a sum by iterating through the elements of this field and adding "weight" to the sum if the node has pods which matches the corresponding podAffinityTerm; the node(s) with the highest sum are the most preferred.
             */
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.certmanager.v1beta1.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            /**
             * If the anti-affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the anti-affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to a pod label update), the system may or may not try to eventually evict the pod from its node. When there are multiple elements, the lists of nodes corresponding to each podAffinityTerm are intersected, i.e. all terms must be satisfied.
             */
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.certmanager.v1beta1.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        /**
         * The weights of all of the matched WeightedPodAffinityTerm fields are added per-node to find the most preferred node(s)
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            /**
             * Required. A pod affinity term, associated with the corresponding weight.
             */
            podAffinityTerm: outputs.certmanager.v1beta1.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            /**
             * weight associated with matching the corresponding podAffinityTerm, in the range 1-100.
             */
            weight: number;
        }

        /**
         * Required. A pod affinity term, associated with the corresponding weight.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            /**
             * A label query over a set of resources, in this case pods.
             */
            labelSelector?: outputs.certmanager.v1beta1.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            /**
             * namespaces specifies which namespaces the labelSelector applies to (matches against); null or empty list means "this pod's namespace"
             */
            namespaces?: string[];
            /**
             * This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed.
             */
            topologyKey: string;
        }

        /**
         * A label query over a set of resources, in this case pods.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.certmanager.v1beta1.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Defines a set of pods (namely those matching the labelSelector relative to the given namespace(s)) that this pod should be co-located (affinity) or not co-located (anti-affinity) with, where co-located is defined as running on a node whose value of the label with key <topologyKey> matches that of any node on which a pod of the set of pods is running
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            /**
             * A label query over a set of resources, in this case pods.
             */
            labelSelector?: outputs.certmanager.v1beta1.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            /**
             * namespaces specifies which namespaces the labelSelector applies to (matches against); null or empty list means "this pod's namespace"
             */
            namespaces?: string[];
            /**
             * This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed.
             */
            topologyKey: string;
        }

        /**
         * A label query over a set of resources, in this case pods.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.certmanager.v1beta1.ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * The pod this Toleration is attached to tolerates any taint that matches the triple <key,value,effect> using the matching operator <operator>.
         */
        export interface ClusterIssuerSpecAcmeSolversHttp01IngressPodTemplateSpecTolerations {
            /**
             * Effect indicates the taint effect to match. Empty means match all taint effects. When specified, allowed values are NoSchedule, PreferNoSchedule and NoExecute.
             */
            effect?: string;
            /**
             * Key is the taint key that the toleration applies to. Empty means match all taint keys. If the key is empty, operator must be Exists; this combination means to match all values and all keys.
             */
            key?: string;
            /**
             * Operator represents a key's relationship to the value. Valid operators are Exists and Equal. Defaults to Equal. Exists is equivalent to wildcard for value, so that a pod can tolerate all taints of a particular category.
             */
            operator?: string;
            /**
             * TolerationSeconds represents the period of time the toleration (which must be of effect NoExecute, otherwise this field is ignored) tolerates the taint. By default, it is not set, which means tolerate the taint forever (do not evict). Zero and negative values will be treated as 0 (evict immediately) by the system.
             */
            tolerationSeconds?: number;
            /**
             * Value is the taint value the toleration matches to. If the operator is Exists, the value should be empty, otherwise just a regular string.
             */
            value?: string;
        }

        /**
         * Selector selects a set of DNSNames on the Certificate resource that should be solved using this challenge solver. If not specified, the solver will be treated as the 'default' solver with the lowest priority, i.e. if any other solver has a more specific match, it will be used instead.
         */
        export interface ClusterIssuerSpecAcmeSolversSelector {
            /**
             * List of DNSNames that this solver will be used to solve. If specified and a match is found, a dnsNames selector will take precedence over a dnsZones selector. If multiple solvers match with the same dnsNames value, the solver with the most matching labels in matchLabels will be selected. If neither has more matches, the solver defined earlier in the list will be selected.
             */
            dnsNames?: string[];
            /**
             * List of DNSZones that this solver will be used to solve. The most specific DNS zone match specified here will take precedence over other DNS zone matches, so a solver specifying sys.example.com will be selected over one specifying example.com for the domain www.sys.example.com. If multiple solvers match with the same dnsZones value, the solver with the most matching labels in matchLabels will be selected. If neither has more matches, the solver defined earlier in the list will be selected.
             */
            dnsZones?: string[];
            /**
             * A label selector that is used to refine the set of certificate's that this challenge solver will apply to.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * CA configures this issuer to sign certificates using a signing CA keypair stored in a Secret resource. This is used to build internal PKIs that are managed by cert-manager.
         */
        export interface ClusterIssuerSpecCa {
            /**
             * The CRL distribution points is an X.509 v3 certificate extension which identifies the location of the CRL from which the revocation of this certificate can be checked. If not set, certificates will be issued without distribution points set.
             */
            crlDistributionPoints?: string[];
            /**
             * SecretName is the name of the secret used to sign Certificates issued by this Issuer.
             */
            secretName: string;
        }

        /**
         * SelfSigned configures this issuer to 'self sign' certificates using the private key used to create the CertificateRequest object.
         */
        export interface ClusterIssuerSpecSelfSigned {
            /**
             * The CRL distribution points is an X.509 v3 certificate extension which identifies the location of the CRL from which the revocation of this certificate can be checked. If not set certificate will be issued without CDP. Values are strings.
             */
            crlDistributionPoints?: string[];
        }

        /**
         * Vault configures this issuer to sign certificates using a HashiCorp Vault PKI backend.
         */
        export interface ClusterIssuerSpecVault {
            /**
             * Auth configures how cert-manager authenticates with the Vault server.
             */
            auth: outputs.certmanager.v1beta1.ClusterIssuerSpecVaultAuth;
            /**
             * PEM encoded CA bundle used to validate Vault server certificate. Only used if the Server URL is using HTTPS protocol. This parameter is ignored for plain HTTP protocol connection. If not set the system root certificates are used to validate the TLS connection.
             */
            caBundle?: string;
            /**
             * Name of the vault namespace. Namespaces is a set of features within Vault Enterprise that allows Vault environments to support Secure Multi-tenancy. e.g: "ns1" More about namespaces can be found here https://www.vaultproject.io/docs/enterprise/namespaces
             */
            namespace?: string;
            /**
             * Path is the mount path of the Vault PKI backend's `sign` endpoint, e.g: "my_pki_mount/sign/my-role-name".
             */
            path: string;
            /**
             * Server is the connection address for the Vault server, e.g: "https://vault.example.com:8200".
             */
            server: string;
        }

        /**
         * Auth configures how cert-manager authenticates with the Vault server.
         */
        export interface ClusterIssuerSpecVaultAuth {
            /**
             * AppRole authenticates with Vault using the App Role auth mechanism, with the role and secret stored in a Kubernetes Secret resource.
             */
            appRole?: outputs.certmanager.v1beta1.ClusterIssuerSpecVaultAuthAppRole;
            /**
             * Kubernetes authenticates with Vault by passing the ServiceAccount token stored in the named Secret resource to the Vault server.
             */
            kubernetes?: outputs.certmanager.v1beta1.ClusterIssuerSpecVaultAuthKubernetes;
            /**
             * TokenSecretRef authenticates with Vault by presenting a token.
             */
            tokenSecretRef?: outputs.certmanager.v1beta1.ClusterIssuerSpecVaultAuthTokenSecretRef;
        }

        /**
         * AppRole authenticates with Vault using the App Role auth mechanism, with the role and secret stored in a Kubernetes Secret resource.
         */
        export interface ClusterIssuerSpecVaultAuthAppRole {
            /**
             * Path where the App Role authentication backend is mounted in Vault, e.g: "approle"
             */
            path: string;
            /**
             * RoleID configured in the App Role authentication backend when setting up the authentication backend in Vault.
             */
            roleId: string;
            /**
             * Reference to a key in a Secret that contains the App Role secret used to authenticate with Vault. The `key` field must be specified and denotes which entry within the Secret resource is used as the app role secret.
             */
            secretRef: outputs.certmanager.v1beta1.ClusterIssuerSpecVaultAuthAppRoleSecretRef;
        }

        /**
         * Reference to a key in a Secret that contains the App Role secret used to authenticate with Vault. The `key` field must be specified and denotes which entry within the Secret resource is used as the app role secret.
         */
        export interface ClusterIssuerSpecVaultAuthAppRoleSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Kubernetes authenticates with Vault by passing the ServiceAccount token stored in the named Secret resource to the Vault server.
         */
        export interface ClusterIssuerSpecVaultAuthKubernetes {
            /**
             * The Vault mountPath here is the mount path to use when authenticating with Vault. For example, setting a value to `/v1/auth/foo`, will use the path `/v1/auth/foo/login` to authenticate with Vault. If unspecified, the default value "/v1/auth/kubernetes" will be used.
             */
            mountPath?: string;
            /**
             * A required field containing the Vault Role to assume. A Role binds a Kubernetes ServiceAccount with a set of Vault policies.
             */
            role: string;
            /**
             * The required Secret field containing a Kubernetes ServiceAccount JWT used for authenticating with Vault. Use of 'ambient credentials' is not supported.
             */
            secretRef: outputs.certmanager.v1beta1.ClusterIssuerSpecVaultAuthKubernetesSecretRef;
        }

        /**
         * The required Secret field containing a Kubernetes ServiceAccount JWT used for authenticating with Vault. Use of 'ambient credentials' is not supported.
         */
        export interface ClusterIssuerSpecVaultAuthKubernetesSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * TokenSecretRef authenticates with Vault by presenting a token.
         */
        export interface ClusterIssuerSpecVaultAuthTokenSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Venafi configures this issuer to sign certificates using a Venafi TPP or Venafi Cloud policy zone.
         */
        export interface ClusterIssuerSpecVenafi {
            /**
             * Cloud specifies the Venafi cloud configuration settings. Only one of TPP or Cloud may be specified.
             */
            cloud?: outputs.certmanager.v1beta1.ClusterIssuerSpecVenafiCloud;
            /**
             * TPP specifies Trust Protection Platform configuration settings. Only one of TPP or Cloud may be specified.
             */
            tpp?: outputs.certmanager.v1beta1.ClusterIssuerSpecVenafiTpp;
            /**
             * Zone is the Venafi Policy Zone to use for this issuer. All requests made to the Venafi platform will be restricted by the named zone policy. This field is required.
             */
            zone: string;
        }

        /**
         * Cloud specifies the Venafi cloud configuration settings. Only one of TPP or Cloud may be specified.
         */
        export interface ClusterIssuerSpecVenafiCloud {
            /**
             * APITokenSecretRef is a secret key selector for the Venafi Cloud API token.
             */
            apiTokenSecretRef: outputs.certmanager.v1beta1.ClusterIssuerSpecVenafiCloudApiTokenSecretRef;
            /**
             * URL is the base URL for Venafi Cloud. Defaults to "https://api.venafi.cloud/v1".
             */
            url?: string;
        }

        /**
         * APITokenSecretRef is a secret key selector for the Venafi Cloud API token.
         */
        export interface ClusterIssuerSpecVenafiCloudApiTokenSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * TPP specifies Trust Protection Platform configuration settings. Only one of TPP or Cloud may be specified.
         */
        export interface ClusterIssuerSpecVenafiTpp {
            /**
             * CABundle is a PEM encoded TLS certificate to use to verify connections to the TPP instance. If specified, system roots will not be used and the issuing CA for the TPP instance must be verifiable using the provided root. If not specified, the connection will be verified using the cert-manager system root certificates.
             */
            caBundle?: string;
            /**
             * CredentialsRef is a reference to a Secret containing the username and password for the TPP server. The secret must contain two keys, 'username' and 'password'.
             */
            credentialsRef: outputs.certmanager.v1beta1.ClusterIssuerSpecVenafiTppCredentialsRef;
            /**
             * URL is the base URL for the vedsdk endpoint of the Venafi TPP instance, for example: "https://tpp.example.com/vedsdk".
             */
            url: string;
        }

        /**
         * CredentialsRef is a reference to a Secret containing the username and password for the TPP server. The secret must contain two keys, 'username' and 'password'.
         */
        export interface ClusterIssuerSpecVenafiTppCredentialsRef {
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Status of the ClusterIssuer. This is set and managed automatically.
         */
        export interface ClusterIssuerStatus {
            /**
             * ACME specific status options. This field should only be set if the Issuer is configured to use an ACME server to issue certificates.
             */
            acme?: outputs.certmanager.v1beta1.ClusterIssuerStatusAcme;
            /**
             * List of status conditions to indicate the status of a CertificateRequest. Known condition types are `Ready`.
             */
            conditions?: outputs.certmanager.v1beta1.ClusterIssuerStatusConditions[];
        }

        /**
         * ACME specific status options. This field should only be set if the Issuer is configured to use an ACME server to issue certificates.
         */
        export interface ClusterIssuerStatusAcme {
            /**
             * LastRegisteredEmail is the email associated with the latest registered ACME account, in order to track changes made to registered account associated with the  Issuer
             */
            lastRegisteredEmail?: string;
            /**
             * URI is the unique account identifier, which can also be used to retrieve account details from the CA
             */
            uri?: string;
        }

        /**
         * IssuerCondition contains condition information for an Issuer.
         */
        export interface ClusterIssuerStatusConditions {
            /**
             * LastTransitionTime is the timestamp corresponding to the last status change of this condition.
             */
            lastTransitionTime?: string;
            /**
             * Message is a human readable description of the details of the last transition, complementing reason.
             */
            message?: string;
            /**
             * Reason is a brief machine readable explanation for the condition's last transition.
             */
            reason?: string;
            /**
             * Status of the condition, one of ('True', 'False', 'Unknown').
             */
            status: string;
            /**
             * Type of the condition, known values are ('Ready').
             */
            type: string;
        }

        /**
         * Desired state of the Issuer resource.
         */
        export interface IssuerSpec {
            /**
             * ACME configures this issuer to communicate with a RFC8555 (ACME) server to obtain signed x509 certificates.
             */
            acme?: outputs.certmanager.v1beta1.IssuerSpecAcme;
            /**
             * CA configures this issuer to sign certificates using a signing CA keypair stored in a Secret resource. This is used to build internal PKIs that are managed by cert-manager.
             */
            ca?: outputs.certmanager.v1beta1.IssuerSpecCa;
            /**
             * SelfSigned configures this issuer to 'self sign' certificates using the private key used to create the CertificateRequest object.
             */
            selfSigned?: outputs.certmanager.v1beta1.IssuerSpecSelfSigned;
            /**
             * Vault configures this issuer to sign certificates using a HashiCorp Vault PKI backend.
             */
            vault?: outputs.certmanager.v1beta1.IssuerSpecVault;
            /**
             * Venafi configures this issuer to sign certificates using a Venafi TPP or Venafi Cloud policy zone.
             */
            venafi?: outputs.certmanager.v1beta1.IssuerSpecVenafi;
        }

        /**
         * ACME configures this issuer to communicate with a RFC8555 (ACME) server to obtain signed x509 certificates.
         */
        export interface IssuerSpecAcme {
            /**
             * Enables or disables generating a new ACME account key. If true, the Issuer resource will *not* request a new account but will expect the account key to be supplied via an existing secret. If false, the cert-manager system will generate a new ACME account key for the Issuer. Defaults to false.
             */
            disableAccountKeyGeneration?: boolean;
            /**
             * Email is the email address to be associated with the ACME account. This field is optional, but it is strongly recommended to be set. It will be used to contact you in case of issues with your account or certificates, including expiry notification emails. This field may be updated after the account is initially registered.
             */
            email?: string;
            /**
             * Enables requesting a Not After date on certificates that matches the duration of the certificate. This is not supported by all ACME servers like Let's Encrypt. If set to true when the ACME server does not support it it will create an error on the Order. Defaults to false.
             */
            enableDurationFeature?: boolean;
            /**
             * ExternalAccountBinding is a reference to a CA external account of the ACME server. If set, upon registration cert-manager will attempt to associate the given external account credentials with the registered ACME account.
             */
            externalAccountBinding?: outputs.certmanager.v1beta1.IssuerSpecAcmeExternalAccountBinding;
            /**
             * PreferredChain is the chain to use if the ACME server outputs multiple. PreferredChain is no guarantee that this one gets delivered by the ACME endpoint. For example, for Let's Encrypt's DST crosssign you would use: "DST Root CA X3" or "ISRG Root X1" for the newer Let's Encrypt root CA. This value picks the first certificate bundle in the ACME alternative chains that has a certificate with this value as its issuer's CN
             */
            preferredChain?: string;
            /**
             * PrivateKey is the name of a Kubernetes Secret resource that will be used to store the automatically generated ACME account private key. Optionally, a `key` may be specified to select a specific entry within the named Secret resource. If `key` is not specified, a default of `tls.key` will be used.
             */
            privateKeySecretRef: outputs.certmanager.v1beta1.IssuerSpecAcmePrivateKeySecretRef;
            /**
             * Server is the URL used to access the ACME server's 'directory' endpoint. For example, for Let's Encrypt's staging endpoint, you would use: "https://acme-staging-v02.api.letsencrypt.org/directory". Only ACME v2 endpoints (i.e. RFC 8555) are supported.
             */
            server: string;
            /**
             * Enables or disables validation of the ACME server TLS certificate. If true, requests to the ACME server will not have their TLS certificate validated (i.e. insecure connections will be allowed). Only enable this option in development environments. The cert-manager system installed roots will be used to verify connections to the ACME server if this is false. Defaults to false.
             */
            skipTLSVerify?: boolean;
            /**
             * Solvers is a list of challenge solvers that will be used to solve ACME challenges for the matching domains. Solver configurations must be provided in order to obtain certificates from an ACME server. For more information, see: https://cert-manager.io/docs/configuration/acme/
             */
            solvers?: outputs.certmanager.v1beta1.IssuerSpecAcmeSolvers[];
        }

        /**
         * ExternalAccountBinding is a reference to a CA external account of the ACME server. If set, upon registration cert-manager will attempt to associate the given external account credentials with the registered ACME account.
         */
        export interface IssuerSpecAcmeExternalAccountBinding {
            /**
             * keyAlgorithm is the MAC key algorithm that the key is used for. Valid values are "HS256", "HS384" and "HS512".
             */
            keyAlgorithm: string;
            /**
             * keyID is the ID of the CA key that the External Account is bound to.
             */
            keyID: string;
            /**
             * keySecretRef is a Secret Key Selector referencing a data item in a Kubernetes Secret which holds the symmetric MAC key of the External Account Binding. The `key` is the index string that is paired with the key data in the Secret and should not be confused with the key data itself, or indeed with the External Account Binding keyID above. The secret key stored in the Secret **must** be un-padded, base64 URL encoded data.
             */
            keySecretRef: outputs.certmanager.v1beta1.IssuerSpecAcmeExternalAccountBindingKeySecretRef;
        }

        /**
         * keySecretRef is a Secret Key Selector referencing a data item in a Kubernetes Secret which holds the symmetric MAC key of the External Account Binding. The `key` is the index string that is paired with the key data in the Secret and should not be confused with the key data itself, or indeed with the External Account Binding keyID above. The secret key stored in the Secret **must** be un-padded, base64 URL encoded data.
         */
        export interface IssuerSpecAcmeExternalAccountBindingKeySecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * PrivateKey is the name of a Kubernetes Secret resource that will be used to store the automatically generated ACME account private key. Optionally, a `key` may be specified to select a specific entry within the named Secret resource. If `key` is not specified, a default of `tls.key` will be used.
         */
        export interface IssuerSpecAcmePrivateKeySecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Configures an issuer to solve challenges using the specified options. Only one of HTTP01 or DNS01 may be provided.
         */
        export interface IssuerSpecAcmeSolvers {
            /**
             * Configures cert-manager to attempt to complete authorizations by performing the DNS01 challenge flow.
             */
            dns01?: outputs.certmanager.v1beta1.IssuerSpecAcmeSolversDns01;
            /**
             * Configures cert-manager to attempt to complete authorizations by performing the HTTP01 challenge flow. It is not possible to obtain certificates for wildcard domain names (e.g. `*.example.com`) using the HTTP01 challenge mechanism.
             */
            http01?: outputs.certmanager.v1beta1.IssuerSpecAcmeSolversHttp01;
            /**
             * Selector selects a set of DNSNames on the Certificate resource that should be solved using this challenge solver. If not specified, the solver will be treated as the 'default' solver with the lowest priority, i.e. if any other solver has a more specific match, it will be used instead.
             */
            selector?: outputs.certmanager.v1beta1.IssuerSpecAcmeSolversSelector;
        }

        /**
         * Configures cert-manager to attempt to complete authorizations by performing the DNS01 challenge flow.
         */
        export interface IssuerSpecAcmeSolversDns01 {
            /**
             * Use the 'ACME DNS' (https://github.com/joohoi/acme-dns) API to manage DNS01 challenge records.
             */
            acmeDNS?: outputs.certmanager.v1beta1.IssuerSpecAcmeSolversDns01AcmeDNS;
            /**
             * Use the Akamai DNS zone management API to manage DNS01 challenge records.
             */
            akamai?: outputs.certmanager.v1beta1.IssuerSpecAcmeSolversDns01Akamai;
            /**
             * Use the Microsoft Azure DNS API to manage DNS01 challenge records.
             */
            azureDNS?: outputs.certmanager.v1beta1.IssuerSpecAcmeSolversDns01AzureDNS;
            /**
             * Use the Google Cloud DNS API to manage DNS01 challenge records.
             */
            cloudDNS?: outputs.certmanager.v1beta1.IssuerSpecAcmeSolversDns01CloudDNS;
            /**
             * Use the Cloudflare API to manage DNS01 challenge records.
             */
            cloudflare?: outputs.certmanager.v1beta1.IssuerSpecAcmeSolversDns01Cloudflare;
            /**
             * CNAMEStrategy configures how the DNS01 provider should handle CNAME records when found in DNS zones.
             */
            cnameStrategy?: string;
            /**
             * Use the DigitalOcean DNS API to manage DNS01 challenge records.
             */
            digitalocean?: outputs.certmanager.v1beta1.IssuerSpecAcmeSolversDns01Digitalocean;
            /**
             * Use RFC2136 ("Dynamic Updates in the Domain Name System") (https://datatracker.ietf.org/doc/rfc2136/) to manage DNS01 challenge records.
             */
            rfc2136?: outputs.certmanager.v1beta1.IssuerSpecAcmeSolversDns01Rfc2136;
            /**
             * Use the AWS Route53 API to manage DNS01 challenge records.
             */
            route53?: outputs.certmanager.v1beta1.IssuerSpecAcmeSolversDns01Route53;
            /**
             * Configure an external webhook based DNS01 challenge solver to manage DNS01 challenge records.
             */
            webhook?: outputs.certmanager.v1beta1.IssuerSpecAcmeSolversDns01Webhook;
        }

        /**
         * Use the 'ACME DNS' (https://github.com/joohoi/acme-dns) API to manage DNS01 challenge records.
         */
        export interface IssuerSpecAcmeSolversDns01AcmeDNS {
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            accountSecretRef: outputs.certmanager.v1beta1.IssuerSpecAcmeSolversDns01AcmeDNSAccountSecretRef;
            host: string;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface IssuerSpecAcmeSolversDns01AcmeDNSAccountSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the Akamai DNS zone management API to manage DNS01 challenge records.
         */
        export interface IssuerSpecAcmeSolversDns01Akamai {
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            accessTokenSecretRef: outputs.certmanager.v1beta1.IssuerSpecAcmeSolversDns01AkamaiAccessTokenSecretRef;
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            clientSecretSecretRef: outputs.certmanager.v1beta1.IssuerSpecAcmeSolversDns01AkamaiClientSecretSecretRef;
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            clientTokenSecretRef: outputs.certmanager.v1beta1.IssuerSpecAcmeSolversDns01AkamaiClientTokenSecretRef;
            serviceConsumerDomain: string;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface IssuerSpecAcmeSolversDns01AkamaiAccessTokenSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface IssuerSpecAcmeSolversDns01AkamaiClientSecretSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface IssuerSpecAcmeSolversDns01AkamaiClientTokenSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the Microsoft Azure DNS API to manage DNS01 challenge records.
         */
        export interface IssuerSpecAcmeSolversDns01AzureDNS {
            /**
             * if both this and ClientSecret are left unset MSI will be used
             */
            clientID?: string;
            /**
             * if both this and ClientID are left unset MSI will be used
             */
            clientSecretSecretRef?: outputs.certmanager.v1beta1.IssuerSpecAcmeSolversDns01AzureDNSClientSecretSecretRef;
            environment?: string;
            hostedZoneName?: string;
            resourceGroupName: string;
            subscriptionID: string;
            /**
             * when specifying ClientID and ClientSecret then this field is also needed
             */
            tenantID?: string;
        }

        /**
         * if both this and ClientID are left unset MSI will be used
         */
        export interface IssuerSpecAcmeSolversDns01AzureDNSClientSecretSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the Google Cloud DNS API to manage DNS01 challenge records.
         */
        export interface IssuerSpecAcmeSolversDns01CloudDNS {
            /**
             * HostedZoneName is an optional field that tells cert-manager in which Cloud DNS zone the challenge record has to be created. If left empty cert-manager will automatically choose a zone.
             */
            hostedZoneName?: string;
            project: string;
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            serviceAccountSecretRef?: outputs.certmanager.v1beta1.IssuerSpecAcmeSolversDns01CloudDNSServiceAccountSecretRef;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface IssuerSpecAcmeSolversDns01CloudDNSServiceAccountSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the Cloudflare API to manage DNS01 challenge records.
         */
        export interface IssuerSpecAcmeSolversDns01Cloudflare {
            /**
             * API key to use to authenticate with Cloudflare. Note: using an API token to authenticate is now the recommended method as it allows greater control of permissions.
             */
            apiKeySecretRef?: outputs.certmanager.v1beta1.IssuerSpecAcmeSolversDns01CloudflareApiKeySecretRef;
            /**
             * API token used to authenticate with Cloudflare.
             */
            apiTokenSecretRef?: outputs.certmanager.v1beta1.IssuerSpecAcmeSolversDns01CloudflareApiTokenSecretRef;
            /**
             * Email of the account, only required when using API key based authentication.
             */
            email?: string;
        }

        /**
         * API key to use to authenticate with Cloudflare. Note: using an API token to authenticate is now the recommended method as it allows greater control of permissions.
         */
        export interface IssuerSpecAcmeSolversDns01CloudflareApiKeySecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * API token used to authenticate with Cloudflare.
         */
        export interface IssuerSpecAcmeSolversDns01CloudflareApiTokenSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the DigitalOcean DNS API to manage DNS01 challenge records.
         */
        export interface IssuerSpecAcmeSolversDns01Digitalocean {
            /**
             * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
             */
            tokenSecretRef: outputs.certmanager.v1beta1.IssuerSpecAcmeSolversDns01DigitaloceanTokenSecretRef;
        }

        /**
         * A reference to a specific 'key' within a Secret resource. In some instances, `key` is a required field.
         */
        export interface IssuerSpecAcmeSolversDns01DigitaloceanTokenSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use RFC2136 ("Dynamic Updates in the Domain Name System") (https://datatracker.ietf.org/doc/rfc2136/) to manage DNS01 challenge records.
         */
        export interface IssuerSpecAcmeSolversDns01Rfc2136 {
            /**
             * The IP address or hostname of an authoritative DNS server supporting RFC2136 in the form host:port. If the host is an IPv6 address it must be enclosed in square brackets (e.g [2001:db8::1]) ; port is optional. This field is required.
             */
            nameserver: string;
            /**
             * The TSIG Algorithm configured in the DNS supporting RFC2136. Used only when ``tsigSecretSecretRef`` and ``tsigKeyName`` are defined. Supported values are (case-insensitive): ``HMACMD5`` (default), ``HMACSHA1``, ``HMACSHA256`` or ``HMACSHA512``.
             */
            tsigAlgorithm?: string;
            /**
             * The TSIG Key name configured in the DNS. If ``tsigSecretSecretRef`` is defined, this field is required.
             */
            tsigKeyName?: string;
            /**
             * The name of the secret containing the TSIG value. If ``tsigKeyName`` is defined, this field is required.
             */
            tsigSecretSecretRef?: outputs.certmanager.v1beta1.IssuerSpecAcmeSolversDns01Rfc2136TsigSecretSecretRef;
        }

        /**
         * The name of the secret containing the TSIG value. If ``tsigKeyName`` is defined, this field is required.
         */
        export interface IssuerSpecAcmeSolversDns01Rfc2136TsigSecretSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Use the AWS Route53 API to manage DNS01 challenge records.
         */
        export interface IssuerSpecAcmeSolversDns01Route53 {
            /**
             * The AccessKeyID is used for authentication. If not set we fall-back to using env vars, shared credentials file or AWS Instance metadata see: https://docs.aws.amazon.com/sdk-for-go/v1/developer-guide/configuring-sdk.html#specifying-credentials
             */
            accessKeyID?: string;
            /**
             * If set, the provider will manage only this zone in Route53 and will not do an lookup using the route53:ListHostedZonesByName api call.
             */
            hostedZoneID?: string;
            /**
             * Always set the region when using AccessKeyID and SecretAccessKey
             */
            region: string;
            /**
             * Role is a Role ARN which the Route53 provider will assume using either the explicit credentials AccessKeyID/SecretAccessKey or the inferred credentials from environment variables, shared credentials file or AWS Instance metadata
             */
            role?: string;
            /**
             * The SecretAccessKey is used for authentication. If not set we fall-back to using env vars, shared credentials file or AWS Instance metadata https://docs.aws.amazon.com/sdk-for-go/v1/developer-guide/configuring-sdk.html#specifying-credentials
             */
            secretAccessKeySecretRef?: outputs.certmanager.v1beta1.IssuerSpecAcmeSolversDns01Route53SecretAccessKeySecretRef;
        }

        /**
         * The SecretAccessKey is used for authentication. If not set we fall-back to using env vars, shared credentials file or AWS Instance metadata https://docs.aws.amazon.com/sdk-for-go/v1/developer-guide/configuring-sdk.html#specifying-credentials
         */
        export interface IssuerSpecAcmeSolversDns01Route53SecretAccessKeySecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Configure an external webhook based DNS01 challenge solver to manage DNS01 challenge records.
         */
        export interface IssuerSpecAcmeSolversDns01Webhook {
            /**
             * Additional configuration that should be passed to the webhook apiserver when challenges are processed. This can contain arbitrary JSON data. Secret values should not be specified in this stanza. If secret values are needed (e.g. credentials for a DNS service), you should use a SecretKeySelector to reference a Secret resource. For details on the schema of this field, consult the webhook provider implementation's documentation.
             */
            config?: {[key: string]: any};
            /**
             * The API group name that should be used when POSTing ChallengePayload resources to the webhook apiserver. This should be the same as the GroupName specified in the webhook provider implementation.
             */
            groupName: string;
            /**
             * The name of the solver to use, as defined in the webhook provider implementation. This will typically be the name of the provider, e.g. 'cloudflare'.
             */
            solverName: string;
        }

        /**
         * Configures cert-manager to attempt to complete authorizations by performing the HTTP01 challenge flow. It is not possible to obtain certificates for wildcard domain names (e.g. `*.example.com`) using the HTTP01 challenge mechanism.
         */
        export interface IssuerSpecAcmeSolversHttp01 {
            /**
             * The ingress based HTTP01 challenge solver will solve challenges by creating or modifying Ingress resources in order to route requests for '/.well-known/acme-challenge/XYZ' to 'challenge solver' pods that are provisioned by cert-manager for each Challenge to be completed.
             */
            ingress?: outputs.certmanager.v1beta1.IssuerSpecAcmeSolversHttp01Ingress;
        }

        /**
         * The ingress based HTTP01 challenge solver will solve challenges by creating or modifying Ingress resources in order to route requests for '/.well-known/acme-challenge/XYZ' to 'challenge solver' pods that are provisioned by cert-manager for each Challenge to be completed.
         */
        export interface IssuerSpecAcmeSolversHttp01Ingress {
            /**
             * The ingress class to use when creating Ingress resources to solve ACME challenges that use this challenge solver. Only one of 'class' or 'name' may be specified.
             */
            class?: string;
            /**
             * Optional ingress template used to configure the ACME challenge solver ingress used for HTTP01 challenges
             */
            ingressTemplate?: outputs.certmanager.v1beta1.IssuerSpecAcmeSolversHttp01IngressIngressTemplate;
            /**
             * The name of the ingress resource that should have ACME challenge solving routes inserted into it in order to solve HTTP01 challenges. This is typically used in conjunction with ingress controllers like ingress-gce, which maintains a 1:1 mapping between external IPs and ingress resources.
             */
            name?: string;
            /**
             * Optional pod template used to configure the ACME challenge solver pods used for HTTP01 challenges
             */
            podTemplate?: outputs.certmanager.v1beta1.IssuerSpecAcmeSolversHttp01IngressPodTemplate;
            /**
             * Optional service type for Kubernetes solver service
             */
            serviceType?: string;
        }

        /**
         * Optional ingress template used to configure the ACME challenge solver ingress used for HTTP01 challenges
         */
        export interface IssuerSpecAcmeSolversHttp01IngressIngressTemplate {
            /**
             * ObjectMeta overrides for the ingress used to solve HTTP01 challenges. Only the 'labels' and 'annotations' fields may be set. If labels or annotations overlap with in-built values, the values here will override the in-built values.
             */
            metadata?: outputs.certmanager.v1beta1.IssuerSpecAcmeSolversHttp01IngressIngressTemplateMetadata;
        }

        /**
         * ObjectMeta overrides for the ingress used to solve HTTP01 challenges. Only the 'labels' and 'annotations' fields may be set. If labels or annotations overlap with in-built values, the values here will override the in-built values.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressIngressTemplateMetadata {
            /**
             * Annotations that should be added to the created ACME HTTP01 solver ingress.
             */
            annotations?: {[key: string]: string};
            /**
             * Labels that should be added to the created ACME HTTP01 solver ingress.
             */
            labels?: {[key: string]: string};
        }

        /**
         * Optional pod template used to configure the ACME challenge solver pods used for HTTP01 challenges
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplate {
            /**
             * ObjectMeta overrides for the pod used to solve HTTP01 challenges. Only the 'labels' and 'annotations' fields may be set. If labels or annotations overlap with in-built values, the values here will override the in-built values.
             */
            metadata?: outputs.certmanager.v1beta1.IssuerSpecAcmeSolversHttp01IngressPodTemplateMetadata;
            /**
             * PodSpec defines overrides for the HTTP01 challenge solver pod. Only the 'priorityClassName', 'nodeSelector', 'affinity', 'serviceAccountName' and 'tolerations' fields are supported currently. All other fields will be ignored.
             */
            spec?: outputs.certmanager.v1beta1.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpec;
        }

        /**
         * ObjectMeta overrides for the pod used to solve HTTP01 challenges. Only the 'labels' and 'annotations' fields may be set. If labels or annotations overlap with in-built values, the values here will override the in-built values.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateMetadata {
            /**
             * Annotations that should be added to the create ACME HTTP01 solver pods.
             */
            annotations?: {[key: string]: string};
            /**
             * Labels that should be added to the created ACME HTTP01 solver pods.
             */
            labels?: {[key: string]: string};
        }

        /**
         * PodSpec defines overrides for the HTTP01 challenge solver pod. Only the 'priorityClassName', 'nodeSelector', 'affinity', 'serviceAccountName' and 'tolerations' fields are supported currently. All other fields will be ignored.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpec {
            /**
             * If specified, the pod's scheduling constraints
             */
            affinity?: outputs.certmanager.v1beta1.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinity;
            /**
             * NodeSelector is a selector which must be true for the pod to fit on a node. Selector which must match a node's labels for the pod to be scheduled on that node. More info: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/
             */
            nodeSelector?: {[key: string]: string};
            /**
             * If specified, the pod's priorityClassName.
             */
            priorityClassName?: string;
            /**
             * If specified, the pod's service account
             */
            serviceAccountName?: string;
            /**
             * If specified, the pod's tolerations.
             */
            tolerations?: outputs.certmanager.v1beta1.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecTolerations[];
        }

        /**
         * If specified, the pod's scheduling constraints
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinity {
            /**
             * Describes node affinity scheduling rules for the pod.
             */
            nodeAffinity?: outputs.certmanager.v1beta1.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinity;
            /**
             * Describes pod affinity scheduling rules (e.g. co-locate this pod in the same node, zone, etc. as some other pod(s)).
             */
            podAffinity?: outputs.certmanager.v1beta1.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinity;
            /**
             * Describes pod anti-affinity scheduling rules (e.g. avoid putting this pod in the same node, zone, etc. as some other pod(s)).
             */
            podAntiAffinity?: outputs.certmanager.v1beta1.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinity;
        }

        /**
         * Describes node affinity scheduling rules for the pod.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinity {
            /**
             * The scheduler will prefer to schedule pods to nodes that satisfy the affinity expressions specified by this field, but it may choose a node that violates one or more of the expressions. The node that is most preferred is the one with the greatest sum of weights, i.e. for each node that meets all of the scheduling requirements (resource request, requiredDuringScheduling affinity expressions, etc.), compute a sum by iterating through the elements of this field and adding "weight" to the sum if the node matches the corresponding matchExpressions; the node(s) with the highest sum are the most preferred.
             */
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.certmanager.v1beta1.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            /**
             * If the affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to an update), the system may or may not try to eventually evict the pod from its node.
             */
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.certmanager.v1beta1.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution;
        }

        /**
         * An empty preferred scheduling term matches all objects with implicit weight 0 (i.e. it's a no-op). A null preferred scheduling term matches no objects (i.e. is also a no-op).
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            /**
             * A node selector term, associated with the corresponding weight.
             */
            preference: outputs.certmanager.v1beta1.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference;
            /**
             * Weight associated with matching the corresponding nodeSelectorTerm, in the range 1-100.
             */
            weight: number;
        }

        /**
         * A node selector term, associated with the corresponding weight.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference {
            /**
             * A list of node selector requirements by node's labels.
             */
            matchExpressions?: outputs.certmanager.v1beta1.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions[];
            /**
             * A list of node selector requirements by node's fields.
             */
            matchFields?: outputs.certmanager.v1beta1.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields[];
        }

        /**
         * A node selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions {
            /**
             * The label key that the selector applies to.
             */
            key: string;
            /**
             * Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
             */
            operator: string;
            /**
             * An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * A node selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields {
            /**
             * The label key that the selector applies to.
             */
            key: string;
            /**
             * Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
             */
            operator: string;
            /**
             * An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * If the affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to an update), the system may or may not try to eventually evict the pod from its node.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            /**
             * Required. A list of node selector terms. The terms are ORed.
             */
            nodeSelectorTerms: outputs.certmanager.v1beta1.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms[];
        }

        /**
         * A null or empty node selector term matches no objects. The requirements of them are ANDed. The TopologySelectorTerm type implements a subset of the NodeSelectorTerm.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms {
            /**
             * A list of node selector requirements by node's labels.
             */
            matchExpressions?: outputs.certmanager.v1beta1.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions[];
            /**
             * A list of node selector requirements by node's fields.
             */
            matchFields?: outputs.certmanager.v1beta1.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields[];
        }

        /**
         * A node selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions {
            /**
             * The label key that the selector applies to.
             */
            key: string;
            /**
             * Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
             */
            operator: string;
            /**
             * An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * A node selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields {
            /**
             * The label key that the selector applies to.
             */
            key: string;
            /**
             * Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
             */
            operator: string;
            /**
             * An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Describes pod affinity scheduling rules (e.g. co-locate this pod in the same node, zone, etc. as some other pod(s)).
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinity {
            /**
             * The scheduler will prefer to schedule pods to nodes that satisfy the affinity expressions specified by this field, but it may choose a node that violates one or more of the expressions. The node that is most preferred is the one with the greatest sum of weights, i.e. for each node that meets all of the scheduling requirements (resource request, requiredDuringScheduling affinity expressions, etc.), compute a sum by iterating through the elements of this field and adding "weight" to the sum if the node has pods which matches the corresponding podAffinityTerm; the node(s) with the highest sum are the most preferred.
             */
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.certmanager.v1beta1.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            /**
             * If the affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to a pod label update), the system may or may not try to eventually evict the pod from its node. When there are multiple elements, the lists of nodes corresponding to each podAffinityTerm are intersected, i.e. all terms must be satisfied.
             */
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.certmanager.v1beta1.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        /**
         * The weights of all of the matched WeightedPodAffinityTerm fields are added per-node to find the most preferred node(s)
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            /**
             * Required. A pod affinity term, associated with the corresponding weight.
             */
            podAffinityTerm: outputs.certmanager.v1beta1.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            /**
             * weight associated with matching the corresponding podAffinityTerm, in the range 1-100.
             */
            weight: number;
        }

        /**
         * Required. A pod affinity term, associated with the corresponding weight.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            /**
             * A label query over a set of resources, in this case pods.
             */
            labelSelector?: outputs.certmanager.v1beta1.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            /**
             * namespaces specifies which namespaces the labelSelector applies to (matches against); null or empty list means "this pod's namespace"
             */
            namespaces?: string[];
            /**
             * This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed.
             */
            topologyKey: string;
        }

        /**
         * A label query over a set of resources, in this case pods.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.certmanager.v1beta1.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Defines a set of pods (namely those matching the labelSelector relative to the given namespace(s)) that this pod should be co-located (affinity) or not co-located (anti-affinity) with, where co-located is defined as running on a node whose value of the label with key <topologyKey> matches that of any node on which a pod of the set of pods is running
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            /**
             * A label query over a set of resources, in this case pods.
             */
            labelSelector?: outputs.certmanager.v1beta1.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            /**
             * namespaces specifies which namespaces the labelSelector applies to (matches against); null or empty list means "this pod's namespace"
             */
            namespaces?: string[];
            /**
             * This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed.
             */
            topologyKey: string;
        }

        /**
         * A label query over a set of resources, in this case pods.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.certmanager.v1beta1.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Describes pod anti-affinity scheduling rules (e.g. avoid putting this pod in the same node, zone, etc. as some other pod(s)).
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinity {
            /**
             * The scheduler will prefer to schedule pods to nodes that satisfy the anti-affinity expressions specified by this field, but it may choose a node that violates one or more of the expressions. The node that is most preferred is the one with the greatest sum of weights, i.e. for each node that meets all of the scheduling requirements (resource request, requiredDuringScheduling anti-affinity expressions, etc.), compute a sum by iterating through the elements of this field and adding "weight" to the sum if the node has pods which matches the corresponding podAffinityTerm; the node(s) with the highest sum are the most preferred.
             */
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.certmanager.v1beta1.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            /**
             * If the anti-affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the anti-affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to a pod label update), the system may or may not try to eventually evict the pod from its node. When there are multiple elements, the lists of nodes corresponding to each podAffinityTerm are intersected, i.e. all terms must be satisfied.
             */
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.certmanager.v1beta1.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        /**
         * The weights of all of the matched WeightedPodAffinityTerm fields are added per-node to find the most preferred node(s)
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            /**
             * Required. A pod affinity term, associated with the corresponding weight.
             */
            podAffinityTerm: outputs.certmanager.v1beta1.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            /**
             * weight associated with matching the corresponding podAffinityTerm, in the range 1-100.
             */
            weight: number;
        }

        /**
         * Required. A pod affinity term, associated with the corresponding weight.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            /**
             * A label query over a set of resources, in this case pods.
             */
            labelSelector?: outputs.certmanager.v1beta1.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            /**
             * namespaces specifies which namespaces the labelSelector applies to (matches against); null or empty list means "this pod's namespace"
             */
            namespaces?: string[];
            /**
             * This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed.
             */
            topologyKey: string;
        }

        /**
         * A label query over a set of resources, in this case pods.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.certmanager.v1beta1.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Defines a set of pods (namely those matching the labelSelector relative to the given namespace(s)) that this pod should be co-located (affinity) or not co-located (anti-affinity) with, where co-located is defined as running on a node whose value of the label with key <topologyKey> matches that of any node on which a pod of the set of pods is running
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            /**
             * A label query over a set of resources, in this case pods.
             */
            labelSelector?: outputs.certmanager.v1beta1.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            /**
             * namespaces specifies which namespaces the labelSelector applies to (matches against); null or empty list means "this pod's namespace"
             */
            namespaces?: string[];
            /**
             * This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed.
             */
            topologyKey: string;
        }

        /**
         * A label query over a set of resources, in this case pods.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.certmanager.v1beta1.IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * The pod this Toleration is attached to tolerates any taint that matches the triple <key,value,effect> using the matching operator <operator>.
         */
        export interface IssuerSpecAcmeSolversHttp01IngressPodTemplateSpecTolerations {
            /**
             * Effect indicates the taint effect to match. Empty means match all taint effects. When specified, allowed values are NoSchedule, PreferNoSchedule and NoExecute.
             */
            effect?: string;
            /**
             * Key is the taint key that the toleration applies to. Empty means match all taint keys. If the key is empty, operator must be Exists; this combination means to match all values and all keys.
             */
            key?: string;
            /**
             * Operator represents a key's relationship to the value. Valid operators are Exists and Equal. Defaults to Equal. Exists is equivalent to wildcard for value, so that a pod can tolerate all taints of a particular category.
             */
            operator?: string;
            /**
             * TolerationSeconds represents the period of time the toleration (which must be of effect NoExecute, otherwise this field is ignored) tolerates the taint. By default, it is not set, which means tolerate the taint forever (do not evict). Zero and negative values will be treated as 0 (evict immediately) by the system.
             */
            tolerationSeconds?: number;
            /**
             * Value is the taint value the toleration matches to. If the operator is Exists, the value should be empty, otherwise just a regular string.
             */
            value?: string;
        }

        /**
         * Selector selects a set of DNSNames on the Certificate resource that should be solved using this challenge solver. If not specified, the solver will be treated as the 'default' solver with the lowest priority, i.e. if any other solver has a more specific match, it will be used instead.
         */
        export interface IssuerSpecAcmeSolversSelector {
            /**
             * List of DNSNames that this solver will be used to solve. If specified and a match is found, a dnsNames selector will take precedence over a dnsZones selector. If multiple solvers match with the same dnsNames value, the solver with the most matching labels in matchLabels will be selected. If neither has more matches, the solver defined earlier in the list will be selected.
             */
            dnsNames?: string[];
            /**
             * List of DNSZones that this solver will be used to solve. The most specific DNS zone match specified here will take precedence over other DNS zone matches, so a solver specifying sys.example.com will be selected over one specifying example.com for the domain www.sys.example.com. If multiple solvers match with the same dnsZones value, the solver with the most matching labels in matchLabels will be selected. If neither has more matches, the solver defined earlier in the list will be selected.
             */
            dnsZones?: string[];
            /**
             * A label selector that is used to refine the set of certificate's that this challenge solver will apply to.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * CA configures this issuer to sign certificates using a signing CA keypair stored in a Secret resource. This is used to build internal PKIs that are managed by cert-manager.
         */
        export interface IssuerSpecCa {
            /**
             * The CRL distribution points is an X.509 v3 certificate extension which identifies the location of the CRL from which the revocation of this certificate can be checked. If not set, certificates will be issued without distribution points set.
             */
            crlDistributionPoints?: string[];
            /**
             * SecretName is the name of the secret used to sign Certificates issued by this Issuer.
             */
            secretName: string;
        }

        /**
         * SelfSigned configures this issuer to 'self sign' certificates using the private key used to create the CertificateRequest object.
         */
        export interface IssuerSpecSelfSigned {
            /**
             * The CRL distribution points is an X.509 v3 certificate extension which identifies the location of the CRL from which the revocation of this certificate can be checked. If not set certificate will be issued without CDP. Values are strings.
             */
            crlDistributionPoints?: string[];
        }

        /**
         * Vault configures this issuer to sign certificates using a HashiCorp Vault PKI backend.
         */
        export interface IssuerSpecVault {
            /**
             * Auth configures how cert-manager authenticates with the Vault server.
             */
            auth: outputs.certmanager.v1beta1.IssuerSpecVaultAuth;
            /**
             * PEM encoded CA bundle used to validate Vault server certificate. Only used if the Server URL is using HTTPS protocol. This parameter is ignored for plain HTTP protocol connection. If not set the system root certificates are used to validate the TLS connection.
             */
            caBundle?: string;
            /**
             * Name of the vault namespace. Namespaces is a set of features within Vault Enterprise that allows Vault environments to support Secure Multi-tenancy. e.g: "ns1" More about namespaces can be found here https://www.vaultproject.io/docs/enterprise/namespaces
             */
            namespace?: string;
            /**
             * Path is the mount path of the Vault PKI backend's `sign` endpoint, e.g: "my_pki_mount/sign/my-role-name".
             */
            path: string;
            /**
             * Server is the connection address for the Vault server, e.g: "https://vault.example.com:8200".
             */
            server: string;
        }

        /**
         * Auth configures how cert-manager authenticates with the Vault server.
         */
        export interface IssuerSpecVaultAuth {
            /**
             * AppRole authenticates with Vault using the App Role auth mechanism, with the role and secret stored in a Kubernetes Secret resource.
             */
            appRole?: outputs.certmanager.v1beta1.IssuerSpecVaultAuthAppRole;
            /**
             * Kubernetes authenticates with Vault by passing the ServiceAccount token stored in the named Secret resource to the Vault server.
             */
            kubernetes?: outputs.certmanager.v1beta1.IssuerSpecVaultAuthKubernetes;
            /**
             * TokenSecretRef authenticates with Vault by presenting a token.
             */
            tokenSecretRef?: outputs.certmanager.v1beta1.IssuerSpecVaultAuthTokenSecretRef;
        }

        /**
         * AppRole authenticates with Vault using the App Role auth mechanism, with the role and secret stored in a Kubernetes Secret resource.
         */
        export interface IssuerSpecVaultAuthAppRole {
            /**
             * Path where the App Role authentication backend is mounted in Vault, e.g: "approle"
             */
            path: string;
            /**
             * RoleID configured in the App Role authentication backend when setting up the authentication backend in Vault.
             */
            roleId: string;
            /**
             * Reference to a key in a Secret that contains the App Role secret used to authenticate with Vault. The `key` field must be specified and denotes which entry within the Secret resource is used as the app role secret.
             */
            secretRef: outputs.certmanager.v1beta1.IssuerSpecVaultAuthAppRoleSecretRef;
        }

        /**
         * Reference to a key in a Secret that contains the App Role secret used to authenticate with Vault. The `key` field must be specified and denotes which entry within the Secret resource is used as the app role secret.
         */
        export interface IssuerSpecVaultAuthAppRoleSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Kubernetes authenticates with Vault by passing the ServiceAccount token stored in the named Secret resource to the Vault server.
         */
        export interface IssuerSpecVaultAuthKubernetes {
            /**
             * The Vault mountPath here is the mount path to use when authenticating with Vault. For example, setting a value to `/v1/auth/foo`, will use the path `/v1/auth/foo/login` to authenticate with Vault. If unspecified, the default value "/v1/auth/kubernetes" will be used.
             */
            mountPath?: string;
            /**
             * A required field containing the Vault Role to assume. A Role binds a Kubernetes ServiceAccount with a set of Vault policies.
             */
            role: string;
            /**
             * The required Secret field containing a Kubernetes ServiceAccount JWT used for authenticating with Vault. Use of 'ambient credentials' is not supported.
             */
            secretRef: outputs.certmanager.v1beta1.IssuerSpecVaultAuthKubernetesSecretRef;
        }

        /**
         * The required Secret field containing a Kubernetes ServiceAccount JWT used for authenticating with Vault. Use of 'ambient credentials' is not supported.
         */
        export interface IssuerSpecVaultAuthKubernetesSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * TokenSecretRef authenticates with Vault by presenting a token.
         */
        export interface IssuerSpecVaultAuthTokenSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Venafi configures this issuer to sign certificates using a Venafi TPP or Venafi Cloud policy zone.
         */
        export interface IssuerSpecVenafi {
            /**
             * Cloud specifies the Venafi cloud configuration settings. Only one of TPP or Cloud may be specified.
             */
            cloud?: outputs.certmanager.v1beta1.IssuerSpecVenafiCloud;
            /**
             * TPP specifies Trust Protection Platform configuration settings. Only one of TPP or Cloud may be specified.
             */
            tpp?: outputs.certmanager.v1beta1.IssuerSpecVenafiTpp;
            /**
             * Zone is the Venafi Policy Zone to use for this issuer. All requests made to the Venafi platform will be restricted by the named zone policy. This field is required.
             */
            zone: string;
        }

        /**
         * Cloud specifies the Venafi cloud configuration settings. Only one of TPP or Cloud may be specified.
         */
        export interface IssuerSpecVenafiCloud {
            /**
             * APITokenSecretRef is a secret key selector for the Venafi Cloud API token.
             */
            apiTokenSecretRef: outputs.certmanager.v1beta1.IssuerSpecVenafiCloudApiTokenSecretRef;
            /**
             * URL is the base URL for Venafi Cloud. Defaults to "https://api.venafi.cloud/v1".
             */
            url?: string;
        }

        /**
         * APITokenSecretRef is a secret key selector for the Venafi Cloud API token.
         */
        export interface IssuerSpecVenafiCloudApiTokenSecretRef {
            /**
             * The key of the entry in the Secret resource's `data` field to be used. Some instances of this field may be defaulted, in others it may be required.
             */
            key?: string;
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * TPP specifies Trust Protection Platform configuration settings. Only one of TPP or Cloud may be specified.
         */
        export interface IssuerSpecVenafiTpp {
            /**
             * CABundle is a PEM encoded TLS certificate to use to verify connections to the TPP instance. If specified, system roots will not be used and the issuing CA for the TPP instance must be verifiable using the provided root. If not specified, the connection will be verified using the cert-manager system root certificates.
             */
            caBundle?: string;
            /**
             * CredentialsRef is a reference to a Secret containing the username and password for the TPP server. The secret must contain two keys, 'username' and 'password'.
             */
            credentialsRef: outputs.certmanager.v1beta1.IssuerSpecVenafiTppCredentialsRef;
            /**
             * URL is the base URL for the vedsdk endpoint of the Venafi TPP instance, for example: "https://tpp.example.com/vedsdk".
             */
            url: string;
        }

        /**
         * CredentialsRef is a reference to a Secret containing the username and password for the TPP server. The secret must contain two keys, 'username' and 'password'.
         */
        export interface IssuerSpecVenafiTppCredentialsRef {
            /**
             * Name of the resource being referred to. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
        }

        /**
         * Status of the Issuer. This is set and managed automatically.
         */
        export interface IssuerStatus {
            /**
             * ACME specific status options. This field should only be set if the Issuer is configured to use an ACME server to issue certificates.
             */
            acme?: outputs.certmanager.v1beta1.IssuerStatusAcme;
            /**
             * List of status conditions to indicate the status of a CertificateRequest. Known condition types are `Ready`.
             */
            conditions?: outputs.certmanager.v1beta1.IssuerStatusConditions[];
        }

        /**
         * ACME specific status options. This field should only be set if the Issuer is configured to use an ACME server to issue certificates.
         */
        export interface IssuerStatusAcme {
            /**
             * LastRegisteredEmail is the email associated with the latest registered ACME account, in order to track changes made to registered account associated with the  Issuer
             */
            lastRegisteredEmail?: string;
            /**
             * URI is the unique account identifier, which can also be used to retrieve account details from the CA
             */
            uri?: string;
        }

        /**
         * IssuerCondition contains condition information for an Issuer.
         */
        export interface IssuerStatusConditions {
            /**
             * LastTransitionTime is the timestamp corresponding to the last status change of this condition.
             */
            lastTransitionTime?: string;
            /**
             * Message is a human readable description of the details of the last transition, complementing reason.
             */
            message?: string;
            /**
             * Reason is a brief machine readable explanation for the condition's last transition.
             */
            reason?: string;
            /**
             * Status of the condition, one of ('True', 'False', 'Unknown').
             */
            status: string;
            /**
             * Type of the condition, known values are ('Ready').
             */
            type: string;
        }
    }
}

export namespace clickhouse {
    export namespace v1 {
    }
}

export namespace configuration {
    export namespace v1 {
        export interface KongClusterPluginConfigFrom {
            secretKeyRef?: outputs.configuration.v1.KongClusterPluginConfigFromSecretKeyRef;
        }

        export interface KongClusterPluginConfigFromSecretKeyRef {
            key: string;
            name: string;
            namespace: string;
        }

        export interface KongIngressProxy {
            connect_timeout?: number;
            path?: string;
            protocol?: string;
            read_timeout?: number;
            retries?: number;
            write_timeout?: number;
        }

        export interface KongIngressUpstream {
            algorithm?: string;
            hash_fallback?: string;
            hash_fallback_header?: string;
            hash_on?: string;
            hash_on_cookie?: string;
            hash_on_cookie_path?: string;
            hash_on_header?: string;
            healthchecks?: outputs.configuration.v1.KongIngressUpstreamHealthchecks;
            host_header?: string;
            slots?: number;
        }

        export interface KongIngressUpstreamHealthchecks {
            active?: outputs.configuration.v1.KongIngressUpstreamHealthchecksActive;
            passive?: outputs.configuration.v1.KongIngressUpstreamHealthchecksPassive;
            threshold?: number;
        }

        export interface KongIngressUpstreamHealthchecksActive {
            concurrency?: number;
            healthy?: outputs.configuration.v1.KongIngressUpstreamHealthchecksActiveHealthy;
            http_path?: string;
            timeout?: number;
            unhealthy?: outputs.configuration.v1.KongIngressUpstreamHealthchecksActiveUnhealthy;
        }

        export interface KongIngressUpstreamHealthchecksActiveHealthy {
            http_statuses?: number[];
            interval?: number;
            successes?: number;
        }

        export interface KongIngressUpstreamHealthchecksActiveUnhealthy {
            http_failures?: number;
            http_statuses?: number[];
            interval?: number;
            tcp_failures?: number;
            timeout?: number;
        }

        export interface KongIngressUpstreamHealthchecksPassive {
            healthy?: outputs.configuration.v1.KongIngressUpstreamHealthchecksPassiveHealthy;
            unhealthy?: outputs.configuration.v1.KongIngressUpstreamHealthchecksPassiveUnhealthy;
        }

        export interface KongIngressUpstreamHealthchecksPassiveHealthy {
            http_statuses?: number[];
            interval?: number;
            successes?: number;
        }

        export interface KongIngressUpstreamHealthchecksPassiveUnhealthy {
            http_failures?: number;
            http_statuses?: number[];
            interval?: number;
            tcp_failures?: number;
            timeout?: number;
        }

        export interface KongPluginConfigFrom {
            secretKeyRef?: outputs.configuration.v1.KongPluginConfigFromSecretKeyRef;
        }

        export interface KongPluginConfigFromSecretKeyRef {
            key: string;
            name: string;
        }
    }

    export namespace v1beta1 {
        export interface TCPIngressSpec {
            rules?: outputs.configuration.v1beta1.TCPIngressSpecRules[];
            tls?: outputs.configuration.v1beta1.TCPIngressSpecTls[];
        }

        export interface TCPIngressSpecRules {
            backend?: outputs.configuration.v1beta1.TCPIngressSpecRulesBackend;
            host?: string;
            port?: number;
        }

        export interface TCPIngressSpecRulesBackend {
            serviceName?: string;
            servicePort?: number;
        }

        export interface TCPIngressSpecTls {
            hosts?: string[];
            secretName?: string;
        }

    }
}

export namespace kafka {
    export namespace v1beta1 {
        /**
         * The specification of the Kafka Connect Source-to-Image (S2I) cluster.
         */
        export interface KafkaConnectS2ISpec {
            /**
             * The pod's affinity rules.
             */
            affinity?: outputs.kafka.v1beta1.KafkaConnectS2ISpecAffinity;
            /**
             * Authentication configuration for Kafka Connect.
             */
            authentication?: outputs.kafka.v1beta1.KafkaConnectS2ISpecAuthentication;
            /**
             * Bootstrap servers to connect to. This should be given as a comma separated list of _<hostname>_:‍_<port>_ pairs.
             */
            bootstrapServers: string;
            /**
             * CPU and memory resources to reserve.
             */
            buildResources?: outputs.kafka.v1beta1.KafkaConnectS2ISpecBuildResources;
            /**
             * The image of the init container used for initializing the `client.rack`.
             */
            clientRackInitImage?: string;
            /**
             * The Kafka Connect configuration. Properties with the following prefixes cannot be set: ssl., sasl., security., listeners, plugin.path, rest., bootstrap.servers, consumer.interceptor.classes, producer.interceptor.classes (with the exception of: ssl.endpoint.identification.algorithm, ssl.cipher.suites, ssl.protocol, ssl.enabled.protocols).
             */
            config?: {[key: string]: any};
            /**
             * Pass data from Secrets or ConfigMaps to the Kafka Connect pods and use them to configure connectors.
             */
            externalConfiguration?: outputs.kafka.v1beta1.KafkaConnectS2ISpecExternalConfiguration;
            /**
             * The docker image for the pods.
             */
            image?: string;
            /**
             * When true this configures the source repository with the 'Local' reference policy and an import policy that accepts insecure source tags.
             */
            insecureSourceRepository?: boolean;
            /**
             * JVM Options for pods.
             */
            jvmOptions?: outputs.kafka.v1beta1.KafkaConnectS2ISpecJvmOptions;
            /**
             * Pod liveness checking.
             */
            livenessProbe?: outputs.kafka.v1beta1.KafkaConnectS2ISpecLivenessProbe;
            /**
             * Logging configuration for Kafka Connect.
             */
            logging?: outputs.kafka.v1beta1.KafkaConnectS2ISpecLogging;
            /**
             * The Prometheus JMX Exporter configuration. See https://github.com/prometheus/jmx_exporter for details of the structure of this configuration.
             */
            metrics?: {[key: string]: any};
            /**
             * Configuration of the node label which will be used as the client.rack consumer configuration.
             */
            rack?: outputs.kafka.v1beta1.KafkaConnectS2ISpecRack;
            /**
             * Pod readiness checking.
             */
            readinessProbe?: outputs.kafka.v1beta1.KafkaConnectS2ISpecReadinessProbe;
            /**
             * The number of pods in the Kafka Connect group.
             */
            replicas?: number;
            /**
             * The maximum limits for CPU and memory resources and the requested initial resources.
             */
            resources?: outputs.kafka.v1beta1.KafkaConnectS2ISpecResources;
            /**
             * Template for Kafka Connect and Kafka Connect S2I resources. The template allows users to specify how the `Deployment`, `Pods` and `Service` are generated.
             */
            template?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplate;
            /**
             * TLS configuration.
             */
            tls?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTls;
            /**
             * The pod's tolerations.
             */
            tolerations?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTolerations[];
            /**
             * The configuration of tracing in Kafka Connect.
             */
            tracing?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTracing;
            /**
             * The Kafka Connect version. Defaults to {DefaultKafkaVersion}. Consult the user documentation to understand the process required to upgrade or downgrade the version.
             */
            version?: string;
        }

        /**
         * The pod's affinity rules.
         */
        export interface KafkaConnectS2ISpecAffinity {
            nodeAffinity?: outputs.kafka.v1beta1.KafkaConnectS2ISpecAffinityNodeAffinity;
            podAffinity?: outputs.kafka.v1beta1.KafkaConnectS2ISpecAffinityPodAffinity;
            podAntiAffinity?: outputs.kafka.v1beta1.KafkaConnectS2ISpecAffinityPodAntiAffinity;
        }

        export interface KafkaConnectS2ISpecAffinityNodeAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaConnectS2ISpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaConnectS2ISpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution;
        }

        export interface KafkaConnectS2ISpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            preference?: outputs.kafka.v1beta1.KafkaConnectS2ISpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference;
            weight?: number;
        }

        export interface KafkaConnectS2ISpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference {
            matchExpressions?: outputs.kafka.v1beta1.KafkaConnectS2ISpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions[];
            matchFields?: outputs.kafka.v1beta1.KafkaConnectS2ISpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields[];
        }

        export interface KafkaConnectS2ISpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaConnectS2ISpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaConnectS2ISpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            nodeSelectorTerms?: outputs.kafka.v1beta1.KafkaConnectS2ISpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms[];
        }

        export interface KafkaConnectS2ISpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms {
            matchExpressions?: outputs.kafka.v1beta1.KafkaConnectS2ISpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions[];
            matchFields?: outputs.kafka.v1beta1.KafkaConnectS2ISpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields[];
        }

        export interface KafkaConnectS2ISpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaConnectS2ISpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaConnectS2ISpecAffinityPodAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaConnectS2ISpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaConnectS2ISpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        export interface KafkaConnectS2ISpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            podAffinityTerm?: outputs.kafka.v1beta1.KafkaConnectS2ISpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            weight?: number;
        }

        export interface KafkaConnectS2ISpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            labelSelector?: outputs.kafka.v1beta1.KafkaConnectS2ISpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaConnectS2ISpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaConnectS2ISpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaConnectS2ISpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaConnectS2ISpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            labelSelector?: outputs.kafka.v1beta1.KafkaConnectS2ISpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaConnectS2ISpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaConnectS2ISpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaConnectS2ISpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaConnectS2ISpecAffinityPodAntiAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaConnectS2ISpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaConnectS2ISpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        export interface KafkaConnectS2ISpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            podAffinityTerm?: outputs.kafka.v1beta1.KafkaConnectS2ISpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            weight?: number;
        }

        export interface KafkaConnectS2ISpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            labelSelector?: outputs.kafka.v1beta1.KafkaConnectS2ISpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaConnectS2ISpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaConnectS2ISpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaConnectS2ISpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaConnectS2ISpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            labelSelector?: outputs.kafka.v1beta1.KafkaConnectS2ISpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaConnectS2ISpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaConnectS2ISpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaConnectS2ISpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        /**
         * Authentication configuration for Kafka Connect.
         */
        export interface KafkaConnectS2ISpecAuthentication {
            /**
             * Link to Kubernetes Secret containing the access token which was obtained from the authorization server.
             */
            accessToken?: outputs.kafka.v1beta1.KafkaConnectS2ISpecAuthenticationAccessToken;
            /**
             * Configure whether access token should be treated as JWT. This should be set to `false` if the authorization server returns opaque tokens. Defaults to `true`.
             */
            accessTokenIsJwt?: boolean;
            /**
             * Reference to the `Secret` which holds the certificate and private key pair.
             */
            certificateAndKey?: outputs.kafka.v1beta1.KafkaConnectS2ISpecAuthenticationCertificateAndKey;
            /**
             * OAuth Client ID which the Kafka client can use to authenticate against the OAuth server and use the token endpoint URI.
             */
            clientId?: string;
            /**
             * Link to Kubernetes Secret containing the OAuth client secret which the Kafka client can use to authenticate against the OAuth server and use the token endpoint URI.
             */
            clientSecret?: outputs.kafka.v1beta1.KafkaConnectS2ISpecAuthenticationClientSecret;
            /**
             * Enable or disable TLS hostname verification. Default value is `false`.
             */
            disableTlsHostnameVerification?: boolean;
            /**
             * Set or limit time-to-live of the access tokens to the specified number of seconds. This should be set if the authorization server returns opaque tokens.
             */
            maxTokenExpirySeconds?: number;
            /**
             * Reference to the `Secret` which holds the password.
             */
            passwordSecret?: outputs.kafka.v1beta1.KafkaConnectS2ISpecAuthenticationPasswordSecret;
            /**
             * Link to Kubernetes Secret containing the refresh token which can be used to obtain access token from the authorization server.
             */
            refreshToken?: outputs.kafka.v1beta1.KafkaConnectS2ISpecAuthenticationRefreshToken;
            /**
             * OAuth scope to use when authenticating against the authorization server. Some authorization servers require this to be set. The possible values depend on how authorization server is configured. By default `scope` is not specified when doing the token endpoint request.
             */
            scope?: string;
            /**
             * Trusted certificates for TLS connection to the OAuth server.
             */
            tlsTrustedCertificates?: outputs.kafka.v1beta1.KafkaConnectS2ISpecAuthenticationTlsTrustedCertificates[];
            /**
             * Authorization server token endpoint URI.
             */
            tokenEndpointUri?: string;
            /**
             * Authentication type. Currently the only supported types are `tls`, `scram-sha-512`, and `plain`. `scram-sha-512` type uses SASL SCRAM-SHA-512 Authentication. `plain` type uses SASL PLAIN Authentication. `oauth` type uses SASL OAUTHBEARER Authentication. The `tls` type uses TLS Client Authentication. The `tls` type is supported only over TLS connections.
             */
            type: string;
            /**
             * Username used for the authentication.
             */
            username?: string;
        }

        /**
         * Link to Kubernetes Secret containing the access token which was obtained from the authorization server.
         */
        export interface KafkaConnectS2ISpecAuthenticationAccessToken {
            /**
             * The key under which the secret value is stored in the Kubernetes Secret.
             */
            key: string;
            /**
             * The name of the Kubernetes Secret containing the secret value.
             */
            secretName: string;
        }

        /**
         * Reference to the `Secret` which holds the certificate and private key pair.
         */
        export interface KafkaConnectS2ISpecAuthenticationCertificateAndKey {
            /**
             * The name of the file certificate in the Secret.
             */
            certificate: string;
            /**
             * The name of the private key in the Secret.
             */
            key: string;
            /**
             * The name of the Secret containing the certificate.
             */
            secretName: string;
        }

        /**
         * Link to Kubernetes Secret containing the OAuth client secret which the Kafka client can use to authenticate against the OAuth server and use the token endpoint URI.
         */
        export interface KafkaConnectS2ISpecAuthenticationClientSecret {
            /**
             * The key under which the secret value is stored in the Kubernetes Secret.
             */
            key: string;
            /**
             * The name of the Kubernetes Secret containing the secret value.
             */
            secretName: string;
        }

        /**
         * Reference to the `Secret` which holds the password.
         */
        export interface KafkaConnectS2ISpecAuthenticationPasswordSecret {
            /**
             * The name of the key in the Secret under which the password is stored.
             */
            password: string;
            /**
             * The name of the Secret containing the password.
             */
            secretName: string;
        }

        /**
         * Link to Kubernetes Secret containing the refresh token which can be used to obtain access token from the authorization server.
         */
        export interface KafkaConnectS2ISpecAuthenticationRefreshToken {
            /**
             * The key under which the secret value is stored in the Kubernetes Secret.
             */
            key: string;
            /**
             * The name of the Kubernetes Secret containing the secret value.
             */
            secretName: string;
        }

        export interface KafkaConnectS2ISpecAuthenticationTlsTrustedCertificates {
            /**
             * The name of the file certificate in the Secret.
             */
            certificate: string;
            /**
             * The name of the Secret containing the certificate.
             */
            secretName: string;
        }

        /**
         * CPU and memory resources to reserve.
         */
        export interface KafkaConnectS2ISpecBuildResources {
            limits?: {[key: string]: any};
            requests?: {[key: string]: any};
        }

        /**
         * Pass data from Secrets or ConfigMaps to the Kafka Connect pods and use them to configure connectors.
         */
        export interface KafkaConnectS2ISpecExternalConfiguration {
            /**
             * Allows to pass data from Secret or ConfigMap to the Kafka Connect pods as environment variables.
             */
            env?: outputs.kafka.v1beta1.KafkaConnectS2ISpecExternalConfigurationEnv[];
            /**
             * Allows to pass data from Secret or ConfigMap to the Kafka Connect pods as volumes.
             */
            volumes?: outputs.kafka.v1beta1.KafkaConnectS2ISpecExternalConfigurationVolumes[];
        }

        export interface KafkaConnectS2ISpecExternalConfigurationEnv {
            /**
             * Name of the environment variable which will be passed to the Kafka Connect pods. The name of the environment variable cannot start with `KAFKA_` or `STRIMZI_`.
             */
            name: string;
            /**
             * Value of the environment variable which will be passed to the Kafka Connect pods. It can be passed either as a reference to Secret or ConfigMap field. The field has to specify exactly one Secret or ConfigMap.
             */
            valueFrom: outputs.kafka.v1beta1.KafkaConnectS2ISpecExternalConfigurationEnvValueFrom;
        }

        /**
         * Value of the environment variable which will be passed to the Kafka Connect pods. It can be passed either as a reference to Secret or ConfigMap field. The field has to specify exactly one Secret or ConfigMap.
         */
        export interface KafkaConnectS2ISpecExternalConfigurationEnvValueFrom {
            /**
             * Refernce to a key in a ConfigMap.
             */
            configMapKeyRef?: outputs.kafka.v1beta1.KafkaConnectS2ISpecExternalConfigurationEnvValueFromConfigMapKeyRef;
            /**
             * Reference to a key in a Secret.
             */
            secretKeyRef?: outputs.kafka.v1beta1.KafkaConnectS2ISpecExternalConfigurationEnvValueFromSecretKeyRef;
        }

        /**
         * Refernce to a key in a ConfigMap.
         */
        export interface KafkaConnectS2ISpecExternalConfigurationEnvValueFromConfigMapKeyRef {
            key?: string;
            name?: string;
            optional?: boolean;
        }

        /**
         * Reference to a key in a Secret.
         */
        export interface KafkaConnectS2ISpecExternalConfigurationEnvValueFromSecretKeyRef {
            key?: string;
            name?: string;
            optional?: boolean;
        }

        export interface KafkaConnectS2ISpecExternalConfigurationVolumes {
            /**
             * Reference to a key in a ConfigMap. Exactly one Secret or ConfigMap has to be specified.
             */
            configMap?: outputs.kafka.v1beta1.KafkaConnectS2ISpecExternalConfigurationVolumesConfigMap;
            /**
             * Name of the volume which will be added to the Kafka Connect pods.
             */
            name: string;
            /**
             * Reference to a key in a Secret. Exactly one Secret or ConfigMap has to be specified.
             */
            secret?: outputs.kafka.v1beta1.KafkaConnectS2ISpecExternalConfigurationVolumesSecret;
        }

        /**
         * Reference to a key in a ConfigMap. Exactly one Secret or ConfigMap has to be specified.
         */
        export interface KafkaConnectS2ISpecExternalConfigurationVolumesConfigMap {
            defaultMode?: number;
            items?: outputs.kafka.v1beta1.KafkaConnectS2ISpecExternalConfigurationVolumesConfigMapItems[];
            name?: string;
            optional?: boolean;
        }

        export interface KafkaConnectS2ISpecExternalConfigurationVolumesConfigMapItems {
            key?: string;
            mode?: number;
            path?: string;
        }

        /**
         * Reference to a key in a Secret. Exactly one Secret or ConfigMap has to be specified.
         */
        export interface KafkaConnectS2ISpecExternalConfigurationVolumesSecret {
            defaultMode?: number;
            items?: outputs.kafka.v1beta1.KafkaConnectS2ISpecExternalConfigurationVolumesSecretItems[];
            optional?: boolean;
            secretName?: string;
        }

        export interface KafkaConnectS2ISpecExternalConfigurationVolumesSecretItems {
            key?: string;
            mode?: number;
            path?: string;
        }

        /**
         * JVM Options for pods.
         */
        export interface KafkaConnectS2ISpecJvmOptions {
            /**
             * A map of -XX options to the JVM.
             */
            "-XX"?: {[key: string]: any};
            /**
             * -Xms option to to the JVM.
             */
            "-Xms"?: string;
            /**
             * -Xmx option to to the JVM.
             */
            "-Xmx"?: string;
            /**
             * Specifies whether the Garbage Collection logging is enabled. The default is false.
             */
            gcLoggingEnabled?: boolean;
            /**
             * A map of additional system properties which will be passed using the `-D` option to the JVM.
             */
            javaSystemProperties?: outputs.kafka.v1beta1.KafkaConnectS2ISpecJvmOptionsJavaSystemProperties[];
        }

        export interface KafkaConnectS2ISpecJvmOptionsJavaSystemProperties {
            /**
             * The system property name.
             */
            name?: string;
            /**
             * The system property value.
             */
            value?: string;
        }

        /**
         * Pod liveness checking.
         */
        export interface KafkaConnectS2ISpecLivenessProbe {
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * The initial delay before first the health is first checked.
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * The timeout for each attempted health check.
             */
            timeoutSeconds?: number;
        }

        /**
         * Logging configuration for Kafka Connect.
         */
        export interface KafkaConnectS2ISpecLogging {
            /**
             * A Map from logger name to logger level.
             */
            loggers?: {[key: string]: any};
            /**
             * The name of the `ConfigMap` from which to get the logging configuration.
             */
            name?: string;
            /**
             * Logging type, must be either 'inline' or 'external'.
             */
            type: string;
        }

        /**
         * Configuration of the node label which will be used as the client.rack consumer configuration.
         */
        export interface KafkaConnectS2ISpecRack {
            /**
             * A key that matches labels assigned to the Kubernetes cluster nodes. The value of the label is used to set the broker's `broker.rack` config.
             */
            topologyKey: string;
        }

        /**
         * Pod readiness checking.
         */
        export interface KafkaConnectS2ISpecReadinessProbe {
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * The initial delay before first the health is first checked.
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * The timeout for each attempted health check.
             */
            timeoutSeconds?: number;
        }

        /**
         * The maximum limits for CPU and memory resources and the requested initial resources.
         */
        export interface KafkaConnectS2ISpecResources {
            limits?: {[key: string]: any};
            requests?: {[key: string]: any};
        }

        /**
         * Template for Kafka Connect and Kafka Connect S2I resources. The template allows users to specify how the `Deployment`, `Pods` and `Service` are generated.
         */
        export interface KafkaConnectS2ISpecTemplate {
            /**
             * Template for Kafka Connect API `Service`.
             */
            apiService?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplateApiService;
            /**
             * Template for the Kafka Connect container.
             */
            connectContainer?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplateConnectContainer;
            /**
             * Template for Kafka Connect `Deployment`.
             */
            deployment?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplateDeployment;
            /**
             * Template for the Kafka init container.
             */
            initContainer?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplateInitContainer;
            /**
             * Template for Kafka Connect `Pods`.
             */
            pod?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplatePod;
            /**
             * Template for Kafka Connect `PodDisruptionBudget`.
             */
            podDisruptionBudget?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplatePodDisruptionBudget;
        }

        /**
         * Template for Kafka Connect API `Service`.
         */
        export interface KafkaConnectS2ISpecTemplateApiService {
            /**
             * Metadata applied to the resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplateApiServiceMetadata;
        }

        /**
         * Metadata applied to the resource.
         */
        export interface KafkaConnectS2ISpecTemplateApiServiceMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        /**
         * Template for the Kafka Connect container.
         */
        export interface KafkaConnectS2ISpecTemplateConnectContainer {
            /**
             * Environment variables which should be applied to the container.
             */
            env?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplateConnectContainerEnv[];
            /**
             * Security context for the container.
             */
            securityContext?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplateConnectContainerSecurityContext;
        }

        export interface KafkaConnectS2ISpecTemplateConnectContainerEnv {
            /**
             * The environment variable key.
             */
            name?: string;
            /**
             * The environment variable value.
             */
            value?: string;
        }

        /**
         * Security context for the container.
         */
        export interface KafkaConnectS2ISpecTemplateConnectContainerSecurityContext {
            allowPrivilegeEscalation?: boolean;
            capabilities?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplateConnectContainerSecurityContextCapabilities;
            privileged?: boolean;
            procMount?: string;
            readOnlyRootFilesystem?: boolean;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplateConnectContainerSecurityContextSeLinuxOptions;
            windowsOptions?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplateConnectContainerSecurityContextWindowsOptions;
        }

        export interface KafkaConnectS2ISpecTemplateConnectContainerSecurityContextCapabilities {
            add?: string[];
            drop?: string[];
        }

        export interface KafkaConnectS2ISpecTemplateConnectContainerSecurityContextSeLinuxOptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface KafkaConnectS2ISpecTemplateConnectContainerSecurityContextWindowsOptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        /**
         * Template for Kafka Connect `Deployment`.
         */
        export interface KafkaConnectS2ISpecTemplateDeployment {
            /**
             * Metadata applied to the resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplateDeploymentMetadata;
        }

        /**
         * Metadata applied to the resource.
         */
        export interface KafkaConnectS2ISpecTemplateDeploymentMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        /**
         * Template for the Kafka init container.
         */
        export interface KafkaConnectS2ISpecTemplateInitContainer {
            /**
             * Environment variables which should be applied to the container.
             */
            env?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplateInitContainerEnv[];
            /**
             * Security context for the container.
             */
            securityContext?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplateInitContainerSecurityContext;
        }

        export interface KafkaConnectS2ISpecTemplateInitContainerEnv {
            /**
             * The environment variable key.
             */
            name?: string;
            /**
             * The environment variable value.
             */
            value?: string;
        }

        /**
         * Security context for the container.
         */
        export interface KafkaConnectS2ISpecTemplateInitContainerSecurityContext {
            allowPrivilegeEscalation?: boolean;
            capabilities?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplateInitContainerSecurityContextCapabilities;
            privileged?: boolean;
            procMount?: string;
            readOnlyRootFilesystem?: boolean;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplateInitContainerSecurityContextSeLinuxOptions;
            windowsOptions?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplateInitContainerSecurityContextWindowsOptions;
        }

        export interface KafkaConnectS2ISpecTemplateInitContainerSecurityContextCapabilities {
            add?: string[];
            drop?: string[];
        }

        export interface KafkaConnectS2ISpecTemplateInitContainerSecurityContextSeLinuxOptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface KafkaConnectS2ISpecTemplateInitContainerSecurityContextWindowsOptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        /**
         * Template for Kafka Connect `Pods`.
         */
        export interface KafkaConnectS2ISpecTemplatePod {
            /**
             * The pod's affinity rules.
             */
            affinity?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplatePodAffinity;
            /**
             * The pod's HostAliases. HostAliases is an optional list of hosts and IPs that will be injected into the pod's hosts file if specified.
             */
            hostAliases?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplatePodHostAliases[];
            /**
             * List of references to secrets in the same namespace to use for pulling any of the images used by this Pod. When the `STRIMZI_IMAGE_PULL_SECRETS` environment variable in Cluster Operator and the `imagePullSecrets` option are specified, only the `imagePullSecrets` variable is used and the `STRIMZI_IMAGE_PULL_SECRETS` variable is ignored.
             */
            imagePullSecrets?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplatePodImagePullSecrets[];
            /**
             * Metadata applied to the resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplatePodMetadata;
            /**
             * The name of the priority class used to assign priority to the pods. For more information about priority classes, see {K8sPriorityClass}.
             */
            priorityClassName?: string;
            /**
             * The name of the scheduler used to dispatch this `Pod`. If not specified, the default scheduler will be used.
             */
            schedulerName?: string;
            /**
             * Configures pod-level security attributes and common container settings.
             */
            securityContext?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplatePodSecurityContext;
            /**
             * The grace period is the duration in seconds after the processes running in the pod are sent a termination signal, and the time when the processes are forcibly halted with a kill signal. Set this value to longer than the expected cleanup time for your process. Value must be a non-negative integer. A zero value indicates delete immediately. You might need to increase the grace period for very large Kafka clusters, so that the Kafka brokers have enough time to transfer their work to another broker before they are terminated. Defaults to 30 seconds.
             */
            terminationGracePeriodSeconds?: number;
            /**
             * The pod's tolerations.
             */
            tolerations?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplatePodTolerations[];
        }

        /**
         * The pod's affinity rules.
         */
        export interface KafkaConnectS2ISpecTemplatePodAffinity {
            nodeAffinity?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplatePodAffinityNodeAffinity;
            podAffinity?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplatePodAffinityPodAffinity;
            podAntiAffinity?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplatePodAffinityPodAntiAffinity;
        }

        export interface KafkaConnectS2ISpecTemplatePodAffinityNodeAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution;
        }

        export interface KafkaConnectS2ISpecTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            preference?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference;
            weight?: number;
        }

        export interface KafkaConnectS2ISpecTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference {
            matchExpressions?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions[];
            matchFields?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields[];
        }

        export interface KafkaConnectS2ISpecTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaConnectS2ISpecTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaConnectS2ISpecTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            nodeSelectorTerms?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms[];
        }

        export interface KafkaConnectS2ISpecTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms {
            matchExpressions?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions[];
            matchFields?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields[];
        }

        export interface KafkaConnectS2ISpecTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaConnectS2ISpecTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaConnectS2ISpecTemplatePodAffinityPodAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        export interface KafkaConnectS2ISpecTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            podAffinityTerm?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            weight?: number;
        }

        export interface KafkaConnectS2ISpecTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            labelSelector?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaConnectS2ISpecTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaConnectS2ISpecTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaConnectS2ISpecTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            labelSelector?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaConnectS2ISpecTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaConnectS2ISpecTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaConnectS2ISpecTemplatePodAffinityPodAntiAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        export interface KafkaConnectS2ISpecTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            podAffinityTerm?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            weight?: number;
        }

        export interface KafkaConnectS2ISpecTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            labelSelector?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaConnectS2ISpecTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaConnectS2ISpecTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaConnectS2ISpecTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            labelSelector?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaConnectS2ISpecTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaConnectS2ISpecTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        /**
         * Template for Kafka Connect `PodDisruptionBudget`.
         */
        export interface KafkaConnectS2ISpecTemplatePodDisruptionBudget {
            /**
             * Maximum number of unavailable pods to allow automatic Pod eviction. A Pod eviction is allowed when the `maxUnavailable` number of pods or fewer are unavailable after the eviction. Setting this value to 0 prevents all voluntary evictions, so the pods must be evicted manually. Defaults to 1.
             */
            maxUnavailable?: number;
            /**
             * Metadata to apply to the `PodDistruptionBugetTemplate` resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplatePodDisruptionBudgetMetadata;
        }

        /**
         * Metadata to apply to the `PodDistruptionBugetTemplate` resource.
         */
        export interface KafkaConnectS2ISpecTemplatePodDisruptionBudgetMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        export interface KafkaConnectS2ISpecTemplatePodHostAliases {
            hostnames?: string[];
            ip?: string;
        }

        export interface KafkaConnectS2ISpecTemplatePodImagePullSecrets {
            name?: string;
        }

        /**
         * Metadata applied to the resource.
         */
        export interface KafkaConnectS2ISpecTemplatePodMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        /**
         * Configures pod-level security attributes and common container settings.
         */
        export interface KafkaConnectS2ISpecTemplatePodSecurityContext {
            fsGroup?: number;
            fsGroupChangePolicy?: string;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplatePodSecurityContextSeLinuxOptions;
            supplementalGroups?: number[];
            sysctls?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplatePodSecurityContextSysctls[];
            windowsOptions?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplatePodSecurityContextWindowsOptions;
        }

        export interface KafkaConnectS2ISpecTemplatePodSecurityContextSeLinuxOptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface KafkaConnectS2ISpecTemplatePodSecurityContextSysctls {
            name?: string;
            value?: string;
        }

        export interface KafkaConnectS2ISpecTemplatePodSecurityContextWindowsOptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        export interface KafkaConnectS2ISpecTemplatePodTolerations {
            effect?: string;
            key?: string;
            operator?: string;
            tolerationSeconds?: number;
            value?: string;
        }

        /**
         * TLS configuration.
         */
        export interface KafkaConnectS2ISpecTls {
            /**
             * Trusted certificates for TLS connection.
             */
            trustedCertificates?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTlsTrustedCertificates[];
        }

        export interface KafkaConnectS2ISpecTlsTrustedCertificates {
            /**
             * The name of the file certificate in the Secret.
             */
            certificate: string;
            /**
             * The name of the Secret containing the certificate.
             */
            secretName: string;
        }

        export interface KafkaConnectS2ISpecTolerations {
            effect?: string;
            key?: string;
            operator?: string;
            tolerationSeconds?: number;
            value?: string;
        }

        /**
         * The configuration of tracing in Kafka Connect.
         */
        export interface KafkaConnectS2ISpecTracing {
            /**
             * Type of the tracing used. Currently the only supported type is `jaeger` for Jaeger tracing.
             */
            type: string;
        }

        /**
         * The status of the Kafka Connect Source-to-Image (S2I) cluster.
         */
        export interface KafkaConnectS2IStatus {
            /**
             * The name of the build configuration.
             */
            buildConfigName?: string;
            /**
             * List of status conditions.
             */
            conditions?: outputs.kafka.v1beta1.KafkaConnectS2IStatusConditions[];
            /**
             * The list of connector plugins available in this Kafka Connect deployment.
             */
            connectorPlugins?: outputs.kafka.v1beta1.KafkaConnectS2IStatusConnectorPlugins[];
            /**
             * Label selector for pods providing this resource.
             */
            labelSelector?: string;
            /**
             * The generation of the CRD that was last reconciled by the operator.
             */
            observedGeneration?: number;
            /**
             * The current number of pods being used to provide this resource.
             */
            replicas?: number;
            /**
             * The URL of the REST API endpoint for managing and monitoring Kafka Connect connectors.
             */
            url?: string;
        }

        export interface KafkaConnectS2IStatusConditions {
            /**
             * Last time the condition of a type changed from one status to another. The required format is 'yyyy-MM-ddTHH:mm:ssZ', in the UTC time zone.
             */
            lastTransitionTime?: string;
            /**
             * Human-readable message indicating details about the condition's last transition.
             */
            message?: string;
            /**
             * The reason for the condition's last transition (a single word in CamelCase).
             */
            reason?: string;
            /**
             * The status of the condition, either True, False or Unknown.
             */
            status?: string;
            /**
             * The unique identifier of a condition, used to distinguish between other conditions in the resource.
             */
            type?: string;
        }

        export interface KafkaConnectS2IStatusConnectorPlugins {
            /**
             * The class of the connector plugin.
             */
            class?: string;
            /**
             * The type of the connector plugin. The available types are `sink` and `source`.
             */
            type?: string;
            /**
             * The version of the connector plugin.
             */
            version?: string;
        }

        /**
         * The specification of the Kafka Connect cluster.
         */
        export interface KafkaConnectSpec {
            /**
             * The pod's affinity rules.
             */
            affinity?: outputs.kafka.v1beta1.KafkaConnectSpecAffinity;
            /**
             * Authentication configuration for Kafka Connect.
             */
            authentication?: outputs.kafka.v1beta1.KafkaConnectSpecAuthentication;
            /**
             * Bootstrap servers to connect to. This should be given as a comma separated list of _<hostname>_:‍_<port>_ pairs.
             */
            bootstrapServers: string;
            /**
             * The image of the init container used for initializing the `client.rack`.
             */
            clientRackInitImage?: string;
            /**
             * The Kafka Connect configuration. Properties with the following prefixes cannot be set: ssl., sasl., security., listeners, plugin.path, rest., bootstrap.servers, consumer.interceptor.classes, producer.interceptor.classes (with the exception of: ssl.endpoint.identification.algorithm, ssl.cipher.suites, ssl.protocol, ssl.enabled.protocols).
             */
            config?: {[key: string]: any};
            /**
             * Pass data from Secrets or ConfigMaps to the Kafka Connect pods and use them to configure connectors.
             */
            externalConfiguration?: outputs.kafka.v1beta1.KafkaConnectSpecExternalConfiguration;
            /**
             * The docker image for the pods.
             */
            image?: string;
            /**
             * JVM Options for pods.
             */
            jvmOptions?: outputs.kafka.v1beta1.KafkaConnectSpecJvmOptions;
            /**
             * Pod liveness checking.
             */
            livenessProbe?: outputs.kafka.v1beta1.KafkaConnectSpecLivenessProbe;
            /**
             * Logging configuration for Kafka Connect.
             */
            logging?: outputs.kafka.v1beta1.KafkaConnectSpecLogging;
            /**
             * The Prometheus JMX Exporter configuration. See https://github.com/prometheus/jmx_exporter for details of the structure of this configuration.
             */
            metrics?: {[key: string]: any};
            /**
             * Configuration of the node label which will be used as the client.rack consumer configuration.
             */
            rack?: outputs.kafka.v1beta1.KafkaConnectSpecRack;
            /**
             * Pod readiness checking.
             */
            readinessProbe?: outputs.kafka.v1beta1.KafkaConnectSpecReadinessProbe;
            /**
             * The number of pods in the Kafka Connect group.
             */
            replicas?: number;
            /**
             * The maximum limits for CPU and memory resources and the requested initial resources.
             */
            resources?: outputs.kafka.v1beta1.KafkaConnectSpecResources;
            /**
             * Template for Kafka Connect and Kafka Connect S2I resources. The template allows users to specify how the `Deployment`, `Pods` and `Service` are generated.
             */
            template?: outputs.kafka.v1beta1.KafkaConnectSpecTemplate;
            /**
             * TLS configuration.
             */
            tls?: outputs.kafka.v1beta1.KafkaConnectSpecTls;
            /**
             * The pod's tolerations.
             */
            tolerations?: outputs.kafka.v1beta1.KafkaConnectSpecTolerations[];
            /**
             * The configuration of tracing in Kafka Connect.
             */
            tracing?: outputs.kafka.v1beta1.KafkaConnectSpecTracing;
            /**
             * The Kafka Connect version. Defaults to {DefaultKafkaVersion}. Consult the user documentation to understand the process required to upgrade or downgrade the version.
             */
            version?: string;
        }

        /**
         * The pod's affinity rules.
         */
        export interface KafkaConnectSpecAffinity {
            nodeAffinity?: outputs.kafka.v1beta1.KafkaConnectSpecAffinityNodeAffinity;
            podAffinity?: outputs.kafka.v1beta1.KafkaConnectSpecAffinityPodAffinity;
            podAntiAffinity?: outputs.kafka.v1beta1.KafkaConnectSpecAffinityPodAntiAffinity;
        }

        export interface KafkaConnectSpecAffinityNodeAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaConnectSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaConnectSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution;
        }

        export interface KafkaConnectSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            preference?: outputs.kafka.v1beta1.KafkaConnectSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference;
            weight?: number;
        }

        export interface KafkaConnectSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference {
            matchExpressions?: outputs.kafka.v1beta1.KafkaConnectSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions[];
            matchFields?: outputs.kafka.v1beta1.KafkaConnectSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields[];
        }

        export interface KafkaConnectSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaConnectSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaConnectSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            nodeSelectorTerms?: outputs.kafka.v1beta1.KafkaConnectSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms[];
        }

        export interface KafkaConnectSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms {
            matchExpressions?: outputs.kafka.v1beta1.KafkaConnectSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions[];
            matchFields?: outputs.kafka.v1beta1.KafkaConnectSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields[];
        }

        export interface KafkaConnectSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaConnectSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaConnectSpecAffinityPodAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaConnectSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaConnectSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        export interface KafkaConnectSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            podAffinityTerm?: outputs.kafka.v1beta1.KafkaConnectSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            weight?: number;
        }

        export interface KafkaConnectSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            labelSelector?: outputs.kafka.v1beta1.KafkaConnectSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaConnectSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaConnectSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaConnectSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaConnectSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            labelSelector?: outputs.kafka.v1beta1.KafkaConnectSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaConnectSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaConnectSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaConnectSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaConnectSpecAffinityPodAntiAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaConnectSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaConnectSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        export interface KafkaConnectSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            podAffinityTerm?: outputs.kafka.v1beta1.KafkaConnectSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            weight?: number;
        }

        export interface KafkaConnectSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            labelSelector?: outputs.kafka.v1beta1.KafkaConnectSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaConnectSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaConnectSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaConnectSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaConnectSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            labelSelector?: outputs.kafka.v1beta1.KafkaConnectSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaConnectSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaConnectSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaConnectSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        /**
         * Authentication configuration for Kafka Connect.
         */
        export interface KafkaConnectSpecAuthentication {
            /**
             * Link to Kubernetes Secret containing the access token which was obtained from the authorization server.
             */
            accessToken?: outputs.kafka.v1beta1.KafkaConnectSpecAuthenticationAccessToken;
            /**
             * Configure whether access token should be treated as JWT. This should be set to `false` if the authorization server returns opaque tokens. Defaults to `true`.
             */
            accessTokenIsJwt?: boolean;
            /**
             * Reference to the `Secret` which holds the certificate and private key pair.
             */
            certificateAndKey?: outputs.kafka.v1beta1.KafkaConnectSpecAuthenticationCertificateAndKey;
            /**
             * OAuth Client ID which the Kafka client can use to authenticate against the OAuth server and use the token endpoint URI.
             */
            clientId?: string;
            /**
             * Link to Kubernetes Secret containing the OAuth client secret which the Kafka client can use to authenticate against the OAuth server and use the token endpoint URI.
             */
            clientSecret?: outputs.kafka.v1beta1.KafkaConnectSpecAuthenticationClientSecret;
            /**
             * Enable or disable TLS hostname verification. Default value is `false`.
             */
            disableTlsHostnameVerification?: boolean;
            /**
             * Set or limit time-to-live of the access tokens to the specified number of seconds. This should be set if the authorization server returns opaque tokens.
             */
            maxTokenExpirySeconds?: number;
            /**
             * Reference to the `Secret` which holds the password.
             */
            passwordSecret?: outputs.kafka.v1beta1.KafkaConnectSpecAuthenticationPasswordSecret;
            /**
             * Link to Kubernetes Secret containing the refresh token which can be used to obtain access token from the authorization server.
             */
            refreshToken?: outputs.kafka.v1beta1.KafkaConnectSpecAuthenticationRefreshToken;
            /**
             * OAuth scope to use when authenticating against the authorization server. Some authorization servers require this to be set. The possible values depend on how authorization server is configured. By default `scope` is not specified when doing the token endpoint request.
             */
            scope?: string;
            /**
             * Trusted certificates for TLS connection to the OAuth server.
             */
            tlsTrustedCertificates?: outputs.kafka.v1beta1.KafkaConnectSpecAuthenticationTlsTrustedCertificates[];
            /**
             * Authorization server token endpoint URI.
             */
            tokenEndpointUri?: string;
            /**
             * Authentication type. Currently the only supported types are `tls`, `scram-sha-512`, and `plain`. `scram-sha-512` type uses SASL SCRAM-SHA-512 Authentication. `plain` type uses SASL PLAIN Authentication. `oauth` type uses SASL OAUTHBEARER Authentication. The `tls` type uses TLS Client Authentication. The `tls` type is supported only over TLS connections.
             */
            type: string;
            /**
             * Username used for the authentication.
             */
            username?: string;
        }

        /**
         * Link to Kubernetes Secret containing the access token which was obtained from the authorization server.
         */
        export interface KafkaConnectSpecAuthenticationAccessToken {
            /**
             * The key under which the secret value is stored in the Kubernetes Secret.
             */
            key: string;
            /**
             * The name of the Kubernetes Secret containing the secret value.
             */
            secretName: string;
        }

        /**
         * Reference to the `Secret` which holds the certificate and private key pair.
         */
        export interface KafkaConnectSpecAuthenticationCertificateAndKey {
            /**
             * The name of the file certificate in the Secret.
             */
            certificate: string;
            /**
             * The name of the private key in the Secret.
             */
            key: string;
            /**
             * The name of the Secret containing the certificate.
             */
            secretName: string;
        }

        /**
         * Link to Kubernetes Secret containing the OAuth client secret which the Kafka client can use to authenticate against the OAuth server and use the token endpoint URI.
         */
        export interface KafkaConnectSpecAuthenticationClientSecret {
            /**
             * The key under which the secret value is stored in the Kubernetes Secret.
             */
            key: string;
            /**
             * The name of the Kubernetes Secret containing the secret value.
             */
            secretName: string;
        }

        /**
         * Reference to the `Secret` which holds the password.
         */
        export interface KafkaConnectSpecAuthenticationPasswordSecret {
            /**
             * The name of the key in the Secret under which the password is stored.
             */
            password: string;
            /**
             * The name of the Secret containing the password.
             */
            secretName: string;
        }

        /**
         * Link to Kubernetes Secret containing the refresh token which can be used to obtain access token from the authorization server.
         */
        export interface KafkaConnectSpecAuthenticationRefreshToken {
            /**
             * The key under which the secret value is stored in the Kubernetes Secret.
             */
            key: string;
            /**
             * The name of the Kubernetes Secret containing the secret value.
             */
            secretName: string;
        }

        export interface KafkaConnectSpecAuthenticationTlsTrustedCertificates {
            /**
             * The name of the file certificate in the Secret.
             */
            certificate: string;
            /**
             * The name of the Secret containing the certificate.
             */
            secretName: string;
        }

        /**
         * Pass data from Secrets or ConfigMaps to the Kafka Connect pods and use them to configure connectors.
         */
        export interface KafkaConnectSpecExternalConfiguration {
            /**
             * Allows to pass data from Secret or ConfigMap to the Kafka Connect pods as environment variables.
             */
            env?: outputs.kafka.v1beta1.KafkaConnectSpecExternalConfigurationEnv[];
            /**
             * Allows to pass data from Secret or ConfigMap to the Kafka Connect pods as volumes.
             */
            volumes?: outputs.kafka.v1beta1.KafkaConnectSpecExternalConfigurationVolumes[];
        }

        export interface KafkaConnectSpecExternalConfigurationEnv {
            /**
             * Name of the environment variable which will be passed to the Kafka Connect pods. The name of the environment variable cannot start with `KAFKA_` or `STRIMZI_`.
             */
            name: string;
            /**
             * Value of the environment variable which will be passed to the Kafka Connect pods. It can be passed either as a reference to Secret or ConfigMap field. The field has to specify exactly one Secret or ConfigMap.
             */
            valueFrom: outputs.kafka.v1beta1.KafkaConnectSpecExternalConfigurationEnvValueFrom;
        }

        /**
         * Value of the environment variable which will be passed to the Kafka Connect pods. It can be passed either as a reference to Secret or ConfigMap field. The field has to specify exactly one Secret or ConfigMap.
         */
        export interface KafkaConnectSpecExternalConfigurationEnvValueFrom {
            /**
             * Refernce to a key in a ConfigMap.
             */
            configMapKeyRef?: outputs.kafka.v1beta1.KafkaConnectSpecExternalConfigurationEnvValueFromConfigMapKeyRef;
            /**
             * Reference to a key in a Secret.
             */
            secretKeyRef?: outputs.kafka.v1beta1.KafkaConnectSpecExternalConfigurationEnvValueFromSecretKeyRef;
        }

        /**
         * Refernce to a key in a ConfigMap.
         */
        export interface KafkaConnectSpecExternalConfigurationEnvValueFromConfigMapKeyRef {
            key?: string;
            name?: string;
            optional?: boolean;
        }

        /**
         * Reference to a key in a Secret.
         */
        export interface KafkaConnectSpecExternalConfigurationEnvValueFromSecretKeyRef {
            key?: string;
            name?: string;
            optional?: boolean;
        }

        export interface KafkaConnectSpecExternalConfigurationVolumes {
            /**
             * Reference to a key in a ConfigMap. Exactly one Secret or ConfigMap has to be specified.
             */
            configMap?: outputs.kafka.v1beta1.KafkaConnectSpecExternalConfigurationVolumesConfigMap;
            /**
             * Name of the volume which will be added to the Kafka Connect pods.
             */
            name: string;
            /**
             * Reference to a key in a Secret. Exactly one Secret or ConfigMap has to be specified.
             */
            secret?: outputs.kafka.v1beta1.KafkaConnectSpecExternalConfigurationVolumesSecret;
        }

        /**
         * Reference to a key in a ConfigMap. Exactly one Secret or ConfigMap has to be specified.
         */
        export interface KafkaConnectSpecExternalConfigurationVolumesConfigMap {
            defaultMode?: number;
            items?: outputs.kafka.v1beta1.KafkaConnectSpecExternalConfigurationVolumesConfigMapItems[];
            name?: string;
            optional?: boolean;
        }

        export interface KafkaConnectSpecExternalConfigurationVolumesConfigMapItems {
            key?: string;
            mode?: number;
            path?: string;
        }

        /**
         * Reference to a key in a Secret. Exactly one Secret or ConfigMap has to be specified.
         */
        export interface KafkaConnectSpecExternalConfigurationVolumesSecret {
            defaultMode?: number;
            items?: outputs.kafka.v1beta1.KafkaConnectSpecExternalConfigurationVolumesSecretItems[];
            optional?: boolean;
            secretName?: string;
        }

        export interface KafkaConnectSpecExternalConfigurationVolumesSecretItems {
            key?: string;
            mode?: number;
            path?: string;
        }

        /**
         * JVM Options for pods.
         */
        export interface KafkaConnectSpecJvmOptions {
            /**
             * A map of -XX options to the JVM.
             */
            "-XX"?: {[key: string]: any};
            /**
             * -Xms option to to the JVM.
             */
            "-Xms"?: string;
            /**
             * -Xmx option to to the JVM.
             */
            "-Xmx"?: string;
            /**
             * Specifies whether the Garbage Collection logging is enabled. The default is false.
             */
            gcLoggingEnabled?: boolean;
            /**
             * A map of additional system properties which will be passed using the `-D` option to the JVM.
             */
            javaSystemProperties?: outputs.kafka.v1beta1.KafkaConnectSpecJvmOptionsJavaSystemProperties[];
        }

        export interface KafkaConnectSpecJvmOptionsJavaSystemProperties {
            /**
             * The system property name.
             */
            name?: string;
            /**
             * The system property value.
             */
            value?: string;
        }

        /**
         * Pod liveness checking.
         */
        export interface KafkaConnectSpecLivenessProbe {
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * The initial delay before first the health is first checked.
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * The timeout for each attempted health check.
             */
            timeoutSeconds?: number;
        }

        /**
         * Logging configuration for Kafka Connect.
         */
        export interface KafkaConnectSpecLogging {
            /**
             * A Map from logger name to logger level.
             */
            loggers?: {[key: string]: any};
            /**
             * The name of the `ConfigMap` from which to get the logging configuration.
             */
            name?: string;
            /**
             * Logging type, must be either 'inline' or 'external'.
             */
            type: string;
        }

        /**
         * Configuration of the node label which will be used as the client.rack consumer configuration.
         */
        export interface KafkaConnectSpecRack {
            /**
             * A key that matches labels assigned to the Kubernetes cluster nodes. The value of the label is used to set the broker's `broker.rack` config.
             */
            topologyKey: string;
        }

        /**
         * Pod readiness checking.
         */
        export interface KafkaConnectSpecReadinessProbe {
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * The initial delay before first the health is first checked.
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * The timeout for each attempted health check.
             */
            timeoutSeconds?: number;
        }

        /**
         * The maximum limits for CPU and memory resources and the requested initial resources.
         */
        export interface KafkaConnectSpecResources {
            limits?: {[key: string]: any};
            requests?: {[key: string]: any};
        }

        /**
         * Template for Kafka Connect and Kafka Connect S2I resources. The template allows users to specify how the `Deployment`, `Pods` and `Service` are generated.
         */
        export interface KafkaConnectSpecTemplate {
            /**
             * Template for Kafka Connect API `Service`.
             */
            apiService?: outputs.kafka.v1beta1.KafkaConnectSpecTemplateApiService;
            /**
             * Template for the Kafka Connect container.
             */
            connectContainer?: outputs.kafka.v1beta1.KafkaConnectSpecTemplateConnectContainer;
            /**
             * Template for Kafka Connect `Deployment`.
             */
            deployment?: outputs.kafka.v1beta1.KafkaConnectSpecTemplateDeployment;
            /**
             * Template for the Kafka init container.
             */
            initContainer?: outputs.kafka.v1beta1.KafkaConnectSpecTemplateInitContainer;
            /**
             * Template for Kafka Connect `Pods`.
             */
            pod?: outputs.kafka.v1beta1.KafkaConnectSpecTemplatePod;
            /**
             * Template for Kafka Connect `PodDisruptionBudget`.
             */
            podDisruptionBudget?: outputs.kafka.v1beta1.KafkaConnectSpecTemplatePodDisruptionBudget;
        }

        /**
         * Template for Kafka Connect API `Service`.
         */
        export interface KafkaConnectSpecTemplateApiService {
            /**
             * Metadata applied to the resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaConnectSpecTemplateApiServiceMetadata;
        }

        /**
         * Metadata applied to the resource.
         */
        export interface KafkaConnectSpecTemplateApiServiceMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        /**
         * Template for the Kafka Connect container.
         */
        export interface KafkaConnectSpecTemplateConnectContainer {
            /**
             * Environment variables which should be applied to the container.
             */
            env?: outputs.kafka.v1beta1.KafkaConnectSpecTemplateConnectContainerEnv[];
            /**
             * Security context for the container.
             */
            securityContext?: outputs.kafka.v1beta1.KafkaConnectSpecTemplateConnectContainerSecurityContext;
        }

        export interface KafkaConnectSpecTemplateConnectContainerEnv {
            /**
             * The environment variable key.
             */
            name?: string;
            /**
             * The environment variable value.
             */
            value?: string;
        }

        /**
         * Security context for the container.
         */
        export interface KafkaConnectSpecTemplateConnectContainerSecurityContext {
            allowPrivilegeEscalation?: boolean;
            capabilities?: outputs.kafka.v1beta1.KafkaConnectSpecTemplateConnectContainerSecurityContextCapabilities;
            privileged?: boolean;
            procMount?: string;
            readOnlyRootFilesystem?: boolean;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.kafka.v1beta1.KafkaConnectSpecTemplateConnectContainerSecurityContextSeLinuxOptions;
            windowsOptions?: outputs.kafka.v1beta1.KafkaConnectSpecTemplateConnectContainerSecurityContextWindowsOptions;
        }

        export interface KafkaConnectSpecTemplateConnectContainerSecurityContextCapabilities {
            add?: string[];
            drop?: string[];
        }

        export interface KafkaConnectSpecTemplateConnectContainerSecurityContextSeLinuxOptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface KafkaConnectSpecTemplateConnectContainerSecurityContextWindowsOptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        /**
         * Template for Kafka Connect `Deployment`.
         */
        export interface KafkaConnectSpecTemplateDeployment {
            /**
             * Metadata applied to the resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaConnectSpecTemplateDeploymentMetadata;
        }

        /**
         * Metadata applied to the resource.
         */
        export interface KafkaConnectSpecTemplateDeploymentMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        /**
         * Template for the Kafka init container.
         */
        export interface KafkaConnectSpecTemplateInitContainer {
            /**
             * Environment variables which should be applied to the container.
             */
            env?: outputs.kafka.v1beta1.KafkaConnectSpecTemplateInitContainerEnv[];
            /**
             * Security context for the container.
             */
            securityContext?: outputs.kafka.v1beta1.KafkaConnectSpecTemplateInitContainerSecurityContext;
        }

        export interface KafkaConnectSpecTemplateInitContainerEnv {
            /**
             * The environment variable key.
             */
            name?: string;
            /**
             * The environment variable value.
             */
            value?: string;
        }

        /**
         * Security context for the container.
         */
        export interface KafkaConnectSpecTemplateInitContainerSecurityContext {
            allowPrivilegeEscalation?: boolean;
            capabilities?: outputs.kafka.v1beta1.KafkaConnectSpecTemplateInitContainerSecurityContextCapabilities;
            privileged?: boolean;
            procMount?: string;
            readOnlyRootFilesystem?: boolean;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.kafka.v1beta1.KafkaConnectSpecTemplateInitContainerSecurityContextSeLinuxOptions;
            windowsOptions?: outputs.kafka.v1beta1.KafkaConnectSpecTemplateInitContainerSecurityContextWindowsOptions;
        }

        export interface KafkaConnectSpecTemplateInitContainerSecurityContextCapabilities {
            add?: string[];
            drop?: string[];
        }

        export interface KafkaConnectSpecTemplateInitContainerSecurityContextSeLinuxOptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface KafkaConnectSpecTemplateInitContainerSecurityContextWindowsOptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        /**
         * Template for Kafka Connect `Pods`.
         */
        export interface KafkaConnectSpecTemplatePod {
            /**
             * The pod's affinity rules.
             */
            affinity?: outputs.kafka.v1beta1.KafkaConnectSpecTemplatePodAffinity;
            /**
             * The pod's HostAliases. HostAliases is an optional list of hosts and IPs that will be injected into the pod's hosts file if specified.
             */
            hostAliases?: outputs.kafka.v1beta1.KafkaConnectSpecTemplatePodHostAliases[];
            /**
             * List of references to secrets in the same namespace to use for pulling any of the images used by this Pod. When the `STRIMZI_IMAGE_PULL_SECRETS` environment variable in Cluster Operator and the `imagePullSecrets` option are specified, only the `imagePullSecrets` variable is used and the `STRIMZI_IMAGE_PULL_SECRETS` variable is ignored.
             */
            imagePullSecrets?: outputs.kafka.v1beta1.KafkaConnectSpecTemplatePodImagePullSecrets[];
            /**
             * Metadata applied to the resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaConnectSpecTemplatePodMetadata;
            /**
             * The name of the priority class used to assign priority to the pods. For more information about priority classes, see {K8sPriorityClass}.
             */
            priorityClassName?: string;
            /**
             * The name of the scheduler used to dispatch this `Pod`. If not specified, the default scheduler will be used.
             */
            schedulerName?: string;
            /**
             * Configures pod-level security attributes and common container settings.
             */
            securityContext?: outputs.kafka.v1beta1.KafkaConnectSpecTemplatePodSecurityContext;
            /**
             * The grace period is the duration in seconds after the processes running in the pod are sent a termination signal, and the time when the processes are forcibly halted with a kill signal. Set this value to longer than the expected cleanup time for your process. Value must be a non-negative integer. A zero value indicates delete immediately. You might need to increase the grace period for very large Kafka clusters, so that the Kafka brokers have enough time to transfer their work to another broker before they are terminated. Defaults to 30 seconds.
             */
            terminationGracePeriodSeconds?: number;
            /**
             * The pod's tolerations.
             */
            tolerations?: outputs.kafka.v1beta1.KafkaConnectSpecTemplatePodTolerations[];
        }

        /**
         * The pod's affinity rules.
         */
        export interface KafkaConnectSpecTemplatePodAffinity {
            nodeAffinity?: outputs.kafka.v1beta1.KafkaConnectSpecTemplatePodAffinityNodeAffinity;
            podAffinity?: outputs.kafka.v1beta1.KafkaConnectSpecTemplatePodAffinityPodAffinity;
            podAntiAffinity?: outputs.kafka.v1beta1.KafkaConnectSpecTemplatePodAffinityPodAntiAffinity;
        }

        export interface KafkaConnectSpecTemplatePodAffinityNodeAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaConnectSpecTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaConnectSpecTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution;
        }

        export interface KafkaConnectSpecTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            preference?: outputs.kafka.v1beta1.KafkaConnectSpecTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference;
            weight?: number;
        }

        export interface KafkaConnectSpecTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference {
            matchExpressions?: outputs.kafka.v1beta1.KafkaConnectSpecTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions[];
            matchFields?: outputs.kafka.v1beta1.KafkaConnectSpecTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields[];
        }

        export interface KafkaConnectSpecTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaConnectSpecTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaConnectSpecTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            nodeSelectorTerms?: outputs.kafka.v1beta1.KafkaConnectSpecTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms[];
        }

        export interface KafkaConnectSpecTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms {
            matchExpressions?: outputs.kafka.v1beta1.KafkaConnectSpecTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions[];
            matchFields?: outputs.kafka.v1beta1.KafkaConnectSpecTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields[];
        }

        export interface KafkaConnectSpecTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaConnectSpecTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaConnectSpecTemplatePodAffinityPodAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaConnectSpecTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaConnectSpecTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        export interface KafkaConnectSpecTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            podAffinityTerm?: outputs.kafka.v1beta1.KafkaConnectSpecTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            weight?: number;
        }

        export interface KafkaConnectSpecTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            labelSelector?: outputs.kafka.v1beta1.KafkaConnectSpecTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaConnectSpecTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaConnectSpecTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaConnectSpecTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaConnectSpecTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            labelSelector?: outputs.kafka.v1beta1.KafkaConnectSpecTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaConnectSpecTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaConnectSpecTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaConnectSpecTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaConnectSpecTemplatePodAffinityPodAntiAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaConnectSpecTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaConnectSpecTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        export interface KafkaConnectSpecTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            podAffinityTerm?: outputs.kafka.v1beta1.KafkaConnectSpecTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            weight?: number;
        }

        export interface KafkaConnectSpecTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            labelSelector?: outputs.kafka.v1beta1.KafkaConnectSpecTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaConnectSpecTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaConnectSpecTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaConnectSpecTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaConnectSpecTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            labelSelector?: outputs.kafka.v1beta1.KafkaConnectSpecTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaConnectSpecTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaConnectSpecTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaConnectSpecTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        /**
         * Template for Kafka Connect `PodDisruptionBudget`.
         */
        export interface KafkaConnectSpecTemplatePodDisruptionBudget {
            /**
             * Maximum number of unavailable pods to allow automatic Pod eviction. A Pod eviction is allowed when the `maxUnavailable` number of pods or fewer are unavailable after the eviction. Setting this value to 0 prevents all voluntary evictions, so the pods must be evicted manually. Defaults to 1.
             */
            maxUnavailable?: number;
            /**
             * Metadata to apply to the `PodDistruptionBugetTemplate` resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaConnectSpecTemplatePodDisruptionBudgetMetadata;
        }

        /**
         * Metadata to apply to the `PodDistruptionBugetTemplate` resource.
         */
        export interface KafkaConnectSpecTemplatePodDisruptionBudgetMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        export interface KafkaConnectSpecTemplatePodHostAliases {
            hostnames?: string[];
            ip?: string;
        }

        export interface KafkaConnectSpecTemplatePodImagePullSecrets {
            name?: string;
        }

        /**
         * Metadata applied to the resource.
         */
        export interface KafkaConnectSpecTemplatePodMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        /**
         * Configures pod-level security attributes and common container settings.
         */
        export interface KafkaConnectSpecTemplatePodSecurityContext {
            fsGroup?: number;
            fsGroupChangePolicy?: string;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.kafka.v1beta1.KafkaConnectSpecTemplatePodSecurityContextSeLinuxOptions;
            supplementalGroups?: number[];
            sysctls?: outputs.kafka.v1beta1.KafkaConnectSpecTemplatePodSecurityContextSysctls[];
            windowsOptions?: outputs.kafka.v1beta1.KafkaConnectSpecTemplatePodSecurityContextWindowsOptions;
        }

        export interface KafkaConnectSpecTemplatePodSecurityContextSeLinuxOptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface KafkaConnectSpecTemplatePodSecurityContextSysctls {
            name?: string;
            value?: string;
        }

        export interface KafkaConnectSpecTemplatePodSecurityContextWindowsOptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        export interface KafkaConnectSpecTemplatePodTolerations {
            effect?: string;
            key?: string;
            operator?: string;
            tolerationSeconds?: number;
            value?: string;
        }

        /**
         * TLS configuration.
         */
        export interface KafkaConnectSpecTls {
            /**
             * Trusted certificates for TLS connection.
             */
            trustedCertificates?: outputs.kafka.v1beta1.KafkaConnectSpecTlsTrustedCertificates[];
        }

        export interface KafkaConnectSpecTlsTrustedCertificates {
            /**
             * The name of the file certificate in the Secret.
             */
            certificate: string;
            /**
             * The name of the Secret containing the certificate.
             */
            secretName: string;
        }

        export interface KafkaConnectSpecTolerations {
            effect?: string;
            key?: string;
            operator?: string;
            tolerationSeconds?: number;
            value?: string;
        }

        /**
         * The configuration of tracing in Kafka Connect.
         */
        export interface KafkaConnectSpecTracing {
            /**
             * Type of the tracing used. Currently the only supported type is `jaeger` for Jaeger tracing.
             */
            type: string;
        }

        /**
         * The status of the Kafka Connect cluster.
         */
        export interface KafkaConnectStatus {
            /**
             * List of status conditions.
             */
            conditions?: outputs.kafka.v1beta1.KafkaConnectStatusConditions[];
            /**
             * The list of connector plugins available in this Kafka Connect deployment.
             */
            connectorPlugins?: outputs.kafka.v1beta1.KafkaConnectStatusConnectorPlugins[];
            /**
             * Label selector for pods providing this resource.
             */
            labelSelector?: string;
            /**
             * The generation of the CRD that was last reconciled by the operator.
             */
            observedGeneration?: number;
            /**
             * The current number of pods being used to provide this resource.
             */
            replicas?: number;
            /**
             * The URL of the REST API endpoint for managing and monitoring Kafka Connect connectors.
             */
            url?: string;
        }

        export interface KafkaConnectStatusConditions {
            /**
             * Last time the condition of a type changed from one status to another. The required format is 'yyyy-MM-ddTHH:mm:ssZ', in the UTC time zone.
             */
            lastTransitionTime?: string;
            /**
             * Human-readable message indicating details about the condition's last transition.
             */
            message?: string;
            /**
             * The reason for the condition's last transition (a single word in CamelCase).
             */
            reason?: string;
            /**
             * The status of the condition, either True, False or Unknown.
             */
            status?: string;
            /**
             * The unique identifier of a condition, used to distinguish between other conditions in the resource.
             */
            type?: string;
        }

        export interface KafkaConnectStatusConnectorPlugins {
            /**
             * The class of the connector plugin.
             */
            class?: string;
            /**
             * The type of the connector plugin. The available types are `sink` and `source`.
             */
            type?: string;
            /**
             * The version of the connector plugin.
             */
            version?: string;
        }

        /**
         * The specification of Kafka MirrorMaker.
         */
        export interface KafkaMirrorMakerSpec {
            /**
             * The pod's affinity rules.
             */
            affinity?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecAffinity;
            /**
             * Configuration of source cluster.
             */
            consumer: outputs.kafka.v1beta1.KafkaMirrorMakerSpecConsumer;
            /**
             * The docker image for the pods.
             */
            image?: string;
            /**
             * JVM Options for pods.
             */
            jvmOptions?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecJvmOptions;
            /**
             * Pod liveness checking.
             */
            livenessProbe?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecLivenessProbe;
            /**
             * Logging configuration for MirrorMaker.
             */
            logging?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecLogging;
            /**
             * The Prometheus JMX Exporter configuration. See {JMXExporter} for details of the structure of this configuration.
             */
            metrics?: {[key: string]: any};
            /**
             * Configuration of target cluster.
             */
            producer: outputs.kafka.v1beta1.KafkaMirrorMakerSpecProducer;
            /**
             * Pod readiness checking.
             */
            readinessProbe?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecReadinessProbe;
            /**
             * The number of pods in the `Deployment`.
             */
            replicas: number;
            /**
             * CPU and memory resources to reserve.
             */
            resources?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecResources;
            /**
             * Template to specify how Kafka MirrorMaker resources, `Deployments` and `Pods`, are generated.
             */
            template?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplate;
            /**
             * The pod's tolerations.
             */
            tolerations?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTolerations[];
            /**
             * The configuration of tracing in Kafka MirrorMaker.
             */
            tracing?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTracing;
            /**
             * The Kafka MirrorMaker version. Defaults to {DefaultKafkaVersion}. Consult the documentation to understand the process required to upgrade or downgrade the version.
             */
            version?: string;
            /**
             * List of topics which are included for mirroring. This option allows any regular expression using Java-style regular expressions. Mirroring two topics named A and B is achieved by using the whitelist `'A\|B'`. Or, as a special case, you can mirror all topics using the whitelist '*'. You can also specify multiple regular expressions separated by commas.
             */
            whitelist: string;
        }

        /**
         * The pod's affinity rules.
         */
        export interface KafkaMirrorMakerSpecAffinity {
            nodeAffinity?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecAffinityNodeAffinity;
            podAffinity?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecAffinityPodAffinity;
            podAntiAffinity?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecAffinityPodAntiAffinity;
        }

        export interface KafkaMirrorMakerSpecAffinityNodeAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution;
        }

        export interface KafkaMirrorMakerSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            preference?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference;
            weight?: number;
        }

        export interface KafkaMirrorMakerSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference {
            matchExpressions?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions[];
            matchFields?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields[];
        }

        export interface KafkaMirrorMakerSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaMirrorMakerSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaMirrorMakerSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            nodeSelectorTerms?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms[];
        }

        export interface KafkaMirrorMakerSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms {
            matchExpressions?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions[];
            matchFields?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields[];
        }

        export interface KafkaMirrorMakerSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaMirrorMakerSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaMirrorMakerSpecAffinityPodAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        export interface KafkaMirrorMakerSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            podAffinityTerm?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            weight?: number;
        }

        export interface KafkaMirrorMakerSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            labelSelector?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaMirrorMakerSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaMirrorMakerSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaMirrorMakerSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            labelSelector?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaMirrorMakerSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaMirrorMakerSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaMirrorMakerSpecAffinityPodAntiAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        export interface KafkaMirrorMakerSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            podAffinityTerm?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            weight?: number;
        }

        export interface KafkaMirrorMakerSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            labelSelector?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaMirrorMakerSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaMirrorMakerSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaMirrorMakerSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            labelSelector?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaMirrorMakerSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaMirrorMakerSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        /**
         * Configuration of source cluster.
         */
        export interface KafkaMirrorMakerSpecConsumer {
            /**
             * Authentication configuration for connecting to the cluster.
             */
            authentication?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecConsumerAuthentication;
            /**
             * A list of host:port pairs for establishing the initial connection to the Kafka cluster.
             */
            bootstrapServers: string;
            /**
             * The MirrorMaker consumer config. Properties with the following prefixes cannot be set: ssl., bootstrap.servers, group.id, sasl., security., interceptor.classes (with the exception of: ssl.endpoint.identification.algorithm, ssl.cipher.suites, ssl.protocol, ssl.enabled.protocols).
             */
            config?: {[key: string]: any};
            /**
             * A unique string that identifies the consumer group this consumer belongs to.
             */
            groupId: string;
            /**
             * Specifies the number of consumer stream threads to create.
             */
            numStreams?: number;
            /**
             * Specifies the offset auto-commit interval in ms. Default value is 60000.
             */
            offsetCommitInterval?: number;
            /**
             * TLS configuration for connecting MirrorMaker to the cluster.
             */
            tls?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecConsumerTls;
        }

        /**
         * Authentication configuration for connecting to the cluster.
         */
        export interface KafkaMirrorMakerSpecConsumerAuthentication {
            /**
             * Link to Kubernetes Secret containing the access token which was obtained from the authorization server.
             */
            accessToken?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecConsumerAuthenticationAccessToken;
            /**
             * Configure whether access token should be treated as JWT. This should be set to `false` if the authorization server returns opaque tokens. Defaults to `true`.
             */
            accessTokenIsJwt?: boolean;
            /**
             * Reference to the `Secret` which holds the certificate and private key pair.
             */
            certificateAndKey?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecConsumerAuthenticationCertificateAndKey;
            /**
             * OAuth Client ID which the Kafka client can use to authenticate against the OAuth server and use the token endpoint URI.
             */
            clientId?: string;
            /**
             * Link to Kubernetes Secret containing the OAuth client secret which the Kafka client can use to authenticate against the OAuth server and use the token endpoint URI.
             */
            clientSecret?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecConsumerAuthenticationClientSecret;
            /**
             * Enable or disable TLS hostname verification. Default value is `false`.
             */
            disableTlsHostnameVerification?: boolean;
            /**
             * Set or limit time-to-live of the access tokens to the specified number of seconds. This should be set if the authorization server returns opaque tokens.
             */
            maxTokenExpirySeconds?: number;
            /**
             * Reference to the `Secret` which holds the password.
             */
            passwordSecret?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecConsumerAuthenticationPasswordSecret;
            /**
             * Link to Kubernetes Secret containing the refresh token which can be used to obtain access token from the authorization server.
             */
            refreshToken?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecConsumerAuthenticationRefreshToken;
            /**
             * OAuth scope to use when authenticating against the authorization server. Some authorization servers require this to be set. The possible values depend on how authorization server is configured. By default `scope` is not specified when doing the token endpoint request.
             */
            scope?: string;
            /**
             * Trusted certificates for TLS connection to the OAuth server.
             */
            tlsTrustedCertificates?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecConsumerAuthenticationTlsTrustedCertificates[];
            /**
             * Authorization server token endpoint URI.
             */
            tokenEndpointUri?: string;
            /**
             * Authentication type. Currently the only supported types are `tls`, `scram-sha-512`, and `plain`. `scram-sha-512` type uses SASL SCRAM-SHA-512 Authentication. `plain` type uses SASL PLAIN Authentication. `oauth` type uses SASL OAUTHBEARER Authentication. The `tls` type uses TLS Client Authentication. The `tls` type is supported only over TLS connections.
             */
            type: string;
            /**
             * Username used for the authentication.
             */
            username?: string;
        }

        /**
         * Link to Kubernetes Secret containing the access token which was obtained from the authorization server.
         */
        export interface KafkaMirrorMakerSpecConsumerAuthenticationAccessToken {
            /**
             * The key under which the secret value is stored in the Kubernetes Secret.
             */
            key: string;
            /**
             * The name of the Kubernetes Secret containing the secret value.
             */
            secretName: string;
        }

        /**
         * Reference to the `Secret` which holds the certificate and private key pair.
         */
        export interface KafkaMirrorMakerSpecConsumerAuthenticationCertificateAndKey {
            /**
             * The name of the file certificate in the Secret.
             */
            certificate: string;
            /**
             * The name of the private key in the Secret.
             */
            key: string;
            /**
             * The name of the Secret containing the certificate.
             */
            secretName: string;
        }

        /**
         * Link to Kubernetes Secret containing the OAuth client secret which the Kafka client can use to authenticate against the OAuth server and use the token endpoint URI.
         */
        export interface KafkaMirrorMakerSpecConsumerAuthenticationClientSecret {
            /**
             * The key under which the secret value is stored in the Kubernetes Secret.
             */
            key: string;
            /**
             * The name of the Kubernetes Secret containing the secret value.
             */
            secretName: string;
        }

        /**
         * Reference to the `Secret` which holds the password.
         */
        export interface KafkaMirrorMakerSpecConsumerAuthenticationPasswordSecret {
            /**
             * The name of the key in the Secret under which the password is stored.
             */
            password: string;
            /**
             * The name of the Secret containing the password.
             */
            secretName: string;
        }

        /**
         * Link to Kubernetes Secret containing the refresh token which can be used to obtain access token from the authorization server.
         */
        export interface KafkaMirrorMakerSpecConsumerAuthenticationRefreshToken {
            /**
             * The key under which the secret value is stored in the Kubernetes Secret.
             */
            key: string;
            /**
             * The name of the Kubernetes Secret containing the secret value.
             */
            secretName: string;
        }

        export interface KafkaMirrorMakerSpecConsumerAuthenticationTlsTrustedCertificates {
            /**
             * The name of the file certificate in the Secret.
             */
            certificate: string;
            /**
             * The name of the Secret containing the certificate.
             */
            secretName: string;
        }

        /**
         * TLS configuration for connecting MirrorMaker to the cluster.
         */
        export interface KafkaMirrorMakerSpecConsumerTls {
            /**
             * Trusted certificates for TLS connection.
             */
            trustedCertificates?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecConsumerTlsTrustedCertificates[];
        }

        export interface KafkaMirrorMakerSpecConsumerTlsTrustedCertificates {
            /**
             * The name of the file certificate in the Secret.
             */
            certificate: string;
            /**
             * The name of the Secret containing the certificate.
             */
            secretName: string;
        }

        /**
         * JVM Options for pods.
         */
        export interface KafkaMirrorMakerSpecJvmOptions {
            /**
             * A map of -XX options to the JVM.
             */
            "-XX"?: {[key: string]: any};
            /**
             * -Xms option to to the JVM.
             */
            "-Xms"?: string;
            /**
             * -Xmx option to to the JVM.
             */
            "-Xmx"?: string;
            /**
             * Specifies whether the Garbage Collection logging is enabled. The default is false.
             */
            gcLoggingEnabled?: boolean;
            /**
             * A map of additional system properties which will be passed using the `-D` option to the JVM.
             */
            javaSystemProperties?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecJvmOptionsJavaSystemProperties[];
        }

        export interface KafkaMirrorMakerSpecJvmOptionsJavaSystemProperties {
            /**
             * The system property name.
             */
            name?: string;
            /**
             * The system property value.
             */
            value?: string;
        }

        /**
         * Pod liveness checking.
         */
        export interface KafkaMirrorMakerSpecLivenessProbe {
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * The initial delay before first the health is first checked.
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * The timeout for each attempted health check.
             */
            timeoutSeconds?: number;
        }

        /**
         * Logging configuration for MirrorMaker.
         */
        export interface KafkaMirrorMakerSpecLogging {
            /**
             * A Map from logger name to logger level.
             */
            loggers?: {[key: string]: any};
            /**
             * The name of the `ConfigMap` from which to get the logging configuration.
             */
            name?: string;
            /**
             * Logging type, must be either 'inline' or 'external'.
             */
            type: string;
        }

        /**
         * Configuration of target cluster.
         */
        export interface KafkaMirrorMakerSpecProducer {
            /**
             * Flag to set the MirrorMaker to exit on a failed send. Default value is `true`.
             */
            abortOnSendFailure?: boolean;
            /**
             * Authentication configuration for connecting to the cluster.
             */
            authentication?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecProducerAuthentication;
            /**
             * A list of host:port pairs for establishing the initial connection to the Kafka cluster.
             */
            bootstrapServers: string;
            /**
             * The MirrorMaker producer config. Properties with the following prefixes cannot be set: ssl., bootstrap.servers, sasl., security., interceptor.classes (with the exception of: ssl.endpoint.identification.algorithm, ssl.cipher.suites, ssl.protocol, ssl.enabled.protocols).
             */
            config?: {[key: string]: any};
            /**
             * TLS configuration for connecting MirrorMaker to the cluster.
             */
            tls?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecProducerTls;
        }

        /**
         * Authentication configuration for connecting to the cluster.
         */
        export interface KafkaMirrorMakerSpecProducerAuthentication {
            /**
             * Link to Kubernetes Secret containing the access token which was obtained from the authorization server.
             */
            accessToken?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecProducerAuthenticationAccessToken;
            /**
             * Configure whether access token should be treated as JWT. This should be set to `false` if the authorization server returns opaque tokens. Defaults to `true`.
             */
            accessTokenIsJwt?: boolean;
            /**
             * Reference to the `Secret` which holds the certificate and private key pair.
             */
            certificateAndKey?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecProducerAuthenticationCertificateAndKey;
            /**
             * OAuth Client ID which the Kafka client can use to authenticate against the OAuth server and use the token endpoint URI.
             */
            clientId?: string;
            /**
             * Link to Kubernetes Secret containing the OAuth client secret which the Kafka client can use to authenticate against the OAuth server and use the token endpoint URI.
             */
            clientSecret?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecProducerAuthenticationClientSecret;
            /**
             * Enable or disable TLS hostname verification. Default value is `false`.
             */
            disableTlsHostnameVerification?: boolean;
            /**
             * Set or limit time-to-live of the access tokens to the specified number of seconds. This should be set if the authorization server returns opaque tokens.
             */
            maxTokenExpirySeconds?: number;
            /**
             * Reference to the `Secret` which holds the password.
             */
            passwordSecret?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecProducerAuthenticationPasswordSecret;
            /**
             * Link to Kubernetes Secret containing the refresh token which can be used to obtain access token from the authorization server.
             */
            refreshToken?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecProducerAuthenticationRefreshToken;
            /**
             * OAuth scope to use when authenticating against the authorization server. Some authorization servers require this to be set. The possible values depend on how authorization server is configured. By default `scope` is not specified when doing the token endpoint request.
             */
            scope?: string;
            /**
             * Trusted certificates for TLS connection to the OAuth server.
             */
            tlsTrustedCertificates?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecProducerAuthenticationTlsTrustedCertificates[];
            /**
             * Authorization server token endpoint URI.
             */
            tokenEndpointUri?: string;
            /**
             * Authentication type. Currently the only supported types are `tls`, `scram-sha-512`, and `plain`. `scram-sha-512` type uses SASL SCRAM-SHA-512 Authentication. `plain` type uses SASL PLAIN Authentication. `oauth` type uses SASL OAUTHBEARER Authentication. The `tls` type uses TLS Client Authentication. The `tls` type is supported only over TLS connections.
             */
            type: string;
            /**
             * Username used for the authentication.
             */
            username?: string;
        }

        /**
         * Link to Kubernetes Secret containing the access token which was obtained from the authorization server.
         */
        export interface KafkaMirrorMakerSpecProducerAuthenticationAccessToken {
            /**
             * The key under which the secret value is stored in the Kubernetes Secret.
             */
            key: string;
            /**
             * The name of the Kubernetes Secret containing the secret value.
             */
            secretName: string;
        }

        /**
         * Reference to the `Secret` which holds the certificate and private key pair.
         */
        export interface KafkaMirrorMakerSpecProducerAuthenticationCertificateAndKey {
            /**
             * The name of the file certificate in the Secret.
             */
            certificate: string;
            /**
             * The name of the private key in the Secret.
             */
            key: string;
            /**
             * The name of the Secret containing the certificate.
             */
            secretName: string;
        }

        /**
         * Link to Kubernetes Secret containing the OAuth client secret which the Kafka client can use to authenticate against the OAuth server and use the token endpoint URI.
         */
        export interface KafkaMirrorMakerSpecProducerAuthenticationClientSecret {
            /**
             * The key under which the secret value is stored in the Kubernetes Secret.
             */
            key: string;
            /**
             * The name of the Kubernetes Secret containing the secret value.
             */
            secretName: string;
        }

        /**
         * Reference to the `Secret` which holds the password.
         */
        export interface KafkaMirrorMakerSpecProducerAuthenticationPasswordSecret {
            /**
             * The name of the key in the Secret under which the password is stored.
             */
            password: string;
            /**
             * The name of the Secret containing the password.
             */
            secretName: string;
        }

        /**
         * Link to Kubernetes Secret containing the refresh token which can be used to obtain access token from the authorization server.
         */
        export interface KafkaMirrorMakerSpecProducerAuthenticationRefreshToken {
            /**
             * The key under which the secret value is stored in the Kubernetes Secret.
             */
            key: string;
            /**
             * The name of the Kubernetes Secret containing the secret value.
             */
            secretName: string;
        }

        export interface KafkaMirrorMakerSpecProducerAuthenticationTlsTrustedCertificates {
            /**
             * The name of the file certificate in the Secret.
             */
            certificate: string;
            /**
             * The name of the Secret containing the certificate.
             */
            secretName: string;
        }

        /**
         * TLS configuration for connecting MirrorMaker to the cluster.
         */
        export interface KafkaMirrorMakerSpecProducerTls {
            /**
             * Trusted certificates for TLS connection.
             */
            trustedCertificates?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecProducerTlsTrustedCertificates[];
        }

        export interface KafkaMirrorMakerSpecProducerTlsTrustedCertificates {
            /**
             * The name of the file certificate in the Secret.
             */
            certificate: string;
            /**
             * The name of the Secret containing the certificate.
             */
            secretName: string;
        }

        /**
         * Pod readiness checking.
         */
        export interface KafkaMirrorMakerSpecReadinessProbe {
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * The initial delay before first the health is first checked.
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * The timeout for each attempted health check.
             */
            timeoutSeconds?: number;
        }

        /**
         * CPU and memory resources to reserve.
         */
        export interface KafkaMirrorMakerSpecResources {
            limits?: {[key: string]: any};
            requests?: {[key: string]: any};
        }

        /**
         * Template to specify how Kafka MirrorMaker resources, `Deployments` and `Pods`, are generated.
         */
        export interface KafkaMirrorMakerSpecTemplate {
            /**
             * Template for Kafka MirrorMaker `Deployment`.
             */
            deployment?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplateDeployment;
            /**
             * Template for Kafka MirrorMaker container.
             */
            mirrorMakerContainer?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplateMirrorMakerContainer;
            /**
             * Template for Kafka MirrorMaker `Pods`.
             */
            pod?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplatePod;
            /**
             * Template for Kafka MirrorMaker `PodDisruptionBudget`.
             */
            podDisruptionBudget?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplatePodDisruptionBudget;
        }

        /**
         * Template for Kafka MirrorMaker `Deployment`.
         */
        export interface KafkaMirrorMakerSpecTemplateDeployment {
            /**
             * Metadata applied to the resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplateDeploymentMetadata;
        }

        /**
         * Metadata applied to the resource.
         */
        export interface KafkaMirrorMakerSpecTemplateDeploymentMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        /**
         * Template for Kafka MirrorMaker container.
         */
        export interface KafkaMirrorMakerSpecTemplateMirrorMakerContainer {
            /**
             * Environment variables which should be applied to the container.
             */
            env?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplateMirrorMakerContainerEnv[];
            /**
             * Security context for the container.
             */
            securityContext?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplateMirrorMakerContainerSecurityContext;
        }

        export interface KafkaMirrorMakerSpecTemplateMirrorMakerContainerEnv {
            /**
             * The environment variable key.
             */
            name?: string;
            /**
             * The environment variable value.
             */
            value?: string;
        }

        /**
         * Security context for the container.
         */
        export interface KafkaMirrorMakerSpecTemplateMirrorMakerContainerSecurityContext {
            allowPrivilegeEscalation?: boolean;
            capabilities?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplateMirrorMakerContainerSecurityContextCapabilities;
            privileged?: boolean;
            procMount?: string;
            readOnlyRootFilesystem?: boolean;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplateMirrorMakerContainerSecurityContextSeLinuxOptions;
            windowsOptions?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplateMirrorMakerContainerSecurityContextWindowsOptions;
        }

        export interface KafkaMirrorMakerSpecTemplateMirrorMakerContainerSecurityContextCapabilities {
            add?: string[];
            drop?: string[];
        }

        export interface KafkaMirrorMakerSpecTemplateMirrorMakerContainerSecurityContextSeLinuxOptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface KafkaMirrorMakerSpecTemplateMirrorMakerContainerSecurityContextWindowsOptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        /**
         * Template for Kafka MirrorMaker `Pods`.
         */
        export interface KafkaMirrorMakerSpecTemplatePod {
            /**
             * The pod's affinity rules.
             */
            affinity?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplatePodAffinity;
            /**
             * The pod's HostAliases. HostAliases is an optional list of hosts and IPs that will be injected into the pod's hosts file if specified.
             */
            hostAliases?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplatePodHostAliases[];
            /**
             * List of references to secrets in the same namespace to use for pulling any of the images used by this Pod. When the `STRIMZI_IMAGE_PULL_SECRETS` environment variable in Cluster Operator and the `imagePullSecrets` option are specified, only the `imagePullSecrets` variable is used and the `STRIMZI_IMAGE_PULL_SECRETS` variable is ignored.
             */
            imagePullSecrets?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplatePodImagePullSecrets[];
            /**
             * Metadata applied to the resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplatePodMetadata;
            /**
             * The name of the priority class used to assign priority to the pods. For more information about priority classes, see {K8sPriorityClass}.
             */
            priorityClassName?: string;
            /**
             * The name of the scheduler used to dispatch this `Pod`. If not specified, the default scheduler will be used.
             */
            schedulerName?: string;
            /**
             * Configures pod-level security attributes and common container settings.
             */
            securityContext?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplatePodSecurityContext;
            /**
             * The grace period is the duration in seconds after the processes running in the pod are sent a termination signal, and the time when the processes are forcibly halted with a kill signal. Set this value to longer than the expected cleanup time for your process. Value must be a non-negative integer. A zero value indicates delete immediately. You might need to increase the grace period for very large Kafka clusters, so that the Kafka brokers have enough time to transfer their work to another broker before they are terminated. Defaults to 30 seconds.
             */
            terminationGracePeriodSeconds?: number;
            /**
             * The pod's tolerations.
             */
            tolerations?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplatePodTolerations[];
        }

        /**
         * The pod's affinity rules.
         */
        export interface KafkaMirrorMakerSpecTemplatePodAffinity {
            nodeAffinity?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplatePodAffinityNodeAffinity;
            podAffinity?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplatePodAffinityPodAffinity;
            podAntiAffinity?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplatePodAffinityPodAntiAffinity;
        }

        export interface KafkaMirrorMakerSpecTemplatePodAffinityNodeAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution;
        }

        export interface KafkaMirrorMakerSpecTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            preference?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference;
            weight?: number;
        }

        export interface KafkaMirrorMakerSpecTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference {
            matchExpressions?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions[];
            matchFields?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields[];
        }

        export interface KafkaMirrorMakerSpecTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaMirrorMakerSpecTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaMirrorMakerSpecTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            nodeSelectorTerms?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms[];
        }

        export interface KafkaMirrorMakerSpecTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms {
            matchExpressions?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions[];
            matchFields?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields[];
        }

        export interface KafkaMirrorMakerSpecTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaMirrorMakerSpecTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaMirrorMakerSpecTemplatePodAffinityPodAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        export interface KafkaMirrorMakerSpecTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            podAffinityTerm?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            weight?: number;
        }

        export interface KafkaMirrorMakerSpecTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            labelSelector?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaMirrorMakerSpecTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaMirrorMakerSpecTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaMirrorMakerSpecTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            labelSelector?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaMirrorMakerSpecTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaMirrorMakerSpecTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaMirrorMakerSpecTemplatePodAffinityPodAntiAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        export interface KafkaMirrorMakerSpecTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            podAffinityTerm?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            weight?: number;
        }

        export interface KafkaMirrorMakerSpecTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            labelSelector?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaMirrorMakerSpecTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaMirrorMakerSpecTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaMirrorMakerSpecTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            labelSelector?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaMirrorMakerSpecTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaMirrorMakerSpecTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        /**
         * Template for Kafka MirrorMaker `PodDisruptionBudget`.
         */
        export interface KafkaMirrorMakerSpecTemplatePodDisruptionBudget {
            /**
             * Maximum number of unavailable pods to allow automatic Pod eviction. A Pod eviction is allowed when the `maxUnavailable` number of pods or fewer are unavailable after the eviction. Setting this value to 0 prevents all voluntary evictions, so the pods must be evicted manually. Defaults to 1.
             */
            maxUnavailable?: number;
            /**
             * Metadata to apply to the `PodDistruptionBugetTemplate` resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplatePodDisruptionBudgetMetadata;
        }

        /**
         * Metadata to apply to the `PodDistruptionBugetTemplate` resource.
         */
        export interface KafkaMirrorMakerSpecTemplatePodDisruptionBudgetMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        export interface KafkaMirrorMakerSpecTemplatePodHostAliases {
            hostnames?: string[];
            ip?: string;
        }

        export interface KafkaMirrorMakerSpecTemplatePodImagePullSecrets {
            name?: string;
        }

        /**
         * Metadata applied to the resource.
         */
        export interface KafkaMirrorMakerSpecTemplatePodMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        /**
         * Configures pod-level security attributes and common container settings.
         */
        export interface KafkaMirrorMakerSpecTemplatePodSecurityContext {
            fsGroup?: number;
            fsGroupChangePolicy?: string;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplatePodSecurityContextSeLinuxOptions;
            supplementalGroups?: number[];
            sysctls?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplatePodSecurityContextSysctls[];
            windowsOptions?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplatePodSecurityContextWindowsOptions;
        }

        export interface KafkaMirrorMakerSpecTemplatePodSecurityContextSeLinuxOptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface KafkaMirrorMakerSpecTemplatePodSecurityContextSysctls {
            name?: string;
            value?: string;
        }

        export interface KafkaMirrorMakerSpecTemplatePodSecurityContextWindowsOptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        export interface KafkaMirrorMakerSpecTemplatePodTolerations {
            effect?: string;
            key?: string;
            operator?: string;
            tolerationSeconds?: number;
            value?: string;
        }

        export interface KafkaMirrorMakerSpecTolerations {
            effect?: string;
            key?: string;
            operator?: string;
            tolerationSeconds?: number;
            value?: string;
        }

        /**
         * The configuration of tracing in Kafka MirrorMaker.
         */
        export interface KafkaMirrorMakerSpecTracing {
            /**
             * Type of the tracing used. Currently the only supported type is `jaeger` for Jaeger tracing.
             */
            type: string;
        }

        /**
         * The status of Kafka MirrorMaker.
         */
        export interface KafkaMirrorMakerStatus {
            /**
             * List of status conditions.
             */
            conditions?: outputs.kafka.v1beta1.KafkaMirrorMakerStatusConditions[];
            /**
             * Label selector for pods providing this resource.
             */
            labelSelector?: string;
            /**
             * The generation of the CRD that was last reconciled by the operator.
             */
            observedGeneration?: number;
            /**
             * The current number of pods being used to provide this resource.
             */
            replicas?: number;
        }

        export interface KafkaMirrorMakerStatusConditions {
            /**
             * Last time the condition of a type changed from one status to another. The required format is 'yyyy-MM-ddTHH:mm:ssZ', in the UTC time zone.
             */
            lastTransitionTime?: string;
            /**
             * Human-readable message indicating details about the condition's last transition.
             */
            message?: string;
            /**
             * The reason for the condition's last transition (a single word in CamelCase).
             */
            reason?: string;
            /**
             * The status of the condition, either True, False or Unknown.
             */
            status?: string;
            /**
             * The unique identifier of a condition, used to distinguish between other conditions in the resource.
             */
            type?: string;
        }

        /**
         * The specification of the Kafka and ZooKeeper clusters, and Topic Operator.
         */
        export interface KafkaSpec {
            /**
             * Configuration of the clients certificate authority.
             */
            clientsCa?: outputs.kafka.v1beta1.KafkaSpecClientsCa;
            /**
             * Configuration of the cluster certificate authority.
             */
            clusterCa?: outputs.kafka.v1beta1.KafkaSpecClusterCa;
            /**
             * Configuration for Cruise Control deployment. Deploys a Cruise Control instance when specified.
             */
            cruiseControl?: outputs.kafka.v1beta1.KafkaSpecCruiseControl;
            /**
             * Configuration of the Entity Operator.
             */
            entityOperator?: outputs.kafka.v1beta1.KafkaSpecEntityOperator;
            /**
             * Configuration for JmxTrans. When the property is present a JmxTrans deployment is created for gathering JMX metrics from each Kafka broker. For more information see https://github.com/jmxtrans/jmxtrans[JmxTrans GitHub].
             */
            jmxTrans?: outputs.kafka.v1beta1.KafkaSpecJmxTrans;
            /**
             * Configuration of the Kafka cluster.
             */
            kafka: outputs.kafka.v1beta1.KafkaSpecKafka;
            /**
             * Configuration of the Kafka Exporter. Kafka Exporter can provide additional metrics, for example lag of consumer group at topic/partition.
             */
            kafkaExporter?: outputs.kafka.v1beta1.KafkaSpecKafkaExporter;
            /**
             * A list of time windows for maintenance tasks (that is, certificates renewal). Each time window is defined by a cron expression.
             */
            maintenanceTimeWindows?: string[];
            /**
             * Configuration of the Topic Operator.
             */
            topicOperator?: outputs.kafka.v1beta1.KafkaSpecTopicOperator;
            /**
             * Configuration of the ZooKeeper cluster.
             */
            zookeeper: outputs.kafka.v1beta1.KafkaSpecZookeeper;
        }

        /**
         * Configuration of the clients certificate authority.
         */
        export interface KafkaSpecClientsCa {
            /**
             * How should CA certificate expiration be handled when `generateCertificateAuthority=true`. The default is for a new CA certificate to be generated reusing the existing private key.
             */
            certificateExpirationPolicy?: string;
            /**
             * If true then Certificate Authority certificates will be generated automatically. Otherwise the user will need to provide a Secret with the CA certificate. Default is true.
             */
            generateCertificateAuthority?: boolean;
            /**
             * The number of days in the certificate renewal period. This is the number of days before the a certificate expires during which renewal actions may be performed. When `generateCertificateAuthority` is true, this will cause the generation of a new certificate. When `generateCertificateAuthority` is true, this will cause extra logging at WARN level about the pending certificate expiry. Default is 30.
             */
            renewalDays?: number;
            /**
             * The number of days generated certificates should be valid for. The default is 365.
             */
            validityDays?: number;
        }

        /**
         * Configuration of the cluster certificate authority.
         */
        export interface KafkaSpecClusterCa {
            /**
             * How should CA certificate expiration be handled when `generateCertificateAuthority=true`. The default is for a new CA certificate to be generated reusing the existing private key.
             */
            certificateExpirationPolicy?: string;
            /**
             * If true then Certificate Authority certificates will be generated automatically. Otherwise the user will need to provide a Secret with the CA certificate. Default is true.
             */
            generateCertificateAuthority?: boolean;
            /**
             * The number of days in the certificate renewal period. This is the number of days before the a certificate expires during which renewal actions may be performed. When `generateCertificateAuthority` is true, this will cause the generation of a new certificate. When `generateCertificateAuthority` is true, this will cause extra logging at WARN level about the pending certificate expiry. Default is 30.
             */
            renewalDays?: number;
            /**
             * The number of days generated certificates should be valid for. The default is 365.
             */
            validityDays?: number;
        }

        /**
         * Configuration for Cruise Control deployment. Deploys a Cruise Control instance when specified.
         */
        export interface KafkaSpecCruiseControl {
            /**
             * The Cruise Control `brokerCapacity` configuration.
             */
            brokerCapacity?: outputs.kafka.v1beta1.KafkaSpecCruiseControlBrokerCapacity;
            /**
             * The Cruise Control configuration. For a full list of configuration options refer to https://github.com/linkedin/cruise-control/wiki/Configurations. Note that properties with the following prefixes cannot be set: bootstrap.servers, client.id, zookeeper., network., security., failed.brokers.zk.path,webserver.http., webserver.api.urlprefix, webserver.session.path, webserver.accesslog., two.step., request.reason.required,metric.reporter.sampler.bootstrap.servers, metric.reporter.topic, partition.metric.sample.store.topic, broker.metric.sample.store.topic,capacity.config.file, self.healing., anomaly.detection., ssl.
             */
            config?: {[key: string]: any};
            /**
             * The docker image for the pods.
             */
            image?: string;
            /**
             * JVM Options for the Cruise Control container.
             */
            jvmOptions?: outputs.kafka.v1beta1.KafkaSpecCruiseControlJvmOptions;
            /**
             * Pod liveness checking for the Cruise Control container.
             */
            livenessProbe?: outputs.kafka.v1beta1.KafkaSpecCruiseControlLivenessProbe;
            /**
             * Logging configuration (log4j1) for Cruise Control.
             */
            logging?: outputs.kafka.v1beta1.KafkaSpecCruiseControlLogging;
            /**
             * The Prometheus JMX Exporter configuration. See https://github.com/prometheus/jmx_exporter for details of the structure of this configuration.
             */
            metrics?: {[key: string]: any};
            /**
             * Pod readiness checking for the Cruise Control container.
             */
            readinessProbe?: outputs.kafka.v1beta1.KafkaSpecCruiseControlReadinessProbe;
            /**
             * CPU and memory resources to reserve for the Cruise Control container.
             */
            resources?: outputs.kafka.v1beta1.KafkaSpecCruiseControlResources;
            /**
             * Template to specify how Cruise Control resources, `Deployments` and `Pods`, are generated.
             */
            template?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplate;
            /**
             * TLS sidecar configuration.
             */
            tlsSidecar?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTlsSidecar;
        }

        /**
         * The Cruise Control `brokerCapacity` configuration.
         */
        export interface KafkaSpecCruiseControlBrokerCapacity {
            /**
             * Broker capacity for CPU resource utilization as a percentage (0 - 100).
             */
            cpuUtilization?: number;
            /**
             * Broker capacity for disk in bytes, for example, 100Gi.
             */
            disk?: string;
            /**
             * Broker capacity for inbound network throughput in bytes per second, for example, 10000KB/s.
             */
            inboundNetwork?: string;
            /**
             * Broker capacity for outbound network throughput in bytes per second, for example 10000KB/s.
             */
            outboundNetwork?: string;
        }

        /**
         * JVM Options for the Cruise Control container.
         */
        export interface KafkaSpecCruiseControlJvmOptions {
            /**
             * A map of -XX options to the JVM.
             */
            "-XX"?: {[key: string]: any};
            /**
             * -Xms option to to the JVM.
             */
            "-Xms"?: string;
            /**
             * -Xmx option to to the JVM.
             */
            "-Xmx"?: string;
            /**
             * Specifies whether the Garbage Collection logging is enabled. The default is false.
             */
            gcLoggingEnabled?: boolean;
            /**
             * A map of additional system properties which will be passed using the `-D` option to the JVM.
             */
            javaSystemProperties?: outputs.kafka.v1beta1.KafkaSpecCruiseControlJvmOptionsJavaSystemProperties[];
        }

        export interface KafkaSpecCruiseControlJvmOptionsJavaSystemProperties {
            /**
             * The system property name.
             */
            name?: string;
            /**
             * The system property value.
             */
            value?: string;
        }

        /**
         * Pod liveness checking for the Cruise Control container.
         */
        export interface KafkaSpecCruiseControlLivenessProbe {
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * The initial delay before first the health is first checked.
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * The timeout for each attempted health check.
             */
            timeoutSeconds?: number;
        }

        /**
         * Logging configuration (log4j1) for Cruise Control.
         */
        export interface KafkaSpecCruiseControlLogging {
            /**
             * A Map from logger name to logger level.
             */
            loggers?: {[key: string]: any};
            /**
             * The name of the `ConfigMap` from which to get the logging configuration.
             */
            name?: string;
            /**
             * Logging type, must be either 'inline' or 'external'.
             */
            type: string;
        }

        /**
         * Pod readiness checking for the Cruise Control container.
         */
        export interface KafkaSpecCruiseControlReadinessProbe {
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * The initial delay before first the health is first checked.
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * The timeout for each attempted health check.
             */
            timeoutSeconds?: number;
        }

        /**
         * CPU and memory resources to reserve for the Cruise Control container.
         */
        export interface KafkaSpecCruiseControlResources {
            limits?: {[key: string]: any};
            requests?: {[key: string]: any};
        }

        /**
         * Template to specify how Cruise Control resources, `Deployments` and `Pods`, are generated.
         */
        export interface KafkaSpecCruiseControlTemplate {
            /**
             * Template for Cruise Control API `Service`.
             */
            apiService?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplateApiService;
            /**
             * Template for the Cruise Control container.
             */
            cruiseControlContainer?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplateCruiseControlContainer;
            /**
             * Template for Cruise Control `Deployment`.
             */
            deployment?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplateDeployment;
            /**
             * Template for Cruise Control `Pods`.
             */
            pod?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplatePod;
            /**
             * Template for Cruise Control `PodDisruptionBudget`.
             */
            podDisruptionBudget?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplatePodDisruptionBudget;
            /**
             * Template for the Cruise Control TLS sidecar container.
             */
            tlsSidecarContainer?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplateTlsSidecarContainer;
        }

        /**
         * Template for Cruise Control API `Service`.
         */
        export interface KafkaSpecCruiseControlTemplateApiService {
            /**
             * Metadata applied to the resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplateApiServiceMetadata;
        }

        /**
         * Metadata applied to the resource.
         */
        export interface KafkaSpecCruiseControlTemplateApiServiceMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        /**
         * Template for the Cruise Control container.
         */
        export interface KafkaSpecCruiseControlTemplateCruiseControlContainer {
            /**
             * Environment variables which should be applied to the container.
             */
            env?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplateCruiseControlContainerEnv[];
            /**
             * Security context for the container.
             */
            securityContext?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplateCruiseControlContainerSecurityContext;
        }

        export interface KafkaSpecCruiseControlTemplateCruiseControlContainerEnv {
            /**
             * The environment variable key.
             */
            name?: string;
            /**
             * The environment variable value.
             */
            value?: string;
        }

        /**
         * Security context for the container.
         */
        export interface KafkaSpecCruiseControlTemplateCruiseControlContainerSecurityContext {
            allowPrivilegeEscalation?: boolean;
            capabilities?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplateCruiseControlContainerSecurityContextCapabilities;
            privileged?: boolean;
            procMount?: string;
            readOnlyRootFilesystem?: boolean;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplateCruiseControlContainerSecurityContextSeLinuxOptions;
            windowsOptions?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplateCruiseControlContainerSecurityContextWindowsOptions;
        }

        export interface KafkaSpecCruiseControlTemplateCruiseControlContainerSecurityContextCapabilities {
            add?: string[];
            drop?: string[];
        }

        export interface KafkaSpecCruiseControlTemplateCruiseControlContainerSecurityContextSeLinuxOptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface KafkaSpecCruiseControlTemplateCruiseControlContainerSecurityContextWindowsOptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        /**
         * Template for Cruise Control `Deployment`.
         */
        export interface KafkaSpecCruiseControlTemplateDeployment {
            /**
             * Metadata applied to the resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplateDeploymentMetadata;
        }

        /**
         * Metadata applied to the resource.
         */
        export interface KafkaSpecCruiseControlTemplateDeploymentMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        /**
         * Template for Cruise Control `Pods`.
         */
        export interface KafkaSpecCruiseControlTemplatePod {
            /**
             * The pod's affinity rules.
             */
            affinity?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplatePodAffinity;
            /**
             * The pod's HostAliases. HostAliases is an optional list of hosts and IPs that will be injected into the pod's hosts file if specified.
             */
            hostAliases?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplatePodHostAliases[];
            /**
             * List of references to secrets in the same namespace to use for pulling any of the images used by this Pod. When the `STRIMZI_IMAGE_PULL_SECRETS` environment variable in Cluster Operator and the `imagePullSecrets` option are specified, only the `imagePullSecrets` variable is used and the `STRIMZI_IMAGE_PULL_SECRETS` variable is ignored.
             */
            imagePullSecrets?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplatePodImagePullSecrets[];
            /**
             * Metadata applied to the resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplatePodMetadata;
            /**
             * The name of the priority class used to assign priority to the pods. For more information about priority classes, see {K8sPriorityClass}.
             */
            priorityClassName?: string;
            /**
             * The name of the scheduler used to dispatch this `Pod`. If not specified, the default scheduler will be used.
             */
            schedulerName?: string;
            /**
             * Configures pod-level security attributes and common container settings.
             */
            securityContext?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplatePodSecurityContext;
            /**
             * The grace period is the duration in seconds after the processes running in the pod are sent a termination signal, and the time when the processes are forcibly halted with a kill signal. Set this value to longer than the expected cleanup time for your process. Value must be a non-negative integer. A zero value indicates delete immediately. You might need to increase the grace period for very large Kafka clusters, so that the Kafka brokers have enough time to transfer their work to another broker before they are terminated. Defaults to 30 seconds.
             */
            terminationGracePeriodSeconds?: number;
            /**
             * The pod's tolerations.
             */
            tolerations?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplatePodTolerations[];
        }

        /**
         * The pod's affinity rules.
         */
        export interface KafkaSpecCruiseControlTemplatePodAffinity {
            nodeAffinity?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplatePodAffinityNodeAffinity;
            podAffinity?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplatePodAffinityPodAffinity;
            podAntiAffinity?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplatePodAffinityPodAntiAffinity;
        }

        export interface KafkaSpecCruiseControlTemplatePodAffinityNodeAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution;
        }

        export interface KafkaSpecCruiseControlTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            preference?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference;
            weight?: number;
        }

        export interface KafkaSpecCruiseControlTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions[];
            matchFields?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields[];
        }

        export interface KafkaSpecCruiseControlTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecCruiseControlTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecCruiseControlTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            nodeSelectorTerms?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms[];
        }

        export interface KafkaSpecCruiseControlTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions[];
            matchFields?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields[];
        }

        export interface KafkaSpecCruiseControlTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecCruiseControlTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecCruiseControlTemplatePodAffinityPodAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        export interface KafkaSpecCruiseControlTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            podAffinityTerm?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            weight?: number;
        }

        export interface KafkaSpecCruiseControlTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            labelSelector?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaSpecCruiseControlTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecCruiseControlTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecCruiseControlTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            labelSelector?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaSpecCruiseControlTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecCruiseControlTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecCruiseControlTemplatePodAffinityPodAntiAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        export interface KafkaSpecCruiseControlTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            podAffinityTerm?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            weight?: number;
        }

        export interface KafkaSpecCruiseControlTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            labelSelector?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaSpecCruiseControlTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecCruiseControlTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecCruiseControlTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            labelSelector?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaSpecCruiseControlTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecCruiseControlTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        /**
         * Template for Cruise Control `PodDisruptionBudget`.
         */
        export interface KafkaSpecCruiseControlTemplatePodDisruptionBudget {
            /**
             * Maximum number of unavailable pods to allow automatic Pod eviction. A Pod eviction is allowed when the `maxUnavailable` number of pods or fewer are unavailable after the eviction. Setting this value to 0 prevents all voluntary evictions, so the pods must be evicted manually. Defaults to 1.
             */
            maxUnavailable?: number;
            /**
             * Metadata to apply to the `PodDistruptionBugetTemplate` resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplatePodDisruptionBudgetMetadata;
        }

        /**
         * Metadata to apply to the `PodDistruptionBugetTemplate` resource.
         */
        export interface KafkaSpecCruiseControlTemplatePodDisruptionBudgetMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        export interface KafkaSpecCruiseControlTemplatePodHostAliases {
            hostnames?: string[];
            ip?: string;
        }

        export interface KafkaSpecCruiseControlTemplatePodImagePullSecrets {
            name?: string;
        }

        /**
         * Metadata applied to the resource.
         */
        export interface KafkaSpecCruiseControlTemplatePodMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        /**
         * Configures pod-level security attributes and common container settings.
         */
        export interface KafkaSpecCruiseControlTemplatePodSecurityContext {
            fsGroup?: number;
            fsGroupChangePolicy?: string;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplatePodSecurityContextSeLinuxOptions;
            supplementalGroups?: number[];
            sysctls?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplatePodSecurityContextSysctls[];
            windowsOptions?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplatePodSecurityContextWindowsOptions;
        }

        export interface KafkaSpecCruiseControlTemplatePodSecurityContextSeLinuxOptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface KafkaSpecCruiseControlTemplatePodSecurityContextSysctls {
            name?: string;
            value?: string;
        }

        export interface KafkaSpecCruiseControlTemplatePodSecurityContextWindowsOptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        export interface KafkaSpecCruiseControlTemplatePodTolerations {
            effect?: string;
            key?: string;
            operator?: string;
            tolerationSeconds?: number;
            value?: string;
        }

        /**
         * Template for the Cruise Control TLS sidecar container.
         */
        export interface KafkaSpecCruiseControlTemplateTlsSidecarContainer {
            /**
             * Environment variables which should be applied to the container.
             */
            env?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplateTlsSidecarContainerEnv[];
            /**
             * Security context for the container.
             */
            securityContext?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplateTlsSidecarContainerSecurityContext;
        }

        export interface KafkaSpecCruiseControlTemplateTlsSidecarContainerEnv {
            /**
             * The environment variable key.
             */
            name?: string;
            /**
             * The environment variable value.
             */
            value?: string;
        }

        /**
         * Security context for the container.
         */
        export interface KafkaSpecCruiseControlTemplateTlsSidecarContainerSecurityContext {
            allowPrivilegeEscalation?: boolean;
            capabilities?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplateTlsSidecarContainerSecurityContextCapabilities;
            privileged?: boolean;
            procMount?: string;
            readOnlyRootFilesystem?: boolean;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplateTlsSidecarContainerSecurityContextSeLinuxOptions;
            windowsOptions?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplateTlsSidecarContainerSecurityContextWindowsOptions;
        }

        export interface KafkaSpecCruiseControlTemplateTlsSidecarContainerSecurityContextCapabilities {
            add?: string[];
            drop?: string[];
        }

        export interface KafkaSpecCruiseControlTemplateTlsSidecarContainerSecurityContextSeLinuxOptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface KafkaSpecCruiseControlTemplateTlsSidecarContainerSecurityContextWindowsOptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        /**
         * TLS sidecar configuration.
         */
        export interface KafkaSpecCruiseControlTlsSidecar {
            /**
             * The docker image for the container.
             */
            image?: string;
            /**
             * Pod liveness checking.
             */
            livenessProbe?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTlsSidecarLivenessProbe;
            /**
             * The log level for the TLS sidecar. Default value is `notice`.
             */
            logLevel?: string;
            /**
             * Pod readiness checking.
             */
            readinessProbe?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTlsSidecarReadinessProbe;
            /**
             * CPU and memory resources to reserve.
             */
            resources?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTlsSidecarResources;
        }

        /**
         * Pod liveness checking.
         */
        export interface KafkaSpecCruiseControlTlsSidecarLivenessProbe {
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * The initial delay before first the health is first checked.
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * The timeout for each attempted health check.
             */
            timeoutSeconds?: number;
        }

        /**
         * Pod readiness checking.
         */
        export interface KafkaSpecCruiseControlTlsSidecarReadinessProbe {
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * The initial delay before first the health is first checked.
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * The timeout for each attempted health check.
             */
            timeoutSeconds?: number;
        }

        /**
         * CPU and memory resources to reserve.
         */
        export interface KafkaSpecCruiseControlTlsSidecarResources {
            limits?: {[key: string]: any};
            requests?: {[key: string]: any};
        }

        /**
         * Configuration of the Entity Operator.
         */
        export interface KafkaSpecEntityOperator {
            /**
             * The pod's affinity rules.
             */
            affinity?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorAffinity;
            /**
             * Template for Entity Operator resources. The template allows users to specify how is the `Deployment` and `Pods` generated.
             */
            template?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplate;
            /**
             * TLS sidecar configuration.
             */
            tlsSidecar?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTlsSidecar;
            /**
             * The pod's tolerations.
             */
            tolerations?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTolerations[];
            /**
             * Configuration of the Topic Operator.
             */
            topicOperator?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTopicOperator;
            /**
             * Configuration of the User Operator.
             */
            userOperator?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorUserOperator;
        }

        /**
         * The pod's affinity rules.
         */
        export interface KafkaSpecEntityOperatorAffinity {
            nodeAffinity?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorAffinityNodeAffinity;
            podAffinity?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorAffinityPodAffinity;
            podAntiAffinity?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorAffinityPodAntiAffinity;
        }

        export interface KafkaSpecEntityOperatorAffinityNodeAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution;
        }

        export interface KafkaSpecEntityOperatorAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            preference?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference;
            weight?: number;
        }

        export interface KafkaSpecEntityOperatorAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions[];
            matchFields?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields[];
        }

        export interface KafkaSpecEntityOperatorAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecEntityOperatorAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecEntityOperatorAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            nodeSelectorTerms?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms[];
        }

        export interface KafkaSpecEntityOperatorAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions[];
            matchFields?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields[];
        }

        export interface KafkaSpecEntityOperatorAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecEntityOperatorAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecEntityOperatorAffinityPodAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        export interface KafkaSpecEntityOperatorAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            podAffinityTerm?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            weight?: number;
        }

        export interface KafkaSpecEntityOperatorAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            labelSelector?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaSpecEntityOperatorAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecEntityOperatorAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecEntityOperatorAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            labelSelector?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaSpecEntityOperatorAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecEntityOperatorAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecEntityOperatorAffinityPodAntiAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        export interface KafkaSpecEntityOperatorAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            podAffinityTerm?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            weight?: number;
        }

        export interface KafkaSpecEntityOperatorAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            labelSelector?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaSpecEntityOperatorAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecEntityOperatorAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecEntityOperatorAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            labelSelector?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaSpecEntityOperatorAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecEntityOperatorAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        /**
         * Template for Entity Operator resources. The template allows users to specify how is the `Deployment` and `Pods` generated.
         */
        export interface KafkaSpecEntityOperatorTemplate {
            /**
             * Template for Entity Operator `Deployment`.
             */
            deployment?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplateDeployment;
            /**
             * Template for Entity Operator `Pods`.
             */
            pod?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplatePod;
            /**
             * Template for the Entity Operator TLS sidecar container.
             */
            tlsSidecarContainer?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplateTlsSidecarContainer;
            /**
             * Template for the Entity Topic Operator container.
             */
            topicOperatorContainer?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplateTopicOperatorContainer;
            /**
             * Template for the Entity User Operator container.
             */
            userOperatorContainer?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplateUserOperatorContainer;
        }

        /**
         * Template for Entity Operator `Deployment`.
         */
        export interface KafkaSpecEntityOperatorTemplateDeployment {
            /**
             * Metadata applied to the resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplateDeploymentMetadata;
        }

        /**
         * Metadata applied to the resource.
         */
        export interface KafkaSpecEntityOperatorTemplateDeploymentMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        /**
         * Template for Entity Operator `Pods`.
         */
        export interface KafkaSpecEntityOperatorTemplatePod {
            /**
             * The pod's affinity rules.
             */
            affinity?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplatePodAffinity;
            /**
             * The pod's HostAliases. HostAliases is an optional list of hosts and IPs that will be injected into the pod's hosts file if specified.
             */
            hostAliases?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplatePodHostAliases[];
            /**
             * List of references to secrets in the same namespace to use for pulling any of the images used by this Pod. When the `STRIMZI_IMAGE_PULL_SECRETS` environment variable in Cluster Operator and the `imagePullSecrets` option are specified, only the `imagePullSecrets` variable is used and the `STRIMZI_IMAGE_PULL_SECRETS` variable is ignored.
             */
            imagePullSecrets?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplatePodImagePullSecrets[];
            /**
             * Metadata applied to the resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplatePodMetadata;
            /**
             * The name of the priority class used to assign priority to the pods. For more information about priority classes, see {K8sPriorityClass}.
             */
            priorityClassName?: string;
            /**
             * The name of the scheduler used to dispatch this `Pod`. If not specified, the default scheduler will be used.
             */
            schedulerName?: string;
            /**
             * Configures pod-level security attributes and common container settings.
             */
            securityContext?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplatePodSecurityContext;
            /**
             * The grace period is the duration in seconds after the processes running in the pod are sent a termination signal, and the time when the processes are forcibly halted with a kill signal. Set this value to longer than the expected cleanup time for your process. Value must be a non-negative integer. A zero value indicates delete immediately. You might need to increase the grace period for very large Kafka clusters, so that the Kafka brokers have enough time to transfer their work to another broker before they are terminated. Defaults to 30 seconds.
             */
            terminationGracePeriodSeconds?: number;
            /**
             * The pod's tolerations.
             */
            tolerations?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplatePodTolerations[];
        }

        /**
         * The pod's affinity rules.
         */
        export interface KafkaSpecEntityOperatorTemplatePodAffinity {
            nodeAffinity?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplatePodAffinityNodeAffinity;
            podAffinity?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplatePodAffinityPodAffinity;
            podAntiAffinity?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplatePodAffinityPodAntiAffinity;
        }

        export interface KafkaSpecEntityOperatorTemplatePodAffinityNodeAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution;
        }

        export interface KafkaSpecEntityOperatorTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            preference?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference;
            weight?: number;
        }

        export interface KafkaSpecEntityOperatorTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions[];
            matchFields?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields[];
        }

        export interface KafkaSpecEntityOperatorTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecEntityOperatorTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecEntityOperatorTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            nodeSelectorTerms?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms[];
        }

        export interface KafkaSpecEntityOperatorTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions[];
            matchFields?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields[];
        }

        export interface KafkaSpecEntityOperatorTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecEntityOperatorTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecEntityOperatorTemplatePodAffinityPodAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        export interface KafkaSpecEntityOperatorTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            podAffinityTerm?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            weight?: number;
        }

        export interface KafkaSpecEntityOperatorTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            labelSelector?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaSpecEntityOperatorTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecEntityOperatorTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecEntityOperatorTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            labelSelector?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaSpecEntityOperatorTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecEntityOperatorTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecEntityOperatorTemplatePodAffinityPodAntiAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        export interface KafkaSpecEntityOperatorTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            podAffinityTerm?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            weight?: number;
        }

        export interface KafkaSpecEntityOperatorTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            labelSelector?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaSpecEntityOperatorTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecEntityOperatorTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecEntityOperatorTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            labelSelector?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaSpecEntityOperatorTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecEntityOperatorTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecEntityOperatorTemplatePodHostAliases {
            hostnames?: string[];
            ip?: string;
        }

        export interface KafkaSpecEntityOperatorTemplatePodImagePullSecrets {
            name?: string;
        }

        /**
         * Metadata applied to the resource.
         */
        export interface KafkaSpecEntityOperatorTemplatePodMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        /**
         * Configures pod-level security attributes and common container settings.
         */
        export interface KafkaSpecEntityOperatorTemplatePodSecurityContext {
            fsGroup?: number;
            fsGroupChangePolicy?: string;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplatePodSecurityContextSeLinuxOptions;
            supplementalGroups?: number[];
            sysctls?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplatePodSecurityContextSysctls[];
            windowsOptions?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplatePodSecurityContextWindowsOptions;
        }

        export interface KafkaSpecEntityOperatorTemplatePodSecurityContextSeLinuxOptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface KafkaSpecEntityOperatorTemplatePodSecurityContextSysctls {
            name?: string;
            value?: string;
        }

        export interface KafkaSpecEntityOperatorTemplatePodSecurityContextWindowsOptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        export interface KafkaSpecEntityOperatorTemplatePodTolerations {
            effect?: string;
            key?: string;
            operator?: string;
            tolerationSeconds?: number;
            value?: string;
        }

        /**
         * Template for the Entity Operator TLS sidecar container.
         */
        export interface KafkaSpecEntityOperatorTemplateTlsSidecarContainer {
            /**
             * Environment variables which should be applied to the container.
             */
            env?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplateTlsSidecarContainerEnv[];
            /**
             * Security context for the container.
             */
            securityContext?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplateTlsSidecarContainerSecurityContext;
        }

        export interface KafkaSpecEntityOperatorTemplateTlsSidecarContainerEnv {
            /**
             * The environment variable key.
             */
            name?: string;
            /**
             * The environment variable value.
             */
            value?: string;
        }

        /**
         * Security context for the container.
         */
        export interface KafkaSpecEntityOperatorTemplateTlsSidecarContainerSecurityContext {
            allowPrivilegeEscalation?: boolean;
            capabilities?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplateTlsSidecarContainerSecurityContextCapabilities;
            privileged?: boolean;
            procMount?: string;
            readOnlyRootFilesystem?: boolean;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplateTlsSidecarContainerSecurityContextSeLinuxOptions;
            windowsOptions?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplateTlsSidecarContainerSecurityContextWindowsOptions;
        }

        export interface KafkaSpecEntityOperatorTemplateTlsSidecarContainerSecurityContextCapabilities {
            add?: string[];
            drop?: string[];
        }

        export interface KafkaSpecEntityOperatorTemplateTlsSidecarContainerSecurityContextSeLinuxOptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface KafkaSpecEntityOperatorTemplateTlsSidecarContainerSecurityContextWindowsOptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        /**
         * Template for the Entity Topic Operator container.
         */
        export interface KafkaSpecEntityOperatorTemplateTopicOperatorContainer {
            /**
             * Environment variables which should be applied to the container.
             */
            env?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplateTopicOperatorContainerEnv[];
            /**
             * Security context for the container.
             */
            securityContext?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplateTopicOperatorContainerSecurityContext;
        }

        export interface KafkaSpecEntityOperatorTemplateTopicOperatorContainerEnv {
            /**
             * The environment variable key.
             */
            name?: string;
            /**
             * The environment variable value.
             */
            value?: string;
        }

        /**
         * Security context for the container.
         */
        export interface KafkaSpecEntityOperatorTemplateTopicOperatorContainerSecurityContext {
            allowPrivilegeEscalation?: boolean;
            capabilities?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplateTopicOperatorContainerSecurityContextCapabilities;
            privileged?: boolean;
            procMount?: string;
            readOnlyRootFilesystem?: boolean;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplateTopicOperatorContainerSecurityContextSeLinuxOptions;
            windowsOptions?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplateTopicOperatorContainerSecurityContextWindowsOptions;
        }

        export interface KafkaSpecEntityOperatorTemplateTopicOperatorContainerSecurityContextCapabilities {
            add?: string[];
            drop?: string[];
        }

        export interface KafkaSpecEntityOperatorTemplateTopicOperatorContainerSecurityContextSeLinuxOptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface KafkaSpecEntityOperatorTemplateTopicOperatorContainerSecurityContextWindowsOptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        /**
         * Template for the Entity User Operator container.
         */
        export interface KafkaSpecEntityOperatorTemplateUserOperatorContainer {
            /**
             * Environment variables which should be applied to the container.
             */
            env?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplateUserOperatorContainerEnv[];
            /**
             * Security context for the container.
             */
            securityContext?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplateUserOperatorContainerSecurityContext;
        }

        export interface KafkaSpecEntityOperatorTemplateUserOperatorContainerEnv {
            /**
             * The environment variable key.
             */
            name?: string;
            /**
             * The environment variable value.
             */
            value?: string;
        }

        /**
         * Security context for the container.
         */
        export interface KafkaSpecEntityOperatorTemplateUserOperatorContainerSecurityContext {
            allowPrivilegeEscalation?: boolean;
            capabilities?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplateUserOperatorContainerSecurityContextCapabilities;
            privileged?: boolean;
            procMount?: string;
            readOnlyRootFilesystem?: boolean;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplateUserOperatorContainerSecurityContextSeLinuxOptions;
            windowsOptions?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplateUserOperatorContainerSecurityContextWindowsOptions;
        }

        export interface KafkaSpecEntityOperatorTemplateUserOperatorContainerSecurityContextCapabilities {
            add?: string[];
            drop?: string[];
        }

        export interface KafkaSpecEntityOperatorTemplateUserOperatorContainerSecurityContextSeLinuxOptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface KafkaSpecEntityOperatorTemplateUserOperatorContainerSecurityContextWindowsOptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        /**
         * TLS sidecar configuration.
         */
        export interface KafkaSpecEntityOperatorTlsSidecar {
            /**
             * The docker image for the container.
             */
            image?: string;
            /**
             * Pod liveness checking.
             */
            livenessProbe?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTlsSidecarLivenessProbe;
            /**
             * The log level for the TLS sidecar. Default value is `notice`.
             */
            logLevel?: string;
            /**
             * Pod readiness checking.
             */
            readinessProbe?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTlsSidecarReadinessProbe;
            /**
             * CPU and memory resources to reserve.
             */
            resources?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTlsSidecarResources;
        }

        /**
         * Pod liveness checking.
         */
        export interface KafkaSpecEntityOperatorTlsSidecarLivenessProbe {
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * The initial delay before first the health is first checked.
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * The timeout for each attempted health check.
             */
            timeoutSeconds?: number;
        }

        /**
         * Pod readiness checking.
         */
        export interface KafkaSpecEntityOperatorTlsSidecarReadinessProbe {
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * The initial delay before first the health is first checked.
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * The timeout for each attempted health check.
             */
            timeoutSeconds?: number;
        }

        /**
         * CPU and memory resources to reserve.
         */
        export interface KafkaSpecEntityOperatorTlsSidecarResources {
            limits?: {[key: string]: any};
            requests?: {[key: string]: any};
        }

        export interface KafkaSpecEntityOperatorTolerations {
            effect?: string;
            key?: string;
            operator?: string;
            tolerationSeconds?: number;
            value?: string;
        }

        /**
         * Configuration of the Topic Operator.
         */
        export interface KafkaSpecEntityOperatorTopicOperator {
            /**
             * The image to use for the Topic Operator.
             */
            image?: string;
            /**
             * JVM Options for pods.
             */
            jvmOptions?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTopicOperatorJvmOptions;
            /**
             * Pod liveness checking.
             */
            livenessProbe?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTopicOperatorLivenessProbe;
            /**
             * Logging configuration.
             */
            logging?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTopicOperatorLogging;
            /**
             * Pod readiness checking.
             */
            readinessProbe?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTopicOperatorReadinessProbe;
            /**
             * Interval between periodic reconciliations.
             */
            reconciliationIntervalSeconds?: number;
            /**
             * CPU and memory resources to reserve.
             */
            resources?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTopicOperatorResources;
            /**
             * The number of attempts at getting topic metadata.
             */
            topicMetadataMaxAttempts?: number;
            /**
             * The namespace the Topic Operator should watch.
             */
            watchedNamespace?: string;
            /**
             * Timeout for the ZooKeeper session.
             */
            zookeeperSessionTimeoutSeconds?: number;
        }

        /**
         * JVM Options for pods.
         */
        export interface KafkaSpecEntityOperatorTopicOperatorJvmOptions {
            /**
             * A map of -XX options to the JVM.
             */
            "-XX"?: {[key: string]: any};
            /**
             * -Xms option to to the JVM.
             */
            "-Xms"?: string;
            /**
             * -Xmx option to to the JVM.
             */
            "-Xmx"?: string;
            /**
             * Specifies whether the Garbage Collection logging is enabled. The default is false.
             */
            gcLoggingEnabled?: boolean;
            /**
             * A map of additional system properties which will be passed using the `-D` option to the JVM.
             */
            javaSystemProperties?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTopicOperatorJvmOptionsJavaSystemProperties[];
        }

        export interface KafkaSpecEntityOperatorTopicOperatorJvmOptionsJavaSystemProperties {
            /**
             * The system property name.
             */
            name?: string;
            /**
             * The system property value.
             */
            value?: string;
        }

        /**
         * Pod liveness checking.
         */
        export interface KafkaSpecEntityOperatorTopicOperatorLivenessProbe {
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * The initial delay before first the health is first checked.
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * The timeout for each attempted health check.
             */
            timeoutSeconds?: number;
        }

        /**
         * Logging configuration.
         */
        export interface KafkaSpecEntityOperatorTopicOperatorLogging {
            /**
             * A Map from logger name to logger level.
             */
            loggers?: {[key: string]: any};
            /**
             * The name of the `ConfigMap` from which to get the logging configuration.
             */
            name?: string;
            /**
             * Logging type, must be either 'inline' or 'external'.
             */
            type: string;
        }

        /**
         * Pod readiness checking.
         */
        export interface KafkaSpecEntityOperatorTopicOperatorReadinessProbe {
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * The initial delay before first the health is first checked.
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * The timeout for each attempted health check.
             */
            timeoutSeconds?: number;
        }

        /**
         * CPU and memory resources to reserve.
         */
        export interface KafkaSpecEntityOperatorTopicOperatorResources {
            limits?: {[key: string]: any};
            requests?: {[key: string]: any};
        }

        /**
         * Configuration of the User Operator.
         */
        export interface KafkaSpecEntityOperatorUserOperator {
            /**
             * The image to use for the User Operator.
             */
            image?: string;
            /**
             * JVM Options for pods.
             */
            jvmOptions?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorUserOperatorJvmOptions;
            /**
             * Pod liveness checking.
             */
            livenessProbe?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorUserOperatorLivenessProbe;
            /**
             * Logging configuration.
             */
            logging?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorUserOperatorLogging;
            /**
             * Pod readiness checking.
             */
            readinessProbe?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorUserOperatorReadinessProbe;
            /**
             * Interval between periodic reconciliations.
             */
            reconciliationIntervalSeconds?: number;
            /**
             * CPU and memory resources to reserve.
             */
            resources?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorUserOperatorResources;
            /**
             * The namespace the User Operator should watch.
             */
            watchedNamespace?: string;
            /**
             * Timeout for the ZooKeeper session.
             */
            zookeeperSessionTimeoutSeconds?: number;
        }

        /**
         * JVM Options for pods.
         */
        export interface KafkaSpecEntityOperatorUserOperatorJvmOptions {
            /**
             * A map of -XX options to the JVM.
             */
            "-XX"?: {[key: string]: any};
            /**
             * -Xms option to to the JVM.
             */
            "-Xms"?: string;
            /**
             * -Xmx option to to the JVM.
             */
            "-Xmx"?: string;
            /**
             * Specifies whether the Garbage Collection logging is enabled. The default is false.
             */
            gcLoggingEnabled?: boolean;
            /**
             * A map of additional system properties which will be passed using the `-D` option to the JVM.
             */
            javaSystemProperties?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorUserOperatorJvmOptionsJavaSystemProperties[];
        }

        export interface KafkaSpecEntityOperatorUserOperatorJvmOptionsJavaSystemProperties {
            /**
             * The system property name.
             */
            name?: string;
            /**
             * The system property value.
             */
            value?: string;
        }

        /**
         * Pod liveness checking.
         */
        export interface KafkaSpecEntityOperatorUserOperatorLivenessProbe {
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * The initial delay before first the health is first checked.
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * The timeout for each attempted health check.
             */
            timeoutSeconds?: number;
        }

        /**
         * Logging configuration.
         */
        export interface KafkaSpecEntityOperatorUserOperatorLogging {
            /**
             * A Map from logger name to logger level.
             */
            loggers?: {[key: string]: any};
            /**
             * The name of the `ConfigMap` from which to get the logging configuration.
             */
            name?: string;
            /**
             * Logging type, must be either 'inline' or 'external'.
             */
            type: string;
        }

        /**
         * Pod readiness checking.
         */
        export interface KafkaSpecEntityOperatorUserOperatorReadinessProbe {
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * The initial delay before first the health is first checked.
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * The timeout for each attempted health check.
             */
            timeoutSeconds?: number;
        }

        /**
         * CPU and memory resources to reserve.
         */
        export interface KafkaSpecEntityOperatorUserOperatorResources {
            limits?: {[key: string]: any};
            requests?: {[key: string]: any};
        }

        /**
         * Configuration for JmxTrans. When the property is present a JmxTrans deployment is created for gathering JMX metrics from each Kafka broker. For more information see https://github.com/jmxtrans/jmxtrans[JmxTrans GitHub].
         */
        export interface KafkaSpecJmxTrans {
            /**
             * The image to use for the JmxTrans.
             */
            image?: string;
            /**
             * Queries to send to the Kafka brokers to define what data should be read from each broker. For more information on these properties see, xref:type-JmxTransQueryTemplate-reference[`JmxTransQueryTemplate` schema reference].
             */
            kafkaQueries: outputs.kafka.v1beta1.KafkaSpecJmxTransKafkaQueries[];
            /**
             * Sets the logging level of the JmxTrans deployment.For more information see, https://github.com/jmxtrans/jmxtrans-agent/wiki/Troubleshooting[JmxTrans Logging Level].
             */
            logLevel?: string;
            /**
             * Defines the output hosts that will be referenced later on. For more information on these properties see, xref:type-JmxTransOutputDefinitionTemplate-reference[`JmxTransOutputDefinitionTemplate` schema reference].
             */
            outputDefinitions: outputs.kafka.v1beta1.KafkaSpecJmxTransOutputDefinitions[];
            /**
             * CPU and memory resources to reserve.
             */
            resources?: outputs.kafka.v1beta1.KafkaSpecJmxTransResources;
            /**
             * Template for JmxTrans resources.
             */
            template?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplate;
        }

        export interface KafkaSpecJmxTransKafkaQueries {
            /**
             * Determine which attributes of the targeted MBean should be included.
             */
            attributes: string[];
            /**
             * List of the names of output definitions specified in the spec.kafka.jmxTrans.outputDefinitions that have defined where JMX metrics are pushed to, and in which data format.
             */
            outputs: string[];
            /**
             * If using wildcards instead of a specific MBean then the data is gathered from multiple MBeans. Otherwise if specifying an MBean then data is gathered from that specified MBean.
             */
            targetMBean: string;
        }

        export interface KafkaSpecJmxTransOutputDefinitions {
            /**
             * How many seconds the JmxTrans waits before pushing a new set of data out.
             */
            flushDelayInSeconds?: number;
            /**
             * The DNS/hostname of the remote host that the data is pushed to.
             */
            host?: string;
            /**
             * Template for setting the name of the output definition. This is used to identify where to send the results of queries should be sent.
             */
            name: string;
            /**
             * Template for setting the format of the data that will be pushed.For more information see https://github.com/jmxtrans/jmxtrans/wiki/OutputWriters[JmxTrans OutputWriters].
             */
            outputType: string;
            /**
             * The port of the remote host that the data is pushed to.
             */
            port?: number;
            /**
             * Template for filtering data to be included in response to a wildcard query. For more information see https://github.com/jmxtrans/jmxtrans/wiki/Queries[JmxTrans queries].
             */
            typeNames?: string[];
        }

        /**
         * CPU and memory resources to reserve.
         */
        export interface KafkaSpecJmxTransResources {
            limits?: {[key: string]: any};
            requests?: {[key: string]: any};
        }

        /**
         * Template for JmxTrans resources.
         */
        export interface KafkaSpecJmxTransTemplate {
            /**
             * Template for JmxTrans container.
             */
            container?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplateContainer;
            /**
             * Template for JmxTrans `Deployment`.
             */
            deployment?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplateDeployment;
            /**
             * Template for JmxTrans `Pods`.
             */
            pod?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplatePod;
        }

        /**
         * Template for JmxTrans container.
         */
        export interface KafkaSpecJmxTransTemplateContainer {
            /**
             * Environment variables which should be applied to the container.
             */
            env?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplateContainerEnv[];
            /**
             * Security context for the container.
             */
            securityContext?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplateContainerSecurityContext;
        }

        export interface KafkaSpecJmxTransTemplateContainerEnv {
            /**
             * The environment variable key.
             */
            name?: string;
            /**
             * The environment variable value.
             */
            value?: string;
        }

        /**
         * Security context for the container.
         */
        export interface KafkaSpecJmxTransTemplateContainerSecurityContext {
            allowPrivilegeEscalation?: boolean;
            capabilities?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplateContainerSecurityContextCapabilities;
            privileged?: boolean;
            procMount?: string;
            readOnlyRootFilesystem?: boolean;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplateContainerSecurityContextSeLinuxOptions;
            windowsOptions?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplateContainerSecurityContextWindowsOptions;
        }

        export interface KafkaSpecJmxTransTemplateContainerSecurityContextCapabilities {
            add?: string[];
            drop?: string[];
        }

        export interface KafkaSpecJmxTransTemplateContainerSecurityContextSeLinuxOptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface KafkaSpecJmxTransTemplateContainerSecurityContextWindowsOptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        /**
         * Template for JmxTrans `Deployment`.
         */
        export interface KafkaSpecJmxTransTemplateDeployment {
            /**
             * Metadata applied to the resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplateDeploymentMetadata;
        }

        /**
         * Metadata applied to the resource.
         */
        export interface KafkaSpecJmxTransTemplateDeploymentMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        /**
         * Template for JmxTrans `Pods`.
         */
        export interface KafkaSpecJmxTransTemplatePod {
            /**
             * The pod's affinity rules.
             */
            affinity?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplatePodAffinity;
            /**
             * The pod's HostAliases. HostAliases is an optional list of hosts and IPs that will be injected into the pod's hosts file if specified.
             */
            hostAliases?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplatePodHostAliases[];
            /**
             * List of references to secrets in the same namespace to use for pulling any of the images used by this Pod. When the `STRIMZI_IMAGE_PULL_SECRETS` environment variable in Cluster Operator and the `imagePullSecrets` option are specified, only the `imagePullSecrets` variable is used and the `STRIMZI_IMAGE_PULL_SECRETS` variable is ignored.
             */
            imagePullSecrets?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplatePodImagePullSecrets[];
            /**
             * Metadata applied to the resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplatePodMetadata;
            /**
             * The name of the priority class used to assign priority to the pods. For more information about priority classes, see {K8sPriorityClass}.
             */
            priorityClassName?: string;
            /**
             * The name of the scheduler used to dispatch this `Pod`. If not specified, the default scheduler will be used.
             */
            schedulerName?: string;
            /**
             * Configures pod-level security attributes and common container settings.
             */
            securityContext?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplatePodSecurityContext;
            /**
             * The grace period is the duration in seconds after the processes running in the pod are sent a termination signal, and the time when the processes are forcibly halted with a kill signal. Set this value to longer than the expected cleanup time for your process. Value must be a non-negative integer. A zero value indicates delete immediately. You might need to increase the grace period for very large Kafka clusters, so that the Kafka brokers have enough time to transfer their work to another broker before they are terminated. Defaults to 30 seconds.
             */
            terminationGracePeriodSeconds?: number;
            /**
             * The pod's tolerations.
             */
            tolerations?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplatePodTolerations[];
        }

        /**
         * The pod's affinity rules.
         */
        export interface KafkaSpecJmxTransTemplatePodAffinity {
            nodeAffinity?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplatePodAffinityNodeAffinity;
            podAffinity?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplatePodAffinityPodAffinity;
            podAntiAffinity?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplatePodAffinityPodAntiAffinity;
        }

        export interface KafkaSpecJmxTransTemplatePodAffinityNodeAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution;
        }

        export interface KafkaSpecJmxTransTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            preference?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference;
            weight?: number;
        }

        export interface KafkaSpecJmxTransTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions[];
            matchFields?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields[];
        }

        export interface KafkaSpecJmxTransTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecJmxTransTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecJmxTransTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            nodeSelectorTerms?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms[];
        }

        export interface KafkaSpecJmxTransTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions[];
            matchFields?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields[];
        }

        export interface KafkaSpecJmxTransTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecJmxTransTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecJmxTransTemplatePodAffinityPodAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        export interface KafkaSpecJmxTransTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            podAffinityTerm?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            weight?: number;
        }

        export interface KafkaSpecJmxTransTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            labelSelector?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaSpecJmxTransTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecJmxTransTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecJmxTransTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            labelSelector?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaSpecJmxTransTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecJmxTransTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecJmxTransTemplatePodAffinityPodAntiAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        export interface KafkaSpecJmxTransTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            podAffinityTerm?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            weight?: number;
        }

        export interface KafkaSpecJmxTransTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            labelSelector?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaSpecJmxTransTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecJmxTransTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecJmxTransTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            labelSelector?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaSpecJmxTransTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecJmxTransTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecJmxTransTemplatePodHostAliases {
            hostnames?: string[];
            ip?: string;
        }

        export interface KafkaSpecJmxTransTemplatePodImagePullSecrets {
            name?: string;
        }

        /**
         * Metadata applied to the resource.
         */
        export interface KafkaSpecJmxTransTemplatePodMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        /**
         * Configures pod-level security attributes and common container settings.
         */
        export interface KafkaSpecJmxTransTemplatePodSecurityContext {
            fsGroup?: number;
            fsGroupChangePolicy?: string;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplatePodSecurityContextSeLinuxOptions;
            supplementalGroups?: number[];
            sysctls?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplatePodSecurityContextSysctls[];
            windowsOptions?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplatePodSecurityContextWindowsOptions;
        }

        export interface KafkaSpecJmxTransTemplatePodSecurityContextSeLinuxOptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface KafkaSpecJmxTransTemplatePodSecurityContextSysctls {
            name?: string;
            value?: string;
        }

        export interface KafkaSpecJmxTransTemplatePodSecurityContextWindowsOptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        export interface KafkaSpecJmxTransTemplatePodTolerations {
            effect?: string;
            key?: string;
            operator?: string;
            tolerationSeconds?: number;
            value?: string;
        }

        /**
         * Configuration of the Kafka cluster.
         */
        export interface KafkaSpecKafka {
            /**
             * The pod's affinity rules.
             */
            affinity?: outputs.kafka.v1beta1.KafkaSpecKafkaAffinity;
            /**
             * Authorization configuration for Kafka brokers.
             */
            authorization?: outputs.kafka.v1beta1.KafkaSpecKafkaAuthorization;
            /**
             * The image of the init container used for initializing the `broker.rack`.
             */
            brokerRackInitImage?: string;
            /**
             * Kafka broker config properties with the following prefixes cannot be set: listeners, advertised., broker., listener., host.name, port, inter.broker.listener.name, sasl., ssl., security., password., principal.builder.class, log.dir, zookeeper.connect, zookeeper.set.acl, zookeeper.ssl, zookeeper.clientCnxnSocket, authorizer., super.user, cruise.control.metrics.topic, cruise.control.metrics.reporter.bootstrap.servers (with the exception of: zookeeper.connection.timeout.ms, ssl.cipher.suites, ssl.protocol, ssl.enabled.protocols,cruise.control.metrics.topic.num.partitions, cruise.control.metrics.topic.replication.factor, cruise.control.metrics.topic.retention.ms,cruise.control.metrics.topic.auto.create.retries, cruise.control.metrics.topic.auto.create.timeout.ms).
             */
            config?: {[key: string]: any};
            /**
             * The docker image for the pods. The default value depends on the configured `Kafka.spec.kafka.version`.
             */
            image?: string;
            /**
             * JMX Options for Kafka brokers.
             */
            jmxOptions?: outputs.kafka.v1beta1.KafkaSpecKafkaJmxOptions;
            /**
             * JVM Options for pods.
             */
            jvmOptions?: outputs.kafka.v1beta1.KafkaSpecKafkaJvmOptions;
            listeners: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf0[] | outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf1;
            /**
             * Pod liveness checking.
             */
            livenessProbe?: outputs.kafka.v1beta1.KafkaSpecKafkaLivenessProbe;
            /**
             * Logging configuration for Kafka.
             */
            logging?: outputs.kafka.v1beta1.KafkaSpecKafkaLogging;
            /**
             * The Prometheus JMX Exporter configuration. See https://github.com/prometheus/jmx_exporter for details of the structure of this configuration.
             */
            metrics?: {[key: string]: any};
            /**
             * Configuration of the `broker.rack` broker config.
             */
            rack?: outputs.kafka.v1beta1.KafkaSpecKafkaRack;
            /**
             * Pod readiness checking.
             */
            readinessProbe?: outputs.kafka.v1beta1.KafkaSpecKafkaReadinessProbe;
            /**
             * The number of pods in the cluster.
             */
            replicas: number;
            /**
             * CPU and memory resources to reserve.
             */
            resources?: outputs.kafka.v1beta1.KafkaSpecKafkaResources;
            /**
             * Storage configuration (disk). Cannot be updated.
             */
            storage: outputs.kafka.v1beta1.KafkaSpecKafkaStorage;
            /**
             * Template for Kafka cluster resources. The template allows users to specify how are the `StatefulSet`, `Pods` and `Services` generated.
             */
            template?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplate;
            /**
             * TLS sidecar configuration.
             */
            tlsSidecar?: outputs.kafka.v1beta1.KafkaSpecKafkaTlsSidecar;
            /**
             * The pod's tolerations.
             */
            tolerations?: outputs.kafka.v1beta1.KafkaSpecKafkaTolerations[];
            /**
             * The kafka broker version. Defaults to {DefaultKafkaVersion}. Consult the user documentation to understand the process required to upgrade or downgrade the version.
             */
            version?: string;
        }

        /**
         * The pod's affinity rules.
         */
        export interface KafkaSpecKafkaAffinity {
            nodeAffinity?: outputs.kafka.v1beta1.KafkaSpecKafkaAffinityNodeAffinity;
            podAffinity?: outputs.kafka.v1beta1.KafkaSpecKafkaAffinityPodAffinity;
            podAntiAffinity?: outputs.kafka.v1beta1.KafkaSpecKafkaAffinityPodAntiAffinity;
        }

        export interface KafkaSpecKafkaAffinityNodeAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecKafkaAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecKafkaAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution;
        }

        export interface KafkaSpecKafkaAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            preference?: outputs.kafka.v1beta1.KafkaSpecKafkaAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference;
            weight?: number;
        }

        export interface KafkaSpecKafkaAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecKafkaAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions[];
            matchFields?: outputs.kafka.v1beta1.KafkaSpecKafkaAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields[];
        }

        export interface KafkaSpecKafkaAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecKafkaAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecKafkaAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            nodeSelectorTerms?: outputs.kafka.v1beta1.KafkaSpecKafkaAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms[];
        }

        export interface KafkaSpecKafkaAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecKafkaAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions[];
            matchFields?: outputs.kafka.v1beta1.KafkaSpecKafkaAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields[];
        }

        export interface KafkaSpecKafkaAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecKafkaAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecKafkaAffinityPodAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecKafkaAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecKafkaAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        export interface KafkaSpecKafkaAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            podAffinityTerm?: outputs.kafka.v1beta1.KafkaSpecKafkaAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            weight?: number;
        }

        export interface KafkaSpecKafkaAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            labelSelector?: outputs.kafka.v1beta1.KafkaSpecKafkaAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaSpecKafkaAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecKafkaAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecKafkaAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecKafkaAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            labelSelector?: outputs.kafka.v1beta1.KafkaSpecKafkaAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaSpecKafkaAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecKafkaAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecKafkaAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecKafkaAffinityPodAntiAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecKafkaAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecKafkaAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        export interface KafkaSpecKafkaAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            podAffinityTerm?: outputs.kafka.v1beta1.KafkaSpecKafkaAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            weight?: number;
        }

        export interface KafkaSpecKafkaAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            labelSelector?: outputs.kafka.v1beta1.KafkaSpecKafkaAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaSpecKafkaAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecKafkaAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecKafkaAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecKafkaAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            labelSelector?: outputs.kafka.v1beta1.KafkaSpecKafkaAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaSpecKafkaAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecKafkaAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecKafkaAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        /**
         * Authorization configuration for Kafka brokers.
         */
        export interface KafkaSpecKafkaAuthorization {
            /**
             * Defines whether a Kafka client should be allowed or denied by default when the authorizer fails to query the Open Policy Agent, for example, when it is temporarily unavailable). Defaults to `false` - all actions will be denied.
             */
            allowOnError?: boolean;
            /**
             * OAuth Client ID which the Kafka client can use to authenticate against the OAuth server and use the token endpoint URI.
             */
            clientId?: string;
            /**
             * Whether authorization decision should be delegated to the 'Simple' authorizer if DENIED by Keycloak Authorization Services policies. Default value is `false`.
             */
            delegateToKafkaAcls?: boolean;
            /**
             * Enable or disable TLS hostname verification. Default value is `false`.
             */
            disableTlsHostnameVerification?: boolean;
            /**
             * The expiration of the records kept in the local cache to avoid querying the Open Policy Agent for every request. Defines how often the cached authorization decisions are reloaded from the Open Policy Agent server. In milliseconds. Defaults to `3600000`.
             */
            expireAfterMs?: number;
            /**
             * The time between two consecutive grants refresh runs in seconds. The default value is 60.
             */
            grantsRefreshPeriodSeconds?: number;
            /**
             * The number of threads to use to refresh grants for active sessions. The more threads, the more parallelism, so the sooner the job completes. However, using more threads places a heavier load on the authorization server. The default value is 5.
             */
            grantsRefreshPoolSize?: number;
            /**
             * Initial capacity of the local cache used by the authorizer to avoid querying the Open Policy Agent for every request Defaults to `5000`.
             */
            initialCacheCapacity?: number;
            /**
             * Maximum capacity of the local cache used by the authorizer to avoid querying the Open Policy Agent for every request. Defaults to `50000`.
             */
            maximumCacheSize?: number;
            /**
             * List of super users. Should contain list of user principals which should get unlimited access rights.
             */
            superUsers?: string[];
            /**
             * Trusted certificates for TLS connection to the OAuth server.
             */
            tlsTrustedCertificates?: outputs.kafka.v1beta1.KafkaSpecKafkaAuthorizationTlsTrustedCertificates[];
            /**
             * Authorization server token endpoint URI.
             */
            tokenEndpointUri?: string;
            /**
             * Authorization type. Currently, the supported types are `simple`, `keycloak`, and `opa`. `simple` authorization type uses Kafka's `kafka.security.authorizer.AclAuthorizer` class for authorization. `keycloak` authorization type uses Keycloak Authorization Services for authorization. `opa` authorization type uses Open Policy Agent based authorization.
             */
            type: string;
            /**
             * The URL used to connect to the Open Policy Agent server. The URL has to include the policy which will be queried by the authorizer. This option is required.
             */
            url?: string;
        }

        export interface KafkaSpecKafkaAuthorizationTlsTrustedCertificates {
            /**
             * The name of the file certificate in the Secret.
             */
            certificate: string;
            /**
             * The name of the Secret containing the certificate.
             */
            secretName: string;
        }

        /**
         * Configuration of the Kafka Exporter. Kafka Exporter can provide additional metrics, for example lag of consumer group at topic/partition.
         */
        export interface KafkaSpecKafkaExporter {
            /**
             * Enable Sarama logging, a Go client library used by the Kafka Exporter.
             */
            enableSaramaLogging?: boolean;
            /**
             * Regular expression to specify which consumer groups to collect. Default value is `.*`.
             */
            groupRegex?: string;
            /**
             * The docker image for the pods.
             */
            image?: string;
            /**
             * Pod liveness check.
             */
            livenessProbe?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterLivenessProbe;
            /**
             * Only log messages with the given severity or above. Valid levels: [`debug`, `info`, `warn`, `error`, `fatal`]. Default log level is `info`.
             */
            logging?: string;
            /**
             * Pod readiness check.
             */
            readinessProbe?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterReadinessProbe;
            /**
             * CPU and memory resources to reserve.
             */
            resources?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterResources;
            /**
             * Customization of deployment templates and pods.
             */
            template?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplate;
            /**
             * Regular expression to specify which topics to collect. Default value is `.*`.
             */
            topicRegex?: string;
        }

        /**
         * Pod liveness check.
         */
        export interface KafkaSpecKafkaExporterLivenessProbe {
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * The initial delay before first the health is first checked.
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * The timeout for each attempted health check.
             */
            timeoutSeconds?: number;
        }

        /**
         * Pod readiness check.
         */
        export interface KafkaSpecKafkaExporterReadinessProbe {
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * The initial delay before first the health is first checked.
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * The timeout for each attempted health check.
             */
            timeoutSeconds?: number;
        }

        /**
         * CPU and memory resources to reserve.
         */
        export interface KafkaSpecKafkaExporterResources {
            limits?: {[key: string]: any};
            requests?: {[key: string]: any};
        }

        /**
         * Customization of deployment templates and pods.
         */
        export interface KafkaSpecKafkaExporterTemplate {
            /**
             * Template for the Kafka Exporter container.
             */
            container?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplateContainer;
            /**
             * Template for Kafka Exporter `Deployment`.
             */
            deployment?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplateDeployment;
            /**
             * Template for Kafka Exporter `Pods`.
             */
            pod?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplatePod;
            /**
             * Template for Kafka Exporter `Service`.
             */
            service?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplateService;
        }

        /**
         * Template for the Kafka Exporter container.
         */
        export interface KafkaSpecKafkaExporterTemplateContainer {
            /**
             * Environment variables which should be applied to the container.
             */
            env?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplateContainerEnv[];
            /**
             * Security context for the container.
             */
            securityContext?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplateContainerSecurityContext;
        }

        export interface KafkaSpecKafkaExporterTemplateContainerEnv {
            /**
             * The environment variable key.
             */
            name?: string;
            /**
             * The environment variable value.
             */
            value?: string;
        }

        /**
         * Security context for the container.
         */
        export interface KafkaSpecKafkaExporterTemplateContainerSecurityContext {
            allowPrivilegeEscalation?: boolean;
            capabilities?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplateContainerSecurityContextCapabilities;
            privileged?: boolean;
            procMount?: string;
            readOnlyRootFilesystem?: boolean;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplateContainerSecurityContextSeLinuxOptions;
            windowsOptions?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplateContainerSecurityContextWindowsOptions;
        }

        export interface KafkaSpecKafkaExporterTemplateContainerSecurityContextCapabilities {
            add?: string[];
            drop?: string[];
        }

        export interface KafkaSpecKafkaExporterTemplateContainerSecurityContextSeLinuxOptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface KafkaSpecKafkaExporterTemplateContainerSecurityContextWindowsOptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        /**
         * Template for Kafka Exporter `Deployment`.
         */
        export interface KafkaSpecKafkaExporterTemplateDeployment {
            /**
             * Metadata applied to the resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplateDeploymentMetadata;
        }

        /**
         * Metadata applied to the resource.
         */
        export interface KafkaSpecKafkaExporterTemplateDeploymentMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        /**
         * Template for Kafka Exporter `Pods`.
         */
        export interface KafkaSpecKafkaExporterTemplatePod {
            /**
             * The pod's affinity rules.
             */
            affinity?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplatePodAffinity;
            /**
             * The pod's HostAliases. HostAliases is an optional list of hosts and IPs that will be injected into the pod's hosts file if specified.
             */
            hostAliases?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplatePodHostAliases[];
            /**
             * List of references to secrets in the same namespace to use for pulling any of the images used by this Pod. When the `STRIMZI_IMAGE_PULL_SECRETS` environment variable in Cluster Operator and the `imagePullSecrets` option are specified, only the `imagePullSecrets` variable is used and the `STRIMZI_IMAGE_PULL_SECRETS` variable is ignored.
             */
            imagePullSecrets?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplatePodImagePullSecrets[];
            /**
             * Metadata applied to the resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplatePodMetadata;
            /**
             * The name of the priority class used to assign priority to the pods. For more information about priority classes, see {K8sPriorityClass}.
             */
            priorityClassName?: string;
            /**
             * The name of the scheduler used to dispatch this `Pod`. If not specified, the default scheduler will be used.
             */
            schedulerName?: string;
            /**
             * Configures pod-level security attributes and common container settings.
             */
            securityContext?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplatePodSecurityContext;
            /**
             * The grace period is the duration in seconds after the processes running in the pod are sent a termination signal, and the time when the processes are forcibly halted with a kill signal. Set this value to longer than the expected cleanup time for your process. Value must be a non-negative integer. A zero value indicates delete immediately. You might need to increase the grace period for very large Kafka clusters, so that the Kafka brokers have enough time to transfer their work to another broker before they are terminated. Defaults to 30 seconds.
             */
            terminationGracePeriodSeconds?: number;
            /**
             * The pod's tolerations.
             */
            tolerations?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplatePodTolerations[];
        }

        /**
         * The pod's affinity rules.
         */
        export interface KafkaSpecKafkaExporterTemplatePodAffinity {
            nodeAffinity?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplatePodAffinityNodeAffinity;
            podAffinity?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplatePodAffinityPodAffinity;
            podAntiAffinity?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplatePodAffinityPodAntiAffinity;
        }

        export interface KafkaSpecKafkaExporterTemplatePodAffinityNodeAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution;
        }

        export interface KafkaSpecKafkaExporterTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            preference?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference;
            weight?: number;
        }

        export interface KafkaSpecKafkaExporterTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions[];
            matchFields?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields[];
        }

        export interface KafkaSpecKafkaExporterTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecKafkaExporterTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecKafkaExporterTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            nodeSelectorTerms?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms[];
        }

        export interface KafkaSpecKafkaExporterTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions[];
            matchFields?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields[];
        }

        export interface KafkaSpecKafkaExporterTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecKafkaExporterTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecKafkaExporterTemplatePodAffinityPodAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        export interface KafkaSpecKafkaExporterTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            podAffinityTerm?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            weight?: number;
        }

        export interface KafkaSpecKafkaExporterTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            labelSelector?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaSpecKafkaExporterTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecKafkaExporterTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecKafkaExporterTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            labelSelector?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaSpecKafkaExporterTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecKafkaExporterTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecKafkaExporterTemplatePodAffinityPodAntiAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        export interface KafkaSpecKafkaExporterTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            podAffinityTerm?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            weight?: number;
        }

        export interface KafkaSpecKafkaExporterTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            labelSelector?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaSpecKafkaExporterTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecKafkaExporterTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecKafkaExporterTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            labelSelector?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaSpecKafkaExporterTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecKafkaExporterTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecKafkaExporterTemplatePodHostAliases {
            hostnames?: string[];
            ip?: string;
        }

        export interface KafkaSpecKafkaExporterTemplatePodImagePullSecrets {
            name?: string;
        }

        /**
         * Metadata applied to the resource.
         */
        export interface KafkaSpecKafkaExporterTemplatePodMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        /**
         * Configures pod-level security attributes and common container settings.
         */
        export interface KafkaSpecKafkaExporterTemplatePodSecurityContext {
            fsGroup?: number;
            fsGroupChangePolicy?: string;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplatePodSecurityContextSeLinuxOptions;
            supplementalGroups?: number[];
            sysctls?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplatePodSecurityContextSysctls[];
            windowsOptions?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplatePodSecurityContextWindowsOptions;
        }

        export interface KafkaSpecKafkaExporterTemplatePodSecurityContextSeLinuxOptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface KafkaSpecKafkaExporterTemplatePodSecurityContextSysctls {
            name?: string;
            value?: string;
        }

        export interface KafkaSpecKafkaExporterTemplatePodSecurityContextWindowsOptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        export interface KafkaSpecKafkaExporterTemplatePodTolerations {
            effect?: string;
            key?: string;
            operator?: string;
            tolerationSeconds?: number;
            value?: string;
        }

        /**
         * Template for Kafka Exporter `Service`.
         */
        export interface KafkaSpecKafkaExporterTemplateService {
            /**
             * Metadata applied to the resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplateServiceMetadata;
        }

        /**
         * Metadata applied to the resource.
         */
        export interface KafkaSpecKafkaExporterTemplateServiceMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        /**
         * JMX Options for Kafka brokers.
         */
        export interface KafkaSpecKafkaJmxOptions {
            /**
             * Authentication configuration for connecting to the Kafka JMX port.
             */
            authentication?: outputs.kafka.v1beta1.KafkaSpecKafkaJmxOptionsAuthentication;
        }

        /**
         * Authentication configuration for connecting to the Kafka JMX port.
         */
        export interface KafkaSpecKafkaJmxOptionsAuthentication {
            /**
             * Authentication type. Currently the only supported types are `password`.`password` type creates a username and protected port with no TLS.
             */
            type: string;
        }

        /**
         * JVM Options for pods.
         */
        export interface KafkaSpecKafkaJvmOptions {
            /**
             * A map of -XX options to the JVM.
             */
            "-XX"?: {[key: string]: any};
            /**
             * -Xms option to to the JVM.
             */
            "-Xms"?: string;
            /**
             * -Xmx option to to the JVM.
             */
            "-Xmx"?: string;
            /**
             * Specifies whether the Garbage Collection logging is enabled. The default is false.
             */
            gcLoggingEnabled?: boolean;
            /**
             * A map of additional system properties which will be passed using the `-D` option to the JVM.
             */
            javaSystemProperties?: outputs.kafka.v1beta1.KafkaSpecKafkaJvmOptionsJavaSystemProperties[];
        }

        export interface KafkaSpecKafkaJvmOptionsJavaSystemProperties {
            /**
             * The system property name.
             */
            name?: string;
            /**
             * The system property value.
             */
            value?: string;
        }

        export interface KafkaSpecKafkaListenersOneOf0 {
            /**
             * Authentication configuration for this listener.
             */
            authentication?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf0Authentication;
            /**
             * Additional listener configuration.
             */
            configuration?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf0Configuration;
            /**
             * Name of the listener. The name will be used to identify the listener and the related Kubernetes objects. The name has to be unique within given a Kafka cluster. The name can consist of lowercase characters and numbers and be up to 11 characters long.
             */
            name: string;
            /**
             * List of peers which should be able to connect to this listener. Peers in this list are combined using a logical OR operation. If this field is empty or missing, all connections will be allowed for this listener. If this field is present and contains at least one item, the listener only allows the traffic which matches at least one item in this list.
             */
            networkPolicyPeers?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf0NetworkPolicyPeers[];
            /**
             * Port number used by the listener inside Kafka. The port number has to be unique within a given Kafka cluster. Allowed port numbers are 9092 and higher with the exception of ports 9404 and 9999, which are already used for Prometheus and JMX. Depending on the listener type, the port number might not be the same as the port number that connects Kafka clients.
             */
            port: number;
            /**
             * Enables TLS encryption on the listener. This is a required property.
             */
            tls: boolean;
            /**
             * Type of the listener. Currently the supported types are `internal`, `route`, `loadbalancer`, `nodeport` and `ingress`. 
             *
             * * `internal` type exposes Kafka internally only within the Kubernetes cluster.
             * * `route` type uses OpenShift Routes to expose Kafka.
             * * `loadbalancer` type uses LoadBalancer type services to expose Kafka.
             * * `nodeport` type uses NodePort type services to expose Kafka.
             * * `ingress` type uses Kubernetes Nginx Ingress to expose Kafka.
             * .
             */
            type: string;
        }

        /**
         * Authentication configuration for this listener.
         */
        export interface KafkaSpecKafkaListenersOneOf0Authentication {
            /**
             * Configure whether the access token is treated as JWT. This must be set to `false` if the authorization server returns opaque tokens. Defaults to `true`.
             */
            accessTokenIsJwt?: boolean;
            /**
             * Configure whether the access token type check is performed or not. This should be set to `false` if the authorization server does not include 'typ' claim in JWT token. Defaults to `true`.
             */
            checkAccessTokenType?: boolean;
            /**
             * Enable or disable issuer checking. By default issuer is checked using the value configured by `validIssuerUri`. Default value is `true`.
             */
            checkIssuer?: boolean;
            /**
             * OAuth Client ID which the Kafka broker can use to authenticate against the authorization server and use the introspect endpoint URI.
             */
            clientId?: string;
            /**
             * Link to Kubernetes Secret containing the OAuth client secret which the Kafka broker can use to authenticate against the authorization server and use the introspect endpoint URI.
             */
            clientSecret?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf0AuthenticationClientSecret;
            /**
             * Enable or disable TLS hostname verification. Default value is `false`.
             */
            disableTlsHostnameVerification?: boolean;
            /**
             * Enable or disable ECDSA support by installing BouncyCastle crypto provider. Default value is `false`.
             */
            enableECDSA?: boolean;
            /**
             * The fallback username claim to be used for the user id if the claim specified by `userNameClaim` is not present. This is useful when `client_credentials` authentication only results in the client id being provided in another claim. It only takes effect if `userNameClaim` is set.
             */
            fallbackUserNameClaim?: string;
            /**
             * The prefix to use with the value of `fallbackUserNameClaim` to construct the user id. This only takes effect if `fallbackUserNameClaim` is true, and the value is present for the claim. Mapping usernames and client ids into the same user id space is useful in preventing name collisions.
             */
            fallbackUserNamePrefix?: string;
            /**
             * URI of the token introspection endpoint which can be used to validate opaque non-JWT tokens.
             */
            introspectionEndpointUri?: string;
            /**
             * URI of the JWKS certificate endpoint, which can be used for local JWT validation.
             */
            jwksEndpointUri?: string;
            /**
             * Configures how often are the JWKS certificates considered valid. The expiry interval has to be at least 60 seconds longer then the refresh interval specified in `jwksRefreshSeconds`. Defaults to 360 seconds.
             */
            jwksExpirySeconds?: number;
            /**
             * The minimum pause between two consecutive refreshes. When an unknown signing key is encountered the refresh is scheduled immediately, but will always wait for this minimum pause. Defaults to 1 second.
             */
            jwksMinRefreshPauseSeconds?: number;
            /**
             * Configures how often are the JWKS certificates refreshed. The refresh interval has to be at least 60 seconds shorter then the expiry interval specified in `jwksExpirySeconds`. Defaults to 300 seconds.
             */
            jwksRefreshSeconds?: number;
            /**
             * Maximum number of seconds the authenticated session remains valid without re-authentication. This enables Apache Kafka re-authentication feature, and causes sessions to expire when the access token expires. If the access token expires before max time or if max time is reached, the client has to re-authenticate, otherwise the server will drop the connection. Not set by default - the authenticated session does not expire when the access token expires.
             */
            maxSecondsWithoutReauthentication?: number;
            /**
             * Trusted certificates for TLS connection to the OAuth server.
             */
            tlsTrustedCertificates?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf0AuthenticationTlsTrustedCertificates[];
            /**
             * Authentication type. `oauth` type uses SASL OAUTHBEARER Authentication. `scram-sha-512` type uses SASL SCRAM-SHA-512 Authentication. `tls` type uses TLS Client Authentication. `tls` type is supported only on TLS listeners.
             */
            type: string;
            /**
             * URI of the User Info Endpoint to use as a fallback to obtaining the user id when the Introspection Endpoint does not return information that can be used for the user id. 
             */
            userInfoEndpointUri?: string;
            /**
             * Name of the claim from the JWT authentication token, Introspection Endpoint response or User Info Endpoint response which will be used to extract the user id. Defaults to `sub`.
             */
            userNameClaim?: string;
            /**
             * URI of the token issuer used for authentication.
             */
            validIssuerUri?: string;
            /**
             * Valid value for the `token_type` attribute returned by the Introspection Endpoint. No default value, and not checked by default.
             */
            validTokenType?: string;
        }

        /**
         * Link to Kubernetes Secret containing the OAuth client secret which the Kafka broker can use to authenticate against the authorization server and use the introspect endpoint URI.
         */
        export interface KafkaSpecKafkaListenersOneOf0AuthenticationClientSecret {
            /**
             * The key under which the secret value is stored in the Kubernetes Secret.
             */
            key: string;
            /**
             * The name of the Kubernetes Secret containing the secret value.
             */
            secretName: string;
        }

        export interface KafkaSpecKafkaListenersOneOf0AuthenticationTlsTrustedCertificates {
            /**
             * The name of the file certificate in the Secret.
             */
            certificate: string;
            /**
             * The name of the Secret containing the certificate.
             */
            secretName: string;
        }

        /**
         * Additional listener configuration.
         */
        export interface KafkaSpecKafkaListenersOneOf0Configuration {
            /**
             * Bootstrap configuration.
             */
            bootstrap?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf0ConfigurationBootstrap;
            /**
             * Reference to the `Secret` which holds the certificate and private key pair which will be used for this listener. The certificate can optionally contain the whole chain. This field can be used only with listeners with enabled TLS encryption.
             */
            brokerCertChainAndKey?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf0ConfigurationBrokerCertChainAndKey;
            /**
             * Per-broker configurations.
             */
            brokers?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf0ConfigurationBrokers[];
            /**
             * Configures the `Ingress` class that defines which `Ingress` controller will be used. If not set, the `Ingress` class is set to `nginx`. This field can be used only with `ingress` type listener.
             */
            class?: string;
            /**
             * Specifies whether the service routes external traffic to node-local or cluster-wide endpoints. `Cluster` may cause a second hop to another node and obscures the client source IP. `Local` avoids a second hop for LoadBalancer and Nodeport type services and preserves the client source IP (when supported by the infrastructure). If unspecified, Kubernetes will use `Cluster` as the default.This field can be used only with `loadbalancer` or `nodeport` type listener.
             */
            externalTrafficPolicy?: string;
            /**
             * A list of CIDR ranges (for example `10.0.0.0/8` or `130.211.204.1/32`) from which clients can connect to load balancer type listeners. If supported by the platform, traffic through the loadbalancer is restricted to the specified CIDR ranges. This field is applicable only for loadbalancer type services and is ignored if the cloud provider does not support the feature. For more information, see https://v1-17.docs.kubernetes.io/docs/tasks/access-application-cluster/configure-cloud-provider-firewall/. This field can be used only with `loadbalancer` type listener.
             */
            loadBalancerSourceRanges?: string[];
            /**
             * Defines which address type should be used as the node address. Available types are: `ExternalDNS`, `ExternalIP`, `InternalDNS`, `InternalIP` and `Hostname`. By default, the addresses will be used in the following order (the first one found will be used):
             * * `ExternalDNS`
             * * `ExternalIP`
             * * `InternalDNS`
             * * `InternalIP`
             * * `Hostname`
             *
             * This field can be used to select the address type which will be used as the preferred type and checked first. In case no address will be found for this address type, the other types will be used in the default order.This field can be used only with `nodeport` type listener..
             */
            preferredNodePortAddressType?: string;
            /**
             * Configures whether the Kubernetes service DNS domain should be used or not. If set to `true`, the generated addresses with contain the service DNS domain suffix (by default `.cluster.local`, can be configured using environment variable `KUBERNETES_SERVICE_DNS_DOMAIN`). Defaults to `false`.This field can be used only with `internal` type listener.
             */
            useServiceDnsDomain?: boolean;
        }

        /**
         * Bootstrap configuration.
         */
        export interface KafkaSpecKafkaListenersOneOf0ConfigurationBootstrap {
            /**
             * Additional alternative names for the bootstrap service. The alternative names will be added to the list of subject alternative names of the TLS certificates.
             */
            alternativeNames?: string[];
            /**
             * Annotations that will be added to the `Ingress` or `Service` resource. You can use this field to configure DNS providers such as External DNS. This field can be used only with `loadbalancer`, `nodeport`, or `ingress` type listeners.
             */
            annotations?: {[key: string]: any};
            /**
             * The bootstrap host. This field will be used in the Ingress resource or in the Route resource to specify the desired hostname. This field can be used only with `route` (optional) or `ingress` (required) type listeners.
             */
            host?: string;
            /**
             * The loadbalancer is requested with the IP address specified in this field. This feature depends on whether the underlying cloud provider supports specifying the `loadBalancerIP` when a load balancer is created. This field is ignored if the cloud provider does not support the feature.This field can be used only with `loadbalancer` type listener.
             */
            loadBalancerIP?: string;
            /**
             * Node port for the bootstrap service. This field can be used only with `nodeport` type listener.
             */
            nodePort?: number;
        }

        /**
         * Reference to the `Secret` which holds the certificate and private key pair which will be used for this listener. The certificate can optionally contain the whole chain. This field can be used only with listeners with enabled TLS encryption.
         */
        export interface KafkaSpecKafkaListenersOneOf0ConfigurationBrokerCertChainAndKey {
            /**
             * The name of the file certificate in the Secret.
             */
            certificate: string;
            /**
             * The name of the private key in the Secret.
             */
            key: string;
            /**
             * The name of the Secret containing the certificate.
             */
            secretName: string;
        }

        export interface KafkaSpecKafkaListenersOneOf0ConfigurationBrokers {
            /**
             * The host name which will be used in the brokers' `advertised.brokers`.
             */
            advertisedHost?: string;
            /**
             * The port number which will be used in the brokers' `advertised.brokers`.
             */
            advertisedPort?: number;
            /**
             * Annotations that will be added to the `Ingress` or `Service` resource. You can use this field to configure DNS providers such as External DNS. This field can be used only with `loadbalancer`, `nodeport`, or `ingress` type listeners.
             */
            annotations?: {[key: string]: any};
            /**
             * ID of the kafka broker (broker identifier). Broker IDs start from 0 and correspond to the number of broker replicas.
             */
            broker: number;
            /**
             * The broker host. This field will be used in the Ingress resource or in the Route resource to specify the desired hostname. This field can be used only with `route` (optional) or `ingress` (required) type listeners.
             */
            host?: string;
            /**
             * The loadbalancer is requested with the IP address specified in this field. This feature depends on whether the underlying cloud provider supports specifying the `loadBalancerIP` when a load balancer is created. This field is ignored if the cloud provider does not support the feature.This field can be used only with `loadbalancer` type listener.
             */
            loadBalancerIP?: string;
            /**
             * Node port for the per-broker service. This field can be used only with `nodeport` type listener.
             */
            nodePort?: number;
        }

        export interface KafkaSpecKafkaListenersOneOf0NetworkPolicyPeers {
            ipBlock?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf0NetworkPolicyPeersIpBlock;
            namespaceSelector?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf0NetworkPolicyPeersNamespaceSelector;
            podSelector?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf0NetworkPolicyPeersPodSelector;
        }

        export interface KafkaSpecKafkaListenersOneOf0NetworkPolicyPeersIpBlock {
            cidr?: string;
            except?: string[];
        }

        export interface KafkaSpecKafkaListenersOneOf0NetworkPolicyPeersNamespaceSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf0NetworkPolicyPeersNamespaceSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecKafkaListenersOneOf0NetworkPolicyPeersNamespaceSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecKafkaListenersOneOf0NetworkPolicyPeersPodSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf0NetworkPolicyPeersPodSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecKafkaListenersOneOf0NetworkPolicyPeersPodSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecKafkaListenersOneOf1 {
            /**
             * Configures external listener on port 9094.
             */
            external?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf1External;
            /**
             * Configures plain listener on port 9092.
             */
            plain?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf1Plain;
            /**
             * Configures TLS listener on port 9093.
             */
            tls?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf1Tls;
        }

        /**
         * Configures external listener on port 9094.
         */
        export interface KafkaSpecKafkaListenersOneOf1External {
            /**
             * Authentication configuration for Kafka brokers.
             */
            authentication?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf1ExternalAuthentication;
            /**
             * Configures the `Ingress` class that defines which `Ingress` controller will be used. If not set, the `Ingress` class is set to `nginx`.
             */
            class?: string;
            /**
             * External listener configuration.
             */
            configuration?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf1ExternalConfiguration;
            /**
             * List of peers which should be able to connect to this listener. Peers in this list are combined using a logical OR operation. If this field is empty or missing, all connections will be allowed for this listener. If this field is present and contains at least one item, the listener only allows the traffic which matches at least one item in this list.
             */
            networkPolicyPeers?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf1ExternalNetworkPolicyPeers[];
            /**
             * Overrides for external bootstrap and broker services and externally advertised addresses.
             */
            overrides?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf1ExternalOverrides;
            /**
             * Enables TLS encryption on the listener. By default set to `true` for enabled TLS encryption.
             */
            tls?: boolean;
            /**
             * Type of the external listener. Currently the supported types are `route`, `loadbalancer`, and `nodeport`. 
             *
             * * `route` type uses OpenShift Routes to expose Kafka.* `loadbalancer` type uses LoadBalancer type services to expose Kafka.* `nodeport` type uses NodePort type services to expose Kafka..
             */
            type: string;
        }

        /**
         * Authentication configuration for Kafka brokers.
         */
        export interface KafkaSpecKafkaListenersOneOf1ExternalAuthentication {
            /**
             * Configure whether the access token is treated as JWT. This must be set to `false` if the authorization server returns opaque tokens. Defaults to `true`.
             */
            accessTokenIsJwt?: boolean;
            /**
             * Configure whether the access token type check is performed or not. This should be set to `false` if the authorization server does not include 'typ' claim in JWT token. Defaults to `true`.
             */
            checkAccessTokenType?: boolean;
            /**
             * Enable or disable issuer checking. By default issuer is checked using the value configured by `validIssuerUri`. Default value is `true`.
             */
            checkIssuer?: boolean;
            /**
             * OAuth Client ID which the Kafka broker can use to authenticate against the authorization server and use the introspect endpoint URI.
             */
            clientId?: string;
            /**
             * Link to Kubernetes Secret containing the OAuth client secret which the Kafka broker can use to authenticate against the authorization server and use the introspect endpoint URI.
             */
            clientSecret?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf1ExternalAuthenticationClientSecret;
            /**
             * Enable or disable TLS hostname verification. Default value is `false`.
             */
            disableTlsHostnameVerification?: boolean;
            /**
             * Enable or disable ECDSA support by installing BouncyCastle crypto provider. Default value is `false`.
             */
            enableECDSA?: boolean;
            /**
             * The fallback username claim to be used for the user id if the claim specified by `userNameClaim` is not present. This is useful when `client_credentials` authentication only results in the client id being provided in another claim. It only takes effect if `userNameClaim` is set.
             */
            fallbackUserNameClaim?: string;
            /**
             * The prefix to use with the value of `fallbackUserNameClaim` to construct the user id. This only takes effect if `fallbackUserNameClaim` is true, and the value is present for the claim. Mapping usernames and client ids into the same user id space is useful in preventing name collisions.
             */
            fallbackUserNamePrefix?: string;
            /**
             * URI of the token introspection endpoint which can be used to validate opaque non-JWT tokens.
             */
            introspectionEndpointUri?: string;
            /**
             * URI of the JWKS certificate endpoint, which can be used for local JWT validation.
             */
            jwksEndpointUri?: string;
            /**
             * Configures how often are the JWKS certificates considered valid. The expiry interval has to be at least 60 seconds longer then the refresh interval specified in `jwksRefreshSeconds`. Defaults to 360 seconds.
             */
            jwksExpirySeconds?: number;
            /**
             * The minimum pause between two consecutive refreshes. When an unknown signing key is encountered the refresh is scheduled immediately, but will always wait for this minimum pause. Defaults to 1 second.
             */
            jwksMinRefreshPauseSeconds?: number;
            /**
             * Configures how often are the JWKS certificates refreshed. The refresh interval has to be at least 60 seconds shorter then the expiry interval specified in `jwksExpirySeconds`. Defaults to 300 seconds.
             */
            jwksRefreshSeconds?: number;
            /**
             * Maximum number of seconds the authenticated session remains valid without re-authentication. This enables Apache Kafka re-authentication feature, and causes sessions to expire when the access token expires. If the access token expires before max time or if max time is reached, the client has to re-authenticate, otherwise the server will drop the connection. Not set by default - the authenticated session does not expire when the access token expires.
             */
            maxSecondsWithoutReauthentication?: number;
            /**
             * Trusted certificates for TLS connection to the OAuth server.
             */
            tlsTrustedCertificates?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf1ExternalAuthenticationTlsTrustedCertificates[];
            /**
             * Authentication type. `oauth` type uses SASL OAUTHBEARER Authentication. `scram-sha-512` type uses SASL SCRAM-SHA-512 Authentication. `tls` type uses TLS Client Authentication. `tls` type is supported only on TLS listeners.
             */
            type: string;
            /**
             * URI of the User Info Endpoint to use as a fallback to obtaining the user id when the Introspection Endpoint does not return information that can be used for the user id. 
             */
            userInfoEndpointUri?: string;
            /**
             * Name of the claim from the JWT authentication token, Introspection Endpoint response or User Info Endpoint response which will be used to extract the user id. Defaults to `sub`.
             */
            userNameClaim?: string;
            /**
             * URI of the token issuer used for authentication.
             */
            validIssuerUri?: string;
            /**
             * Valid value for the `token_type` attribute returned by the Introspection Endpoint. No default value, and not checked by default.
             */
            validTokenType?: string;
        }

        /**
         * Link to Kubernetes Secret containing the OAuth client secret which the Kafka broker can use to authenticate against the authorization server and use the introspect endpoint URI.
         */
        export interface KafkaSpecKafkaListenersOneOf1ExternalAuthenticationClientSecret {
            /**
             * The key under which the secret value is stored in the Kubernetes Secret.
             */
            key: string;
            /**
             * The name of the Kubernetes Secret containing the secret value.
             */
            secretName: string;
        }

        export interface KafkaSpecKafkaListenersOneOf1ExternalAuthenticationTlsTrustedCertificates {
            /**
             * The name of the file certificate in the Secret.
             */
            certificate: string;
            /**
             * The name of the Secret containing the certificate.
             */
            secretName: string;
        }

        /**
         * External listener configuration.
         */
        export interface KafkaSpecKafkaListenersOneOf1ExternalConfiguration {
            /**
             * External bootstrap ingress configuration.
             */
            bootstrap?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf1ExternalConfigurationBootstrap;
            /**
             * Reference to the `Secret` which holds the certificate and private key pair. The certificate can optionally contain the whole chain.
             */
            brokerCertChainAndKey?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf1ExternalConfigurationBrokerCertChainAndKey;
            /**
             * External broker ingress configuration.
             */
            brokers?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf1ExternalConfigurationBrokers[];
        }

        /**
         * External bootstrap ingress configuration.
         */
        export interface KafkaSpecKafkaListenersOneOf1ExternalConfigurationBootstrap {
            /**
             * Additional address name for the bootstrap service. The address will be added to the list of subject alternative names of the TLS certificates.
             */
            address?: string;
            /**
             * Annotations that will be added to the `Ingress` resource. You can use this field to configure DNS providers such as External DNS.
             */
            dnsAnnotations?: {[key: string]: any};
            /**
             * Host for the bootstrap route. This field will be used in the Ingress resource.
             */
            host: string;
        }

        /**
         * Reference to the `Secret` which holds the certificate and private key pair. The certificate can optionally contain the whole chain.
         */
        export interface KafkaSpecKafkaListenersOneOf1ExternalConfigurationBrokerCertChainAndKey {
            /**
             * The name of the file certificate in the Secret.
             */
            certificate: string;
            /**
             * The name of the private key in the Secret.
             */
            key: string;
            /**
             * The name of the Secret containing the certificate.
             */
            secretName: string;
        }

        export interface KafkaSpecKafkaListenersOneOf1ExternalConfigurationBrokers {
            /**
             * The host name which will be used in the brokers' `advertised.brokers`.
             */
            advertisedHost?: string;
            /**
             * The port number which will be used in the brokers' `advertised.brokers`.
             */
            advertisedPort?: number;
            /**
             * Id of the kafka broker (broker identifier).
             */
            broker?: number;
            /**
             * Annotations that will be added to the `Ingress` resources for individual brokers. You can use this field to configure DNS providers such as External DNS.
             */
            dnsAnnotations?: {[key: string]: any};
            /**
             * Host for the broker ingress. This field will be used in the Ingress resource.
             */
            host: string;
        }

        export interface KafkaSpecKafkaListenersOneOf1ExternalNetworkPolicyPeers {
            ipBlock?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf1ExternalNetworkPolicyPeersIpBlock;
            namespaceSelector?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf1ExternalNetworkPolicyPeersNamespaceSelector;
            podSelector?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf1ExternalNetworkPolicyPeersPodSelector;
        }

        export interface KafkaSpecKafkaListenersOneOf1ExternalNetworkPolicyPeersIpBlock {
            cidr?: string;
            except?: string[];
        }

        export interface KafkaSpecKafkaListenersOneOf1ExternalNetworkPolicyPeersNamespaceSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf1ExternalNetworkPolicyPeersNamespaceSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecKafkaListenersOneOf1ExternalNetworkPolicyPeersNamespaceSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecKafkaListenersOneOf1ExternalNetworkPolicyPeersPodSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf1ExternalNetworkPolicyPeersPodSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecKafkaListenersOneOf1ExternalNetworkPolicyPeersPodSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        /**
         * Overrides for external bootstrap and broker services and externally advertised addresses.
         */
        export interface KafkaSpecKafkaListenersOneOf1ExternalOverrides {
            /**
             * External bootstrap service configuration.
             */
            bootstrap?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf1ExternalOverridesBootstrap;
            /**
             * External broker services configuration.
             */
            brokers?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf1ExternalOverridesBrokers[];
        }

        /**
         * External bootstrap service configuration.
         */
        export interface KafkaSpecKafkaListenersOneOf1ExternalOverridesBootstrap {
            /**
             * Additional address name for the bootstrap service. The address will be added to the list of subject alternative names of the TLS certificates.
             */
            address?: string;
            /**
             * Annotations that will be added to the `Service` resource. You can use this field to configure DNS providers such as External DNS.
             */
            dnsAnnotations?: {[key: string]: any};
            /**
             * Node port for the bootstrap service.
             */
            nodePort?: number;
        }

        export interface KafkaSpecKafkaListenersOneOf1ExternalOverridesBrokers {
            /**
             * The host name which will be used in the brokers' `advertised.brokers`.
             */
            advertisedHost?: string;
            /**
             * The port number which will be used in the brokers' `advertised.brokers`.
             */
            advertisedPort?: number;
            /**
             * Id of the kafka broker (broker identifier).
             */
            broker?: number;
            /**
             * Annotations that will be added to the `Service` resources for individual brokers. You can use this field to configure DNS providers such as External DNS.
             */
            dnsAnnotations?: {[key: string]: any};
            /**
             * Node port for the broker service.
             */
            nodePort?: number;
        }

        /**
         * Configures plain listener on port 9092.
         */
        export interface KafkaSpecKafkaListenersOneOf1Plain {
            /**
             * Authentication configuration for this listener. Since this listener does not use TLS transport you cannot configure an authentication with `type: tls`.
             */
            authentication?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf1PlainAuthentication;
            /**
             * List of peers which should be able to connect to this listener. Peers in this list are combined using a logical OR operation. If this field is empty or missing, all connections will be allowed for this listener. If this field is present and contains at least one item, the listener only allows the traffic which matches at least one item in this list.
             */
            networkPolicyPeers?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf1PlainNetworkPolicyPeers[];
        }

        /**
         * Authentication configuration for this listener. Since this listener does not use TLS transport you cannot configure an authentication with `type: tls`.
         */
        export interface KafkaSpecKafkaListenersOneOf1PlainAuthentication {
            /**
             * Configure whether the access token is treated as JWT. This must be set to `false` if the authorization server returns opaque tokens. Defaults to `true`.
             */
            accessTokenIsJwt?: boolean;
            /**
             * Configure whether the access token type check is performed or not. This should be set to `false` if the authorization server does not include 'typ' claim in JWT token. Defaults to `true`.
             */
            checkAccessTokenType?: boolean;
            /**
             * Enable or disable issuer checking. By default issuer is checked using the value configured by `validIssuerUri`. Default value is `true`.
             */
            checkIssuer?: boolean;
            /**
             * OAuth Client ID which the Kafka broker can use to authenticate against the authorization server and use the introspect endpoint URI.
             */
            clientId?: string;
            /**
             * Link to Kubernetes Secret containing the OAuth client secret which the Kafka broker can use to authenticate against the authorization server and use the introspect endpoint URI.
             */
            clientSecret?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf1PlainAuthenticationClientSecret;
            /**
             * Enable or disable TLS hostname verification. Default value is `false`.
             */
            disableTlsHostnameVerification?: boolean;
            /**
             * Enable or disable ECDSA support by installing BouncyCastle crypto provider. Default value is `false`.
             */
            enableECDSA?: boolean;
            /**
             * The fallback username claim to be used for the user id if the claim specified by `userNameClaim` is not present. This is useful when `client_credentials` authentication only results in the client id being provided in another claim. It only takes effect if `userNameClaim` is set.
             */
            fallbackUserNameClaim?: string;
            /**
             * The prefix to use with the value of `fallbackUserNameClaim` to construct the user id. This only takes effect if `fallbackUserNameClaim` is true, and the value is present for the claim. Mapping usernames and client ids into the same user id space is useful in preventing name collisions.
             */
            fallbackUserNamePrefix?: string;
            /**
             * URI of the token introspection endpoint which can be used to validate opaque non-JWT tokens.
             */
            introspectionEndpointUri?: string;
            /**
             * URI of the JWKS certificate endpoint, which can be used for local JWT validation.
             */
            jwksEndpointUri?: string;
            /**
             * Configures how often are the JWKS certificates considered valid. The expiry interval has to be at least 60 seconds longer then the refresh interval specified in `jwksRefreshSeconds`. Defaults to 360 seconds.
             */
            jwksExpirySeconds?: number;
            /**
             * The minimum pause between two consecutive refreshes. When an unknown signing key is encountered the refresh is scheduled immediately, but will always wait for this minimum pause. Defaults to 1 second.
             */
            jwksMinRefreshPauseSeconds?: number;
            /**
             * Configures how often are the JWKS certificates refreshed. The refresh interval has to be at least 60 seconds shorter then the expiry interval specified in `jwksExpirySeconds`. Defaults to 300 seconds.
             */
            jwksRefreshSeconds?: number;
            /**
             * Maximum number of seconds the authenticated session remains valid without re-authentication. This enables Apache Kafka re-authentication feature, and causes sessions to expire when the access token expires. If the access token expires before max time or if max time is reached, the client has to re-authenticate, otherwise the server will drop the connection. Not set by default - the authenticated session does not expire when the access token expires.
             */
            maxSecondsWithoutReauthentication?: number;
            /**
             * Trusted certificates for TLS connection to the OAuth server.
             */
            tlsTrustedCertificates?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf1PlainAuthenticationTlsTrustedCertificates[];
            /**
             * Authentication type. `oauth` type uses SASL OAUTHBEARER Authentication. `scram-sha-512` type uses SASL SCRAM-SHA-512 Authentication. `tls` type uses TLS Client Authentication. `tls` type is supported only on TLS listeners.
             */
            type: string;
            /**
             * URI of the User Info Endpoint to use as a fallback to obtaining the user id when the Introspection Endpoint does not return information that can be used for the user id. 
             */
            userInfoEndpointUri?: string;
            /**
             * Name of the claim from the JWT authentication token, Introspection Endpoint response or User Info Endpoint response which will be used to extract the user id. Defaults to `sub`.
             */
            userNameClaim?: string;
            /**
             * URI of the token issuer used for authentication.
             */
            validIssuerUri?: string;
            /**
             * Valid value for the `token_type` attribute returned by the Introspection Endpoint. No default value, and not checked by default.
             */
            validTokenType?: string;
        }

        /**
         * Link to Kubernetes Secret containing the OAuth client secret which the Kafka broker can use to authenticate against the authorization server and use the introspect endpoint URI.
         */
        export interface KafkaSpecKafkaListenersOneOf1PlainAuthenticationClientSecret {
            /**
             * The key under which the secret value is stored in the Kubernetes Secret.
             */
            key: string;
            /**
             * The name of the Kubernetes Secret containing the secret value.
             */
            secretName: string;
        }

        export interface KafkaSpecKafkaListenersOneOf1PlainAuthenticationTlsTrustedCertificates {
            /**
             * The name of the file certificate in the Secret.
             */
            certificate: string;
            /**
             * The name of the Secret containing the certificate.
             */
            secretName: string;
        }

        export interface KafkaSpecKafkaListenersOneOf1PlainNetworkPolicyPeers {
            ipBlock?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf1PlainNetworkPolicyPeersIpBlock;
            namespaceSelector?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf1PlainNetworkPolicyPeersNamespaceSelector;
            podSelector?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf1PlainNetworkPolicyPeersPodSelector;
        }

        export interface KafkaSpecKafkaListenersOneOf1PlainNetworkPolicyPeersIpBlock {
            cidr?: string;
            except?: string[];
        }

        export interface KafkaSpecKafkaListenersOneOf1PlainNetworkPolicyPeersNamespaceSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf1PlainNetworkPolicyPeersNamespaceSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecKafkaListenersOneOf1PlainNetworkPolicyPeersNamespaceSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecKafkaListenersOneOf1PlainNetworkPolicyPeersPodSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf1PlainNetworkPolicyPeersPodSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecKafkaListenersOneOf1PlainNetworkPolicyPeersPodSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        /**
         * Configures TLS listener on port 9093.
         */
        export interface KafkaSpecKafkaListenersOneOf1Tls {
            /**
             * Authentication configuration for this listener.
             */
            authentication?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf1TlsAuthentication;
            /**
             * Configuration of TLS listener.
             */
            configuration?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf1TlsConfiguration;
            /**
             * List of peers which should be able to connect to this listener. Peers in this list are combined using a logical OR operation. If this field is empty or missing, all connections will be allowed for this listener. If this field is present and contains at least one item, the listener only allows the traffic which matches at least one item in this list.
             */
            networkPolicyPeers?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf1TlsNetworkPolicyPeers[];
        }

        /**
         * Authentication configuration for this listener.
         */
        export interface KafkaSpecKafkaListenersOneOf1TlsAuthentication {
            /**
             * Configure whether the access token is treated as JWT. This must be set to `false` if the authorization server returns opaque tokens. Defaults to `true`.
             */
            accessTokenIsJwt?: boolean;
            /**
             * Configure whether the access token type check is performed or not. This should be set to `false` if the authorization server does not include 'typ' claim in JWT token. Defaults to `true`.
             */
            checkAccessTokenType?: boolean;
            /**
             * Enable or disable issuer checking. By default issuer is checked using the value configured by `validIssuerUri`. Default value is `true`.
             */
            checkIssuer?: boolean;
            /**
             * OAuth Client ID which the Kafka broker can use to authenticate against the authorization server and use the introspect endpoint URI.
             */
            clientId?: string;
            /**
             * Link to Kubernetes Secret containing the OAuth client secret which the Kafka broker can use to authenticate against the authorization server and use the introspect endpoint URI.
             */
            clientSecret?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf1TlsAuthenticationClientSecret;
            /**
             * Enable or disable TLS hostname verification. Default value is `false`.
             */
            disableTlsHostnameVerification?: boolean;
            /**
             * Enable or disable ECDSA support by installing BouncyCastle crypto provider. Default value is `false`.
             */
            enableECDSA?: boolean;
            /**
             * The fallback username claim to be used for the user id if the claim specified by `userNameClaim` is not present. This is useful when `client_credentials` authentication only results in the client id being provided in another claim. It only takes effect if `userNameClaim` is set.
             */
            fallbackUserNameClaim?: string;
            /**
             * The prefix to use with the value of `fallbackUserNameClaim` to construct the user id. This only takes effect if `fallbackUserNameClaim` is true, and the value is present for the claim. Mapping usernames and client ids into the same user id space is useful in preventing name collisions.
             */
            fallbackUserNamePrefix?: string;
            /**
             * URI of the token introspection endpoint which can be used to validate opaque non-JWT tokens.
             */
            introspectionEndpointUri?: string;
            /**
             * URI of the JWKS certificate endpoint, which can be used for local JWT validation.
             */
            jwksEndpointUri?: string;
            /**
             * Configures how often are the JWKS certificates considered valid. The expiry interval has to be at least 60 seconds longer then the refresh interval specified in `jwksRefreshSeconds`. Defaults to 360 seconds.
             */
            jwksExpirySeconds?: number;
            /**
             * The minimum pause between two consecutive refreshes. When an unknown signing key is encountered the refresh is scheduled immediately, but will always wait for this minimum pause. Defaults to 1 second.
             */
            jwksMinRefreshPauseSeconds?: number;
            /**
             * Configures how often are the JWKS certificates refreshed. The refresh interval has to be at least 60 seconds shorter then the expiry interval specified in `jwksExpirySeconds`. Defaults to 300 seconds.
             */
            jwksRefreshSeconds?: number;
            /**
             * Maximum number of seconds the authenticated session remains valid without re-authentication. This enables Apache Kafka re-authentication feature, and causes sessions to expire when the access token expires. If the access token expires before max time or if max time is reached, the client has to re-authenticate, otherwise the server will drop the connection. Not set by default - the authenticated session does not expire when the access token expires.
             */
            maxSecondsWithoutReauthentication?: number;
            /**
             * Trusted certificates for TLS connection to the OAuth server.
             */
            tlsTrustedCertificates?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf1TlsAuthenticationTlsTrustedCertificates[];
            /**
             * Authentication type. `oauth` type uses SASL OAUTHBEARER Authentication. `scram-sha-512` type uses SASL SCRAM-SHA-512 Authentication. `tls` type uses TLS Client Authentication. `tls` type is supported only on TLS listeners.
             */
            type: string;
            /**
             * URI of the User Info Endpoint to use as a fallback to obtaining the user id when the Introspection Endpoint does not return information that can be used for the user id. 
             */
            userInfoEndpointUri?: string;
            /**
             * Name of the claim from the JWT authentication token, Introspection Endpoint response or User Info Endpoint response which will be used to extract the user id. Defaults to `sub`.
             */
            userNameClaim?: string;
            /**
             * URI of the token issuer used for authentication.
             */
            validIssuerUri?: string;
            /**
             * Valid value for the `token_type` attribute returned by the Introspection Endpoint. No default value, and not checked by default.
             */
            validTokenType?: string;
        }

        /**
         * Link to Kubernetes Secret containing the OAuth client secret which the Kafka broker can use to authenticate against the authorization server and use the introspect endpoint URI.
         */
        export interface KafkaSpecKafkaListenersOneOf1TlsAuthenticationClientSecret {
            /**
             * The key under which the secret value is stored in the Kubernetes Secret.
             */
            key: string;
            /**
             * The name of the Kubernetes Secret containing the secret value.
             */
            secretName: string;
        }

        export interface KafkaSpecKafkaListenersOneOf1TlsAuthenticationTlsTrustedCertificates {
            /**
             * The name of the file certificate in the Secret.
             */
            certificate: string;
            /**
             * The name of the Secret containing the certificate.
             */
            secretName: string;
        }

        /**
         * Configuration of TLS listener.
         */
        export interface KafkaSpecKafkaListenersOneOf1TlsConfiguration {
            /**
             * Reference to the `Secret` which holds the certificate and private key pair. The certificate can optionally contain the whole chain.
             */
            brokerCertChainAndKey?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf1TlsConfigurationBrokerCertChainAndKey;
        }

        /**
         * Reference to the `Secret` which holds the certificate and private key pair. The certificate can optionally contain the whole chain.
         */
        export interface KafkaSpecKafkaListenersOneOf1TlsConfigurationBrokerCertChainAndKey {
            /**
             * The name of the file certificate in the Secret.
             */
            certificate: string;
            /**
             * The name of the private key in the Secret.
             */
            key: string;
            /**
             * The name of the Secret containing the certificate.
             */
            secretName: string;
        }

        export interface KafkaSpecKafkaListenersOneOf1TlsNetworkPolicyPeers {
            ipBlock?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf1TlsNetworkPolicyPeersIpBlock;
            namespaceSelector?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf1TlsNetworkPolicyPeersNamespaceSelector;
            podSelector?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf1TlsNetworkPolicyPeersPodSelector;
        }

        export interface KafkaSpecKafkaListenersOneOf1TlsNetworkPolicyPeersIpBlock {
            cidr?: string;
            except?: string[];
        }

        export interface KafkaSpecKafkaListenersOneOf1TlsNetworkPolicyPeersNamespaceSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf1TlsNetworkPolicyPeersNamespaceSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecKafkaListenersOneOf1TlsNetworkPolicyPeersNamespaceSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecKafkaListenersOneOf1TlsNetworkPolicyPeersPodSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf1TlsNetworkPolicyPeersPodSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecKafkaListenersOneOf1TlsNetworkPolicyPeersPodSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        /**
         * Pod liveness checking.
         */
        export interface KafkaSpecKafkaLivenessProbe {
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * The initial delay before first the health is first checked.
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * The timeout for each attempted health check.
             */
            timeoutSeconds?: number;
        }

        /**
         * Logging configuration for Kafka.
         */
        export interface KafkaSpecKafkaLogging {
            /**
             * A Map from logger name to logger level.
             */
            loggers?: {[key: string]: any};
            /**
             * The name of the `ConfigMap` from which to get the logging configuration.
             */
            name?: string;
            /**
             * Logging type, must be either 'inline' or 'external'.
             */
            type: string;
        }

        /**
         * Configuration of the `broker.rack` broker config.
         */
        export interface KafkaSpecKafkaRack {
            /**
             * A key that matches labels assigned to the Kubernetes cluster nodes. The value of the label is used to set the broker's `broker.rack` config.
             */
            topologyKey: string;
        }

        /**
         * Pod readiness checking.
         */
        export interface KafkaSpecKafkaReadinessProbe {
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * The initial delay before first the health is first checked.
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * The timeout for each attempted health check.
             */
            timeoutSeconds?: number;
        }

        /**
         * CPU and memory resources to reserve.
         */
        export interface KafkaSpecKafkaResources {
            limits?: {[key: string]: any};
            requests?: {[key: string]: any};
        }

        /**
         * Storage configuration (disk). Cannot be updated.
         */
        export interface KafkaSpecKafkaStorage {
            /**
             * The storage class to use for dynamic volume allocation.
             */
            class?: string;
            /**
             * Specifies if the persistent volume claim has to be deleted when the cluster is un-deployed.
             */
            deleteClaim?: boolean;
            /**
             * Storage identification number. It is mandatory only for storage volumes defined in a storage of type 'jbod'.
             */
            id?: number;
            /**
             * Overrides for individual brokers. The `overrides` field allows to specify a different configuration for different brokers.
             */
            overrides?: outputs.kafka.v1beta1.KafkaSpecKafkaStorageOverrides[];
            /**
             * Specifies a specific persistent volume to use. It contains key:value pairs representing labels for selecting such a volume.
             */
            selector?: {[key: string]: any};
            /**
             * When type=persistent-claim, defines the size of the persistent volume claim (i.e 1Gi). Mandatory when type=persistent-claim.
             */
            size?: string;
            /**
             * When type=ephemeral, defines the total amount of local storage required for this EmptyDir volume (for example 1Gi).
             */
            sizeLimit?: string;
            /**
             * Storage type, must be either 'ephemeral', 'persistent-claim', or 'jbod'.
             */
            type: string;
            /**
             * List of volumes as Storage objects representing the JBOD disks array.
             */
            volumes?: outputs.kafka.v1beta1.KafkaSpecKafkaStorageVolumes[];
        }

        export interface KafkaSpecKafkaStorageOverrides {
            /**
             * Id of the kafka broker (broker identifier).
             */
            broker?: number;
            /**
             * The storage class to use for dynamic volume allocation for this broker.
             */
            class?: string;
        }

        export interface KafkaSpecKafkaStorageVolumes {
            /**
             * The storage class to use for dynamic volume allocation.
             */
            class?: string;
            /**
             * Specifies if the persistent volume claim has to be deleted when the cluster is un-deployed.
             */
            deleteClaim?: boolean;
            /**
             * Storage identification number. It is mandatory only for storage volumes defined in a storage of type 'jbod'.
             */
            id?: number;
            /**
             * Overrides for individual brokers. The `overrides` field allows to specify a different configuration for different brokers.
             */
            overrides?: outputs.kafka.v1beta1.KafkaSpecKafkaStorageVolumesOverrides[];
            /**
             * Specifies a specific persistent volume to use. It contains key:value pairs representing labels for selecting such a volume.
             */
            selector?: {[key: string]: any};
            /**
             * When type=persistent-claim, defines the size of the persistent volume claim (i.e 1Gi). Mandatory when type=persistent-claim.
             */
            size?: string;
            /**
             * When type=ephemeral, defines the total amount of local storage required for this EmptyDir volume (for example 1Gi).
             */
            sizeLimit?: string;
            /**
             * Storage type, must be either 'ephemeral' or 'persistent-claim'.
             */
            type: string;
        }

        export interface KafkaSpecKafkaStorageVolumesOverrides {
            /**
             * Id of the kafka broker (broker identifier).
             */
            broker?: number;
            /**
             * The storage class to use for dynamic volume allocation for this broker.
             */
            class?: string;
        }

        /**
         * Template for Kafka cluster resources. The template allows users to specify how are the `StatefulSet`, `Pods` and `Services` generated.
         */
        export interface KafkaSpecKafkaTemplate {
            /**
             * Template for Kafka bootstrap `Service`.
             */
            bootstrapService?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplateBootstrapService;
            /**
             * Template for Kafka broker `Service`.
             */
            brokersService?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplateBrokersService;
            /**
             * Template for Kafka external bootstrap `Ingress`.
             */
            externalBootstrapIngress?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplateExternalBootstrapIngress;
            /**
             * Template for Kafka external bootstrap `Route`.
             */
            externalBootstrapRoute?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplateExternalBootstrapRoute;
            /**
             * Template for Kafka external bootstrap `Service`.
             */
            externalBootstrapService?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplateExternalBootstrapService;
            /**
             * Template for the Kafka init container.
             */
            initContainer?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplateInitContainer;
            /**
             * Template for the Kafka broker container.
             */
            kafkaContainer?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplateKafkaContainer;
            /**
             * Template for Kafka per-pod `Ingress` used for access from outside of Kubernetes.
             */
            perPodIngress?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePerPodIngress;
            /**
             * Template for Kafka per-pod `Routes` used for access from outside of OpenShift.
             */
            perPodRoute?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePerPodRoute;
            /**
             * Template for Kafka per-pod `Services` used for access from outside of Kubernetes.
             */
            perPodService?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePerPodService;
            /**
             * Template for all Kafka `PersistentVolumeClaims`.
             */
            persistentVolumeClaim?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePersistentVolumeClaim;
            /**
             * Template for Kafka `Pods`.
             */
            pod?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePod;
            /**
             * Template for Kafka `PodDisruptionBudget`.
             */
            podDisruptionBudget?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePodDisruptionBudget;
            /**
             * Template for Kafka `StatefulSet`.
             */
            statefulset?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplateStatefulset;
            /**
             * Template for the Kafka broker TLS sidecar container.
             */
            tlsSidecarContainer?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplateTlsSidecarContainer;
        }

        /**
         * Template for Kafka bootstrap `Service`.
         */
        export interface KafkaSpecKafkaTemplateBootstrapService {
            /**
             * Metadata applied to the resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplateBootstrapServiceMetadata;
        }

        /**
         * Metadata applied to the resource.
         */
        export interface KafkaSpecKafkaTemplateBootstrapServiceMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        /**
         * Template for Kafka broker `Service`.
         */
        export interface KafkaSpecKafkaTemplateBrokersService {
            /**
             * Metadata applied to the resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplateBrokersServiceMetadata;
        }

        /**
         * Metadata applied to the resource.
         */
        export interface KafkaSpecKafkaTemplateBrokersServiceMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        /**
         * Template for Kafka external bootstrap `Ingress`.
         */
        export interface KafkaSpecKafkaTemplateExternalBootstrapIngress {
            /**
             * Metadata applied to the resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplateExternalBootstrapIngressMetadata;
        }

        /**
         * Metadata applied to the resource.
         */
        export interface KafkaSpecKafkaTemplateExternalBootstrapIngressMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        /**
         * Template for Kafka external bootstrap `Route`.
         */
        export interface KafkaSpecKafkaTemplateExternalBootstrapRoute {
            /**
             * Metadata applied to the resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplateExternalBootstrapRouteMetadata;
        }

        /**
         * Metadata applied to the resource.
         */
        export interface KafkaSpecKafkaTemplateExternalBootstrapRouteMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        /**
         * Template for Kafka external bootstrap `Service`.
         */
        export interface KafkaSpecKafkaTemplateExternalBootstrapService {
            /**
             * Specifies whether the service routes external traffic to node-local or cluster-wide endpoints. `Cluster` may cause a second hop to another node and obscures the client source IP. `Local` avoids a second hop for LoadBalancer and Nodeport type services and preserves the client source IP (when supported by the infrastructure). If unspecified, Kubernetes will use `Cluster` as the default.
             */
            externalTrafficPolicy?: string;
            /**
             * A list of CIDR ranges (for example `10.0.0.0/8` or `130.211.204.1/32`) from which clients can connect to load balancer type listeners. If supported by the platform, traffic through the loadbalancer is restricted to the specified CIDR ranges. This field is applicable only for loadbalancer type services and is ignored if the cloud provider does not support the feature. For more information, see https://v1-17.docs.kubernetes.io/docs/tasks/access-application-cluster/configure-cloud-provider-firewall/. 
             */
            loadBalancerSourceRanges?: string[];
            /**
             * Metadata applied to the resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplateExternalBootstrapServiceMetadata;
        }

        /**
         * Metadata applied to the resource.
         */
        export interface KafkaSpecKafkaTemplateExternalBootstrapServiceMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        /**
         * Template for the Kafka init container.
         */
        export interface KafkaSpecKafkaTemplateInitContainer {
            /**
             * Environment variables which should be applied to the container.
             */
            env?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplateInitContainerEnv[];
            /**
             * Security context for the container.
             */
            securityContext?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplateInitContainerSecurityContext;
        }

        export interface KafkaSpecKafkaTemplateInitContainerEnv {
            /**
             * The environment variable key.
             */
            name?: string;
            /**
             * The environment variable value.
             */
            value?: string;
        }

        /**
         * Security context for the container.
         */
        export interface KafkaSpecKafkaTemplateInitContainerSecurityContext {
            allowPrivilegeEscalation?: boolean;
            capabilities?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplateInitContainerSecurityContextCapabilities;
            privileged?: boolean;
            procMount?: string;
            readOnlyRootFilesystem?: boolean;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplateInitContainerSecurityContextSeLinuxOptions;
            windowsOptions?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplateInitContainerSecurityContextWindowsOptions;
        }

        export interface KafkaSpecKafkaTemplateInitContainerSecurityContextCapabilities {
            add?: string[];
            drop?: string[];
        }

        export interface KafkaSpecKafkaTemplateInitContainerSecurityContextSeLinuxOptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface KafkaSpecKafkaTemplateInitContainerSecurityContextWindowsOptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        /**
         * Template for the Kafka broker container.
         */
        export interface KafkaSpecKafkaTemplateKafkaContainer {
            /**
             * Environment variables which should be applied to the container.
             */
            env?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplateKafkaContainerEnv[];
            /**
             * Security context for the container.
             */
            securityContext?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplateKafkaContainerSecurityContext;
        }

        export interface KafkaSpecKafkaTemplateKafkaContainerEnv {
            /**
             * The environment variable key.
             */
            name?: string;
            /**
             * The environment variable value.
             */
            value?: string;
        }

        /**
         * Security context for the container.
         */
        export interface KafkaSpecKafkaTemplateKafkaContainerSecurityContext {
            allowPrivilegeEscalation?: boolean;
            capabilities?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplateKafkaContainerSecurityContextCapabilities;
            privileged?: boolean;
            procMount?: string;
            readOnlyRootFilesystem?: boolean;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplateKafkaContainerSecurityContextSeLinuxOptions;
            windowsOptions?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplateKafkaContainerSecurityContextWindowsOptions;
        }

        export interface KafkaSpecKafkaTemplateKafkaContainerSecurityContextCapabilities {
            add?: string[];
            drop?: string[];
        }

        export interface KafkaSpecKafkaTemplateKafkaContainerSecurityContextSeLinuxOptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface KafkaSpecKafkaTemplateKafkaContainerSecurityContextWindowsOptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        /**
         * Template for Kafka per-pod `Ingress` used for access from outside of Kubernetes.
         */
        export interface KafkaSpecKafkaTemplatePerPodIngress {
            /**
             * Metadata applied to the resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePerPodIngressMetadata;
        }

        /**
         * Metadata applied to the resource.
         */
        export interface KafkaSpecKafkaTemplatePerPodIngressMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        /**
         * Template for Kafka per-pod `Routes` used for access from outside of OpenShift.
         */
        export interface KafkaSpecKafkaTemplatePerPodRoute {
            /**
             * Metadata applied to the resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePerPodRouteMetadata;
        }

        /**
         * Metadata applied to the resource.
         */
        export interface KafkaSpecKafkaTemplatePerPodRouteMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        /**
         * Template for Kafka per-pod `Services` used for access from outside of Kubernetes.
         */
        export interface KafkaSpecKafkaTemplatePerPodService {
            /**
             * Specifies whether the service routes external traffic to node-local or cluster-wide endpoints. `Cluster` may cause a second hop to another node and obscures the client source IP. `Local` avoids a second hop for LoadBalancer and Nodeport type services and preserves the client source IP (when supported by the infrastructure). If unspecified, Kubernetes will use `Cluster` as the default.
             */
            externalTrafficPolicy?: string;
            /**
             * A list of CIDR ranges (for example `10.0.0.0/8` or `130.211.204.1/32`) from which clients can connect to load balancer type listeners. If supported by the platform, traffic through the loadbalancer is restricted to the specified CIDR ranges. This field is applicable only for loadbalancer type services and is ignored if the cloud provider does not support the feature. For more information, see https://v1-17.docs.kubernetes.io/docs/tasks/access-application-cluster/configure-cloud-provider-firewall/. 
             */
            loadBalancerSourceRanges?: string[];
            /**
             * Metadata applied to the resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePerPodServiceMetadata;
        }

        /**
         * Metadata applied to the resource.
         */
        export interface KafkaSpecKafkaTemplatePerPodServiceMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        /**
         * Template for all Kafka `PersistentVolumeClaims`.
         */
        export interface KafkaSpecKafkaTemplatePersistentVolumeClaim {
            /**
             * Metadata applied to the resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePersistentVolumeClaimMetadata;
        }

        /**
         * Metadata applied to the resource.
         */
        export interface KafkaSpecKafkaTemplatePersistentVolumeClaimMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        /**
         * Template for Kafka `Pods`.
         */
        export interface KafkaSpecKafkaTemplatePod {
            /**
             * The pod's affinity rules.
             */
            affinity?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePodAffinity;
            /**
             * The pod's HostAliases. HostAliases is an optional list of hosts and IPs that will be injected into the pod's hosts file if specified.
             */
            hostAliases?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePodHostAliases[];
            /**
             * List of references to secrets in the same namespace to use for pulling any of the images used by this Pod. When the `STRIMZI_IMAGE_PULL_SECRETS` environment variable in Cluster Operator and the `imagePullSecrets` option are specified, only the `imagePullSecrets` variable is used and the `STRIMZI_IMAGE_PULL_SECRETS` variable is ignored.
             */
            imagePullSecrets?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePodImagePullSecrets[];
            /**
             * Metadata applied to the resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePodMetadata;
            /**
             * The name of the priority class used to assign priority to the pods. For more information about priority classes, see {K8sPriorityClass}.
             */
            priorityClassName?: string;
            /**
             * The name of the scheduler used to dispatch this `Pod`. If not specified, the default scheduler will be used.
             */
            schedulerName?: string;
            /**
             * Configures pod-level security attributes and common container settings.
             */
            securityContext?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePodSecurityContext;
            /**
             * The grace period is the duration in seconds after the processes running in the pod are sent a termination signal, and the time when the processes are forcibly halted with a kill signal. Set this value to longer than the expected cleanup time for your process. Value must be a non-negative integer. A zero value indicates delete immediately. You might need to increase the grace period for very large Kafka clusters, so that the Kafka brokers have enough time to transfer their work to another broker before they are terminated. Defaults to 30 seconds.
             */
            terminationGracePeriodSeconds?: number;
            /**
             * The pod's tolerations.
             */
            tolerations?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePodTolerations[];
        }

        /**
         * The pod's affinity rules.
         */
        export interface KafkaSpecKafkaTemplatePodAffinity {
            nodeAffinity?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePodAffinityNodeAffinity;
            podAffinity?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePodAffinityPodAffinity;
            podAntiAffinity?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePodAffinityPodAntiAffinity;
        }

        export interface KafkaSpecKafkaTemplatePodAffinityNodeAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution;
        }

        export interface KafkaSpecKafkaTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            preference?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference;
            weight?: number;
        }

        export interface KafkaSpecKafkaTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions[];
            matchFields?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields[];
        }

        export interface KafkaSpecKafkaTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecKafkaTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecKafkaTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            nodeSelectorTerms?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms[];
        }

        export interface KafkaSpecKafkaTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions[];
            matchFields?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields[];
        }

        export interface KafkaSpecKafkaTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecKafkaTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecKafkaTemplatePodAffinityPodAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        export interface KafkaSpecKafkaTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            podAffinityTerm?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            weight?: number;
        }

        export interface KafkaSpecKafkaTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            labelSelector?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaSpecKafkaTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecKafkaTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecKafkaTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            labelSelector?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaSpecKafkaTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecKafkaTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecKafkaTemplatePodAffinityPodAntiAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        export interface KafkaSpecKafkaTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            podAffinityTerm?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            weight?: number;
        }

        export interface KafkaSpecKafkaTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            labelSelector?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaSpecKafkaTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecKafkaTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecKafkaTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            labelSelector?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaSpecKafkaTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecKafkaTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        /**
         * Template for Kafka `PodDisruptionBudget`.
         */
        export interface KafkaSpecKafkaTemplatePodDisruptionBudget {
            /**
             * Maximum number of unavailable pods to allow automatic Pod eviction. A Pod eviction is allowed when the `maxUnavailable` number of pods or fewer are unavailable after the eviction. Setting this value to 0 prevents all voluntary evictions, so the pods must be evicted manually. Defaults to 1.
             */
            maxUnavailable?: number;
            /**
             * Metadata to apply to the `PodDistruptionBugetTemplate` resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePodDisruptionBudgetMetadata;
        }

        /**
         * Metadata to apply to the `PodDistruptionBugetTemplate` resource.
         */
        export interface KafkaSpecKafkaTemplatePodDisruptionBudgetMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        export interface KafkaSpecKafkaTemplatePodHostAliases {
            hostnames?: string[];
            ip?: string;
        }

        export interface KafkaSpecKafkaTemplatePodImagePullSecrets {
            name?: string;
        }

        /**
         * Metadata applied to the resource.
         */
        export interface KafkaSpecKafkaTemplatePodMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        /**
         * Configures pod-level security attributes and common container settings.
         */
        export interface KafkaSpecKafkaTemplatePodSecurityContext {
            fsGroup?: number;
            fsGroupChangePolicy?: string;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePodSecurityContextSeLinuxOptions;
            supplementalGroups?: number[];
            sysctls?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePodSecurityContextSysctls[];
            windowsOptions?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePodSecurityContextWindowsOptions;
        }

        export interface KafkaSpecKafkaTemplatePodSecurityContextSeLinuxOptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface KafkaSpecKafkaTemplatePodSecurityContextSysctls {
            name?: string;
            value?: string;
        }

        export interface KafkaSpecKafkaTemplatePodSecurityContextWindowsOptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        export interface KafkaSpecKafkaTemplatePodTolerations {
            effect?: string;
            key?: string;
            operator?: string;
            tolerationSeconds?: number;
            value?: string;
        }

        /**
         * Template for Kafka `StatefulSet`.
         */
        export interface KafkaSpecKafkaTemplateStatefulset {
            /**
             * Metadata applied to the resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplateStatefulsetMetadata;
            /**
             * PodManagementPolicy which will be used for this StatefulSet. Valid values are `Parallel` and `OrderedReady`. Defaults to `Parallel`.
             */
            podManagementPolicy?: string;
        }

        /**
         * Metadata applied to the resource.
         */
        export interface KafkaSpecKafkaTemplateStatefulsetMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        /**
         * Template for the Kafka broker TLS sidecar container.
         */
        export interface KafkaSpecKafkaTemplateTlsSidecarContainer {
            /**
             * Environment variables which should be applied to the container.
             */
            env?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplateTlsSidecarContainerEnv[];
            /**
             * Security context for the container.
             */
            securityContext?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplateTlsSidecarContainerSecurityContext;
        }

        export interface KafkaSpecKafkaTemplateTlsSidecarContainerEnv {
            /**
             * The environment variable key.
             */
            name?: string;
            /**
             * The environment variable value.
             */
            value?: string;
        }

        /**
         * Security context for the container.
         */
        export interface KafkaSpecKafkaTemplateTlsSidecarContainerSecurityContext {
            allowPrivilegeEscalation?: boolean;
            capabilities?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplateTlsSidecarContainerSecurityContextCapabilities;
            privileged?: boolean;
            procMount?: string;
            readOnlyRootFilesystem?: boolean;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplateTlsSidecarContainerSecurityContextSeLinuxOptions;
            windowsOptions?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplateTlsSidecarContainerSecurityContextWindowsOptions;
        }

        export interface KafkaSpecKafkaTemplateTlsSidecarContainerSecurityContextCapabilities {
            add?: string[];
            drop?: string[];
        }

        export interface KafkaSpecKafkaTemplateTlsSidecarContainerSecurityContextSeLinuxOptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface KafkaSpecKafkaTemplateTlsSidecarContainerSecurityContextWindowsOptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        /**
         * TLS sidecar configuration.
         */
        export interface KafkaSpecKafkaTlsSidecar {
            /**
             * The docker image for the container.
             */
            image?: string;
            /**
             * Pod liveness checking.
             */
            livenessProbe?: outputs.kafka.v1beta1.KafkaSpecKafkaTlsSidecarLivenessProbe;
            /**
             * The log level for the TLS sidecar. Default value is `notice`.
             */
            logLevel?: string;
            /**
             * Pod readiness checking.
             */
            readinessProbe?: outputs.kafka.v1beta1.KafkaSpecKafkaTlsSidecarReadinessProbe;
            /**
             * CPU and memory resources to reserve.
             */
            resources?: outputs.kafka.v1beta1.KafkaSpecKafkaTlsSidecarResources;
        }

        /**
         * Pod liveness checking.
         */
        export interface KafkaSpecKafkaTlsSidecarLivenessProbe {
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * The initial delay before first the health is first checked.
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * The timeout for each attempted health check.
             */
            timeoutSeconds?: number;
        }

        /**
         * Pod readiness checking.
         */
        export interface KafkaSpecKafkaTlsSidecarReadinessProbe {
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * The initial delay before first the health is first checked.
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * The timeout for each attempted health check.
             */
            timeoutSeconds?: number;
        }

        /**
         * CPU and memory resources to reserve.
         */
        export interface KafkaSpecKafkaTlsSidecarResources {
            limits?: {[key: string]: any};
            requests?: {[key: string]: any};
        }

        export interface KafkaSpecKafkaTolerations {
            effect?: string;
            key?: string;
            operator?: string;
            tolerationSeconds?: number;
            value?: string;
        }

        /**
         * Configuration of the Topic Operator.
         */
        export interface KafkaSpecTopicOperator {
            /**
             * Pod affinity rules.
             */
            affinity?: outputs.kafka.v1beta1.KafkaSpecTopicOperatorAffinity;
            /**
             * The image to use for the Topic Operator.
             */
            image?: string;
            /**
             * JVM Options for pods.
             */
            jvmOptions?: outputs.kafka.v1beta1.KafkaSpecTopicOperatorJvmOptions;
            /**
             * Pod liveness checking.
             */
            livenessProbe?: outputs.kafka.v1beta1.KafkaSpecTopicOperatorLivenessProbe;
            /**
             * Logging configuration.
             */
            logging?: outputs.kafka.v1beta1.KafkaSpecTopicOperatorLogging;
            /**
             * Pod readiness checking.
             */
            readinessProbe?: outputs.kafka.v1beta1.KafkaSpecTopicOperatorReadinessProbe;
            /**
             * Interval between periodic reconciliations.
             */
            reconciliationIntervalSeconds?: number;
            /**
             * CPU and memory resources to reserve.
             */
            resources?: outputs.kafka.v1beta1.KafkaSpecTopicOperatorResources;
            /**
             * TLS sidecar configuration.
             */
            tlsSidecar?: outputs.kafka.v1beta1.KafkaSpecTopicOperatorTlsSidecar;
            /**
             * The number of attempts at getting topic metadata.
             */
            topicMetadataMaxAttempts?: number;
            /**
             * The namespace the Topic Operator should watch.
             */
            watchedNamespace?: string;
            /**
             * Timeout for the ZooKeeper session.
             */
            zookeeperSessionTimeoutSeconds?: number;
        }

        /**
         * Pod affinity rules.
         */
        export interface KafkaSpecTopicOperatorAffinity {
            nodeAffinity?: outputs.kafka.v1beta1.KafkaSpecTopicOperatorAffinityNodeAffinity;
            podAffinity?: outputs.kafka.v1beta1.KafkaSpecTopicOperatorAffinityPodAffinity;
            podAntiAffinity?: outputs.kafka.v1beta1.KafkaSpecTopicOperatorAffinityPodAntiAffinity;
        }

        export interface KafkaSpecTopicOperatorAffinityNodeAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecTopicOperatorAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecTopicOperatorAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution;
        }

        export interface KafkaSpecTopicOperatorAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            preference?: outputs.kafka.v1beta1.KafkaSpecTopicOperatorAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference;
            weight?: number;
        }

        export interface KafkaSpecTopicOperatorAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecTopicOperatorAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions[];
            matchFields?: outputs.kafka.v1beta1.KafkaSpecTopicOperatorAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields[];
        }

        export interface KafkaSpecTopicOperatorAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecTopicOperatorAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecTopicOperatorAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            nodeSelectorTerms?: outputs.kafka.v1beta1.KafkaSpecTopicOperatorAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms[];
        }

        export interface KafkaSpecTopicOperatorAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecTopicOperatorAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions[];
            matchFields?: outputs.kafka.v1beta1.KafkaSpecTopicOperatorAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields[];
        }

        export interface KafkaSpecTopicOperatorAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecTopicOperatorAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecTopicOperatorAffinityPodAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecTopicOperatorAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecTopicOperatorAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        export interface KafkaSpecTopicOperatorAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            podAffinityTerm?: outputs.kafka.v1beta1.KafkaSpecTopicOperatorAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            weight?: number;
        }

        export interface KafkaSpecTopicOperatorAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            labelSelector?: outputs.kafka.v1beta1.KafkaSpecTopicOperatorAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaSpecTopicOperatorAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecTopicOperatorAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecTopicOperatorAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecTopicOperatorAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            labelSelector?: outputs.kafka.v1beta1.KafkaSpecTopicOperatorAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaSpecTopicOperatorAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecTopicOperatorAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecTopicOperatorAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecTopicOperatorAffinityPodAntiAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecTopicOperatorAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecTopicOperatorAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        export interface KafkaSpecTopicOperatorAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            podAffinityTerm?: outputs.kafka.v1beta1.KafkaSpecTopicOperatorAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            weight?: number;
        }

        export interface KafkaSpecTopicOperatorAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            labelSelector?: outputs.kafka.v1beta1.KafkaSpecTopicOperatorAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaSpecTopicOperatorAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecTopicOperatorAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecTopicOperatorAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecTopicOperatorAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            labelSelector?: outputs.kafka.v1beta1.KafkaSpecTopicOperatorAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaSpecTopicOperatorAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecTopicOperatorAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecTopicOperatorAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        /**
         * JVM Options for pods.
         */
        export interface KafkaSpecTopicOperatorJvmOptions {
            /**
             * A map of -XX options to the JVM.
             */
            "-XX"?: {[key: string]: any};
            /**
             * -Xms option to to the JVM.
             */
            "-Xms"?: string;
            /**
             * -Xmx option to to the JVM.
             */
            "-Xmx"?: string;
            /**
             * Specifies whether the Garbage Collection logging is enabled. The default is false.
             */
            gcLoggingEnabled?: boolean;
            /**
             * A map of additional system properties which will be passed using the `-D` option to the JVM.
             */
            javaSystemProperties?: outputs.kafka.v1beta1.KafkaSpecTopicOperatorJvmOptionsJavaSystemProperties[];
        }

        export interface KafkaSpecTopicOperatorJvmOptionsJavaSystemProperties {
            /**
             * The system property name.
             */
            name?: string;
            /**
             * The system property value.
             */
            value?: string;
        }

        /**
         * Pod liveness checking.
         */
        export interface KafkaSpecTopicOperatorLivenessProbe {
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * The initial delay before first the health is first checked.
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * The timeout for each attempted health check.
             */
            timeoutSeconds?: number;
        }

        /**
         * Logging configuration.
         */
        export interface KafkaSpecTopicOperatorLogging {
            /**
             * A Map from logger name to logger level.
             */
            loggers?: {[key: string]: any};
            /**
             * The name of the `ConfigMap` from which to get the logging configuration.
             */
            name?: string;
            /**
             * Logging type, must be either 'inline' or 'external'.
             */
            type: string;
        }

        /**
         * Pod readiness checking.
         */
        export interface KafkaSpecTopicOperatorReadinessProbe {
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * The initial delay before first the health is first checked.
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * The timeout for each attempted health check.
             */
            timeoutSeconds?: number;
        }

        /**
         * CPU and memory resources to reserve.
         */
        export interface KafkaSpecTopicOperatorResources {
            limits?: {[key: string]: any};
            requests?: {[key: string]: any};
        }

        /**
         * TLS sidecar configuration.
         */
        export interface KafkaSpecTopicOperatorTlsSidecar {
            /**
             * The docker image for the container.
             */
            image?: string;
            /**
             * Pod liveness checking.
             */
            livenessProbe?: outputs.kafka.v1beta1.KafkaSpecTopicOperatorTlsSidecarLivenessProbe;
            /**
             * The log level for the TLS sidecar. Default value is `notice`.
             */
            logLevel?: string;
            /**
             * Pod readiness checking.
             */
            readinessProbe?: outputs.kafka.v1beta1.KafkaSpecTopicOperatorTlsSidecarReadinessProbe;
            /**
             * CPU and memory resources to reserve.
             */
            resources?: outputs.kafka.v1beta1.KafkaSpecTopicOperatorTlsSidecarResources;
        }

        /**
         * Pod liveness checking.
         */
        export interface KafkaSpecTopicOperatorTlsSidecarLivenessProbe {
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * The initial delay before first the health is first checked.
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * The timeout for each attempted health check.
             */
            timeoutSeconds?: number;
        }

        /**
         * Pod readiness checking.
         */
        export interface KafkaSpecTopicOperatorTlsSidecarReadinessProbe {
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * The initial delay before first the health is first checked.
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * The timeout for each attempted health check.
             */
            timeoutSeconds?: number;
        }

        /**
         * CPU and memory resources to reserve.
         */
        export interface KafkaSpecTopicOperatorTlsSidecarResources {
            limits?: {[key: string]: any};
            requests?: {[key: string]: any};
        }

        /**
         * Configuration of the ZooKeeper cluster.
         */
        export interface KafkaSpecZookeeper {
            /**
             * The pod's affinity rules.
             */
            affinity?: outputs.kafka.v1beta1.KafkaSpecZookeeperAffinity;
            /**
             * The ZooKeeper broker config. Properties with the following prefixes cannot be set: server., dataDir, dataLogDir, clientPort, authProvider, quorum.auth, requireClientAuthScheme, snapshot.trust.empty, standaloneEnabled, reconfigEnabled, 4lw.commands.whitelist, secureClientPort, ssl., serverCnxnFactory, sslQuorum (with the exception of: ssl.protocol, ssl.quorum.protocol, ssl.enabledProtocols, ssl.quorum.enabledProtocols, ssl.ciphersuites, ssl.quorum.ciphersuites, ssl.hostnameVerification, ssl.quorum.hostnameVerification).
             */
            config?: {[key: string]: any};
            /**
             * The docker image for the pods.
             */
            image?: string;
            /**
             * JVM Options for pods.
             */
            jvmOptions?: outputs.kafka.v1beta1.KafkaSpecZookeeperJvmOptions;
            /**
             * Pod liveness checking.
             */
            livenessProbe?: outputs.kafka.v1beta1.KafkaSpecZookeeperLivenessProbe;
            /**
             * Logging configuration for ZooKeeper.
             */
            logging?: outputs.kafka.v1beta1.KafkaSpecZookeeperLogging;
            /**
             * The Prometheus JMX Exporter configuration. See https://github.com/prometheus/jmx_exporter for details of the structure of this configuration.
             */
            metrics?: {[key: string]: any};
            /**
             * Pod readiness checking.
             */
            readinessProbe?: outputs.kafka.v1beta1.KafkaSpecZookeeperReadinessProbe;
            /**
             * The number of pods in the cluster.
             */
            replicas: number;
            /**
             * CPU and memory resources to reserve.
             */
            resources?: outputs.kafka.v1beta1.KafkaSpecZookeeperResources;
            /**
             * Storage configuration (disk). Cannot be updated.
             */
            storage: outputs.kafka.v1beta1.KafkaSpecZookeeperStorage;
            /**
             * Template for ZooKeeper cluster resources. The template allows users to specify how are the `StatefulSet`, `Pods` and `Services` generated.
             */
            template?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplate;
            /**
             * TLS sidecar configuration. The TLS sidecar is not used anymore and this option will be ignored.
             */
            tlsSidecar?: outputs.kafka.v1beta1.KafkaSpecZookeeperTlsSidecar;
            /**
             * The pod's tolerations.
             */
            tolerations?: outputs.kafka.v1beta1.KafkaSpecZookeeperTolerations[];
        }

        /**
         * The pod's affinity rules.
         */
        export interface KafkaSpecZookeeperAffinity {
            nodeAffinity?: outputs.kafka.v1beta1.KafkaSpecZookeeperAffinityNodeAffinity;
            podAffinity?: outputs.kafka.v1beta1.KafkaSpecZookeeperAffinityPodAffinity;
            podAntiAffinity?: outputs.kafka.v1beta1.KafkaSpecZookeeperAffinityPodAntiAffinity;
        }

        export interface KafkaSpecZookeeperAffinityNodeAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecZookeeperAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecZookeeperAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution;
        }

        export interface KafkaSpecZookeeperAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            preference?: outputs.kafka.v1beta1.KafkaSpecZookeeperAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference;
            weight?: number;
        }

        export interface KafkaSpecZookeeperAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecZookeeperAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions[];
            matchFields?: outputs.kafka.v1beta1.KafkaSpecZookeeperAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields[];
        }

        export interface KafkaSpecZookeeperAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecZookeeperAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecZookeeperAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            nodeSelectorTerms?: outputs.kafka.v1beta1.KafkaSpecZookeeperAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms[];
        }

        export interface KafkaSpecZookeeperAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecZookeeperAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions[];
            matchFields?: outputs.kafka.v1beta1.KafkaSpecZookeeperAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields[];
        }

        export interface KafkaSpecZookeeperAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecZookeeperAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecZookeeperAffinityPodAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecZookeeperAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecZookeeperAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        export interface KafkaSpecZookeeperAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            podAffinityTerm?: outputs.kafka.v1beta1.KafkaSpecZookeeperAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            weight?: number;
        }

        export interface KafkaSpecZookeeperAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            labelSelector?: outputs.kafka.v1beta1.KafkaSpecZookeeperAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaSpecZookeeperAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecZookeeperAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecZookeeperAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecZookeeperAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            labelSelector?: outputs.kafka.v1beta1.KafkaSpecZookeeperAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaSpecZookeeperAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecZookeeperAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecZookeeperAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecZookeeperAffinityPodAntiAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecZookeeperAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecZookeeperAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        export interface KafkaSpecZookeeperAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            podAffinityTerm?: outputs.kafka.v1beta1.KafkaSpecZookeeperAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            weight?: number;
        }

        export interface KafkaSpecZookeeperAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            labelSelector?: outputs.kafka.v1beta1.KafkaSpecZookeeperAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaSpecZookeeperAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecZookeeperAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecZookeeperAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecZookeeperAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            labelSelector?: outputs.kafka.v1beta1.KafkaSpecZookeeperAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaSpecZookeeperAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecZookeeperAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecZookeeperAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        /**
         * JVM Options for pods.
         */
        export interface KafkaSpecZookeeperJvmOptions {
            /**
             * A map of -XX options to the JVM.
             */
            "-XX"?: {[key: string]: any};
            /**
             * -Xms option to to the JVM.
             */
            "-Xms"?: string;
            /**
             * -Xmx option to to the JVM.
             */
            "-Xmx"?: string;
            /**
             * Specifies whether the Garbage Collection logging is enabled. The default is false.
             */
            gcLoggingEnabled?: boolean;
            /**
             * A map of additional system properties which will be passed using the `-D` option to the JVM.
             */
            javaSystemProperties?: outputs.kafka.v1beta1.KafkaSpecZookeeperJvmOptionsJavaSystemProperties[];
        }

        export interface KafkaSpecZookeeperJvmOptionsJavaSystemProperties {
            /**
             * The system property name.
             */
            name?: string;
            /**
             * The system property value.
             */
            value?: string;
        }

        /**
         * Pod liveness checking.
         */
        export interface KafkaSpecZookeeperLivenessProbe {
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * The initial delay before first the health is first checked.
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * The timeout for each attempted health check.
             */
            timeoutSeconds?: number;
        }

        /**
         * Logging configuration for ZooKeeper.
         */
        export interface KafkaSpecZookeeperLogging {
            /**
             * A Map from logger name to logger level.
             */
            loggers?: {[key: string]: any};
            /**
             * The name of the `ConfigMap` from which to get the logging configuration.
             */
            name?: string;
            /**
             * Logging type, must be either 'inline' or 'external'.
             */
            type: string;
        }

        /**
         * Pod readiness checking.
         */
        export interface KafkaSpecZookeeperReadinessProbe {
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * The initial delay before first the health is first checked.
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * The timeout for each attempted health check.
             */
            timeoutSeconds?: number;
        }

        /**
         * CPU and memory resources to reserve.
         */
        export interface KafkaSpecZookeeperResources {
            limits?: {[key: string]: any};
            requests?: {[key: string]: any};
        }

        /**
         * Storage configuration (disk). Cannot be updated.
         */
        export interface KafkaSpecZookeeperStorage {
            /**
             * The storage class to use for dynamic volume allocation.
             */
            class?: string;
            /**
             * Specifies if the persistent volume claim has to be deleted when the cluster is un-deployed.
             */
            deleteClaim?: boolean;
            /**
             * Storage identification number. It is mandatory only for storage volumes defined in a storage of type 'jbod'.
             */
            id?: number;
            /**
             * Overrides for individual brokers. The `overrides` field allows to specify a different configuration for different brokers.
             */
            overrides?: outputs.kafka.v1beta1.KafkaSpecZookeeperStorageOverrides[];
            /**
             * Specifies a specific persistent volume to use. It contains key:value pairs representing labels for selecting such a volume.
             */
            selector?: {[key: string]: any};
            /**
             * When type=persistent-claim, defines the size of the persistent volume claim (i.e 1Gi). Mandatory when type=persistent-claim.
             */
            size?: string;
            /**
             * When type=ephemeral, defines the total amount of local storage required for this EmptyDir volume (for example 1Gi).
             */
            sizeLimit?: string;
            /**
             * Storage type, must be either 'ephemeral' or 'persistent-claim'.
             */
            type: string;
        }

        export interface KafkaSpecZookeeperStorageOverrides {
            /**
             * Id of the kafka broker (broker identifier).
             */
            broker?: number;
            /**
             * The storage class to use for dynamic volume allocation for this broker.
             */
            class?: string;
        }

        /**
         * Template for ZooKeeper cluster resources. The template allows users to specify how are the `StatefulSet`, `Pods` and `Services` generated.
         */
        export interface KafkaSpecZookeeperTemplate {
            /**
             * Template for ZooKeeper client `Service`.
             */
            clientService?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplateClientService;
            /**
             * Template for ZooKeeper nodes `Service`.
             */
            nodesService?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplateNodesService;
            /**
             * Template for all ZooKeeper `PersistentVolumeClaims`.
             */
            persistentVolumeClaim?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplatePersistentVolumeClaim;
            /**
             * Template for ZooKeeper `Pods`.
             */
            pod?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplatePod;
            /**
             * Template for ZooKeeper `PodDisruptionBudget`.
             */
            podDisruptionBudget?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplatePodDisruptionBudget;
            /**
             * Template for ZooKeeper `StatefulSet`.
             */
            statefulset?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplateStatefulset;
            /**
             * Template for the Zookeeper server TLS sidecar container. The TLS sidecar is not used anymore and this option will be ignored.
             */
            tlsSidecarContainer?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplateTlsSidecarContainer;
            /**
             * Template for the ZooKeeper container.
             */
            zookeeperContainer?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplateZookeeperContainer;
        }

        /**
         * Template for ZooKeeper client `Service`.
         */
        export interface KafkaSpecZookeeperTemplateClientService {
            /**
             * Metadata applied to the resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplateClientServiceMetadata;
        }

        /**
         * Metadata applied to the resource.
         */
        export interface KafkaSpecZookeeperTemplateClientServiceMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        /**
         * Template for ZooKeeper nodes `Service`.
         */
        export interface KafkaSpecZookeeperTemplateNodesService {
            /**
             * Metadata applied to the resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplateNodesServiceMetadata;
        }

        /**
         * Metadata applied to the resource.
         */
        export interface KafkaSpecZookeeperTemplateNodesServiceMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        /**
         * Template for all ZooKeeper `PersistentVolumeClaims`.
         */
        export interface KafkaSpecZookeeperTemplatePersistentVolumeClaim {
            /**
             * Metadata applied to the resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplatePersistentVolumeClaimMetadata;
        }

        /**
         * Metadata applied to the resource.
         */
        export interface KafkaSpecZookeeperTemplatePersistentVolumeClaimMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        /**
         * Template for ZooKeeper `Pods`.
         */
        export interface KafkaSpecZookeeperTemplatePod {
            /**
             * The pod's affinity rules.
             */
            affinity?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplatePodAffinity;
            /**
             * The pod's HostAliases. HostAliases is an optional list of hosts and IPs that will be injected into the pod's hosts file if specified.
             */
            hostAliases?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplatePodHostAliases[];
            /**
             * List of references to secrets in the same namespace to use for pulling any of the images used by this Pod. When the `STRIMZI_IMAGE_PULL_SECRETS` environment variable in Cluster Operator and the `imagePullSecrets` option are specified, only the `imagePullSecrets` variable is used and the `STRIMZI_IMAGE_PULL_SECRETS` variable is ignored.
             */
            imagePullSecrets?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplatePodImagePullSecrets[];
            /**
             * Metadata applied to the resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplatePodMetadata;
            /**
             * The name of the priority class used to assign priority to the pods. For more information about priority classes, see {K8sPriorityClass}.
             */
            priorityClassName?: string;
            /**
             * The name of the scheduler used to dispatch this `Pod`. If not specified, the default scheduler will be used.
             */
            schedulerName?: string;
            /**
             * Configures pod-level security attributes and common container settings.
             */
            securityContext?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplatePodSecurityContext;
            /**
             * The grace period is the duration in seconds after the processes running in the pod are sent a termination signal, and the time when the processes are forcibly halted with a kill signal. Set this value to longer than the expected cleanup time for your process. Value must be a non-negative integer. A zero value indicates delete immediately. You might need to increase the grace period for very large Kafka clusters, so that the Kafka brokers have enough time to transfer their work to another broker before they are terminated. Defaults to 30 seconds.
             */
            terminationGracePeriodSeconds?: number;
            /**
             * The pod's tolerations.
             */
            tolerations?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplatePodTolerations[];
        }

        /**
         * The pod's affinity rules.
         */
        export interface KafkaSpecZookeeperTemplatePodAffinity {
            nodeAffinity?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplatePodAffinityNodeAffinity;
            podAffinity?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplatePodAffinityPodAffinity;
            podAntiAffinity?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplatePodAffinityPodAntiAffinity;
        }

        export interface KafkaSpecZookeeperTemplatePodAffinityNodeAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution;
        }

        export interface KafkaSpecZookeeperTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            preference?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference;
            weight?: number;
        }

        export interface KafkaSpecZookeeperTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions[];
            matchFields?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields[];
        }

        export interface KafkaSpecZookeeperTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecZookeeperTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecZookeeperTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            nodeSelectorTerms?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms[];
        }

        export interface KafkaSpecZookeeperTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions[];
            matchFields?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields[];
        }

        export interface KafkaSpecZookeeperTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecZookeeperTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecZookeeperTemplatePodAffinityPodAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        export interface KafkaSpecZookeeperTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            podAffinityTerm?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            weight?: number;
        }

        export interface KafkaSpecZookeeperTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            labelSelector?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaSpecZookeeperTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecZookeeperTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecZookeeperTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            labelSelector?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaSpecZookeeperTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecZookeeperTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecZookeeperTemplatePodAffinityPodAntiAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        export interface KafkaSpecZookeeperTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            podAffinityTerm?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            weight?: number;
        }

        export interface KafkaSpecZookeeperTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            labelSelector?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaSpecZookeeperTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecZookeeperTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecZookeeperTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            labelSelector?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaSpecZookeeperTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecZookeeperTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        /**
         * Template for ZooKeeper `PodDisruptionBudget`.
         */
        export interface KafkaSpecZookeeperTemplatePodDisruptionBudget {
            /**
             * Maximum number of unavailable pods to allow automatic Pod eviction. A Pod eviction is allowed when the `maxUnavailable` number of pods or fewer are unavailable after the eviction. Setting this value to 0 prevents all voluntary evictions, so the pods must be evicted manually. Defaults to 1.
             */
            maxUnavailable?: number;
            /**
             * Metadata to apply to the `PodDistruptionBugetTemplate` resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplatePodDisruptionBudgetMetadata;
        }

        /**
         * Metadata to apply to the `PodDistruptionBugetTemplate` resource.
         */
        export interface KafkaSpecZookeeperTemplatePodDisruptionBudgetMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        export interface KafkaSpecZookeeperTemplatePodHostAliases {
            hostnames?: string[];
            ip?: string;
        }

        export interface KafkaSpecZookeeperTemplatePodImagePullSecrets {
            name?: string;
        }

        /**
         * Metadata applied to the resource.
         */
        export interface KafkaSpecZookeeperTemplatePodMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        /**
         * Configures pod-level security attributes and common container settings.
         */
        export interface KafkaSpecZookeeperTemplatePodSecurityContext {
            fsGroup?: number;
            fsGroupChangePolicy?: string;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplatePodSecurityContextSeLinuxOptions;
            supplementalGroups?: number[];
            sysctls?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplatePodSecurityContextSysctls[];
            windowsOptions?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplatePodSecurityContextWindowsOptions;
        }

        export interface KafkaSpecZookeeperTemplatePodSecurityContextSeLinuxOptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface KafkaSpecZookeeperTemplatePodSecurityContextSysctls {
            name?: string;
            value?: string;
        }

        export interface KafkaSpecZookeeperTemplatePodSecurityContextWindowsOptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        export interface KafkaSpecZookeeperTemplatePodTolerations {
            effect?: string;
            key?: string;
            operator?: string;
            tolerationSeconds?: number;
            value?: string;
        }

        /**
         * Template for ZooKeeper `StatefulSet`.
         */
        export interface KafkaSpecZookeeperTemplateStatefulset {
            /**
             * Metadata applied to the resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplateStatefulsetMetadata;
            /**
             * PodManagementPolicy which will be used for this StatefulSet. Valid values are `Parallel` and `OrderedReady`. Defaults to `Parallel`.
             */
            podManagementPolicy?: string;
        }

        /**
         * Metadata applied to the resource.
         */
        export interface KafkaSpecZookeeperTemplateStatefulsetMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        /**
         * Template for the Zookeeper server TLS sidecar container. The TLS sidecar is not used anymore and this option will be ignored.
         */
        export interface KafkaSpecZookeeperTemplateTlsSidecarContainer {
            /**
             * Environment variables which should be applied to the container.
             */
            env?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplateTlsSidecarContainerEnv[];
            /**
             * Security context for the container.
             */
            securityContext?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplateTlsSidecarContainerSecurityContext;
        }

        export interface KafkaSpecZookeeperTemplateTlsSidecarContainerEnv {
            /**
             * The environment variable key.
             */
            name?: string;
            /**
             * The environment variable value.
             */
            value?: string;
        }

        /**
         * Security context for the container.
         */
        export interface KafkaSpecZookeeperTemplateTlsSidecarContainerSecurityContext {
            allowPrivilegeEscalation?: boolean;
            capabilities?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplateTlsSidecarContainerSecurityContextCapabilities;
            privileged?: boolean;
            procMount?: string;
            readOnlyRootFilesystem?: boolean;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplateTlsSidecarContainerSecurityContextSeLinuxOptions;
            windowsOptions?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplateTlsSidecarContainerSecurityContextWindowsOptions;
        }

        export interface KafkaSpecZookeeperTemplateTlsSidecarContainerSecurityContextCapabilities {
            add?: string[];
            drop?: string[];
        }

        export interface KafkaSpecZookeeperTemplateTlsSidecarContainerSecurityContextSeLinuxOptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface KafkaSpecZookeeperTemplateTlsSidecarContainerSecurityContextWindowsOptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        /**
         * Template for the ZooKeeper container.
         */
        export interface KafkaSpecZookeeperTemplateZookeeperContainer {
            /**
             * Environment variables which should be applied to the container.
             */
            env?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplateZookeeperContainerEnv[];
            /**
             * Security context for the container.
             */
            securityContext?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplateZookeeperContainerSecurityContext;
        }

        export interface KafkaSpecZookeeperTemplateZookeeperContainerEnv {
            /**
             * The environment variable key.
             */
            name?: string;
            /**
             * The environment variable value.
             */
            value?: string;
        }

        /**
         * Security context for the container.
         */
        export interface KafkaSpecZookeeperTemplateZookeeperContainerSecurityContext {
            allowPrivilegeEscalation?: boolean;
            capabilities?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplateZookeeperContainerSecurityContextCapabilities;
            privileged?: boolean;
            procMount?: string;
            readOnlyRootFilesystem?: boolean;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplateZookeeperContainerSecurityContextSeLinuxOptions;
            windowsOptions?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplateZookeeperContainerSecurityContextWindowsOptions;
        }

        export interface KafkaSpecZookeeperTemplateZookeeperContainerSecurityContextCapabilities {
            add?: string[];
            drop?: string[];
        }

        export interface KafkaSpecZookeeperTemplateZookeeperContainerSecurityContextSeLinuxOptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface KafkaSpecZookeeperTemplateZookeeperContainerSecurityContextWindowsOptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        /**
         * TLS sidecar configuration. The TLS sidecar is not used anymore and this option will be ignored.
         */
        export interface KafkaSpecZookeeperTlsSidecar {
            /**
             * The docker image for the container.
             */
            image?: string;
            /**
             * Pod liveness checking.
             */
            livenessProbe?: outputs.kafka.v1beta1.KafkaSpecZookeeperTlsSidecarLivenessProbe;
            /**
             * The log level for the TLS sidecar. Default value is `notice`.
             */
            logLevel?: string;
            /**
             * Pod readiness checking.
             */
            readinessProbe?: outputs.kafka.v1beta1.KafkaSpecZookeeperTlsSidecarReadinessProbe;
            /**
             * CPU and memory resources to reserve.
             */
            resources?: outputs.kafka.v1beta1.KafkaSpecZookeeperTlsSidecarResources;
        }

        /**
         * Pod liveness checking.
         */
        export interface KafkaSpecZookeeperTlsSidecarLivenessProbe {
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * The initial delay before first the health is first checked.
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * The timeout for each attempted health check.
             */
            timeoutSeconds?: number;
        }

        /**
         * Pod readiness checking.
         */
        export interface KafkaSpecZookeeperTlsSidecarReadinessProbe {
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * The initial delay before first the health is first checked.
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * The timeout for each attempted health check.
             */
            timeoutSeconds?: number;
        }

        /**
         * CPU and memory resources to reserve.
         */
        export interface KafkaSpecZookeeperTlsSidecarResources {
            limits?: {[key: string]: any};
            requests?: {[key: string]: any};
        }

        export interface KafkaSpecZookeeperTolerations {
            effect?: string;
            key?: string;
            operator?: string;
            tolerationSeconds?: number;
            value?: string;
        }

        /**
         * The status of the Kafka and ZooKeeper clusters, and Topic Operator.
         */
        export interface KafkaStatus {
            /**
             * List of status conditions.
             */
            conditions?: outputs.kafka.v1beta1.KafkaStatusConditions[];
            /**
             * Addresses of the internal and external listeners.
             */
            listeners?: outputs.kafka.v1beta1.KafkaStatusListeners[];
            /**
             * The generation of the CRD that was last reconciled by the operator.
             */
            observedGeneration?: number;
        }

        export interface KafkaStatusConditions {
            /**
             * Last time the condition of a type changed from one status to another. The required format is 'yyyy-MM-ddTHH:mm:ssZ', in the UTC time zone.
             */
            lastTransitionTime?: string;
            /**
             * Human-readable message indicating details about the condition's last transition.
             */
            message?: string;
            /**
             * The reason for the condition's last transition (a single word in CamelCase).
             */
            reason?: string;
            /**
             * The status of the condition, either True, False or Unknown.
             */
            status?: string;
            /**
             * The unique identifier of a condition, used to distinguish between other conditions in the resource.
             */
            type?: string;
        }

        export interface KafkaStatusListeners {
            /**
             * A list of the addresses for this listener.
             */
            addresses?: outputs.kafka.v1beta1.KafkaStatusListenersAddresses[];
            /**
             * A comma-separated list of `host:port` pairs for connecting to the Kafka cluster using this listener.
             */
            bootstrapServers?: string;
            /**
             * A list of TLS certificates which can be used to verify the identity of the server when connecting to the given listener. Set only for `tls` and `external` listeners.
             */
            certificates?: string[];
            /**
             * The type of the listener. Can be one of the following three types: `plain`, `tls`, and `external`.
             */
            type?: string;
        }

        export interface KafkaStatusListenersAddresses {
            /**
             * The DNS name or IP address of the Kafka bootstrap service.
             */
            host?: string;
            /**
             * The port of the Kafka bootstrap service.
             */
            port?: number;
        }

        /**
         * The specification of the topic.
         */
        export interface KafkaTopicSpec {
            /**
             * The topic configuration.
             */
            config?: {[key: string]: any};
            /**
             * The number of partitions the topic should have. This cannot be decreased after topic creation. It can be increased after topic creation, but it is important to understand the consequences that has, especially for topics with semantic partitioning.
             */
            partitions: number;
            /**
             * The number of replicas the topic should have.
             */
            replicas: number;
            /**
             * The name of the topic. When absent this will default to the metadata.name of the topic. It is recommended to not set this unless the topic name is not a valid Kubernetes resource name.
             */
            topicName?: string;
        }

        /**
         * The status of the topic.
         */
        export interface KafkaTopicStatus {
            /**
             * List of status conditions.
             */
            conditions?: outputs.kafka.v1beta1.KafkaTopicStatusConditions[];
            /**
             * The generation of the CRD that was last reconciled by the operator.
             */
            observedGeneration?: number;
        }

        export interface KafkaTopicStatusConditions {
            /**
             * Last time the condition of a type changed from one status to another. The required format is 'yyyy-MM-ddTHH:mm:ssZ', in the UTC time zone.
             */
            lastTransitionTime?: string;
            /**
             * Human-readable message indicating details about the condition's last transition.
             */
            message?: string;
            /**
             * The reason for the condition's last transition (a single word in CamelCase).
             */
            reason?: string;
            /**
             * The status of the condition, either True, False or Unknown.
             */
            status?: string;
            /**
             * The unique identifier of a condition, used to distinguish between other conditions in the resource.
             */
            type?: string;
        }

        /**
         * The specification of the user.
         */
        export interface KafkaUserSpec {
            /**
             * Authentication mechanism enabled for this Kafka user.
             */
            authentication?: outputs.kafka.v1beta1.KafkaUserSpecAuthentication;
            /**
             * Authorization rules for this Kafka user.
             */
            authorization?: outputs.kafka.v1beta1.KafkaUserSpecAuthorization;
            /**
             * Quotas on requests to control the broker resources used by clients. Network bandwidth and request rate quotas can be enforced.Kafka documentation for Kafka User quotas can be found at http://kafka.apache.org/documentation/#design_quotas.
             */
            quotas?: outputs.kafka.v1beta1.KafkaUserSpecQuotas;
            /**
             * Template to specify how Kafka User `Secrets` are generated.
             */
            template?: outputs.kafka.v1beta1.KafkaUserSpecTemplate;
        }

        /**
         * Authentication mechanism enabled for this Kafka user.
         */
        export interface KafkaUserSpecAuthentication {
            /**
             * Authentication type.
             */
            type: string;
        }

        /**
         * Authorization rules for this Kafka user.
         */
        export interface KafkaUserSpecAuthorization {
            /**
             * List of ACL rules which should be applied to this user.
             */
            acls: outputs.kafka.v1beta1.KafkaUserSpecAuthorizationAcls[];
            /**
             * Authorization type. Currently the only supported type is `simple`. `simple` authorization type uses Kafka's `kafka.security.authorizer.AclAuthorizer` class for authorization.
             */
            type: string;
        }

        export interface KafkaUserSpecAuthorizationAcls {
            /**
             * The host from which the action described in the ACL rule is allowed or denied.
             */
            host?: string;
            /**
             * Operation which will be allowed or denied. Supported operations are: Read, Write, Create, Delete, Alter, Describe, ClusterAction, AlterConfigs, DescribeConfigs, IdempotentWrite and All.
             */
            operation: string;
            /**
             * Indicates the resource for which given ACL rule applies.
             */
            resource: outputs.kafka.v1beta1.KafkaUserSpecAuthorizationAclsResource;
            /**
             * The type of the rule. Currently the only supported type is `allow`. ACL rules with type `allow` are used to allow user to execute the specified operations. Default value is `allow`.
             */
            type?: string;
        }

        /**
         * Indicates the resource for which given ACL rule applies.
         */
        export interface KafkaUserSpecAuthorizationAclsResource {
            /**
             * Name of resource for which given ACL rule applies. Can be combined with `patternType` field to use prefix pattern.
             */
            name?: string;
            /**
             * Describes the pattern used in the resource field. The supported types are `literal` and `prefix`. With `literal` pattern type, the resource field will be used as a definition of a full name. With `prefix` pattern type, the resource name will be used only as a prefix. Default value is `literal`.
             */
            patternType?: string;
            /**
             * Resource type. The available resource types are `topic`, `group`, `cluster`, and `transactionalId`.
             */
            type: string;
        }

        /**
         * Quotas on requests to control the broker resources used by clients. Network bandwidth and request rate quotas can be enforced.Kafka documentation for Kafka User quotas can be found at http://kafka.apache.org/documentation/#design_quotas.
         */
        export interface KafkaUserSpecQuotas {
            /**
             * A quota on the maximum bytes per-second that each client group can fetch from a broker before the clients in the group are throttled. Defined on a per-broker basis.
             */
            consumerByteRate?: number;
            /**
             * A quota on the maximum bytes per-second that each client group can publish to a broker before the clients in the group are throttled. Defined on a per-broker basis.
             */
            producerByteRate?: number;
            /**
             * A quota on the maximum CPU utilization of each client group as a percentage of network and I/O threads.
             */
            requestPercentage?: number;
        }

        /**
         * Template to specify how Kafka User `Secrets` are generated.
         */
        export interface KafkaUserSpecTemplate {
            /**
             * Template for KafkaUser resources. The template allows users to specify how the `Secret` with password or TLS certificates is generated.
             */
            secret?: outputs.kafka.v1beta1.KafkaUserSpecTemplateSecret;
        }

        /**
         * Template for KafkaUser resources. The template allows users to specify how the `Secret` with password or TLS certificates is generated.
         */
        export interface KafkaUserSpecTemplateSecret {
            /**
             * Metadata applied to the resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaUserSpecTemplateSecretMetadata;
        }

        /**
         * Metadata applied to the resource.
         */
        export interface KafkaUserSpecTemplateSecretMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        /**
         * The status of the Kafka User.
         */
        export interface KafkaUserStatus {
            /**
             * List of status conditions.
             */
            conditions?: outputs.kafka.v1beta1.KafkaUserStatusConditions[];
            /**
             * The generation of the CRD that was last reconciled by the operator.
             */
            observedGeneration?: number;
            /**
             * The name of `Secret` where the credentials are stored.
             */
            secret?: string;
            /**
             * Username.
             */
            username?: string;
        }

        export interface KafkaUserStatusConditions {
            /**
             * Last time the condition of a type changed from one status to another. The required format is 'yyyy-MM-ddTHH:mm:ssZ', in the UTC time zone.
             */
            lastTransitionTime?: string;
            /**
             * Human-readable message indicating details about the condition's last transition.
             */
            message?: string;
            /**
             * The reason for the condition's last transition (a single word in CamelCase).
             */
            reason?: string;
            /**
             * The status of the condition, either True, False or Unknown.
             */
            status?: string;
            /**
             * The unique identifier of a condition, used to distinguish between other conditions in the resource.
             */
            type?: string;
        }
    }
}

export namespace logging {
    export namespace v1beta1 {
        export interface ClusterFlowSpec {
            filters?: outputs.logging.v1beta1.ClusterFlowSpecFilters[];
            globalOutputRefs?: string[];
            loggingRef?: string;
            match?: outputs.logging.v1beta1.ClusterFlowSpecMatch[];
            outputRefs?: string[];
            selectors?: { [key: string]: string };
        }

        export interface ClusterFlowSpecFilters {
            concat?: outputs.logging.v1beta1.ClusterFlowSpecFiltersConcat;
            dedot?: outputs.logging.v1beta1.ClusterFlowSpecFiltersDedot;
            detectExceptions?: outputs.logging.v1beta1.ClusterFlowSpecFiltersDetectExceptions;
            geoip?: outputs.logging.v1beta1.ClusterFlowSpecFiltersGeoip;
            grep?: outputs.logging.v1beta1.ClusterFlowSpecFiltersGrep;
            parser?: outputs.logging.v1beta1.ClusterFlowSpecFiltersParser;
            prometheus?: outputs.logging.v1beta1.ClusterFlowSpecFiltersPrometheus;
            record_modifier?: outputs.logging.v1beta1.ClusterFlowSpecFiltersRecord_modifier;
            record_transformer?: outputs.logging.v1beta1.ClusterFlowSpecFiltersRecord_transformer;
            stdout?: outputs.logging.v1beta1.ClusterFlowSpecFiltersStdout;
            sumologic?: outputs.logging.v1beta1.ClusterFlowSpecFiltersSumologic;
            tag_normaliser?: outputs.logging.v1beta1.ClusterFlowSpecFiltersTag_normaliser;
            throttle?: outputs.logging.v1beta1.ClusterFlowSpecFiltersThrottle;
        }

        export interface ClusterFlowSpecFiltersConcat {
            continuous_line_regexp?: string;
            flush_interval?: number;
            keep_partial_key?: boolean;
            keep_partial_metadata?: string;
            key?: string;
            multiline_end_regexp?: string;
            multiline_start_regexp?: string;
            n_lines?: number;
            partial_key?: string;
            partial_value?: string;
            separator?: string;
            stream_identity_key?: string;
            timeout_label?: string;
            use_first_timestamp?: boolean;
            use_partial_metadata?: string;
        }

        export interface ClusterFlowSpecFiltersDedot {
            de_dot_nested?: boolean;
            de_dot_separator?: string;
        }

        export interface ClusterFlowSpecFiltersDetectExceptions {
            languages?: string[];
            max_bytes?: number;
            max_lines?: number;
            message?: string;
            multiline_flush_interval?: string;
            remove_tag_prefix?: string;
            stream?: string;
        }

        export interface ClusterFlowSpecFiltersGeoip {
            backend_library?: string;
            geoip_2_database?: string;
            geoip_database?: string;
            geoip_lookup_keys?: string;
            records?: { [key: string]: string }[];
            skip_adding_null_record?: boolean;
        }

        export interface ClusterFlowSpecFiltersGrep {
            and?: outputs.logging.v1beta1.ClusterFlowSpecFiltersGrepAnd[];
            exclude?: outputs.logging.v1beta1.ClusterFlowSpecFiltersGrepExclude[];
            or?: outputs.logging.v1beta1.ClusterFlowSpecFiltersGrepOr[];
            regexp?: outputs.logging.v1beta1.ClusterFlowSpecFiltersGrepRegexp[];
        }

        export interface ClusterFlowSpecFiltersGrepAnd {
            exclude?: outputs.logging.v1beta1.ClusterFlowSpecFiltersGrepAndExclude[];
            regexp?: outputs.logging.v1beta1.ClusterFlowSpecFiltersGrepAndRegexp[];
        }

        export interface ClusterFlowSpecFiltersGrepAndExclude {
            key: string;
            pattern: string;
        }

        export interface ClusterFlowSpecFiltersGrepAndRegexp {
            key: string;
            pattern: string;
        }

        export interface ClusterFlowSpecFiltersGrepExclude {
            key: string;
            pattern: string;
        }

        export interface ClusterFlowSpecFiltersGrepOr {
            exclude?: outputs.logging.v1beta1.ClusterFlowSpecFiltersGrepOrExclude[];
            regexp?: outputs.logging.v1beta1.ClusterFlowSpecFiltersGrepOrRegexp[];
        }

        export interface ClusterFlowSpecFiltersGrepOrExclude {
            key: string;
            pattern: string;
        }

        export interface ClusterFlowSpecFiltersGrepOrRegexp {
            key: string;
            pattern: string;
        }

        export interface ClusterFlowSpecFiltersGrepRegexp {
            key: string;
            pattern: string;
        }

        export interface ClusterFlowSpecFiltersParser {
            emit_invalid_record_to_error?: boolean;
            hash_value_field?: string;
            inject_key_prefix?: string;
            key_name?: string;
            parse?: outputs.logging.v1beta1.ClusterFlowSpecFiltersParserParse;
            parsers?: outputs.logging.v1beta1.ClusterFlowSpecFiltersParserParsers[];
            remove_key_name_field?: boolean;
            replace_invalid_sequence?: boolean;
            reserve_data?: boolean;
            reserve_time?: boolean;
        }

        export interface ClusterFlowSpecFiltersParserParse {
            delimiter?: string;
            delimiter_pattern?: string;
            estimate_current_event?: boolean;
            expression?: string;
            format?: string;
            format_firstline?: string;
            keep_time_key?: boolean;
            label_delimiter?: string;
            local_time?: boolean;
            multiline?: string[];
            null_empty_string?: boolean;
            null_value_pattern?: string;
            patterns?: outputs.logging.v1beta1.ClusterFlowSpecFiltersParserParsePatterns[];
            time_format?: string;
            time_key?: string;
            time_type?: string;
            timezone?: string;
            type?: string;
            types?: string;
            utc?: boolean;
        }

        export interface ClusterFlowSpecFiltersParserParsePatterns {
            estimate_current_event?: boolean;
            expression?: string;
            format?: string;
            keep_time_key?: boolean;
            local_time?: boolean;
            null_empty_string?: boolean;
            null_value_pattern?: string;
            time_format?: string;
            time_key?: string;
            time_type?: string;
            timezone?: string;
            type?: string;
            types?: string;
            utc?: boolean;
        }

        export interface ClusterFlowSpecFiltersParserParsers {
            delimiter?: string;
            delimiter_pattern?: string;
            estimate_current_event?: boolean;
            expression?: string;
            format?: string;
            format_firstline?: string;
            keep_time_key?: boolean;
            label_delimiter?: string;
            local_time?: boolean;
            multiline?: string[];
            null_empty_string?: boolean;
            null_value_pattern?: string;
            patterns?: outputs.logging.v1beta1.ClusterFlowSpecFiltersParserParsersPatterns[];
            time_format?: string;
            time_key?: string;
            time_type?: string;
            timezone?: string;
            type?: string;
            types?: string;
            utc?: boolean;
        }

        export interface ClusterFlowSpecFiltersParserParsersPatterns {
            estimate_current_event?: boolean;
            expression?: string;
            format?: string;
            keep_time_key?: boolean;
            local_time?: boolean;
            null_empty_string?: boolean;
            null_value_pattern?: string;
            time_format?: string;
            time_key?: string;
            time_type?: string;
            timezone?: string;
            type?: string;
            types?: string;
            utc?: boolean;
        }

        export interface ClusterFlowSpecFiltersPrometheus {
            labels?: { [key: string]: string };
            metrics?: outputs.logging.v1beta1.ClusterFlowSpecFiltersPrometheusMetrics[];
        }

        export interface ClusterFlowSpecFiltersPrometheusMetrics {
            buckets?: string;
            desc: string;
            key?: string;
            labels?: { [key: string]: string };
            name: string;
            type: string;
        }

        export interface ClusterFlowSpecFiltersRecord_modifier {
            char_encoding?: string;
            prepare_value?: string;
            records?: { [key: string]: string }[];
            remove_keys?: string;
            replaces?: outputs.logging.v1beta1.ClusterFlowSpecFiltersRecord_modifierReplaces[];
            whitelist_keys?: string;
        }

        export interface ClusterFlowSpecFiltersRecord_modifierReplaces {
            expression: string;
            key: string;
            replace: string;
        }

        export interface ClusterFlowSpecFiltersRecord_transformer {
            auto_typecast?: boolean;
            enable_ruby?: boolean;
            keep_keys?: string;
            records?: { [key: string]: string }[];
            remove_keys?: string;
            renew_record?: boolean;
            renew_time_key?: string;
        }

        export interface ClusterFlowSpecFiltersStdout {
            output_type?: string;
        }

        export interface ClusterFlowSpecFiltersSumologic {
            collector_key_name?: string;
            collector_value?: string;
            exclude_container_regex?: string;
            exclude_facility_regex?: string;
            exclude_host_regex?: string;
            exclude_namespace_regex?: string;
            exclude_pod_regex?: string;
            exclude_priority_regex?: string;
            exclude_unit_regex?: string;
            log_format?: string;
            source_category?: string;
            source_category_key_name?: string;
            source_category_prefix?: string;
            source_category_replace_dash?: string;
            source_host?: string;
            source_host_key_name?: string;
            source_name?: string;
            source_name_key_name?: string;
            tracing_annotation_prefix?: string;
            tracing_container_name?: string;
            tracing_format?: boolean;
            tracing_host?: string;
            tracing_label_prefix?: string;
            tracing_namespace?: string;
            tracing_pod?: string;
            tracing_pod_id?: string;
        }

        export interface ClusterFlowSpecFiltersTag_normaliser {
            format?: string;
        }

        export interface ClusterFlowSpecFiltersThrottle {
            group_bucket_limit?: number;
            group_bucket_period_s?: number;
            group_drop_logs?: boolean;
            group_key?: string;
            group_reset_rate_s?: number;
            group_warning_delay_s?: number;
        }

        export interface ClusterFlowSpecMatch {
            exclude?: outputs.logging.v1beta1.ClusterFlowSpecMatchExclude;
            select?: outputs.logging.v1beta1.ClusterFlowSpecMatchSelect;
        }

        export interface ClusterFlowSpecMatchExclude {
            container_names?: string[];
            hosts?: string[];
            labels?: { [key: string]: string };
            namespaces?: string[];
        }

        export interface ClusterFlowSpecMatchSelect {
            container_names?: string[];
            hosts?: string[];
            labels?: { [key: string]: string };
            namespaces?: string[];
        }

        export interface ClusterFlowStatus {
            active?: boolean;
            problems?: string[];
            problemsCount?: number;
        }

        export interface ClusterOutputSpec {
            awsElasticsearch?: outputs.logging.v1beta1.ClusterOutputSpecAwsElasticsearch;
            azurestorage?: outputs.logging.v1beta1.ClusterOutputSpecAzurestorage;
            cloudwatch?: outputs.logging.v1beta1.ClusterOutputSpecCloudwatch;
            datadog?: outputs.logging.v1beta1.ClusterOutputSpecDatadog;
            elasticsearch?: outputs.logging.v1beta1.ClusterOutputSpecElasticsearch;
            enabledNamespaces?: string[];
            file?: outputs.logging.v1beta1.ClusterOutputSpecFile;
            forward?: outputs.logging.v1beta1.ClusterOutputSpecForward;
            gcs?: outputs.logging.v1beta1.ClusterOutputSpecGcs;
            http?: outputs.logging.v1beta1.ClusterOutputSpecHttp;
            kafka?: outputs.logging.v1beta1.ClusterOutputSpecKafka;
            kinesisStream?: outputs.logging.v1beta1.ClusterOutputSpecKinesisStream;
            logdna?: outputs.logging.v1beta1.ClusterOutputSpecLogdna;
            loggingRef?: string;
            logz?: outputs.logging.v1beta1.ClusterOutputSpecLogz;
            loki?: outputs.logging.v1beta1.ClusterOutputSpecLoki;
            newrelic?: outputs.logging.v1beta1.ClusterOutputSpecNewrelic;
            nullout?: { [key: string]: any };
            oss?: outputs.logging.v1beta1.ClusterOutputSpecOss;
            redis?: outputs.logging.v1beta1.ClusterOutputSpecRedis;
            s3?: outputs.logging.v1beta1.ClusterOutputSpecS3;
            splunkHec?: outputs.logging.v1beta1.ClusterOutputSpecSplunkHec;
            sumologic?: outputs.logging.v1beta1.ClusterOutputSpecSumologic;
            syslog?: outputs.logging.v1beta1.ClusterOutputSpecSyslog;
        }

        export interface ClusterOutputSpecAwsElasticsearch {
            buffer?: outputs.logging.v1beta1.ClusterOutputSpecAwsElasticsearchBuffer;
            endpoint?: outputs.logging.v1beta1.ClusterOutputSpecAwsElasticsearchEndpoint;
            flush_interval?: string;
            format?: outputs.logging.v1beta1.ClusterOutputSpecAwsElasticsearchFormat;
            include_tag_key?: boolean;
            logstash_format?: boolean;
            tag_key?: string;
        }

        export interface ClusterOutputSpecAwsElasticsearchBuffer {
            chunk_full_threshold?: string;
            chunk_limit_records?: number;
            chunk_limit_size?: string;
            compress?: string;
            delayed_commit_timeout?: string;
            disable_chunk_backup?: boolean;
            flush_at_shutdown?: boolean;
            flush_interval?: string;
            flush_mode?: string;
            flush_thread_burst_interval?: string;
            flush_thread_count?: number;
            flush_thread_interval?: string;
            overflow_action?: string;
            path?: string;
            queue_limit_length?: number;
            queued_chunks_limit_size?: number;
            retry_exponential_backoff_base?: string;
            retry_forever?: boolean;
            retry_max_interval?: string;
            retry_max_times?: number;
            retry_randomize?: boolean;
            retry_secondary_threshold?: string;
            retry_timeout?: string;
            retry_type?: string;
            retry_wait?: string;
            tags?: string;
            timekey?: string;
            timekey_use_utc?: boolean;
            timekey_wait?: string;
            timekey_zone?: string;
            total_limit_size?: string;
            type?: string;
        }

        export interface ClusterOutputSpecAwsElasticsearchEndpoint {
            access_key_id?: outputs.logging.v1beta1.ClusterOutputSpecAwsElasticsearchEndpointAccess_key_id;
            assume_role_arn?: outputs.logging.v1beta1.ClusterOutputSpecAwsElasticsearchEndpointAssume_role_arn;
            assume_role_session_name?: outputs.logging.v1beta1.ClusterOutputSpecAwsElasticsearchEndpointAssume_role_session_name;
            assume_role_web_identity_token_file?: outputs.logging.v1beta1.ClusterOutputSpecAwsElasticsearchEndpointAssume_role_web_identity_token_file;
            ecs_container_credentials_relative_uri?: outputs.logging.v1beta1.ClusterOutputSpecAwsElasticsearchEndpointEcs_container_credentials_relative_uri;
            region?: string;
            secret_access_key?: outputs.logging.v1beta1.ClusterOutputSpecAwsElasticsearchEndpointSecret_access_key;
            sts_credentials_region?: outputs.logging.v1beta1.ClusterOutputSpecAwsElasticsearchEndpointSts_credentials_region;
            url?: string;
        }

        export interface ClusterOutputSpecAwsElasticsearchEndpointAccess_key_id {
            mountFrom?: outputs.logging.v1beta1.ClusterOutputSpecAwsElasticsearchEndpointAccess_key_idMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.ClusterOutputSpecAwsElasticsearchEndpointAccess_key_idValueFrom;
        }

        export interface ClusterOutputSpecAwsElasticsearchEndpointAccess_key_idMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecAwsElasticsearchEndpointAccess_key_idMountFromSecretKeyRef;
        }

        export interface ClusterOutputSpecAwsElasticsearchEndpointAccess_key_idMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecAwsElasticsearchEndpointAccess_key_idValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecAwsElasticsearchEndpointAccess_key_idValueFromSecretKeyRef;
        }

        export interface ClusterOutputSpecAwsElasticsearchEndpointAccess_key_idValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecAwsElasticsearchEndpointAssume_role_arn {
            mountFrom?: outputs.logging.v1beta1.ClusterOutputSpecAwsElasticsearchEndpointAssume_role_arnMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.ClusterOutputSpecAwsElasticsearchEndpointAssume_role_arnValueFrom;
        }

        export interface ClusterOutputSpecAwsElasticsearchEndpointAssume_role_arnMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecAwsElasticsearchEndpointAssume_role_arnMountFromSecretKeyRef;
        }

        export interface ClusterOutputSpecAwsElasticsearchEndpointAssume_role_arnMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecAwsElasticsearchEndpointAssume_role_arnValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecAwsElasticsearchEndpointAssume_role_arnValueFromSecretKeyRef;
        }

        export interface ClusterOutputSpecAwsElasticsearchEndpointAssume_role_arnValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecAwsElasticsearchEndpointAssume_role_session_name {
            mountFrom?: outputs.logging.v1beta1.ClusterOutputSpecAwsElasticsearchEndpointAssume_role_session_nameMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.ClusterOutputSpecAwsElasticsearchEndpointAssume_role_session_nameValueFrom;
        }

        export interface ClusterOutputSpecAwsElasticsearchEndpointAssume_role_session_nameMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecAwsElasticsearchEndpointAssume_role_session_nameMountFromSecretKeyRef;
        }

        export interface ClusterOutputSpecAwsElasticsearchEndpointAssume_role_session_nameMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecAwsElasticsearchEndpointAssume_role_session_nameValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecAwsElasticsearchEndpointAssume_role_session_nameValueFromSecretKeyRef;
        }

        export interface ClusterOutputSpecAwsElasticsearchEndpointAssume_role_session_nameValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecAwsElasticsearchEndpointAssume_role_web_identity_token_file {
            mountFrom?: outputs.logging.v1beta1.ClusterOutputSpecAwsElasticsearchEndpointAssume_role_web_identity_token_fileMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.ClusterOutputSpecAwsElasticsearchEndpointAssume_role_web_identity_token_fileValueFrom;
        }

        export interface ClusterOutputSpecAwsElasticsearchEndpointAssume_role_web_identity_token_fileMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecAwsElasticsearchEndpointAssume_role_web_identity_token_fileMountFromSecretKeyRef;
        }

        export interface ClusterOutputSpecAwsElasticsearchEndpointAssume_role_web_identity_token_fileMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecAwsElasticsearchEndpointAssume_role_web_identity_token_fileValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecAwsElasticsearchEndpointAssume_role_web_identity_token_fileValueFromSecretKeyRef;
        }

        export interface ClusterOutputSpecAwsElasticsearchEndpointAssume_role_web_identity_token_fileValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecAwsElasticsearchEndpointEcs_container_credentials_relative_uri {
            mountFrom?: outputs.logging.v1beta1.ClusterOutputSpecAwsElasticsearchEndpointEcs_container_credentials_relative_uriMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.ClusterOutputSpecAwsElasticsearchEndpointEcs_container_credentials_relative_uriValueFrom;
        }

        export interface ClusterOutputSpecAwsElasticsearchEndpointEcs_container_credentials_relative_uriMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecAwsElasticsearchEndpointEcs_container_credentials_relative_uriMountFromSecretKeyRef;
        }

        export interface ClusterOutputSpecAwsElasticsearchEndpointEcs_container_credentials_relative_uriMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecAwsElasticsearchEndpointEcs_container_credentials_relative_uriValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecAwsElasticsearchEndpointEcs_container_credentials_relative_uriValueFromSecretKeyRef;
        }

        export interface ClusterOutputSpecAwsElasticsearchEndpointEcs_container_credentials_relative_uriValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecAwsElasticsearchEndpointSecret_access_key {
            mountFrom?: outputs.logging.v1beta1.ClusterOutputSpecAwsElasticsearchEndpointSecret_access_keyMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.ClusterOutputSpecAwsElasticsearchEndpointSecret_access_keyValueFrom;
        }

        export interface ClusterOutputSpecAwsElasticsearchEndpointSecret_access_keyMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecAwsElasticsearchEndpointSecret_access_keyMountFromSecretKeyRef;
        }

        export interface ClusterOutputSpecAwsElasticsearchEndpointSecret_access_keyMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecAwsElasticsearchEndpointSecret_access_keyValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecAwsElasticsearchEndpointSecret_access_keyValueFromSecretKeyRef;
        }

        export interface ClusterOutputSpecAwsElasticsearchEndpointSecret_access_keyValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecAwsElasticsearchEndpointSts_credentials_region {
            mountFrom?: outputs.logging.v1beta1.ClusterOutputSpecAwsElasticsearchEndpointSts_credentials_regionMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.ClusterOutputSpecAwsElasticsearchEndpointSts_credentials_regionValueFrom;
        }

        export interface ClusterOutputSpecAwsElasticsearchEndpointSts_credentials_regionMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecAwsElasticsearchEndpointSts_credentials_regionMountFromSecretKeyRef;
        }

        export interface ClusterOutputSpecAwsElasticsearchEndpointSts_credentials_regionMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecAwsElasticsearchEndpointSts_credentials_regionValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecAwsElasticsearchEndpointSts_credentials_regionValueFromSecretKeyRef;
        }

        export interface ClusterOutputSpecAwsElasticsearchEndpointSts_credentials_regionValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecAwsElasticsearchFormat {
            add_newline?: boolean;
            message_key?: string;
            type?: string;
        }

        export interface ClusterOutputSpecAzurestorage {
            auto_create_container?: boolean;
            azure_container: string;
            azure_imds_api_version?: string;
            azure_object_key_format?: string;
            azure_storage_access_key: outputs.logging.v1beta1.ClusterOutputSpecAzurestorageAzure_storage_access_key;
            azure_storage_account: outputs.logging.v1beta1.ClusterOutputSpecAzurestorageAzure_storage_account;
            azure_storage_sas_token: outputs.logging.v1beta1.ClusterOutputSpecAzurestorageAzure_storage_sas_token;
            buffer?: outputs.logging.v1beta1.ClusterOutputSpecAzurestorageBuffer;
            format?: string;
            path?: string;
        }

        export interface ClusterOutputSpecAzurestorageAzure_storage_access_key {
            mountFrom?: outputs.logging.v1beta1.ClusterOutputSpecAzurestorageAzure_storage_access_keyMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.ClusterOutputSpecAzurestorageAzure_storage_access_keyValueFrom;
        }

        export interface ClusterOutputSpecAzurestorageAzure_storage_access_keyMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecAzurestorageAzure_storage_access_keyMountFromSecretKeyRef;
        }

        export interface ClusterOutputSpecAzurestorageAzure_storage_access_keyMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecAzurestorageAzure_storage_access_keyValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecAzurestorageAzure_storage_access_keyValueFromSecretKeyRef;
        }

        export interface ClusterOutputSpecAzurestorageAzure_storage_access_keyValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecAzurestorageAzure_storage_account {
            mountFrom?: outputs.logging.v1beta1.ClusterOutputSpecAzurestorageAzure_storage_accountMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.ClusterOutputSpecAzurestorageAzure_storage_accountValueFrom;
        }

        export interface ClusterOutputSpecAzurestorageAzure_storage_accountMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecAzurestorageAzure_storage_accountMountFromSecretKeyRef;
        }

        export interface ClusterOutputSpecAzurestorageAzure_storage_accountMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecAzurestorageAzure_storage_accountValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecAzurestorageAzure_storage_accountValueFromSecretKeyRef;
        }

        export interface ClusterOutputSpecAzurestorageAzure_storage_accountValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecAzurestorageAzure_storage_sas_token {
            mountFrom?: outputs.logging.v1beta1.ClusterOutputSpecAzurestorageAzure_storage_sas_tokenMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.ClusterOutputSpecAzurestorageAzure_storage_sas_tokenValueFrom;
        }

        export interface ClusterOutputSpecAzurestorageAzure_storage_sas_tokenMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecAzurestorageAzure_storage_sas_tokenMountFromSecretKeyRef;
        }

        export interface ClusterOutputSpecAzurestorageAzure_storage_sas_tokenMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecAzurestorageAzure_storage_sas_tokenValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecAzurestorageAzure_storage_sas_tokenValueFromSecretKeyRef;
        }

        export interface ClusterOutputSpecAzurestorageAzure_storage_sas_tokenValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecAzurestorageBuffer {
            chunk_full_threshold?: string;
            chunk_limit_records?: number;
            chunk_limit_size?: string;
            compress?: string;
            delayed_commit_timeout?: string;
            disable_chunk_backup?: boolean;
            flush_at_shutdown?: boolean;
            flush_interval?: string;
            flush_mode?: string;
            flush_thread_burst_interval?: string;
            flush_thread_count?: number;
            flush_thread_interval?: string;
            overflow_action?: string;
            path?: string;
            queue_limit_length?: number;
            queued_chunks_limit_size?: number;
            retry_exponential_backoff_base?: string;
            retry_forever?: boolean;
            retry_max_interval?: string;
            retry_max_times?: number;
            retry_randomize?: boolean;
            retry_secondary_threshold?: string;
            retry_timeout?: string;
            retry_type?: string;
            retry_wait?: string;
            tags?: string;
            timekey?: string;
            timekey_use_utc?: boolean;
            timekey_wait?: string;
            timekey_zone?: string;
            total_limit_size?: string;
            type?: string;
        }

        export interface ClusterOutputSpecCloudwatch {
            auto_create_stream?: boolean;
            aws_instance_profile_credentials_retries?: number;
            aws_key_id?: outputs.logging.v1beta1.ClusterOutputSpecCloudwatchAws_key_id;
            aws_sec_key?: outputs.logging.v1beta1.ClusterOutputSpecCloudwatchAws_sec_key;
            aws_sts_role_arn?: string;
            aws_sts_session_name?: string;
            aws_use_sts?: boolean;
            buffer?: outputs.logging.v1beta1.ClusterOutputSpecCloudwatchBuffer;
            concurrency?: number;
            endpoint?: string;
            format?: outputs.logging.v1beta1.ClusterOutputSpecCloudwatchFormat;
            http_proxy?: string;
            include_time_key?: boolean;
            json_handler?: string;
            localtime?: boolean;
            log_group_aws_tags?: string;
            log_group_aws_tags_key?: string;
            log_group_name?: string;
            log_group_name_key?: string;
            log_rejected_request?: string;
            log_stream_name?: string;
            log_stream_name_key?: string;
            max_events_per_batch?: number;
            max_message_length?: number;
            message_keys?: string;
            put_log_events_disable_retry_limit?: boolean;
            put_log_events_retry_limit?: number;
            put_log_events_retry_wait?: string;
            region: string;
            remove_log_group_aws_tags_key?: string;
            remove_log_group_name_key?: string;
            remove_log_stream_name_key?: string;
            remove_retention_in_days?: string;
            retention_in_days?: string;
            retention_in_days_key?: string;
            use_tag_as_group?: boolean;
            use_tag_as_stream?: boolean;
        }

        export interface ClusterOutputSpecCloudwatchAws_key_id {
            mountFrom?: outputs.logging.v1beta1.ClusterOutputSpecCloudwatchAws_key_idMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.ClusterOutputSpecCloudwatchAws_key_idValueFrom;
        }

        export interface ClusterOutputSpecCloudwatchAws_key_idMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecCloudwatchAws_key_idMountFromSecretKeyRef;
        }

        export interface ClusterOutputSpecCloudwatchAws_key_idMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecCloudwatchAws_key_idValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecCloudwatchAws_key_idValueFromSecretKeyRef;
        }

        export interface ClusterOutputSpecCloudwatchAws_key_idValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecCloudwatchAws_sec_key {
            mountFrom?: outputs.logging.v1beta1.ClusterOutputSpecCloudwatchAws_sec_keyMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.ClusterOutputSpecCloudwatchAws_sec_keyValueFrom;
        }

        export interface ClusterOutputSpecCloudwatchAws_sec_keyMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecCloudwatchAws_sec_keyMountFromSecretKeyRef;
        }

        export interface ClusterOutputSpecCloudwatchAws_sec_keyMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecCloudwatchAws_sec_keyValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecCloudwatchAws_sec_keyValueFromSecretKeyRef;
        }

        export interface ClusterOutputSpecCloudwatchAws_sec_keyValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecCloudwatchBuffer {
            chunk_full_threshold?: string;
            chunk_limit_records?: number;
            chunk_limit_size?: string;
            compress?: string;
            delayed_commit_timeout?: string;
            disable_chunk_backup?: boolean;
            flush_at_shutdown?: boolean;
            flush_interval?: string;
            flush_mode?: string;
            flush_thread_burst_interval?: string;
            flush_thread_count?: number;
            flush_thread_interval?: string;
            overflow_action?: string;
            path?: string;
            queue_limit_length?: number;
            queued_chunks_limit_size?: number;
            retry_exponential_backoff_base?: string;
            retry_forever?: boolean;
            retry_max_interval?: string;
            retry_max_times?: number;
            retry_randomize?: boolean;
            retry_secondary_threshold?: string;
            retry_timeout?: string;
            retry_type?: string;
            retry_wait?: string;
            tags?: string;
            timekey?: string;
            timekey_use_utc?: boolean;
            timekey_wait?: string;
            timekey_zone?: string;
            total_limit_size?: string;
            type?: string;
        }

        export interface ClusterOutputSpecCloudwatchFormat {
            add_newline?: boolean;
            message_key?: string;
            type?: string;
        }

        export interface ClusterOutputSpecDatadog {
            api_key: outputs.logging.v1beta1.ClusterOutputSpecDatadogApi_key;
            buffer?: outputs.logging.v1beta1.ClusterOutputSpecDatadogBuffer;
            compression_level?: string;
            dd_hostname?: string;
            dd_source?: string;
            dd_sourcecategory?: string;
            dd_tags?: string;
            host?: string;
            include_tag_key?: boolean;
            max_backoff?: string;
            max_retries?: string;
            no_ssl_validation?: boolean;
            port?: string;
            service?: string;
            ssl_port?: string;
            tag_key?: string;
            timestamp_key?: string;
            use_compression?: boolean;
            use_http?: boolean;
            use_json?: boolean;
            use_ssl?: boolean;
        }

        export interface ClusterOutputSpecDatadogApi_key {
            mountFrom?: outputs.logging.v1beta1.ClusterOutputSpecDatadogApi_keyMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.ClusterOutputSpecDatadogApi_keyValueFrom;
        }

        export interface ClusterOutputSpecDatadogApi_keyMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecDatadogApi_keyMountFromSecretKeyRef;
        }

        export interface ClusterOutputSpecDatadogApi_keyMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecDatadogApi_keyValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecDatadogApi_keyValueFromSecretKeyRef;
        }

        export interface ClusterOutputSpecDatadogApi_keyValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecDatadogBuffer {
            chunk_full_threshold?: string;
            chunk_limit_records?: number;
            chunk_limit_size?: string;
            compress?: string;
            delayed_commit_timeout?: string;
            disable_chunk_backup?: boolean;
            flush_at_shutdown?: boolean;
            flush_interval?: string;
            flush_mode?: string;
            flush_thread_burst_interval?: string;
            flush_thread_count?: number;
            flush_thread_interval?: string;
            overflow_action?: string;
            path?: string;
            queue_limit_length?: number;
            queued_chunks_limit_size?: number;
            retry_exponential_backoff_base?: string;
            retry_forever?: boolean;
            retry_max_interval?: string;
            retry_max_times?: number;
            retry_randomize?: boolean;
            retry_secondary_threshold?: string;
            retry_timeout?: string;
            retry_type?: string;
            retry_wait?: string;
            tags?: string;
            timekey?: string;
            timekey_use_utc?: boolean;
            timekey_wait?: string;
            timekey_zone?: string;
            total_limit_size?: string;
            type?: string;
        }

        export interface ClusterOutputSpecElasticsearch {
            application_name?: string;
            buffer?: outputs.logging.v1beta1.ClusterOutputSpecElasticsearchBuffer;
            bulk_message_request_threshold?: string;
            ca_file?: outputs.logging.v1beta1.ClusterOutputSpecElasticsearchCa_file;
            client_cert?: outputs.logging.v1beta1.ClusterOutputSpecElasticsearchClient_cert;
            client_key?: outputs.logging.v1beta1.ClusterOutputSpecElasticsearchClient_key;
            client_key_pass?: outputs.logging.v1beta1.ClusterOutputSpecElasticsearchClient_key_pass;
            content_type?: string;
            custom_headers?: string;
            customize_template?: string;
            default_elasticsearch_version?: string;
            deflector_alias?: string;
            enable_ilm?: boolean;
            exception_backup?: boolean;
            fail_on_putting_template_retry_exceed?: boolean;
            flatten_hashes?: boolean;
            flatten_hashes_separator?: string;
            host?: string;
            hosts?: string;
            http_backend?: string;
            id_key?: string;
            ignore_exceptions?: string;
            ilm_policy?: string;
            ilm_policy_id?: string;
            ilm_policy_overwrite?: boolean;
            include_index_in_url?: boolean;
            include_tag_key?: boolean;
            include_timestamp?: boolean;
            index_date_pattern?: string;
            index_name?: string;
            index_prefix?: string;
            log_es_400_reason?: boolean;
            logstash_dateformat?: string;
            logstash_format?: boolean;
            logstash_prefix?: string;
            logstash_prefix_separator?: string;
            max_retry_get_es_version?: string;
            max_retry_putting_template?: string;
            password?: outputs.logging.v1beta1.ClusterOutputSpecElasticsearchPassword;
            path?: string;
            pipeline?: string;
            port?: number;
            prefer_oj_serializer?: boolean;
            reconnect_on_error?: boolean;
            reload_after?: string;
            reload_connections?: boolean;
            reload_on_failure?: boolean;
            remove_keys_on_update?: string;
            remove_keys_on_update_key?: string;
            request_timeout?: string;
            resurrect_after?: string;
            retry_tag?: string;
            rollover_index?: boolean;
            routing_key?: string;
            scheme?: string;
            sniffer_class_name?: string;
            ssl_max_version?: string;
            ssl_min_version?: string;
            ssl_verify?: boolean;
            ssl_version?: string;
            suppress_doc_wrap?: boolean;
            suppress_type_name?: boolean;
            tag_key?: string;
            target_index_key?: string;
            target_type_key?: string;
            template_file?: outputs.logging.v1beta1.ClusterOutputSpecElasticsearchTemplate_file;
            template_name?: string;
            template_overwrite?: boolean;
            templates?: string;
            time_key?: string;
            time_key_format?: string;
            time_parse_error_tag?: string;
            time_precision?: string;
            type_name?: string;
            unrecoverable_error_types?: string;
            user?: string;
            utc_index?: boolean;
            validate_client_version?: boolean;
            verify_es_version_at_startup?: boolean;
            with_transporter_log?: boolean;
            write_operation?: string;
        }

        export interface ClusterOutputSpecElasticsearchBuffer {
            chunk_full_threshold?: string;
            chunk_limit_records?: number;
            chunk_limit_size?: string;
            compress?: string;
            delayed_commit_timeout?: string;
            disable_chunk_backup?: boolean;
            flush_at_shutdown?: boolean;
            flush_interval?: string;
            flush_mode?: string;
            flush_thread_burst_interval?: string;
            flush_thread_count?: number;
            flush_thread_interval?: string;
            overflow_action?: string;
            path?: string;
            queue_limit_length?: number;
            queued_chunks_limit_size?: number;
            retry_exponential_backoff_base?: string;
            retry_forever?: boolean;
            retry_max_interval?: string;
            retry_max_times?: number;
            retry_randomize?: boolean;
            retry_secondary_threshold?: string;
            retry_timeout?: string;
            retry_type?: string;
            retry_wait?: string;
            tags?: string;
            timekey?: string;
            timekey_use_utc?: boolean;
            timekey_wait?: string;
            timekey_zone?: string;
            total_limit_size?: string;
            type?: string;
        }

        export interface ClusterOutputSpecElasticsearchCa_file {
            mountFrom?: outputs.logging.v1beta1.ClusterOutputSpecElasticsearchCa_fileMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.ClusterOutputSpecElasticsearchCa_fileValueFrom;
        }

        export interface ClusterOutputSpecElasticsearchCa_fileMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecElasticsearchCa_fileMountFromSecretKeyRef;
        }

        export interface ClusterOutputSpecElasticsearchCa_fileMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecElasticsearchCa_fileValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecElasticsearchCa_fileValueFromSecretKeyRef;
        }

        export interface ClusterOutputSpecElasticsearchCa_fileValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecElasticsearchClient_cert {
            mountFrom?: outputs.logging.v1beta1.ClusterOutputSpecElasticsearchClient_certMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.ClusterOutputSpecElasticsearchClient_certValueFrom;
        }

        export interface ClusterOutputSpecElasticsearchClient_certMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecElasticsearchClient_certMountFromSecretKeyRef;
        }

        export interface ClusterOutputSpecElasticsearchClient_certMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecElasticsearchClient_certValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecElasticsearchClient_certValueFromSecretKeyRef;
        }

        export interface ClusterOutputSpecElasticsearchClient_certValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecElasticsearchClient_key {
            mountFrom?: outputs.logging.v1beta1.ClusterOutputSpecElasticsearchClient_keyMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.ClusterOutputSpecElasticsearchClient_keyValueFrom;
        }

        export interface ClusterOutputSpecElasticsearchClient_keyMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecElasticsearchClient_keyMountFromSecretKeyRef;
        }

        export interface ClusterOutputSpecElasticsearchClient_keyMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecElasticsearchClient_keyValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecElasticsearchClient_keyValueFromSecretKeyRef;
        }

        export interface ClusterOutputSpecElasticsearchClient_keyValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecElasticsearchClient_key_pass {
            mountFrom?: outputs.logging.v1beta1.ClusterOutputSpecElasticsearchClient_key_passMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.ClusterOutputSpecElasticsearchClient_key_passValueFrom;
        }

        export interface ClusterOutputSpecElasticsearchClient_key_passMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecElasticsearchClient_key_passMountFromSecretKeyRef;
        }

        export interface ClusterOutputSpecElasticsearchClient_key_passMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecElasticsearchClient_key_passValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecElasticsearchClient_key_passValueFromSecretKeyRef;
        }

        export interface ClusterOutputSpecElasticsearchClient_key_passValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecElasticsearchPassword {
            mountFrom?: outputs.logging.v1beta1.ClusterOutputSpecElasticsearchPasswordMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.ClusterOutputSpecElasticsearchPasswordValueFrom;
        }

        export interface ClusterOutputSpecElasticsearchPasswordMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecElasticsearchPasswordMountFromSecretKeyRef;
        }

        export interface ClusterOutputSpecElasticsearchPasswordMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecElasticsearchPasswordValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecElasticsearchPasswordValueFromSecretKeyRef;
        }

        export interface ClusterOutputSpecElasticsearchPasswordValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecElasticsearchTemplate_file {
            mountFrom?: outputs.logging.v1beta1.ClusterOutputSpecElasticsearchTemplate_fileMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.ClusterOutputSpecElasticsearchTemplate_fileValueFrom;
        }

        export interface ClusterOutputSpecElasticsearchTemplate_fileMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecElasticsearchTemplate_fileMountFromSecretKeyRef;
        }

        export interface ClusterOutputSpecElasticsearchTemplate_fileMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecElasticsearchTemplate_fileValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecElasticsearchTemplate_fileValueFromSecretKeyRef;
        }

        export interface ClusterOutputSpecElasticsearchTemplate_fileValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecFile {
            add_path_suffix?: boolean;
            append?: boolean;
            buffer?: outputs.logging.v1beta1.ClusterOutputSpecFileBuffer;
            format?: outputs.logging.v1beta1.ClusterOutputSpecFileFormat;
            path: string;
            path_suffix?: string;
            symlink_path?: boolean;
        }

        export interface ClusterOutputSpecFileBuffer {
            chunk_full_threshold?: string;
            chunk_limit_records?: number;
            chunk_limit_size?: string;
            compress?: string;
            delayed_commit_timeout?: string;
            disable_chunk_backup?: boolean;
            flush_at_shutdown?: boolean;
            flush_interval?: string;
            flush_mode?: string;
            flush_thread_burst_interval?: string;
            flush_thread_count?: number;
            flush_thread_interval?: string;
            overflow_action?: string;
            path?: string;
            queue_limit_length?: number;
            queued_chunks_limit_size?: number;
            retry_exponential_backoff_base?: string;
            retry_forever?: boolean;
            retry_max_interval?: string;
            retry_max_times?: number;
            retry_randomize?: boolean;
            retry_secondary_threshold?: string;
            retry_timeout?: string;
            retry_type?: string;
            retry_wait?: string;
            tags?: string;
            timekey?: string;
            timekey_use_utc?: boolean;
            timekey_wait?: string;
            timekey_zone?: string;
            total_limit_size?: string;
            type?: string;
        }

        export interface ClusterOutputSpecFileFormat {
            add_newline?: boolean;
            message_key?: string;
            type?: string;
        }

        export interface ClusterOutputSpecForward {
            ack_response_timeout?: number;
            buffer?: outputs.logging.v1beta1.ClusterOutputSpecForwardBuffer;
            connect_timeout?: number;
            dns_round_robin?: boolean;
            expire_dns_cache?: number;
            hard_timeout?: number;
            heartbeat_interval?: number;
            heartbeat_type?: string;
            ignore_network_errors_at_startup?: boolean;
            keepalive?: boolean;
            keepalive_timeout?: number;
            phi_failure_detector?: boolean;
            phi_threshold?: number;
            recover_wait?: number;
            require_ack_response?: boolean;
            security?: outputs.logging.v1beta1.ClusterOutputSpecForwardSecurity;
            send_timeout?: number;
            servers: outputs.logging.v1beta1.ClusterOutputSpecForwardServers[];
            tls_allow_self_signed_cert?: boolean;
            tls_cert_logical_store_name?: string;
            tls_cert_path?: outputs.logging.v1beta1.ClusterOutputSpecForwardTls_cert_path;
            tls_cert_thumbprint?: string;
            tls_cert_use_enterprise_store?: boolean;
            tls_ciphers?: string;
            tls_client_cert_path?: outputs.logging.v1beta1.ClusterOutputSpecForwardTls_client_cert_path;
            tls_client_private_key_passphrase?: outputs.logging.v1beta1.ClusterOutputSpecForwardTls_client_private_key_passphrase;
            tls_client_private_key_path?: outputs.logging.v1beta1.ClusterOutputSpecForwardTls_client_private_key_path;
            tls_insecure_mode?: boolean;
            tls_verify_hostname?: boolean;
            tls_version?: string;
            verify_connection_at_startup?: boolean;
        }

        export interface ClusterOutputSpecForwardBuffer {
            chunk_full_threshold?: string;
            chunk_limit_records?: number;
            chunk_limit_size?: string;
            compress?: string;
            delayed_commit_timeout?: string;
            disable_chunk_backup?: boolean;
            flush_at_shutdown?: boolean;
            flush_interval?: string;
            flush_mode?: string;
            flush_thread_burst_interval?: string;
            flush_thread_count?: number;
            flush_thread_interval?: string;
            overflow_action?: string;
            path?: string;
            queue_limit_length?: number;
            queued_chunks_limit_size?: number;
            retry_exponential_backoff_base?: string;
            retry_forever?: boolean;
            retry_max_interval?: string;
            retry_max_times?: number;
            retry_randomize?: boolean;
            retry_secondary_threshold?: string;
            retry_timeout?: string;
            retry_type?: string;
            retry_wait?: string;
            tags?: string;
            timekey?: string;
            timekey_use_utc?: boolean;
            timekey_wait?: string;
            timekey_zone?: string;
            total_limit_size?: string;
            type?: string;
        }

        export interface ClusterOutputSpecForwardSecurity {
            allow_anonymous_source?: boolean;
            self_hostname: string;
            shared_key: string;
            user_auth?: boolean;
        }

        export interface ClusterOutputSpecForwardServers {
            host: string;
            name?: string;
            password?: outputs.logging.v1beta1.ClusterOutputSpecForwardServersPassword;
            port?: number;
            shared_key?: outputs.logging.v1beta1.ClusterOutputSpecForwardServersShared_key;
            standby?: boolean;
            username?: outputs.logging.v1beta1.ClusterOutputSpecForwardServersUsername;
            weight?: number;
        }

        export interface ClusterOutputSpecForwardServersPassword {
            mountFrom?: outputs.logging.v1beta1.ClusterOutputSpecForwardServersPasswordMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.ClusterOutputSpecForwardServersPasswordValueFrom;
        }

        export interface ClusterOutputSpecForwardServersPasswordMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecForwardServersPasswordMountFromSecretKeyRef;
        }

        export interface ClusterOutputSpecForwardServersPasswordMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecForwardServersPasswordValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecForwardServersPasswordValueFromSecretKeyRef;
        }

        export interface ClusterOutputSpecForwardServersPasswordValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecForwardServersShared_key {
            mountFrom?: outputs.logging.v1beta1.ClusterOutputSpecForwardServersShared_keyMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.ClusterOutputSpecForwardServersShared_keyValueFrom;
        }

        export interface ClusterOutputSpecForwardServersShared_keyMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecForwardServersShared_keyMountFromSecretKeyRef;
        }

        export interface ClusterOutputSpecForwardServersShared_keyMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecForwardServersShared_keyValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecForwardServersShared_keyValueFromSecretKeyRef;
        }

        export interface ClusterOutputSpecForwardServersShared_keyValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecForwardServersUsername {
            mountFrom?: outputs.logging.v1beta1.ClusterOutputSpecForwardServersUsernameMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.ClusterOutputSpecForwardServersUsernameValueFrom;
        }

        export interface ClusterOutputSpecForwardServersUsernameMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecForwardServersUsernameMountFromSecretKeyRef;
        }

        export interface ClusterOutputSpecForwardServersUsernameMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecForwardServersUsernameValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecForwardServersUsernameValueFromSecretKeyRef;
        }

        export interface ClusterOutputSpecForwardServersUsernameValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecForwardTls_cert_path {
            mountFrom?: outputs.logging.v1beta1.ClusterOutputSpecForwardTls_cert_pathMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.ClusterOutputSpecForwardTls_cert_pathValueFrom;
        }

        export interface ClusterOutputSpecForwardTls_cert_pathMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecForwardTls_cert_pathMountFromSecretKeyRef;
        }

        export interface ClusterOutputSpecForwardTls_cert_pathMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecForwardTls_cert_pathValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecForwardTls_cert_pathValueFromSecretKeyRef;
        }

        export interface ClusterOutputSpecForwardTls_cert_pathValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecForwardTls_client_cert_path {
            mountFrom?: outputs.logging.v1beta1.ClusterOutputSpecForwardTls_client_cert_pathMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.ClusterOutputSpecForwardTls_client_cert_pathValueFrom;
        }

        export interface ClusterOutputSpecForwardTls_client_cert_pathMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecForwardTls_client_cert_pathMountFromSecretKeyRef;
        }

        export interface ClusterOutputSpecForwardTls_client_cert_pathMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecForwardTls_client_cert_pathValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecForwardTls_client_cert_pathValueFromSecretKeyRef;
        }

        export interface ClusterOutputSpecForwardTls_client_cert_pathValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecForwardTls_client_private_key_passphrase {
            mountFrom?: outputs.logging.v1beta1.ClusterOutputSpecForwardTls_client_private_key_passphraseMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.ClusterOutputSpecForwardTls_client_private_key_passphraseValueFrom;
        }

        export interface ClusterOutputSpecForwardTls_client_private_key_passphraseMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecForwardTls_client_private_key_passphraseMountFromSecretKeyRef;
        }

        export interface ClusterOutputSpecForwardTls_client_private_key_passphraseMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecForwardTls_client_private_key_passphraseValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecForwardTls_client_private_key_passphraseValueFromSecretKeyRef;
        }

        export interface ClusterOutputSpecForwardTls_client_private_key_passphraseValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecForwardTls_client_private_key_path {
            mountFrom?: outputs.logging.v1beta1.ClusterOutputSpecForwardTls_client_private_key_pathMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.ClusterOutputSpecForwardTls_client_private_key_pathValueFrom;
        }

        export interface ClusterOutputSpecForwardTls_client_private_key_pathMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecForwardTls_client_private_key_pathMountFromSecretKeyRef;
        }

        export interface ClusterOutputSpecForwardTls_client_private_key_pathMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecForwardTls_client_private_key_pathValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecForwardTls_client_private_key_pathValueFromSecretKeyRef;
        }

        export interface ClusterOutputSpecForwardTls_client_private_key_pathValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecGcs {
            acl?: string;
            auto_create_bucket?: boolean;
            bucket: string;
            buffer?: outputs.logging.v1beta1.ClusterOutputSpecGcsBuffer;
            client_retries?: number;
            client_timeout?: number;
            credentials_json?: outputs.logging.v1beta1.ClusterOutputSpecGcsCredentials_json;
            encryption_key?: string;
            format?: outputs.logging.v1beta1.ClusterOutputSpecGcsFormat;
            hex_random_length?: number;
            keyfile?: string;
            object_key_format?: string;
            object_metadata?: outputs.logging.v1beta1.ClusterOutputSpecGcsObject_metadata[];
            overwrite?: boolean;
            path?: string;
            project: string;
            storage_class?: string;
            store_as?: string;
            transcoding?: boolean;
        }

        export interface ClusterOutputSpecGcsBuffer {
            chunk_full_threshold?: string;
            chunk_limit_records?: number;
            chunk_limit_size?: string;
            compress?: string;
            delayed_commit_timeout?: string;
            disable_chunk_backup?: boolean;
            flush_at_shutdown?: boolean;
            flush_interval?: string;
            flush_mode?: string;
            flush_thread_burst_interval?: string;
            flush_thread_count?: number;
            flush_thread_interval?: string;
            overflow_action?: string;
            path?: string;
            queue_limit_length?: number;
            queued_chunks_limit_size?: number;
            retry_exponential_backoff_base?: string;
            retry_forever?: boolean;
            retry_max_interval?: string;
            retry_max_times?: number;
            retry_randomize?: boolean;
            retry_secondary_threshold?: string;
            retry_timeout?: string;
            retry_type?: string;
            retry_wait?: string;
            tags?: string;
            timekey?: string;
            timekey_use_utc?: boolean;
            timekey_wait?: string;
            timekey_zone?: string;
            total_limit_size?: string;
            type?: string;
        }

        export interface ClusterOutputSpecGcsCredentials_json {
            mountFrom?: outputs.logging.v1beta1.ClusterOutputSpecGcsCredentials_jsonMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.ClusterOutputSpecGcsCredentials_jsonValueFrom;
        }

        export interface ClusterOutputSpecGcsCredentials_jsonMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecGcsCredentials_jsonMountFromSecretKeyRef;
        }

        export interface ClusterOutputSpecGcsCredentials_jsonMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecGcsCredentials_jsonValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecGcsCredentials_jsonValueFromSecretKeyRef;
        }

        export interface ClusterOutputSpecGcsCredentials_jsonValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecGcsFormat {
            add_newline?: boolean;
            message_key?: string;
            type?: string;
        }

        export interface ClusterOutputSpecGcsObject_metadata {
            key: string;
            value: string;
        }

        export interface ClusterOutputSpecHttp {
            auth?: outputs.logging.v1beta1.ClusterOutputSpecHttpAuth;
            buffer?: outputs.logging.v1beta1.ClusterOutputSpecHttpBuffer;
            content_type?: string;
            endpoint: string;
            error_response_as_unrecoverable?: boolean;
            format?: outputs.logging.v1beta1.ClusterOutputSpecHttpFormat;
            headers?: { [key: string]: string };
            http_method?: string;
            json_array?: boolean;
            open_timeout?: number;
            proxy?: string;
            read_timeout?: number;
            retryable_response_codes?: number[];
            ssl_timeout?: number;
            tls_ca_cert_path?: outputs.logging.v1beta1.ClusterOutputSpecHttpTls_ca_cert_path;
            tls_ciphers?: string;
            tls_client_cert_path?: outputs.logging.v1beta1.ClusterOutputSpecHttpTls_client_cert_path;
            tls_private_key_passphrase?: outputs.logging.v1beta1.ClusterOutputSpecHttpTls_private_key_passphrase;
            tls_private_key_path?: outputs.logging.v1beta1.ClusterOutputSpecHttpTls_private_key_path;
            tls_verify_mode?: string;
            tls_version?: string;
        }

        export interface ClusterOutputSpecHttpAuth {
            password: outputs.logging.v1beta1.ClusterOutputSpecHttpAuthPassword;
            username: outputs.logging.v1beta1.ClusterOutputSpecHttpAuthUsername;
        }

        export interface ClusterOutputSpecHttpAuthPassword {
            mountFrom?: outputs.logging.v1beta1.ClusterOutputSpecHttpAuthPasswordMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.ClusterOutputSpecHttpAuthPasswordValueFrom;
        }

        export interface ClusterOutputSpecHttpAuthPasswordMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecHttpAuthPasswordMountFromSecretKeyRef;
        }

        export interface ClusterOutputSpecHttpAuthPasswordMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecHttpAuthPasswordValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecHttpAuthPasswordValueFromSecretKeyRef;
        }

        export interface ClusterOutputSpecHttpAuthPasswordValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecHttpAuthUsername {
            mountFrom?: outputs.logging.v1beta1.ClusterOutputSpecHttpAuthUsernameMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.ClusterOutputSpecHttpAuthUsernameValueFrom;
        }

        export interface ClusterOutputSpecHttpAuthUsernameMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecHttpAuthUsernameMountFromSecretKeyRef;
        }

        export interface ClusterOutputSpecHttpAuthUsernameMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecHttpAuthUsernameValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecHttpAuthUsernameValueFromSecretKeyRef;
        }

        export interface ClusterOutputSpecHttpAuthUsernameValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecHttpBuffer {
            chunk_full_threshold?: string;
            chunk_limit_records?: number;
            chunk_limit_size?: string;
            compress?: string;
            delayed_commit_timeout?: string;
            disable_chunk_backup?: boolean;
            flush_at_shutdown?: boolean;
            flush_interval?: string;
            flush_mode?: string;
            flush_thread_burst_interval?: string;
            flush_thread_count?: number;
            flush_thread_interval?: string;
            overflow_action?: string;
            path?: string;
            queue_limit_length?: number;
            queued_chunks_limit_size?: number;
            retry_exponential_backoff_base?: string;
            retry_forever?: boolean;
            retry_max_interval?: string;
            retry_max_times?: number;
            retry_randomize?: boolean;
            retry_secondary_threshold?: string;
            retry_timeout?: string;
            retry_type?: string;
            retry_wait?: string;
            tags?: string;
            timekey?: string;
            timekey_use_utc?: boolean;
            timekey_wait?: string;
            timekey_zone?: string;
            total_limit_size?: string;
            type?: string;
        }

        export interface ClusterOutputSpecHttpFormat {
            add_newline?: boolean;
            message_key?: string;
            type?: string;
        }

        export interface ClusterOutputSpecHttpTls_ca_cert_path {
            mountFrom?: outputs.logging.v1beta1.ClusterOutputSpecHttpTls_ca_cert_pathMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.ClusterOutputSpecHttpTls_ca_cert_pathValueFrom;
        }

        export interface ClusterOutputSpecHttpTls_ca_cert_pathMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecHttpTls_ca_cert_pathMountFromSecretKeyRef;
        }

        export interface ClusterOutputSpecHttpTls_ca_cert_pathMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecHttpTls_ca_cert_pathValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecHttpTls_ca_cert_pathValueFromSecretKeyRef;
        }

        export interface ClusterOutputSpecHttpTls_ca_cert_pathValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecHttpTls_client_cert_path {
            mountFrom?: outputs.logging.v1beta1.ClusterOutputSpecHttpTls_client_cert_pathMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.ClusterOutputSpecHttpTls_client_cert_pathValueFrom;
        }

        export interface ClusterOutputSpecHttpTls_client_cert_pathMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecHttpTls_client_cert_pathMountFromSecretKeyRef;
        }

        export interface ClusterOutputSpecHttpTls_client_cert_pathMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecHttpTls_client_cert_pathValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecHttpTls_client_cert_pathValueFromSecretKeyRef;
        }

        export interface ClusterOutputSpecHttpTls_client_cert_pathValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecHttpTls_private_key_passphrase {
            mountFrom?: outputs.logging.v1beta1.ClusterOutputSpecHttpTls_private_key_passphraseMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.ClusterOutputSpecHttpTls_private_key_passphraseValueFrom;
        }

        export interface ClusterOutputSpecHttpTls_private_key_passphraseMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecHttpTls_private_key_passphraseMountFromSecretKeyRef;
        }

        export interface ClusterOutputSpecHttpTls_private_key_passphraseMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecHttpTls_private_key_passphraseValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecHttpTls_private_key_passphraseValueFromSecretKeyRef;
        }

        export interface ClusterOutputSpecHttpTls_private_key_passphraseValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecHttpTls_private_key_path {
            mountFrom?: outputs.logging.v1beta1.ClusterOutputSpecHttpTls_private_key_pathMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.ClusterOutputSpecHttpTls_private_key_pathValueFrom;
        }

        export interface ClusterOutputSpecHttpTls_private_key_pathMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecHttpTls_private_key_pathMountFromSecretKeyRef;
        }

        export interface ClusterOutputSpecHttpTls_private_key_pathMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecHttpTls_private_key_pathValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecHttpTls_private_key_pathValueFromSecretKeyRef;
        }

        export interface ClusterOutputSpecHttpTls_private_key_pathValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecKafka {
            ack_timeout?: number;
            brokers: string;
            buffer?: outputs.logging.v1beta1.ClusterOutputSpecKafkaBuffer;
            compression_codec?: string;
            default_message_key?: string;
            default_partition_key?: string;
            default_topic?: string;
            exclude_partion_key?: boolean;
            exclude_topic_key?: boolean;
            format: outputs.logging.v1beta1.ClusterOutputSpecKafkaFormat;
            get_kafka_client_log?: boolean;
            headers?: { [key: string]: string };
            headers_from_record?: { [key: string]: string };
            idempotent?: boolean;
            max_send_retries?: number;
            message_key_key?: string;
            partition_key?: string;
            partition_key_key?: string;
            password?: outputs.logging.v1beta1.ClusterOutputSpecKafkaPassword;
            required_acks?: number;
            sasl_over_ssl?: boolean;
            scram_mechanism?: string;
            ssl_ca_cert?: outputs.logging.v1beta1.ClusterOutputSpecKafkaSsl_ca_cert;
            ssl_ca_certs_from_system?: boolean;
            ssl_client_cert?: outputs.logging.v1beta1.ClusterOutputSpecKafkaSsl_client_cert;
            ssl_client_cert_chain?: outputs.logging.v1beta1.ClusterOutputSpecKafkaSsl_client_cert_chain;
            ssl_client_cert_key?: outputs.logging.v1beta1.ClusterOutputSpecKafkaSsl_client_cert_key;
            ssl_verify_hostname?: boolean;
            topic_key?: string;
            use_default_for_unknown_topic?: boolean;
            username?: outputs.logging.v1beta1.ClusterOutputSpecKafkaUsername;
        }

        export interface ClusterOutputSpecKafkaBuffer {
            chunk_full_threshold?: string;
            chunk_limit_records?: number;
            chunk_limit_size?: string;
            compress?: string;
            delayed_commit_timeout?: string;
            disable_chunk_backup?: boolean;
            flush_at_shutdown?: boolean;
            flush_interval?: string;
            flush_mode?: string;
            flush_thread_burst_interval?: string;
            flush_thread_count?: number;
            flush_thread_interval?: string;
            overflow_action?: string;
            path?: string;
            queue_limit_length?: number;
            queued_chunks_limit_size?: number;
            retry_exponential_backoff_base?: string;
            retry_forever?: boolean;
            retry_max_interval?: string;
            retry_max_times?: number;
            retry_randomize?: boolean;
            retry_secondary_threshold?: string;
            retry_timeout?: string;
            retry_type?: string;
            retry_wait?: string;
            tags?: string;
            timekey?: string;
            timekey_use_utc?: boolean;
            timekey_wait?: string;
            timekey_zone?: string;
            total_limit_size?: string;
            type?: string;
        }

        export interface ClusterOutputSpecKafkaFormat {
            add_newline?: boolean;
            message_key?: string;
            type?: string;
        }

        export interface ClusterOutputSpecKafkaPassword {
            mountFrom?: outputs.logging.v1beta1.ClusterOutputSpecKafkaPasswordMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.ClusterOutputSpecKafkaPasswordValueFrom;
        }

        export interface ClusterOutputSpecKafkaPasswordMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecKafkaPasswordMountFromSecretKeyRef;
        }

        export interface ClusterOutputSpecKafkaPasswordMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecKafkaPasswordValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecKafkaPasswordValueFromSecretKeyRef;
        }

        export interface ClusterOutputSpecKafkaPasswordValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecKafkaSsl_ca_cert {
            mountFrom?: outputs.logging.v1beta1.ClusterOutputSpecKafkaSsl_ca_certMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.ClusterOutputSpecKafkaSsl_ca_certValueFrom;
        }

        export interface ClusterOutputSpecKafkaSsl_ca_certMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecKafkaSsl_ca_certMountFromSecretKeyRef;
        }

        export interface ClusterOutputSpecKafkaSsl_ca_certMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecKafkaSsl_ca_certValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecKafkaSsl_ca_certValueFromSecretKeyRef;
        }

        export interface ClusterOutputSpecKafkaSsl_ca_certValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecKafkaSsl_client_cert {
            mountFrom?: outputs.logging.v1beta1.ClusterOutputSpecKafkaSsl_client_certMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.ClusterOutputSpecKafkaSsl_client_certValueFrom;
        }

        export interface ClusterOutputSpecKafkaSsl_client_certMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecKafkaSsl_client_certMountFromSecretKeyRef;
        }

        export interface ClusterOutputSpecKafkaSsl_client_certMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecKafkaSsl_client_certValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecKafkaSsl_client_certValueFromSecretKeyRef;
        }

        export interface ClusterOutputSpecKafkaSsl_client_certValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecKafkaSsl_client_cert_chain {
            mountFrom?: outputs.logging.v1beta1.ClusterOutputSpecKafkaSsl_client_cert_chainMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.ClusterOutputSpecKafkaSsl_client_cert_chainValueFrom;
        }

        export interface ClusterOutputSpecKafkaSsl_client_cert_chainMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecKafkaSsl_client_cert_chainMountFromSecretKeyRef;
        }

        export interface ClusterOutputSpecKafkaSsl_client_cert_chainMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecKafkaSsl_client_cert_chainValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecKafkaSsl_client_cert_chainValueFromSecretKeyRef;
        }

        export interface ClusterOutputSpecKafkaSsl_client_cert_chainValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecKafkaSsl_client_cert_key {
            mountFrom?: outputs.logging.v1beta1.ClusterOutputSpecKafkaSsl_client_cert_keyMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.ClusterOutputSpecKafkaSsl_client_cert_keyValueFrom;
        }

        export interface ClusterOutputSpecKafkaSsl_client_cert_keyMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecKafkaSsl_client_cert_keyMountFromSecretKeyRef;
        }

        export interface ClusterOutputSpecKafkaSsl_client_cert_keyMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecKafkaSsl_client_cert_keyValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecKafkaSsl_client_cert_keyValueFromSecretKeyRef;
        }

        export interface ClusterOutputSpecKafkaSsl_client_cert_keyValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecKafkaUsername {
            mountFrom?: outputs.logging.v1beta1.ClusterOutputSpecKafkaUsernameMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.ClusterOutputSpecKafkaUsernameValueFrom;
        }

        export interface ClusterOutputSpecKafkaUsernameMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecKafkaUsernameMountFromSecretKeyRef;
        }

        export interface ClusterOutputSpecKafkaUsernameMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecKafkaUsernameValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecKafkaUsernameValueFromSecretKeyRef;
        }

        export interface ClusterOutputSpecKafkaUsernameValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecKinesisStream {
            assume_role_credentials?: outputs.logging.v1beta1.ClusterOutputSpecKinesisStreamAssume_role_credentials;
            aws_iam_retries?: number;
            aws_key_id?: outputs.logging.v1beta1.ClusterOutputSpecKinesisStreamAws_key_id;
            aws_sec_key?: outputs.logging.v1beta1.ClusterOutputSpecKinesisStreamAws_sec_key;
            aws_ses_token?: outputs.logging.v1beta1.ClusterOutputSpecKinesisStreamAws_ses_token;
            batch_request_max_count?: number;
            batch_request_max_size?: number;
            buffer?: outputs.logging.v1beta1.ClusterOutputSpecKinesisStreamBuffer;
            format?: outputs.logging.v1beta1.ClusterOutputSpecKinesisStreamFormat;
            partition_key?: string;
            process_credentials?: outputs.logging.v1beta1.ClusterOutputSpecKinesisStreamProcess_credentials;
            region?: string;
            reset_backoff_if_success?: boolean;
            retries_on_batch_request?: number;
            stream_name: string;
        }

        export interface ClusterOutputSpecKinesisStreamAssume_role_credentials {
            duration_seconds?: string;
            external_id?: string;
            policy?: string;
            role_arn: string;
            role_session_name: string;
        }

        export interface ClusterOutputSpecKinesisStreamAws_key_id {
            mountFrom?: outputs.logging.v1beta1.ClusterOutputSpecKinesisStreamAws_key_idMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.ClusterOutputSpecKinesisStreamAws_key_idValueFrom;
        }

        export interface ClusterOutputSpecKinesisStreamAws_key_idMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecKinesisStreamAws_key_idMountFromSecretKeyRef;
        }

        export interface ClusterOutputSpecKinesisStreamAws_key_idMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecKinesisStreamAws_key_idValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecKinesisStreamAws_key_idValueFromSecretKeyRef;
        }

        export interface ClusterOutputSpecKinesisStreamAws_key_idValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecKinesisStreamAws_sec_key {
            mountFrom?: outputs.logging.v1beta1.ClusterOutputSpecKinesisStreamAws_sec_keyMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.ClusterOutputSpecKinesisStreamAws_sec_keyValueFrom;
        }

        export interface ClusterOutputSpecKinesisStreamAws_sec_keyMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecKinesisStreamAws_sec_keyMountFromSecretKeyRef;
        }

        export interface ClusterOutputSpecKinesisStreamAws_sec_keyMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecKinesisStreamAws_sec_keyValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecKinesisStreamAws_sec_keyValueFromSecretKeyRef;
        }

        export interface ClusterOutputSpecKinesisStreamAws_sec_keyValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecKinesisStreamAws_ses_token {
            mountFrom?: outputs.logging.v1beta1.ClusterOutputSpecKinesisStreamAws_ses_tokenMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.ClusterOutputSpecKinesisStreamAws_ses_tokenValueFrom;
        }

        export interface ClusterOutputSpecKinesisStreamAws_ses_tokenMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecKinesisStreamAws_ses_tokenMountFromSecretKeyRef;
        }

        export interface ClusterOutputSpecKinesisStreamAws_ses_tokenMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecKinesisStreamAws_ses_tokenValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecKinesisStreamAws_ses_tokenValueFromSecretKeyRef;
        }

        export interface ClusterOutputSpecKinesisStreamAws_ses_tokenValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecKinesisStreamBuffer {
            chunk_full_threshold?: string;
            chunk_limit_records?: number;
            chunk_limit_size?: string;
            compress?: string;
            delayed_commit_timeout?: string;
            disable_chunk_backup?: boolean;
            flush_at_shutdown?: boolean;
            flush_interval?: string;
            flush_mode?: string;
            flush_thread_burst_interval?: string;
            flush_thread_count?: number;
            flush_thread_interval?: string;
            overflow_action?: string;
            path?: string;
            queue_limit_length?: number;
            queued_chunks_limit_size?: number;
            retry_exponential_backoff_base?: string;
            retry_forever?: boolean;
            retry_max_interval?: string;
            retry_max_times?: number;
            retry_randomize?: boolean;
            retry_secondary_threshold?: string;
            retry_timeout?: string;
            retry_type?: string;
            retry_wait?: string;
            tags?: string;
            timekey?: string;
            timekey_use_utc?: boolean;
            timekey_wait?: string;
            timekey_zone?: string;
            total_limit_size?: string;
            type?: string;
        }

        export interface ClusterOutputSpecKinesisStreamFormat {
            add_newline?: boolean;
            message_key?: string;
            type?: string;
        }

        export interface ClusterOutputSpecKinesisStreamProcess_credentials {
            process: string;
        }

        export interface ClusterOutputSpecLogdna {
            api_key: string;
            app?: string;
            buffer_chunk_limit?: string;
            hostname: string;
        }

        export interface ClusterOutputSpecLogz {
            buffer?: outputs.logging.v1beta1.ClusterOutputSpecLogzBuffer;
            endpoint: outputs.logging.v1beta1.ClusterOutputSpecLogzEndpoint;
            gzip?: boolean;
            http_idle_timeout?: number;
            output_include_tags?: boolean;
            output_include_time?: boolean;
            retry_count?: number;
            retry_sleep?: number;
        }

        export interface ClusterOutputSpecLogzBuffer {
            chunk_full_threshold?: string;
            chunk_limit_records?: number;
            chunk_limit_size?: string;
            compress?: string;
            delayed_commit_timeout?: string;
            disable_chunk_backup?: boolean;
            flush_at_shutdown?: boolean;
            flush_interval?: string;
            flush_mode?: string;
            flush_thread_burst_interval?: string;
            flush_thread_count?: number;
            flush_thread_interval?: string;
            overflow_action?: string;
            path?: string;
            queue_limit_length?: number;
            queued_chunks_limit_size?: number;
            retry_exponential_backoff_base?: string;
            retry_forever?: boolean;
            retry_max_interval?: string;
            retry_max_times?: number;
            retry_randomize?: boolean;
            retry_secondary_threshold?: string;
            retry_timeout?: string;
            retry_type?: string;
            retry_wait?: string;
            tags?: string;
            timekey?: string;
            timekey_use_utc?: boolean;
            timekey_wait?: string;
            timekey_zone?: string;
            total_limit_size?: string;
            type?: string;
        }

        export interface ClusterOutputSpecLogzEndpoint {
            port?: number;
            token?: outputs.logging.v1beta1.ClusterOutputSpecLogzEndpointToken;
            url?: string;
        }

        export interface ClusterOutputSpecLogzEndpointToken {
            mountFrom?: outputs.logging.v1beta1.ClusterOutputSpecLogzEndpointTokenMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.ClusterOutputSpecLogzEndpointTokenValueFrom;
        }

        export interface ClusterOutputSpecLogzEndpointTokenMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecLogzEndpointTokenMountFromSecretKeyRef;
        }

        export interface ClusterOutputSpecLogzEndpointTokenMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecLogzEndpointTokenValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecLogzEndpointTokenValueFromSecretKeyRef;
        }

        export interface ClusterOutputSpecLogzEndpointTokenValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecLoki {
            buffer?: outputs.logging.v1beta1.ClusterOutputSpecLokiBuffer;
            ca_cert?: outputs.logging.v1beta1.ClusterOutputSpecLokiCa_cert;
            cert?: outputs.logging.v1beta1.ClusterOutputSpecLokiCert;
            configure_kubernetes_labels?: boolean;
            drop_single_key?: boolean;
            extra_labels?: { [key: string]: string };
            extract_kubernetes_labels?: boolean;
            insecure_tls?: boolean;
            key?: outputs.logging.v1beta1.ClusterOutputSpecLokiKey;
            labels?: { [key: string]: string };
            line_format?: string;
            password?: outputs.logging.v1beta1.ClusterOutputSpecLokiPassword;
            remove_keys?: string[];
            tenant?: string;
            url?: string;
            username?: outputs.logging.v1beta1.ClusterOutputSpecLokiUsername;
        }

        export interface ClusterOutputSpecLokiBuffer {
            chunk_full_threshold?: string;
            chunk_limit_records?: number;
            chunk_limit_size?: string;
            compress?: string;
            delayed_commit_timeout?: string;
            disable_chunk_backup?: boolean;
            flush_at_shutdown?: boolean;
            flush_interval?: string;
            flush_mode?: string;
            flush_thread_burst_interval?: string;
            flush_thread_count?: number;
            flush_thread_interval?: string;
            overflow_action?: string;
            path?: string;
            queue_limit_length?: number;
            queued_chunks_limit_size?: number;
            retry_exponential_backoff_base?: string;
            retry_forever?: boolean;
            retry_max_interval?: string;
            retry_max_times?: number;
            retry_randomize?: boolean;
            retry_secondary_threshold?: string;
            retry_timeout?: string;
            retry_type?: string;
            retry_wait?: string;
            tags?: string;
            timekey?: string;
            timekey_use_utc?: boolean;
            timekey_wait?: string;
            timekey_zone?: string;
            total_limit_size?: string;
            type?: string;
        }

        export interface ClusterOutputSpecLokiCa_cert {
            mountFrom?: outputs.logging.v1beta1.ClusterOutputSpecLokiCa_certMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.ClusterOutputSpecLokiCa_certValueFrom;
        }

        export interface ClusterOutputSpecLokiCa_certMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecLokiCa_certMountFromSecretKeyRef;
        }

        export interface ClusterOutputSpecLokiCa_certMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecLokiCa_certValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecLokiCa_certValueFromSecretKeyRef;
        }

        export interface ClusterOutputSpecLokiCa_certValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecLokiCert {
            mountFrom?: outputs.logging.v1beta1.ClusterOutputSpecLokiCertMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.ClusterOutputSpecLokiCertValueFrom;
        }

        export interface ClusterOutputSpecLokiCertMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecLokiCertMountFromSecretKeyRef;
        }

        export interface ClusterOutputSpecLokiCertMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecLokiCertValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecLokiCertValueFromSecretKeyRef;
        }

        export interface ClusterOutputSpecLokiCertValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecLokiKey {
            mountFrom?: outputs.logging.v1beta1.ClusterOutputSpecLokiKeyMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.ClusterOutputSpecLokiKeyValueFrom;
        }

        export interface ClusterOutputSpecLokiKeyMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecLokiKeyMountFromSecretKeyRef;
        }

        export interface ClusterOutputSpecLokiKeyMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecLokiKeyValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecLokiKeyValueFromSecretKeyRef;
        }

        export interface ClusterOutputSpecLokiKeyValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecLokiPassword {
            mountFrom?: outputs.logging.v1beta1.ClusterOutputSpecLokiPasswordMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.ClusterOutputSpecLokiPasswordValueFrom;
        }

        export interface ClusterOutputSpecLokiPasswordMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecLokiPasswordMountFromSecretKeyRef;
        }

        export interface ClusterOutputSpecLokiPasswordMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecLokiPasswordValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecLokiPasswordValueFromSecretKeyRef;
        }

        export interface ClusterOutputSpecLokiPasswordValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecLokiUsername {
            mountFrom?: outputs.logging.v1beta1.ClusterOutputSpecLokiUsernameMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.ClusterOutputSpecLokiUsernameValueFrom;
        }

        export interface ClusterOutputSpecLokiUsernameMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecLokiUsernameMountFromSecretKeyRef;
        }

        export interface ClusterOutputSpecLokiUsernameMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecLokiUsernameValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecLokiUsernameValueFromSecretKeyRef;
        }

        export interface ClusterOutputSpecLokiUsernameValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecNewrelic {
            api_key?: outputs.logging.v1beta1.ClusterOutputSpecNewrelicApi_key;
            base_uri?: string;
            license_key?: outputs.logging.v1beta1.ClusterOutputSpecNewrelicLicense_key;
        }

        export interface ClusterOutputSpecNewrelicApi_key {
            mountFrom?: outputs.logging.v1beta1.ClusterOutputSpecNewrelicApi_keyMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.ClusterOutputSpecNewrelicApi_keyValueFrom;
        }

        export interface ClusterOutputSpecNewrelicApi_keyMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecNewrelicApi_keyMountFromSecretKeyRef;
        }

        export interface ClusterOutputSpecNewrelicApi_keyMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecNewrelicApi_keyValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecNewrelicApi_keyValueFromSecretKeyRef;
        }

        export interface ClusterOutputSpecNewrelicApi_keyValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecNewrelicLicense_key {
            mountFrom?: outputs.logging.v1beta1.ClusterOutputSpecNewrelicLicense_keyMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.ClusterOutputSpecNewrelicLicense_keyValueFrom;
        }

        export interface ClusterOutputSpecNewrelicLicense_keyMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecNewrelicLicense_keyMountFromSecretKeyRef;
        }

        export interface ClusterOutputSpecNewrelicLicense_keyMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecNewrelicLicense_keyValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecNewrelicLicense_keyValueFromSecretKeyRef;
        }

        export interface ClusterOutputSpecNewrelicLicense_keyValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecOss {
            aaccess_key_secret: outputs.logging.v1beta1.ClusterOutputSpecOssAaccess_key_secret;
            access_key_id: outputs.logging.v1beta1.ClusterOutputSpecOssAccess_key_id;
            auto_create_bucket?: boolean;
            bucket: string;
            buffer?: outputs.logging.v1beta1.ClusterOutputSpecOssBuffer;
            check_bucket?: boolean;
            check_object?: boolean;
            download_crc_enable?: boolean;
            endpoint: string;
            format?: outputs.logging.v1beta1.ClusterOutputSpecOssFormat;
            hex_random_length?: number;
            index_format?: string;
            key_format?: string;
            open_timeout?: number;
            oss_sdk_log_dir?: string;
            overwrite?: boolean;
            path?: string;
            read_timeout?: number;
            store_as?: string;
            upload_crc_enable?: boolean;
            warn_for_delay?: string;
        }

        export interface ClusterOutputSpecOssAaccess_key_secret {
            mountFrom?: outputs.logging.v1beta1.ClusterOutputSpecOssAaccess_key_secretMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.ClusterOutputSpecOssAaccess_key_secretValueFrom;
        }

        export interface ClusterOutputSpecOssAaccess_key_secretMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecOssAaccess_key_secretMountFromSecretKeyRef;
        }

        export interface ClusterOutputSpecOssAaccess_key_secretMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecOssAaccess_key_secretValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecOssAaccess_key_secretValueFromSecretKeyRef;
        }

        export interface ClusterOutputSpecOssAaccess_key_secretValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecOssAccess_key_id {
            mountFrom?: outputs.logging.v1beta1.ClusterOutputSpecOssAccess_key_idMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.ClusterOutputSpecOssAccess_key_idValueFrom;
        }

        export interface ClusterOutputSpecOssAccess_key_idMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecOssAccess_key_idMountFromSecretKeyRef;
        }

        export interface ClusterOutputSpecOssAccess_key_idMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecOssAccess_key_idValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecOssAccess_key_idValueFromSecretKeyRef;
        }

        export interface ClusterOutputSpecOssAccess_key_idValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecOssBuffer {
            chunk_full_threshold?: string;
            chunk_limit_records?: number;
            chunk_limit_size?: string;
            compress?: string;
            delayed_commit_timeout?: string;
            disable_chunk_backup?: boolean;
            flush_at_shutdown?: boolean;
            flush_interval?: string;
            flush_mode?: string;
            flush_thread_burst_interval?: string;
            flush_thread_count?: number;
            flush_thread_interval?: string;
            overflow_action?: string;
            path?: string;
            queue_limit_length?: number;
            queued_chunks_limit_size?: number;
            retry_exponential_backoff_base?: string;
            retry_forever?: boolean;
            retry_max_interval?: string;
            retry_max_times?: number;
            retry_randomize?: boolean;
            retry_secondary_threshold?: string;
            retry_timeout?: string;
            retry_type?: string;
            retry_wait?: string;
            tags?: string;
            timekey?: string;
            timekey_use_utc?: boolean;
            timekey_wait?: string;
            timekey_zone?: string;
            total_limit_size?: string;
            type?: string;
        }

        export interface ClusterOutputSpecOssFormat {
            add_newline?: boolean;
            message_key?: string;
            type?: string;
        }

        export interface ClusterOutputSpecRedis {
            allow_duplicate_key?: boolean;
            buffer?: outputs.logging.v1beta1.ClusterOutputSpecRedisBuffer;
            db_number?: number;
            format?: outputs.logging.v1beta1.ClusterOutputSpecRedisFormat;
            host?: string;
            insert_key_prefix?: string;
            password?: outputs.logging.v1beta1.ClusterOutputSpecRedisPassword;
            port?: number;
            strftime_format?: string;
            ttl?: number;
        }

        export interface ClusterOutputSpecRedisBuffer {
            chunk_full_threshold?: string;
            chunk_limit_records?: number;
            chunk_limit_size?: string;
            compress?: string;
            delayed_commit_timeout?: string;
            disable_chunk_backup?: boolean;
            flush_at_shutdown?: boolean;
            flush_interval?: string;
            flush_mode?: string;
            flush_thread_burst_interval?: string;
            flush_thread_count?: number;
            flush_thread_interval?: string;
            overflow_action?: string;
            path?: string;
            queue_limit_length?: number;
            queued_chunks_limit_size?: number;
            retry_exponential_backoff_base?: string;
            retry_forever?: boolean;
            retry_max_interval?: string;
            retry_max_times?: number;
            retry_randomize?: boolean;
            retry_secondary_threshold?: string;
            retry_timeout?: string;
            retry_type?: string;
            retry_wait?: string;
            tags?: string;
            timekey?: string;
            timekey_use_utc?: boolean;
            timekey_wait?: string;
            timekey_zone?: string;
            total_limit_size?: string;
            type?: string;
        }

        export interface ClusterOutputSpecRedisFormat {
            add_newline?: boolean;
            message_key?: string;
            type?: string;
        }

        export interface ClusterOutputSpecRedisPassword {
            mountFrom?: outputs.logging.v1beta1.ClusterOutputSpecRedisPasswordMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.ClusterOutputSpecRedisPasswordValueFrom;
        }

        export interface ClusterOutputSpecRedisPasswordMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecRedisPasswordMountFromSecretKeyRef;
        }

        export interface ClusterOutputSpecRedisPasswordMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecRedisPasswordValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecRedisPasswordValueFromSecretKeyRef;
        }

        export interface ClusterOutputSpecRedisPasswordValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecS3 {
            acl?: string;
            assume_role_credentials?: outputs.logging.v1beta1.ClusterOutputSpecS3Assume_role_credentials;
            auto_create_bucket?: string;
            aws_iam_retries?: string;
            aws_key_id?: outputs.logging.v1beta1.ClusterOutputSpecS3Aws_key_id;
            aws_sec_key?: outputs.logging.v1beta1.ClusterOutputSpecS3Aws_sec_key;
            buffer?: outputs.logging.v1beta1.ClusterOutputSpecS3Buffer;
            check_apikey_on_start?: string;
            check_bucket?: string;
            check_object?: string;
            clustername?: string;
            compute_checksums?: string;
            enable_transfer_acceleration?: string;
            force_path_style?: string;
            format?: outputs.logging.v1beta1.ClusterOutputSpecS3Format;
            grant_full_control?: string;
            grant_read?: string;
            grant_read_acp?: string;
            grant_write_acp?: string;
            hex_random_length?: string;
            index_format?: string;
            instance_profile_credentials?: outputs.logging.v1beta1.ClusterOutputSpecS3Instance_profile_credentials;
            oneeye_format?: boolean;
            overwrite?: string;
            path?: string;
            proxy_uri?: string;
            s3_bucket: string;
            s3_endpoint?: string;
            s3_metadata?: string;
            s3_object_key_format?: string;
            s3_region?: string;
            shared_credentials?: outputs.logging.v1beta1.ClusterOutputSpecS3Shared_credentials;
            signature_version?: string;
            sse_customer_algorithm?: string;
            sse_customer_key?: string;
            sse_customer_key_md5?: string;
            ssekms_key_id?: string;
            ssl_verify_peer?: string;
            storage_class?: string;
            store_as?: string;
            use_bundled_cert?: string;
            use_server_side_encryption?: string;
            warn_for_delay?: string;
        }

        export interface ClusterOutputSpecS3Assume_role_credentials {
            duration_seconds?: string;
            external_id?: string;
            policy?: string;
            role_arn: string;
            role_session_name: string;
        }

        export interface ClusterOutputSpecS3Aws_key_id {
            mountFrom?: outputs.logging.v1beta1.ClusterOutputSpecS3Aws_key_idMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.ClusterOutputSpecS3Aws_key_idValueFrom;
        }

        export interface ClusterOutputSpecS3Aws_key_idMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecS3Aws_key_idMountFromSecretKeyRef;
        }

        export interface ClusterOutputSpecS3Aws_key_idMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecS3Aws_key_idValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecS3Aws_key_idValueFromSecretKeyRef;
        }

        export interface ClusterOutputSpecS3Aws_key_idValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecS3Aws_sec_key {
            mountFrom?: outputs.logging.v1beta1.ClusterOutputSpecS3Aws_sec_keyMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.ClusterOutputSpecS3Aws_sec_keyValueFrom;
        }

        export interface ClusterOutputSpecS3Aws_sec_keyMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecS3Aws_sec_keyMountFromSecretKeyRef;
        }

        export interface ClusterOutputSpecS3Aws_sec_keyMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecS3Aws_sec_keyValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecS3Aws_sec_keyValueFromSecretKeyRef;
        }

        export interface ClusterOutputSpecS3Aws_sec_keyValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecS3Buffer {
            chunk_full_threshold?: string;
            chunk_limit_records?: number;
            chunk_limit_size?: string;
            compress?: string;
            delayed_commit_timeout?: string;
            disable_chunk_backup?: boolean;
            flush_at_shutdown?: boolean;
            flush_interval?: string;
            flush_mode?: string;
            flush_thread_burst_interval?: string;
            flush_thread_count?: number;
            flush_thread_interval?: string;
            overflow_action?: string;
            path?: string;
            queue_limit_length?: number;
            queued_chunks_limit_size?: number;
            retry_exponential_backoff_base?: string;
            retry_forever?: boolean;
            retry_max_interval?: string;
            retry_max_times?: number;
            retry_randomize?: boolean;
            retry_secondary_threshold?: string;
            retry_timeout?: string;
            retry_type?: string;
            retry_wait?: string;
            tags?: string;
            timekey?: string;
            timekey_use_utc?: boolean;
            timekey_wait?: string;
            timekey_zone?: string;
            total_limit_size?: string;
            type?: string;
        }

        export interface ClusterOutputSpecS3Format {
            add_newline?: boolean;
            message_key?: string;
            type?: string;
        }

        export interface ClusterOutputSpecS3Instance_profile_credentials {
            http_open_timeout?: string;
            http_read_timeout?: string;
            ip_address?: string;
            port?: string;
            retries?: string;
        }

        export interface ClusterOutputSpecS3Shared_credentials {
            path?: string;
            profile_name?: string;
        }

        export interface ClusterOutputSpecSplunkHec {
            buffer?: outputs.logging.v1beta1.ClusterOutputSpecSplunkHecBuffer;
            ca_file?: outputs.logging.v1beta1.ClusterOutputSpecSplunkHecCa_file;
            ca_path?: outputs.logging.v1beta1.ClusterOutputSpecSplunkHecCa_path;
            client_cert?: outputs.logging.v1beta1.ClusterOutputSpecSplunkHecClient_cert;
            client_key?: outputs.logging.v1beta1.ClusterOutputSpecSplunkHecClient_key;
            coerce_to_utf8?: boolean;
            data_type?: string;
            fields?: { [key: string]: string };
            format?: outputs.logging.v1beta1.ClusterOutputSpecSplunkHecFormat;
            hec_host: string;
            hec_port?: number;
            hec_token: outputs.logging.v1beta1.ClusterOutputSpecSplunkHecHec_token;
            host?: string;
            host_key?: string;
            idle_timeout?: number;
            index?: string;
            index_key?: string;
            insecure_ssl?: boolean;
            keep_keys?: boolean;
            metric_name_key?: string;
            metric_value_key?: string;
            metrics_from_event?: boolean;
            non_utf8_replacement_string?: string;
            open_timeout?: number;
            protocol?: string;
            read_timeout?: number;
            source?: string;
            source_key?: string;
            sourcetype?: string;
            sourcetype_key?: string;
            ssl_ciphers?: string;
        }

        export interface ClusterOutputSpecSplunkHecBuffer {
            chunk_full_threshold?: string;
            chunk_limit_records?: number;
            chunk_limit_size?: string;
            compress?: string;
            delayed_commit_timeout?: string;
            disable_chunk_backup?: boolean;
            flush_at_shutdown?: boolean;
            flush_interval?: string;
            flush_mode?: string;
            flush_thread_burst_interval?: string;
            flush_thread_count?: number;
            flush_thread_interval?: string;
            overflow_action?: string;
            path?: string;
            queue_limit_length?: number;
            queued_chunks_limit_size?: number;
            retry_exponential_backoff_base?: string;
            retry_forever?: boolean;
            retry_max_interval?: string;
            retry_max_times?: number;
            retry_randomize?: boolean;
            retry_secondary_threshold?: string;
            retry_timeout?: string;
            retry_type?: string;
            retry_wait?: string;
            tags?: string;
            timekey?: string;
            timekey_use_utc?: boolean;
            timekey_wait?: string;
            timekey_zone?: string;
            total_limit_size?: string;
            type?: string;
        }

        export interface ClusterOutputSpecSplunkHecCa_file {
            mountFrom?: outputs.logging.v1beta1.ClusterOutputSpecSplunkHecCa_fileMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.ClusterOutputSpecSplunkHecCa_fileValueFrom;
        }

        export interface ClusterOutputSpecSplunkHecCa_fileMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecSplunkHecCa_fileMountFromSecretKeyRef;
        }

        export interface ClusterOutputSpecSplunkHecCa_fileMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecSplunkHecCa_fileValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecSplunkHecCa_fileValueFromSecretKeyRef;
        }

        export interface ClusterOutputSpecSplunkHecCa_fileValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecSplunkHecCa_path {
            mountFrom?: outputs.logging.v1beta1.ClusterOutputSpecSplunkHecCa_pathMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.ClusterOutputSpecSplunkHecCa_pathValueFrom;
        }

        export interface ClusterOutputSpecSplunkHecCa_pathMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecSplunkHecCa_pathMountFromSecretKeyRef;
        }

        export interface ClusterOutputSpecSplunkHecCa_pathMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecSplunkHecCa_pathValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecSplunkHecCa_pathValueFromSecretKeyRef;
        }

        export interface ClusterOutputSpecSplunkHecCa_pathValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecSplunkHecClient_cert {
            mountFrom?: outputs.logging.v1beta1.ClusterOutputSpecSplunkHecClient_certMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.ClusterOutputSpecSplunkHecClient_certValueFrom;
        }

        export interface ClusterOutputSpecSplunkHecClient_certMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecSplunkHecClient_certMountFromSecretKeyRef;
        }

        export interface ClusterOutputSpecSplunkHecClient_certMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecSplunkHecClient_certValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecSplunkHecClient_certValueFromSecretKeyRef;
        }

        export interface ClusterOutputSpecSplunkHecClient_certValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecSplunkHecClient_key {
            mountFrom?: outputs.logging.v1beta1.ClusterOutputSpecSplunkHecClient_keyMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.ClusterOutputSpecSplunkHecClient_keyValueFrom;
        }

        export interface ClusterOutputSpecSplunkHecClient_keyMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecSplunkHecClient_keyMountFromSecretKeyRef;
        }

        export interface ClusterOutputSpecSplunkHecClient_keyMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecSplunkHecClient_keyValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecSplunkHecClient_keyValueFromSecretKeyRef;
        }

        export interface ClusterOutputSpecSplunkHecClient_keyValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecSplunkHecFormat {
            add_newline?: boolean;
            message_key?: string;
            type?: string;
        }

        export interface ClusterOutputSpecSplunkHecHec_token {
            mountFrom?: outputs.logging.v1beta1.ClusterOutputSpecSplunkHecHec_tokenMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.ClusterOutputSpecSplunkHecHec_tokenValueFrom;
        }

        export interface ClusterOutputSpecSplunkHecHec_tokenMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecSplunkHecHec_tokenMountFromSecretKeyRef;
        }

        export interface ClusterOutputSpecSplunkHecHec_tokenMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecSplunkHecHec_tokenValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecSplunkHecHec_tokenValueFromSecretKeyRef;
        }

        export interface ClusterOutputSpecSplunkHecHec_tokenValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecSumologic {
            add_timestamp?: boolean;
            buffer?: outputs.logging.v1beta1.ClusterOutputSpecSumologicBuffer;
            compress?: boolean;
            compress_encoding?: string;
            custom_dimensions?: string;
            custom_fields?: string[];
            data_type?: string;
            delimiter?: string;
            disable_cookies?: boolean;
            endpoint: outputs.logging.v1beta1.ClusterOutputSpecSumologicEndpoint;
            log_format?: string;
            log_key?: string;
            metric_data_format?: string;
            open_timeout?: number;
            proxy_uri?: string;
            source_category?: string;
            source_host?: string;
            source_name: string;
            source_name_key?: string;
            sumo_client?: string;
            timestamp_key?: string;
            verify_ssl?: boolean;
        }

        export interface ClusterOutputSpecSumologicBuffer {
            chunk_full_threshold?: string;
            chunk_limit_records?: number;
            chunk_limit_size?: string;
            compress?: string;
            delayed_commit_timeout?: string;
            disable_chunk_backup?: boolean;
            flush_at_shutdown?: boolean;
            flush_interval?: string;
            flush_mode?: string;
            flush_thread_burst_interval?: string;
            flush_thread_count?: number;
            flush_thread_interval?: string;
            overflow_action?: string;
            path?: string;
            queue_limit_length?: number;
            queued_chunks_limit_size?: number;
            retry_exponential_backoff_base?: string;
            retry_forever?: boolean;
            retry_max_interval?: string;
            retry_max_times?: number;
            retry_randomize?: boolean;
            retry_secondary_threshold?: string;
            retry_timeout?: string;
            retry_type?: string;
            retry_wait?: string;
            tags?: string;
            timekey?: string;
            timekey_use_utc?: boolean;
            timekey_wait?: string;
            timekey_zone?: string;
            total_limit_size?: string;
            type?: string;
        }

        export interface ClusterOutputSpecSumologicEndpoint {
            mountFrom?: outputs.logging.v1beta1.ClusterOutputSpecSumologicEndpointMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.ClusterOutputSpecSumologicEndpointValueFrom;
        }

        export interface ClusterOutputSpecSumologicEndpointMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecSumologicEndpointMountFromSecretKeyRef;
        }

        export interface ClusterOutputSpecSumologicEndpointMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecSumologicEndpointValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecSumologicEndpointValueFromSecretKeyRef;
        }

        export interface ClusterOutputSpecSumologicEndpointValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecSyslog {
            buffer?: outputs.logging.v1beta1.ClusterOutputSpecSyslogBuffer;
            format?: outputs.logging.v1beta1.ClusterOutputSpecSyslogFormat;
            host: string;
            insecure?: boolean;
            port?: number;
            transport?: string;
            trusted_ca_path?: outputs.logging.v1beta1.ClusterOutputSpecSyslogTrusted_ca_path;
        }

        export interface ClusterOutputSpecSyslogBuffer {
            chunk_full_threshold?: string;
            chunk_limit_records?: number;
            chunk_limit_size?: string;
            compress?: string;
            delayed_commit_timeout?: string;
            disable_chunk_backup?: boolean;
            flush_at_shutdown?: boolean;
            flush_interval?: string;
            flush_mode?: string;
            flush_thread_burst_interval?: string;
            flush_thread_count?: number;
            flush_thread_interval?: string;
            overflow_action?: string;
            path?: string;
            queue_limit_length?: number;
            queued_chunks_limit_size?: number;
            retry_exponential_backoff_base?: string;
            retry_forever?: boolean;
            retry_max_interval?: string;
            retry_max_times?: number;
            retry_randomize?: boolean;
            retry_secondary_threshold?: string;
            retry_timeout?: string;
            retry_type?: string;
            retry_wait?: string;
            tags?: string;
            timekey?: string;
            timekey_use_utc?: boolean;
            timekey_wait?: string;
            timekey_zone?: string;
            total_limit_size?: string;
            type?: string;
        }

        export interface ClusterOutputSpecSyslogFormat {
            app_name_field?: string;
            hostname_field?: string;
            log_field?: string;
            message_id_field?: string;
            proc_id_field?: string;
            rfc6587_message_size?: boolean;
            structured_data_field?: string;
            type?: string;
        }

        export interface ClusterOutputSpecSyslogTrusted_ca_path {
            mountFrom?: outputs.logging.v1beta1.ClusterOutputSpecSyslogTrusted_ca_pathMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.ClusterOutputSpecSyslogTrusted_ca_pathValueFrom;
        }

        export interface ClusterOutputSpecSyslogTrusted_ca_pathMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecSyslogTrusted_ca_pathMountFromSecretKeyRef;
        }

        export interface ClusterOutputSpecSyslogTrusted_ca_pathMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputSpecSyslogTrusted_ca_pathValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.ClusterOutputSpecSyslogTrusted_ca_pathValueFromSecretKeyRef;
        }

        export interface ClusterOutputSpecSyslogTrusted_ca_pathValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface ClusterOutputStatus {
            active?: boolean;
            problems?: string[];
            problemsCount?: number;
        }

        export interface FlowSpec {
            filters?: outputs.logging.v1beta1.FlowSpecFilters[];
            globalOutputRefs?: string[];
            localOutputRefs?: string[];
            loggingRef?: string;
            match?: outputs.logging.v1beta1.FlowSpecMatch[];
            outputRefs?: string[];
            selectors?: { [key: string]: string };
        }

        export interface FlowSpecFilters {
            concat?: outputs.logging.v1beta1.FlowSpecFiltersConcat;
            dedot?: outputs.logging.v1beta1.FlowSpecFiltersDedot;
            detectExceptions?: outputs.logging.v1beta1.FlowSpecFiltersDetectExceptions;
            geoip?: outputs.logging.v1beta1.FlowSpecFiltersGeoip;
            grep?: outputs.logging.v1beta1.FlowSpecFiltersGrep;
            parser?: outputs.logging.v1beta1.FlowSpecFiltersParser;
            prometheus?: outputs.logging.v1beta1.FlowSpecFiltersPrometheus;
            record_modifier?: outputs.logging.v1beta1.FlowSpecFiltersRecord_modifier;
            record_transformer?: outputs.logging.v1beta1.FlowSpecFiltersRecord_transformer;
            stdout?: outputs.logging.v1beta1.FlowSpecFiltersStdout;
            sumologic?: outputs.logging.v1beta1.FlowSpecFiltersSumologic;
            tag_normaliser?: outputs.logging.v1beta1.FlowSpecFiltersTag_normaliser;
            throttle?: outputs.logging.v1beta1.FlowSpecFiltersThrottle;
        }

        export interface FlowSpecFiltersConcat {
            continuous_line_regexp?: string;
            flush_interval?: number;
            keep_partial_key?: boolean;
            keep_partial_metadata?: string;
            key?: string;
            multiline_end_regexp?: string;
            multiline_start_regexp?: string;
            n_lines?: number;
            partial_key?: string;
            partial_value?: string;
            separator?: string;
            stream_identity_key?: string;
            timeout_label?: string;
            use_first_timestamp?: boolean;
            use_partial_metadata?: string;
        }

        export interface FlowSpecFiltersDedot {
            de_dot_nested?: boolean;
            de_dot_separator?: string;
        }

        export interface FlowSpecFiltersDetectExceptions {
            languages?: string[];
            max_bytes?: number;
            max_lines?: number;
            message?: string;
            multiline_flush_interval?: string;
            remove_tag_prefix?: string;
            stream?: string;
        }

        export interface FlowSpecFiltersGeoip {
            backend_library?: string;
            geoip_2_database?: string;
            geoip_database?: string;
            geoip_lookup_keys?: string;
            records?: { [key: string]: string }[];
            skip_adding_null_record?: boolean;
        }

        export interface FlowSpecFiltersGrep {
            and?: outputs.logging.v1beta1.FlowSpecFiltersGrepAnd[];
            exclude?: outputs.logging.v1beta1.FlowSpecFiltersGrepExclude[];
            or?: outputs.logging.v1beta1.FlowSpecFiltersGrepOr[];
            regexp?: outputs.logging.v1beta1.FlowSpecFiltersGrepRegexp[];
        }

        export interface FlowSpecFiltersGrepAnd {
            exclude?: outputs.logging.v1beta1.FlowSpecFiltersGrepAndExclude[];
            regexp?: outputs.logging.v1beta1.FlowSpecFiltersGrepAndRegexp[];
        }

        export interface FlowSpecFiltersGrepAndExclude {
            key: string;
            pattern: string;
        }

        export interface FlowSpecFiltersGrepAndRegexp {
            key: string;
            pattern: string;
        }

        export interface FlowSpecFiltersGrepExclude {
            key: string;
            pattern: string;
        }

        export interface FlowSpecFiltersGrepOr {
            exclude?: outputs.logging.v1beta1.FlowSpecFiltersGrepOrExclude[];
            regexp?: outputs.logging.v1beta1.FlowSpecFiltersGrepOrRegexp[];
        }

        export interface FlowSpecFiltersGrepOrExclude {
            key: string;
            pattern: string;
        }

        export interface FlowSpecFiltersGrepOrRegexp {
            key: string;
            pattern: string;
        }

        export interface FlowSpecFiltersGrepRegexp {
            key: string;
            pattern: string;
        }

        export interface FlowSpecFiltersParser {
            emit_invalid_record_to_error?: boolean;
            hash_value_field?: string;
            inject_key_prefix?: string;
            key_name?: string;
            parse?: outputs.logging.v1beta1.FlowSpecFiltersParserParse;
            parsers?: outputs.logging.v1beta1.FlowSpecFiltersParserParsers[];
            remove_key_name_field?: boolean;
            replace_invalid_sequence?: boolean;
            reserve_data?: boolean;
            reserve_time?: boolean;
        }

        export interface FlowSpecFiltersParserParse {
            delimiter?: string;
            delimiter_pattern?: string;
            estimate_current_event?: boolean;
            expression?: string;
            format?: string;
            format_firstline?: string;
            keep_time_key?: boolean;
            label_delimiter?: string;
            local_time?: boolean;
            multiline?: string[];
            null_empty_string?: boolean;
            null_value_pattern?: string;
            patterns?: outputs.logging.v1beta1.FlowSpecFiltersParserParsePatterns[];
            time_format?: string;
            time_key?: string;
            time_type?: string;
            timezone?: string;
            type?: string;
            types?: string;
            utc?: boolean;
        }

        export interface FlowSpecFiltersParserParsePatterns {
            estimate_current_event?: boolean;
            expression?: string;
            format?: string;
            keep_time_key?: boolean;
            local_time?: boolean;
            null_empty_string?: boolean;
            null_value_pattern?: string;
            time_format?: string;
            time_key?: string;
            time_type?: string;
            timezone?: string;
            type?: string;
            types?: string;
            utc?: boolean;
        }

        export interface FlowSpecFiltersParserParsers {
            delimiter?: string;
            delimiter_pattern?: string;
            estimate_current_event?: boolean;
            expression?: string;
            format?: string;
            format_firstline?: string;
            keep_time_key?: boolean;
            label_delimiter?: string;
            local_time?: boolean;
            multiline?: string[];
            null_empty_string?: boolean;
            null_value_pattern?: string;
            patterns?: outputs.logging.v1beta1.FlowSpecFiltersParserParsersPatterns[];
            time_format?: string;
            time_key?: string;
            time_type?: string;
            timezone?: string;
            type?: string;
            types?: string;
            utc?: boolean;
        }

        export interface FlowSpecFiltersParserParsersPatterns {
            estimate_current_event?: boolean;
            expression?: string;
            format?: string;
            keep_time_key?: boolean;
            local_time?: boolean;
            null_empty_string?: boolean;
            null_value_pattern?: string;
            time_format?: string;
            time_key?: string;
            time_type?: string;
            timezone?: string;
            type?: string;
            types?: string;
            utc?: boolean;
        }

        export interface FlowSpecFiltersPrometheus {
            labels?: { [key: string]: string };
            metrics?: outputs.logging.v1beta1.FlowSpecFiltersPrometheusMetrics[];
        }

        export interface FlowSpecFiltersPrometheusMetrics {
            buckets?: string;
            desc: string;
            key?: string;
            labels?: { [key: string]: string };
            name: string;
            type: string;
        }

        export interface FlowSpecFiltersRecord_modifier {
            char_encoding?: string;
            prepare_value?: string;
            records?: { [key: string]: string }[];
            remove_keys?: string;
            replaces?: outputs.logging.v1beta1.FlowSpecFiltersRecord_modifierReplaces[];
            whitelist_keys?: string;
        }

        export interface FlowSpecFiltersRecord_modifierReplaces {
            expression: string;
            key: string;
            replace: string;
        }

        export interface FlowSpecFiltersRecord_transformer {
            auto_typecast?: boolean;
            enable_ruby?: boolean;
            keep_keys?: string;
            records?: { [key: string]: string }[];
            remove_keys?: string;
            renew_record?: boolean;
            renew_time_key?: string;
        }

        export interface FlowSpecFiltersStdout {
            output_type?: string;
        }

        export interface FlowSpecFiltersSumologic {
            collector_key_name?: string;
            collector_value?: string;
            exclude_container_regex?: string;
            exclude_facility_regex?: string;
            exclude_host_regex?: string;
            exclude_namespace_regex?: string;
            exclude_pod_regex?: string;
            exclude_priority_regex?: string;
            exclude_unit_regex?: string;
            log_format?: string;
            source_category?: string;
            source_category_key_name?: string;
            source_category_prefix?: string;
            source_category_replace_dash?: string;
            source_host?: string;
            source_host_key_name?: string;
            source_name?: string;
            source_name_key_name?: string;
            tracing_annotation_prefix?: string;
            tracing_container_name?: string;
            tracing_format?: boolean;
            tracing_host?: string;
            tracing_label_prefix?: string;
            tracing_namespace?: string;
            tracing_pod?: string;
            tracing_pod_id?: string;
        }

        export interface FlowSpecFiltersTag_normaliser {
            format?: string;
        }

        export interface FlowSpecFiltersThrottle {
            group_bucket_limit?: number;
            group_bucket_period_s?: number;
            group_drop_logs?: boolean;
            group_key?: string;
            group_reset_rate_s?: number;
            group_warning_delay_s?: number;
        }

        export interface FlowSpecMatch {
            exclude?: outputs.logging.v1beta1.FlowSpecMatchExclude;
            select?: outputs.logging.v1beta1.FlowSpecMatchSelect;
        }

        export interface FlowSpecMatchExclude {
            container_names?: string[];
            hosts?: string[];
            labels?: { [key: string]: string };
        }

        export interface FlowSpecMatchSelect {
            container_names?: string[];
            hosts?: string[];
            labels?: { [key: string]: string };
        }

        export interface FlowStatus {
            active?: boolean;
            problems?: string[];
            problemsCount?: number;
        }

        export interface LoggingSpec {
            allowClusterResourcesFromAllNamespaces?: boolean;
            controlNamespace: string;
            defaultFlow?: outputs.logging.v1beta1.LoggingSpecDefaultFlow;
            enableRecreateWorkloadOnImmutableFieldChange?: boolean;
            flowConfigCheckDisabled?: boolean;
            flowConfigOverride?: string;
            fluentbit?: outputs.logging.v1beta1.LoggingSpecFluentbit;
            fluentd?: outputs.logging.v1beta1.LoggingSpecFluentd;
            loggingRef?: string;
            watchNamespaces?: string[];
        }

        export interface LoggingSpecDefaultFlow {
            filters?: outputs.logging.v1beta1.LoggingSpecDefaultFlowFilters[];
            globalOutputRefs?: string[];
            outputRefs?: string[];
        }

        export interface LoggingSpecDefaultFlowFilters {
            concat?: outputs.logging.v1beta1.LoggingSpecDefaultFlowFiltersConcat;
            dedot?: outputs.logging.v1beta1.LoggingSpecDefaultFlowFiltersDedot;
            detectExceptions?: outputs.logging.v1beta1.LoggingSpecDefaultFlowFiltersDetectExceptions;
            geoip?: outputs.logging.v1beta1.LoggingSpecDefaultFlowFiltersGeoip;
            grep?: outputs.logging.v1beta1.LoggingSpecDefaultFlowFiltersGrep;
            parser?: outputs.logging.v1beta1.LoggingSpecDefaultFlowFiltersParser;
            prometheus?: outputs.logging.v1beta1.LoggingSpecDefaultFlowFiltersPrometheus;
            record_modifier?: outputs.logging.v1beta1.LoggingSpecDefaultFlowFiltersRecord_modifier;
            record_transformer?: outputs.logging.v1beta1.LoggingSpecDefaultFlowFiltersRecord_transformer;
            stdout?: outputs.logging.v1beta1.LoggingSpecDefaultFlowFiltersStdout;
            sumologic?: outputs.logging.v1beta1.LoggingSpecDefaultFlowFiltersSumologic;
            tag_normaliser?: outputs.logging.v1beta1.LoggingSpecDefaultFlowFiltersTag_normaliser;
            throttle?: outputs.logging.v1beta1.LoggingSpecDefaultFlowFiltersThrottle;
        }

        export interface LoggingSpecDefaultFlowFiltersConcat {
            continuous_line_regexp?: string;
            flush_interval?: number;
            keep_partial_key?: boolean;
            keep_partial_metadata?: string;
            key?: string;
            multiline_end_regexp?: string;
            multiline_start_regexp?: string;
            n_lines?: number;
            partial_key?: string;
            partial_value?: string;
            separator?: string;
            stream_identity_key?: string;
            timeout_label?: string;
            use_first_timestamp?: boolean;
            use_partial_metadata?: string;
        }

        export interface LoggingSpecDefaultFlowFiltersDedot {
            de_dot_nested?: boolean;
            de_dot_separator?: string;
        }

        export interface LoggingSpecDefaultFlowFiltersDetectExceptions {
            languages?: string[];
            max_bytes?: number;
            max_lines?: number;
            message?: string;
            multiline_flush_interval?: string;
            remove_tag_prefix?: string;
            stream?: string;
        }

        export interface LoggingSpecDefaultFlowFiltersGeoip {
            backend_library?: string;
            geoip_2_database?: string;
            geoip_database?: string;
            geoip_lookup_keys?: string;
            records?: { [key: string]: string }[];
            skip_adding_null_record?: boolean;
        }

        export interface LoggingSpecDefaultFlowFiltersGrep {
            and?: outputs.logging.v1beta1.LoggingSpecDefaultFlowFiltersGrepAnd[];
            exclude?: outputs.logging.v1beta1.LoggingSpecDefaultFlowFiltersGrepExclude[];
            or?: outputs.logging.v1beta1.LoggingSpecDefaultFlowFiltersGrepOr[];
            regexp?: outputs.logging.v1beta1.LoggingSpecDefaultFlowFiltersGrepRegexp[];
        }

        export interface LoggingSpecDefaultFlowFiltersGrepAnd {
            exclude?: outputs.logging.v1beta1.LoggingSpecDefaultFlowFiltersGrepAndExclude[];
            regexp?: outputs.logging.v1beta1.LoggingSpecDefaultFlowFiltersGrepAndRegexp[];
        }

        export interface LoggingSpecDefaultFlowFiltersGrepAndExclude {
            key: string;
            pattern: string;
        }

        export interface LoggingSpecDefaultFlowFiltersGrepAndRegexp {
            key: string;
            pattern: string;
        }

        export interface LoggingSpecDefaultFlowFiltersGrepExclude {
            key: string;
            pattern: string;
        }

        export interface LoggingSpecDefaultFlowFiltersGrepOr {
            exclude?: outputs.logging.v1beta1.LoggingSpecDefaultFlowFiltersGrepOrExclude[];
            regexp?: outputs.logging.v1beta1.LoggingSpecDefaultFlowFiltersGrepOrRegexp[];
        }

        export interface LoggingSpecDefaultFlowFiltersGrepOrExclude {
            key: string;
            pattern: string;
        }

        export interface LoggingSpecDefaultFlowFiltersGrepOrRegexp {
            key: string;
            pattern: string;
        }

        export interface LoggingSpecDefaultFlowFiltersGrepRegexp {
            key: string;
            pattern: string;
        }

        export interface LoggingSpecDefaultFlowFiltersParser {
            emit_invalid_record_to_error?: boolean;
            hash_value_field?: string;
            inject_key_prefix?: string;
            key_name?: string;
            parse?: outputs.logging.v1beta1.LoggingSpecDefaultFlowFiltersParserParse;
            parsers?: outputs.logging.v1beta1.LoggingSpecDefaultFlowFiltersParserParsers[];
            remove_key_name_field?: boolean;
            replace_invalid_sequence?: boolean;
            reserve_data?: boolean;
            reserve_time?: boolean;
        }

        export interface LoggingSpecDefaultFlowFiltersParserParse {
            delimiter?: string;
            delimiter_pattern?: string;
            estimate_current_event?: boolean;
            expression?: string;
            format?: string;
            format_firstline?: string;
            keep_time_key?: boolean;
            label_delimiter?: string;
            local_time?: boolean;
            multiline?: string[];
            null_empty_string?: boolean;
            null_value_pattern?: string;
            patterns?: outputs.logging.v1beta1.LoggingSpecDefaultFlowFiltersParserParsePatterns[];
            time_format?: string;
            time_key?: string;
            time_type?: string;
            timezone?: string;
            type?: string;
            types?: string;
            utc?: boolean;
        }

        export interface LoggingSpecDefaultFlowFiltersParserParsePatterns {
            estimate_current_event?: boolean;
            expression?: string;
            format?: string;
            keep_time_key?: boolean;
            local_time?: boolean;
            null_empty_string?: boolean;
            null_value_pattern?: string;
            time_format?: string;
            time_key?: string;
            time_type?: string;
            timezone?: string;
            type?: string;
            types?: string;
            utc?: boolean;
        }

        export interface LoggingSpecDefaultFlowFiltersParserParsers {
            delimiter?: string;
            delimiter_pattern?: string;
            estimate_current_event?: boolean;
            expression?: string;
            format?: string;
            format_firstline?: string;
            keep_time_key?: boolean;
            label_delimiter?: string;
            local_time?: boolean;
            multiline?: string[];
            null_empty_string?: boolean;
            null_value_pattern?: string;
            patterns?: outputs.logging.v1beta1.LoggingSpecDefaultFlowFiltersParserParsersPatterns[];
            time_format?: string;
            time_key?: string;
            time_type?: string;
            timezone?: string;
            type?: string;
            types?: string;
            utc?: boolean;
        }

        export interface LoggingSpecDefaultFlowFiltersParserParsersPatterns {
            estimate_current_event?: boolean;
            expression?: string;
            format?: string;
            keep_time_key?: boolean;
            local_time?: boolean;
            null_empty_string?: boolean;
            null_value_pattern?: string;
            time_format?: string;
            time_key?: string;
            time_type?: string;
            timezone?: string;
            type?: string;
            types?: string;
            utc?: boolean;
        }

        export interface LoggingSpecDefaultFlowFiltersPrometheus {
            labels?: { [key: string]: string };
            metrics?: outputs.logging.v1beta1.LoggingSpecDefaultFlowFiltersPrometheusMetrics[];
        }

        export interface LoggingSpecDefaultFlowFiltersPrometheusMetrics {
            buckets?: string;
            desc: string;
            key?: string;
            labels?: { [key: string]: string };
            name: string;
            type: string;
        }

        export interface LoggingSpecDefaultFlowFiltersRecord_modifier {
            char_encoding?: string;
            prepare_value?: string;
            records?: { [key: string]: string }[];
            remove_keys?: string;
            replaces?: outputs.logging.v1beta1.LoggingSpecDefaultFlowFiltersRecord_modifierReplaces[];
            whitelist_keys?: string;
        }

        export interface LoggingSpecDefaultFlowFiltersRecord_modifierReplaces {
            expression: string;
            key: string;
            replace: string;
        }

        export interface LoggingSpecDefaultFlowFiltersRecord_transformer {
            auto_typecast?: boolean;
            enable_ruby?: boolean;
            keep_keys?: string;
            records?: { [key: string]: string }[];
            remove_keys?: string;
            renew_record?: boolean;
            renew_time_key?: string;
        }

        export interface LoggingSpecDefaultFlowFiltersStdout {
            output_type?: string;
        }

        export interface LoggingSpecDefaultFlowFiltersSumologic {
            collector_key_name?: string;
            collector_value?: string;
            exclude_container_regex?: string;
            exclude_facility_regex?: string;
            exclude_host_regex?: string;
            exclude_namespace_regex?: string;
            exclude_pod_regex?: string;
            exclude_priority_regex?: string;
            exclude_unit_regex?: string;
            log_format?: string;
            source_category?: string;
            source_category_key_name?: string;
            source_category_prefix?: string;
            source_category_replace_dash?: string;
            source_host?: string;
            source_host_key_name?: string;
            source_name?: string;
            source_name_key_name?: string;
            tracing_annotation_prefix?: string;
            tracing_container_name?: string;
            tracing_format?: boolean;
            tracing_host?: string;
            tracing_label_prefix?: string;
            tracing_namespace?: string;
            tracing_pod?: string;
            tracing_pod_id?: string;
        }

        export interface LoggingSpecDefaultFlowFiltersTag_normaliser {
            format?: string;
        }

        export interface LoggingSpecDefaultFlowFiltersThrottle {
            group_bucket_limit?: number;
            group_bucket_period_s?: number;
            group_drop_logs?: boolean;
            group_key?: string;
            group_reset_rate_s?: number;
            group_warning_delay_s?: number;
        }

        export interface LoggingSpecFluentbit {
            affinity?: outputs.logging.v1beta1.LoggingSpecFluentbitAffinity;
            annotations?: { [key: string]: string };
            bufferStorage?: outputs.logging.v1beta1.LoggingSpecFluentbitBufferStorage;
            bufferStorageVolume?: outputs.logging.v1beta1.LoggingSpecFluentbitBufferStorageVolume;
            coroStackSize?: number;
            customConfigSecret?: string;
            enableUpstream?: boolean;
            extraVolumeMounts?: outputs.logging.v1beta1.LoggingSpecFluentbitExtraVolumeMounts[];
            filterAws?: outputs.logging.v1beta1.LoggingSpecFluentbitFilterAws;
            filterKubernetes?: outputs.logging.v1beta1.LoggingSpecFluentbitFilterKubernetes;
            flush?: number;
            forwardOptions?: outputs.logging.v1beta1.LoggingSpecFluentbitForwardOptions;
            grace?: number;
            image?: outputs.logging.v1beta1.LoggingSpecFluentbitImage;
            inputTail?: outputs.logging.v1beta1.LoggingSpecFluentbitInputTail;
            labels?: { [key: string]: string };
            livenessDefaultCheck?: boolean;
            livenessProbe?: outputs.logging.v1beta1.LoggingSpecFluentbitLivenessProbe;
            logLevel?: string;
            metrics?: outputs.logging.v1beta1.LoggingSpecFluentbitMetrics;
            mountPath?: string;
            network?: outputs.logging.v1beta1.LoggingSpecFluentbitNetwork;
            nodeSelector?: { [key: string]: string };
            parser?: string;
            podPriorityClassName?: string;
            position_db?: outputs.logging.v1beta1.LoggingSpecFluentbitPosition_db;
            positiondb?: outputs.logging.v1beta1.LoggingSpecFluentbitPositiondb;
            readinessProbe?: outputs.logging.v1beta1.LoggingSpecFluentbitReadinessProbe;
            resources?: outputs.logging.v1beta1.LoggingSpecFluentbitResources;
            security?: outputs.logging.v1beta1.LoggingSpecFluentbitSecurity;
            targetHost?: string;
            targetPort?: number;
            tls?: outputs.logging.v1beta1.LoggingSpecFluentbitTls;
            tolerations?: outputs.logging.v1beta1.LoggingSpecFluentbitTolerations[];
        }

        export interface LoggingSpecFluentbitAffinity {
            nodeAffinity?: outputs.logging.v1beta1.LoggingSpecFluentbitAffinityNodeAffinity;
            podAffinity?: outputs.logging.v1beta1.LoggingSpecFluentbitAffinityPodAffinity;
            podAntiAffinity?: outputs.logging.v1beta1.LoggingSpecFluentbitAffinityPodAntiAffinity;
        }

        export interface LoggingSpecFluentbitAffinityNodeAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.logging.v1beta1.LoggingSpecFluentbitAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.logging.v1beta1.LoggingSpecFluentbitAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution;
        }

        export interface LoggingSpecFluentbitAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            preference: outputs.logging.v1beta1.LoggingSpecFluentbitAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference;
            weight: number;
        }

        export interface LoggingSpecFluentbitAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference {
            matchExpressions?: outputs.logging.v1beta1.LoggingSpecFluentbitAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions[];
            matchFields?: outputs.logging.v1beta1.LoggingSpecFluentbitAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields[];
        }

        export interface LoggingSpecFluentbitAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface LoggingSpecFluentbitAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface LoggingSpecFluentbitAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            nodeSelectorTerms: outputs.logging.v1beta1.LoggingSpecFluentbitAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms[];
        }

        export interface LoggingSpecFluentbitAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms {
            matchExpressions?: outputs.logging.v1beta1.LoggingSpecFluentbitAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions[];
            matchFields?: outputs.logging.v1beta1.LoggingSpecFluentbitAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields[];
        }

        export interface LoggingSpecFluentbitAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface LoggingSpecFluentbitAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface LoggingSpecFluentbitAffinityPodAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.logging.v1beta1.LoggingSpecFluentbitAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.logging.v1beta1.LoggingSpecFluentbitAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        export interface LoggingSpecFluentbitAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            podAffinityTerm: outputs.logging.v1beta1.LoggingSpecFluentbitAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            weight: number;
        }

        export interface LoggingSpecFluentbitAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            labelSelector?: outputs.logging.v1beta1.LoggingSpecFluentbitAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            namespaces?: string[];
            topologyKey: string;
        }

        export interface LoggingSpecFluentbitAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            matchExpressions?: outputs.logging.v1beta1.LoggingSpecFluentbitAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            matchLabels?: { [key: string]: string };
        }

        export interface LoggingSpecFluentbitAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface LoggingSpecFluentbitAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            labelSelector?: outputs.logging.v1beta1.LoggingSpecFluentbitAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            namespaces?: string[];
            topologyKey: string;
        }

        export interface LoggingSpecFluentbitAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            matchExpressions?: outputs.logging.v1beta1.LoggingSpecFluentbitAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            matchLabels?: { [key: string]: string };
        }

        export interface LoggingSpecFluentbitAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface LoggingSpecFluentbitAffinityPodAntiAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.logging.v1beta1.LoggingSpecFluentbitAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.logging.v1beta1.LoggingSpecFluentbitAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        export interface LoggingSpecFluentbitAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            podAffinityTerm: outputs.logging.v1beta1.LoggingSpecFluentbitAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            weight: number;
        }

        export interface LoggingSpecFluentbitAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            labelSelector?: outputs.logging.v1beta1.LoggingSpecFluentbitAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            namespaces?: string[];
            topologyKey: string;
        }

        export interface LoggingSpecFluentbitAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            matchExpressions?: outputs.logging.v1beta1.LoggingSpecFluentbitAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            matchLabels?: { [key: string]: string };
        }

        export interface LoggingSpecFluentbitAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface LoggingSpecFluentbitAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            labelSelector?: outputs.logging.v1beta1.LoggingSpecFluentbitAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            namespaces?: string[];
            topologyKey: string;
        }

        export interface LoggingSpecFluentbitAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            matchExpressions?: outputs.logging.v1beta1.LoggingSpecFluentbitAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            matchLabels?: { [key: string]: string };
        }

        export interface LoggingSpecFluentbitAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface LoggingSpecFluentbitBufferStorage {
            "storage.backlog.mem_limit"?: string;
            "storage.checksum"?: string;
            "storage.path"?: string;
            "storage.sync"?: string;
        }

        export interface LoggingSpecFluentbitBufferStorageVolume {
            emptyDir?: outputs.logging.v1beta1.LoggingSpecFluentbitBufferStorageVolumeEmptyDir;
            hostPath?: outputs.logging.v1beta1.LoggingSpecFluentbitBufferStorageVolumeHostPath;
            host_path?: outputs.logging.v1beta1.LoggingSpecFluentbitBufferStorageVolumeHost_path;
            pvc?: outputs.logging.v1beta1.LoggingSpecFluentbitBufferStorageVolumePvc;
        }

        export interface LoggingSpecFluentbitBufferStorageVolumeEmptyDir {
            medium?: string;
            sizeLimit?: string;
        }

        export interface LoggingSpecFluentbitBufferStorageVolumeHostPath {
            path: string;
            type?: string;
        }

        export interface LoggingSpecFluentbitBufferStorageVolumeHost_path {
            path: string;
            type?: string;
        }

        export interface LoggingSpecFluentbitBufferStorageVolumePvc {
            source?: outputs.logging.v1beta1.LoggingSpecFluentbitBufferStorageVolumePvcSource;
            spec?: outputs.logging.v1beta1.LoggingSpecFluentbitBufferStorageVolumePvcSpec;
        }

        export interface LoggingSpecFluentbitBufferStorageVolumePvcSource {
            claimName: string;
            readOnly?: boolean;
        }

        export interface LoggingSpecFluentbitBufferStorageVolumePvcSpec {
            accessModes?: string[];
            dataSource?: outputs.logging.v1beta1.LoggingSpecFluentbitBufferStorageVolumePvcSpecDataSource;
            resources?: outputs.logging.v1beta1.LoggingSpecFluentbitBufferStorageVolumePvcSpecResources;
            selector?: outputs.logging.v1beta1.LoggingSpecFluentbitBufferStorageVolumePvcSpecSelector;
            storageClassName?: string;
            volumeMode?: string;
            volumeName?: string;
        }

        export interface LoggingSpecFluentbitBufferStorageVolumePvcSpecDataSource {
            apiGroup?: string;
            kind: string;
            name: string;
        }

        export interface LoggingSpecFluentbitBufferStorageVolumePvcSpecResources {
            limits?: { [key: string]: string };
            requests?: { [key: string]: string };
        }

        export interface LoggingSpecFluentbitBufferStorageVolumePvcSpecSelector {
            matchExpressions?: outputs.logging.v1beta1.LoggingSpecFluentbitBufferStorageVolumePvcSpecSelectorMatchExpressions[];
            matchLabels?: { [key: string]: string };
        }

        export interface LoggingSpecFluentbitBufferStorageVolumePvcSpecSelectorMatchExpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface LoggingSpecFluentbitExtraVolumeMounts {
            destination: string;
            readOnly?: boolean;
            source: string;
        }

        export interface LoggingSpecFluentbitFilterAws {
            Match?: string;
            account_id?: boolean;
            ami_id?: boolean;
            az?: boolean;
            ec2_instance_id?: boolean;
            ec2_instance_type?: boolean;
            hostname?: boolean;
            imds_version?: string;
            private_ip?: boolean;
            vpc_id?: boolean;
        }

        export interface LoggingSpecFluentbitFilterKubernetes {
            Annotations?: string;
            Buffer_Size?: string;
            Dummy_Meta?: string;
            "K8S-Logging.Exclude"?: string;
            "K8S-Logging.Parser"?: string;
            Keep_Log?: string;
            Kube_CA_File?: string;
            Kube_CA_Path?: string;
            Kube_Tag_Prefix?: string;
            Kube_Token_File?: string;
            Kube_URL?: string;
            Kube_meta_preload_cache_dir?: string;
            Labels?: string;
            Match?: string;
            Merge_Log?: string;
            Merge_Log_Key?: string;
            Merge_Log_Trim?: string;
            Merge_Parser?: string;
            Regex_Parser?: string;
            Use_Journal?: string;
            "tls.debug"?: string;
            "tls.verify"?: string;
        }

        export interface LoggingSpecFluentbitForwardOptions {
            Require_ack_response?: boolean;
            Retry_Limit?: string;
            Send_options?: boolean;
            Tag?: string;
            Time_as_Integer?: boolean;
        }

        export interface LoggingSpecFluentbitImage {
            imagePullSecrets?: outputs.logging.v1beta1.LoggingSpecFluentbitImageImagePullSecrets[];
            pullPolicy?: string;
            repository?: string;
            tag?: string;
        }

        export interface LoggingSpecFluentbitImageImagePullSecrets {
            name?: string;
        }

        export interface LoggingSpecFluentbitInputTail {
            Buffer_Chunk_Size?: string;
            Buffer_Max_Size?: string;
            DB?: string;
            DB_Sync?: string;
            Docker_Mode?: string;
            Docker_Mode_Flush?: string;
            Exclude_Path?: string;
            Ignore_Older?: string;
            Key?: string;
            Mem_Buf_Limit?: string;
            Multiline?: string;
            Multiline_Flush?: string;
            Parser?: string;
            Parser_Firstline?: string;
            Parser_N?: string[];
            Path?: string;
            Path_Key?: string;
            Refresh_Interval?: string;
            Rotate_Wait?: string;
            Skip_Long_Lines?: string;
            Tag?: string;
            Tag_Regex?: string;
            "storage.type"?: string;
        }

        export interface LoggingSpecFluentbitLivenessProbe {
            exec?: outputs.logging.v1beta1.LoggingSpecFluentbitLivenessProbeExec;
            failureThreshold?: number;
            httpGet?: outputs.logging.v1beta1.LoggingSpecFluentbitLivenessProbeHttpGet;
            initialDelaySeconds?: number;
            periodSeconds?: number;
            successThreshold?: number;
            tcpSocket?: outputs.logging.v1beta1.LoggingSpecFluentbitLivenessProbeTcpSocket;
            timeoutSeconds?: number;
        }

        export interface LoggingSpecFluentbitLivenessProbeExec {
            command?: string[];
        }

        export interface LoggingSpecFluentbitLivenessProbeHttpGet {
            host?: string;
            httpHeaders?: outputs.logging.v1beta1.LoggingSpecFluentbitLivenessProbeHttpGetHttpHeaders[];
            path?: string;
            port: outputs.logging.v1beta1.LoggingSpecFluentbitLivenessProbeHttpGetPort;
            scheme?: string;
        }

        export interface LoggingSpecFluentbitLivenessProbeHttpGetHttpHeaders {
            name: string;
            value: string;
        }

        export interface LoggingSpecFluentbitLivenessProbeHttpGetPort {
        }

        export interface LoggingSpecFluentbitLivenessProbeTcpSocket {
            host?: string;
            port: outputs.logging.v1beta1.LoggingSpecFluentbitLivenessProbeTcpSocketPort;
        }

        export interface LoggingSpecFluentbitLivenessProbeTcpSocketPort {
        }

        export interface LoggingSpecFluentbitMetrics {
            interval?: string;
            path?: string;
            port?: number;
            prometheusAnnotations?: boolean;
            serviceMonitor?: boolean;
            serviceMonitorConfig?: outputs.logging.v1beta1.LoggingSpecFluentbitMetricsServiceMonitorConfig;
            timeout?: string;
        }

        export interface LoggingSpecFluentbitMetricsServiceMonitorConfig {
            additionalLabels?: { [key: string]: string };
            honorLabels?: boolean;
            metricRelabelings?: outputs.logging.v1beta1.LoggingSpecFluentbitMetricsServiceMonitorConfigMetricRelabelings[];
            relabelings?: outputs.logging.v1beta1.LoggingSpecFluentbitMetricsServiceMonitorConfigRelabelings[];
        }

        export interface LoggingSpecFluentbitMetricsServiceMonitorConfigMetricRelabelings {
            action?: string;
            modulus?: number;
            regex?: string;
            replacement?: string;
            separator?: string;
            sourceLabels?: string[];
            targetLabel?: string;
        }

        export interface LoggingSpecFluentbitMetricsServiceMonitorConfigRelabelings {
            action?: string;
            modulus?: number;
            regex?: string;
            replacement?: string;
            separator?: string;
            sourceLabels?: string[];
            targetLabel?: string;
        }

        export interface LoggingSpecFluentbitNetwork {
            connectTimeout?: number;
            keepalive?: boolean;
            keepaliveIdleTimeout?: number;
            keepaliveMaxRecycle?: number;
        }

        export interface LoggingSpecFluentbitPosition_db {
            emptyDir?: outputs.logging.v1beta1.LoggingSpecFluentbitPosition_dbEmptyDir;
            hostPath?: outputs.logging.v1beta1.LoggingSpecFluentbitPosition_dbHostPath;
            host_path?: outputs.logging.v1beta1.LoggingSpecFluentbitPosition_dbHost_path;
            pvc?: outputs.logging.v1beta1.LoggingSpecFluentbitPosition_dbPvc;
        }

        export interface LoggingSpecFluentbitPosition_dbEmptyDir {
            medium?: string;
            sizeLimit?: string;
        }

        export interface LoggingSpecFluentbitPosition_dbHostPath {
            path: string;
            type?: string;
        }

        export interface LoggingSpecFluentbitPosition_dbHost_path {
            path: string;
            type?: string;
        }

        export interface LoggingSpecFluentbitPosition_dbPvc {
            source?: outputs.logging.v1beta1.LoggingSpecFluentbitPosition_dbPvcSource;
            spec?: outputs.logging.v1beta1.LoggingSpecFluentbitPosition_dbPvcSpec;
        }

        export interface LoggingSpecFluentbitPosition_dbPvcSource {
            claimName: string;
            readOnly?: boolean;
        }

        export interface LoggingSpecFluentbitPosition_dbPvcSpec {
            accessModes?: string[];
            dataSource?: outputs.logging.v1beta1.LoggingSpecFluentbitPosition_dbPvcSpecDataSource;
            resources?: outputs.logging.v1beta1.LoggingSpecFluentbitPosition_dbPvcSpecResources;
            selector?: outputs.logging.v1beta1.LoggingSpecFluentbitPosition_dbPvcSpecSelector;
            storageClassName?: string;
            volumeMode?: string;
            volumeName?: string;
        }

        export interface LoggingSpecFluentbitPosition_dbPvcSpecDataSource {
            apiGroup?: string;
            kind: string;
            name: string;
        }

        export interface LoggingSpecFluentbitPosition_dbPvcSpecResources {
            limits?: { [key: string]: string };
            requests?: { [key: string]: string };
        }

        export interface LoggingSpecFluentbitPosition_dbPvcSpecSelector {
            matchExpressions?: outputs.logging.v1beta1.LoggingSpecFluentbitPosition_dbPvcSpecSelectorMatchExpressions[];
            matchLabels?: { [key: string]: string };
        }

        export interface LoggingSpecFluentbitPosition_dbPvcSpecSelectorMatchExpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface LoggingSpecFluentbitPositiondb {
            emptyDir?: outputs.logging.v1beta1.LoggingSpecFluentbitPositiondbEmptyDir;
            hostPath?: outputs.logging.v1beta1.LoggingSpecFluentbitPositiondbHostPath;
            host_path?: outputs.logging.v1beta1.LoggingSpecFluentbitPositiondbHost_path;
            pvc?: outputs.logging.v1beta1.LoggingSpecFluentbitPositiondbPvc;
        }

        export interface LoggingSpecFluentbitPositiondbEmptyDir {
            medium?: string;
            sizeLimit?: string;
        }

        export interface LoggingSpecFluentbitPositiondbHostPath {
            path: string;
            type?: string;
        }

        export interface LoggingSpecFluentbitPositiondbHost_path {
            path: string;
            type?: string;
        }

        export interface LoggingSpecFluentbitPositiondbPvc {
            source?: outputs.logging.v1beta1.LoggingSpecFluentbitPositiondbPvcSource;
            spec?: outputs.logging.v1beta1.LoggingSpecFluentbitPositiondbPvcSpec;
        }

        export interface LoggingSpecFluentbitPositiondbPvcSource {
            claimName: string;
            readOnly?: boolean;
        }

        export interface LoggingSpecFluentbitPositiondbPvcSpec {
            accessModes?: string[];
            dataSource?: outputs.logging.v1beta1.LoggingSpecFluentbitPositiondbPvcSpecDataSource;
            resources?: outputs.logging.v1beta1.LoggingSpecFluentbitPositiondbPvcSpecResources;
            selector?: outputs.logging.v1beta1.LoggingSpecFluentbitPositiondbPvcSpecSelector;
            storageClassName?: string;
            volumeMode?: string;
            volumeName?: string;
        }

        export interface LoggingSpecFluentbitPositiondbPvcSpecDataSource {
            apiGroup?: string;
            kind: string;
            name: string;
        }

        export interface LoggingSpecFluentbitPositiondbPvcSpecResources {
            limits?: { [key: string]: string };
            requests?: { [key: string]: string };
        }

        export interface LoggingSpecFluentbitPositiondbPvcSpecSelector {
            matchExpressions?: outputs.logging.v1beta1.LoggingSpecFluentbitPositiondbPvcSpecSelectorMatchExpressions[];
            matchLabels?: { [key: string]: string };
        }

        export interface LoggingSpecFluentbitPositiondbPvcSpecSelectorMatchExpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface LoggingSpecFluentbitReadinessProbe {
            exec?: outputs.logging.v1beta1.LoggingSpecFluentbitReadinessProbeExec;
            failureThreshold?: number;
            httpGet?: outputs.logging.v1beta1.LoggingSpecFluentbitReadinessProbeHttpGet;
            initialDelaySeconds?: number;
            periodSeconds?: number;
            successThreshold?: number;
            tcpSocket?: outputs.logging.v1beta1.LoggingSpecFluentbitReadinessProbeTcpSocket;
            timeoutSeconds?: number;
        }

        export interface LoggingSpecFluentbitReadinessProbeExec {
            command?: string[];
        }

        export interface LoggingSpecFluentbitReadinessProbeHttpGet {
            host?: string;
            httpHeaders?: outputs.logging.v1beta1.LoggingSpecFluentbitReadinessProbeHttpGetHttpHeaders[];
            path?: string;
            port: outputs.logging.v1beta1.LoggingSpecFluentbitReadinessProbeHttpGetPort;
            scheme?: string;
        }

        export interface LoggingSpecFluentbitReadinessProbeHttpGetHttpHeaders {
            name: string;
            value: string;
        }

        export interface LoggingSpecFluentbitReadinessProbeHttpGetPort {
        }

        export interface LoggingSpecFluentbitReadinessProbeTcpSocket {
            host?: string;
            port: outputs.logging.v1beta1.LoggingSpecFluentbitReadinessProbeTcpSocketPort;
        }

        export interface LoggingSpecFluentbitReadinessProbeTcpSocketPort {
        }

        export interface LoggingSpecFluentbitResources {
            limits?: { [key: string]: string };
            requests?: { [key: string]: string };
        }

        export interface LoggingSpecFluentbitSecurity {
            podSecurityContext?: outputs.logging.v1beta1.LoggingSpecFluentbitSecurityPodSecurityContext;
            podSecurityPolicyCreate?: boolean;
            roleBasedAccessControlCreate?: boolean;
            securityContext?: outputs.logging.v1beta1.LoggingSpecFluentbitSecuritySecurityContext;
            serviceAccount?: string;
        }

        export interface LoggingSpecFluentbitSecurityPodSecurityContext {
            fsGroup?: number;
            fsGroupChangePolicy?: string;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.logging.v1beta1.LoggingSpecFluentbitSecurityPodSecurityContextSeLinuxOptions;
            seccompProfile?: outputs.logging.v1beta1.LoggingSpecFluentbitSecurityPodSecurityContextSeccompProfile;
            supplementalGroups?: number[];
            sysctls?: outputs.logging.v1beta1.LoggingSpecFluentbitSecurityPodSecurityContextSysctls[];
            windowsOptions?: outputs.logging.v1beta1.LoggingSpecFluentbitSecurityPodSecurityContextWindowsOptions;
        }

        export interface LoggingSpecFluentbitSecurityPodSecurityContextSeLinuxOptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface LoggingSpecFluentbitSecurityPodSecurityContextSeccompProfile {
            localhostProfile?: string;
            type: string;
        }

        export interface LoggingSpecFluentbitSecurityPodSecurityContextSysctls {
            name: string;
            value: string;
        }

        export interface LoggingSpecFluentbitSecurityPodSecurityContextWindowsOptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        export interface LoggingSpecFluentbitSecuritySecurityContext {
            allowPrivilegeEscalation?: boolean;
            capabilities?: outputs.logging.v1beta1.LoggingSpecFluentbitSecuritySecurityContextCapabilities;
            privileged?: boolean;
            procMount?: string;
            readOnlyRootFilesystem?: boolean;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.logging.v1beta1.LoggingSpecFluentbitSecuritySecurityContextSeLinuxOptions;
            seccompProfile?: outputs.logging.v1beta1.LoggingSpecFluentbitSecuritySecurityContextSeccompProfile;
            windowsOptions?: outputs.logging.v1beta1.LoggingSpecFluentbitSecuritySecurityContextWindowsOptions;
        }

        export interface LoggingSpecFluentbitSecuritySecurityContextCapabilities {
            add?: string[];
            drop?: string[];
        }

        export interface LoggingSpecFluentbitSecuritySecurityContextSeLinuxOptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface LoggingSpecFluentbitSecuritySecurityContextSeccompProfile {
            localhostProfile?: string;
            type: string;
        }

        export interface LoggingSpecFluentbitSecuritySecurityContextWindowsOptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        export interface LoggingSpecFluentbitTls {
            enabled: boolean;
            secretName?: string;
            sharedKey?: string;
        }

        export interface LoggingSpecFluentbitTolerations {
            effect?: string;
            key?: string;
            operator?: string;
            tolerationSeconds?: number;
            value?: string;
        }

        export interface LoggingSpecFluentd {
            affinity?: outputs.logging.v1beta1.LoggingSpecFluentdAffinity;
            annotations?: { [key: string]: string };
            bufferStorageVolume?: outputs.logging.v1beta1.LoggingSpecFluentdBufferStorageVolume;
            configCheckAnnotations?: { [key: string]: string };
            configReloaderImage?: outputs.logging.v1beta1.LoggingSpecFluentdConfigReloaderImage;
            disablePvc?: boolean;
            fluentLogDestination?: string;
            fluentOutLogrotate?: outputs.logging.v1beta1.LoggingSpecFluentdFluentOutLogrotate;
            fluentdPvcSpec?: outputs.logging.v1beta1.LoggingSpecFluentdFluentdPvcSpec;
            forwardInputConfig?: outputs.logging.v1beta1.LoggingSpecFluentdForwardInputConfig;
            ignoreRepeatedLogInterval?: string;
            ignoreSameLogInterval?: string;
            image?: outputs.logging.v1beta1.LoggingSpecFluentdImage;
            labels?: { [key: string]: string };
            livenessDefaultCheck?: boolean;
            livenessProbe?: outputs.logging.v1beta1.LoggingSpecFluentdLivenessProbe;
            logLevel?: string;
            metrics?: outputs.logging.v1beta1.LoggingSpecFluentdMetrics;
            nodeSelector?: { [key: string]: string };
            podPriorityClassName?: string;
            port?: number;
            readinessProbe?: outputs.logging.v1beta1.LoggingSpecFluentdReadinessProbe;
            resources?: outputs.logging.v1beta1.LoggingSpecFluentdResources;
            rootDir?: string;
            scaling?: outputs.logging.v1beta1.LoggingSpecFluentdScaling;
            security?: outputs.logging.v1beta1.LoggingSpecFluentdSecurity;
            tls?: outputs.logging.v1beta1.LoggingSpecFluentdTls;
            tolerations?: outputs.logging.v1beta1.LoggingSpecFluentdTolerations[];
            volumeModImage?: outputs.logging.v1beta1.LoggingSpecFluentdVolumeModImage;
            volumeMountChmod?: boolean;
            workers?: number;
        }

        export interface LoggingSpecFluentdAffinity {
            nodeAffinity?: outputs.logging.v1beta1.LoggingSpecFluentdAffinityNodeAffinity;
            podAffinity?: outputs.logging.v1beta1.LoggingSpecFluentdAffinityPodAffinity;
            podAntiAffinity?: outputs.logging.v1beta1.LoggingSpecFluentdAffinityPodAntiAffinity;
        }

        export interface LoggingSpecFluentdAffinityNodeAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.logging.v1beta1.LoggingSpecFluentdAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.logging.v1beta1.LoggingSpecFluentdAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution;
        }

        export interface LoggingSpecFluentdAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            preference: outputs.logging.v1beta1.LoggingSpecFluentdAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference;
            weight: number;
        }

        export interface LoggingSpecFluentdAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference {
            matchExpressions?: outputs.logging.v1beta1.LoggingSpecFluentdAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions[];
            matchFields?: outputs.logging.v1beta1.LoggingSpecFluentdAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields[];
        }

        export interface LoggingSpecFluentdAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface LoggingSpecFluentdAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface LoggingSpecFluentdAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            nodeSelectorTerms: outputs.logging.v1beta1.LoggingSpecFluentdAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms[];
        }

        export interface LoggingSpecFluentdAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms {
            matchExpressions?: outputs.logging.v1beta1.LoggingSpecFluentdAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions[];
            matchFields?: outputs.logging.v1beta1.LoggingSpecFluentdAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields[];
        }

        export interface LoggingSpecFluentdAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface LoggingSpecFluentdAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface LoggingSpecFluentdAffinityPodAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.logging.v1beta1.LoggingSpecFluentdAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.logging.v1beta1.LoggingSpecFluentdAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        export interface LoggingSpecFluentdAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            podAffinityTerm: outputs.logging.v1beta1.LoggingSpecFluentdAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            weight: number;
        }

        export interface LoggingSpecFluentdAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            labelSelector?: outputs.logging.v1beta1.LoggingSpecFluentdAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            namespaces?: string[];
            topologyKey: string;
        }

        export interface LoggingSpecFluentdAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            matchExpressions?: outputs.logging.v1beta1.LoggingSpecFluentdAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            matchLabels?: { [key: string]: string };
        }

        export interface LoggingSpecFluentdAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface LoggingSpecFluentdAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            labelSelector?: outputs.logging.v1beta1.LoggingSpecFluentdAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            namespaces?: string[];
            topologyKey: string;
        }

        export interface LoggingSpecFluentdAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            matchExpressions?: outputs.logging.v1beta1.LoggingSpecFluentdAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            matchLabels?: { [key: string]: string };
        }

        export interface LoggingSpecFluentdAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface LoggingSpecFluentdAffinityPodAntiAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.logging.v1beta1.LoggingSpecFluentdAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.logging.v1beta1.LoggingSpecFluentdAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        export interface LoggingSpecFluentdAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            podAffinityTerm: outputs.logging.v1beta1.LoggingSpecFluentdAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            weight: number;
        }

        export interface LoggingSpecFluentdAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            labelSelector?: outputs.logging.v1beta1.LoggingSpecFluentdAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            namespaces?: string[];
            topologyKey: string;
        }

        export interface LoggingSpecFluentdAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            matchExpressions?: outputs.logging.v1beta1.LoggingSpecFluentdAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            matchLabels?: { [key: string]: string };
        }

        export interface LoggingSpecFluentdAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface LoggingSpecFluentdAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            labelSelector?: outputs.logging.v1beta1.LoggingSpecFluentdAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            namespaces?: string[];
            topologyKey: string;
        }

        export interface LoggingSpecFluentdAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            matchExpressions?: outputs.logging.v1beta1.LoggingSpecFluentdAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            matchLabels?: { [key: string]: string };
        }

        export interface LoggingSpecFluentdAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface LoggingSpecFluentdBufferStorageVolume {
            emptyDir?: outputs.logging.v1beta1.LoggingSpecFluentdBufferStorageVolumeEmptyDir;
            hostPath?: outputs.logging.v1beta1.LoggingSpecFluentdBufferStorageVolumeHostPath;
            host_path?: outputs.logging.v1beta1.LoggingSpecFluentdBufferStorageVolumeHost_path;
            pvc?: outputs.logging.v1beta1.LoggingSpecFluentdBufferStorageVolumePvc;
        }

        export interface LoggingSpecFluentdBufferStorageVolumeEmptyDir {
            medium?: string;
            sizeLimit?: string;
        }

        export interface LoggingSpecFluentdBufferStorageVolumeHostPath {
            path: string;
            type?: string;
        }

        export interface LoggingSpecFluentdBufferStorageVolumeHost_path {
            path: string;
            type?: string;
        }

        export interface LoggingSpecFluentdBufferStorageVolumePvc {
            source?: outputs.logging.v1beta1.LoggingSpecFluentdBufferStorageVolumePvcSource;
            spec?: outputs.logging.v1beta1.LoggingSpecFluentdBufferStorageVolumePvcSpec;
        }

        export interface LoggingSpecFluentdBufferStorageVolumePvcSource {
            claimName: string;
            readOnly?: boolean;
        }

        export interface LoggingSpecFluentdBufferStorageVolumePvcSpec {
            accessModes?: string[];
            dataSource?: outputs.logging.v1beta1.LoggingSpecFluentdBufferStorageVolumePvcSpecDataSource;
            resources?: outputs.logging.v1beta1.LoggingSpecFluentdBufferStorageVolumePvcSpecResources;
            selector?: outputs.logging.v1beta1.LoggingSpecFluentdBufferStorageVolumePvcSpecSelector;
            storageClassName?: string;
            volumeMode?: string;
            volumeName?: string;
        }

        export interface LoggingSpecFluentdBufferStorageVolumePvcSpecDataSource {
            apiGroup?: string;
            kind: string;
            name: string;
        }

        export interface LoggingSpecFluentdBufferStorageVolumePvcSpecResources {
            limits?: { [key: string]: string };
            requests?: { [key: string]: string };
        }

        export interface LoggingSpecFluentdBufferStorageVolumePvcSpecSelector {
            matchExpressions?: outputs.logging.v1beta1.LoggingSpecFluentdBufferStorageVolumePvcSpecSelectorMatchExpressions[];
            matchLabels?: { [key: string]: string };
        }

        export interface LoggingSpecFluentdBufferStorageVolumePvcSpecSelectorMatchExpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface LoggingSpecFluentdConfigReloaderImage {
            imagePullSecrets?: outputs.logging.v1beta1.LoggingSpecFluentdConfigReloaderImageImagePullSecrets[];
            pullPolicy?: string;
            repository?: string;
            tag?: string;
        }

        export interface LoggingSpecFluentdConfigReloaderImageImagePullSecrets {
            name?: string;
        }

        export interface LoggingSpecFluentdFluentOutLogrotate {
            age?: string;
            enabled: boolean;
            path?: string;
            size?: string;
        }

        export interface LoggingSpecFluentdFluentdPvcSpec {
            emptyDir?: outputs.logging.v1beta1.LoggingSpecFluentdFluentdPvcSpecEmptyDir;
            hostPath?: outputs.logging.v1beta1.LoggingSpecFluentdFluentdPvcSpecHostPath;
            host_path?: outputs.logging.v1beta1.LoggingSpecFluentdFluentdPvcSpecHost_path;
            pvc?: outputs.logging.v1beta1.LoggingSpecFluentdFluentdPvcSpecPvc;
        }

        export interface LoggingSpecFluentdFluentdPvcSpecEmptyDir {
            medium?: string;
            sizeLimit?: string;
        }

        export interface LoggingSpecFluentdFluentdPvcSpecHostPath {
            path: string;
            type?: string;
        }

        export interface LoggingSpecFluentdFluentdPvcSpecHost_path {
            path: string;
            type?: string;
        }

        export interface LoggingSpecFluentdFluentdPvcSpecPvc {
            source?: outputs.logging.v1beta1.LoggingSpecFluentdFluentdPvcSpecPvcSource;
            spec?: outputs.logging.v1beta1.LoggingSpecFluentdFluentdPvcSpecPvcSpec;
        }

        export interface LoggingSpecFluentdFluentdPvcSpecPvcSource {
            claimName: string;
            readOnly?: boolean;
        }

        export interface LoggingSpecFluentdFluentdPvcSpecPvcSpec {
            accessModes?: string[];
            dataSource?: outputs.logging.v1beta1.LoggingSpecFluentdFluentdPvcSpecPvcSpecDataSource;
            resources?: outputs.logging.v1beta1.LoggingSpecFluentdFluentdPvcSpecPvcSpecResources;
            selector?: outputs.logging.v1beta1.LoggingSpecFluentdFluentdPvcSpecPvcSpecSelector;
            storageClassName?: string;
            volumeMode?: string;
            volumeName?: string;
        }

        export interface LoggingSpecFluentdFluentdPvcSpecPvcSpecDataSource {
            apiGroup?: string;
            kind: string;
            name: string;
        }

        export interface LoggingSpecFluentdFluentdPvcSpecPvcSpecResources {
            limits?: { [key: string]: string };
            requests?: { [key: string]: string };
        }

        export interface LoggingSpecFluentdFluentdPvcSpecPvcSpecSelector {
            matchExpressions?: outputs.logging.v1beta1.LoggingSpecFluentdFluentdPvcSpecPvcSpecSelectorMatchExpressions[];
            matchLabels?: { [key: string]: string };
        }

        export interface LoggingSpecFluentdFluentdPvcSpecPvcSpecSelectorMatchExpressions {
            key: string;
            operator: string;
            values?: string[];
        }

        export interface LoggingSpecFluentdForwardInputConfig {
            add_tag_prefix?: string;
            bind?: string;
            chunk_size_limit?: string;
            chunk_size_warn_limit?: string;
            deny_keepalive?: boolean;
            linger_timeout?: number;
            port?: string;
            resolve_hostname?: boolean;
            security?: outputs.logging.v1beta1.LoggingSpecFluentdForwardInputConfigSecurity;
            send_keepalive_packet?: boolean;
            skip_invalid_event?: boolean;
            sourceHostnameKey?: string;
            source_address_key?: string;
            tag?: string;
            transport?: outputs.logging.v1beta1.LoggingSpecFluentdForwardInputConfigTransport;
        }

        export interface LoggingSpecFluentdForwardInputConfigSecurity {
            allow_anonymous_source?: boolean;
            self_hostname: string;
            shared_key: string;
            user_auth?: boolean;
        }

        export interface LoggingSpecFluentdForwardInputConfigTransport {
            ca_cert_path?: string;
            ca_path?: string;
            ca_private_key_passphrase?: string;
            ca_private_key_path?: string;
            cert_path?: string;
            ciphers?: string;
            client_cert_auth?: boolean;
            insecure?: boolean;
            private_key_passphrase?: string;
            private_key_path?: string;
            protocol?: string;
            version?: string;
        }

        export interface LoggingSpecFluentdImage {
            imagePullSecrets?: outputs.logging.v1beta1.LoggingSpecFluentdImageImagePullSecrets[];
            pullPolicy?: string;
            repository?: string;
            tag?: string;
        }

        export interface LoggingSpecFluentdImageImagePullSecrets {
            name?: string;
        }

        export interface LoggingSpecFluentdLivenessProbe {
            exec?: outputs.logging.v1beta1.LoggingSpecFluentdLivenessProbeExec;
            failureThreshold?: number;
            httpGet?: outputs.logging.v1beta1.LoggingSpecFluentdLivenessProbeHttpGet;
            initialDelaySeconds?: number;
            periodSeconds?: number;
            successThreshold?: number;
            tcpSocket?: outputs.logging.v1beta1.LoggingSpecFluentdLivenessProbeTcpSocket;
            timeoutSeconds?: number;
        }

        export interface LoggingSpecFluentdLivenessProbeExec {
            command?: string[];
        }

        export interface LoggingSpecFluentdLivenessProbeHttpGet {
            host?: string;
            httpHeaders?: outputs.logging.v1beta1.LoggingSpecFluentdLivenessProbeHttpGetHttpHeaders[];
            path?: string;
            port: outputs.logging.v1beta1.LoggingSpecFluentdLivenessProbeHttpGetPort;
            scheme?: string;
        }

        export interface LoggingSpecFluentdLivenessProbeHttpGetHttpHeaders {
            name: string;
            value: string;
        }

        export interface LoggingSpecFluentdLivenessProbeHttpGetPort {
        }

        export interface LoggingSpecFluentdLivenessProbeTcpSocket {
            host?: string;
            port: outputs.logging.v1beta1.LoggingSpecFluentdLivenessProbeTcpSocketPort;
        }

        export interface LoggingSpecFluentdLivenessProbeTcpSocketPort {
        }

        export interface LoggingSpecFluentdMetrics {
            interval?: string;
            path?: string;
            port?: number;
            prometheusAnnotations?: boolean;
            serviceMonitor?: boolean;
            serviceMonitorConfig?: outputs.logging.v1beta1.LoggingSpecFluentdMetricsServiceMonitorConfig;
            timeout?: string;
        }

        export interface LoggingSpecFluentdMetricsServiceMonitorConfig {
            additionalLabels?: { [key: string]: string };
            honorLabels?: boolean;
            metricRelabelings?: outputs.logging.v1beta1.LoggingSpecFluentdMetricsServiceMonitorConfigMetricRelabelings[];
            relabelings?: outputs.logging.v1beta1.LoggingSpecFluentdMetricsServiceMonitorConfigRelabelings[];
        }

        export interface LoggingSpecFluentdMetricsServiceMonitorConfigMetricRelabelings {
            action?: string;
            modulus?: number;
            regex?: string;
            replacement?: string;
            separator?: string;
            sourceLabels?: string[];
            targetLabel?: string;
        }

        export interface LoggingSpecFluentdMetricsServiceMonitorConfigRelabelings {
            action?: string;
            modulus?: number;
            regex?: string;
            replacement?: string;
            separator?: string;
            sourceLabels?: string[];
            targetLabel?: string;
        }

        export interface LoggingSpecFluentdReadinessProbe {
            exec?: outputs.logging.v1beta1.LoggingSpecFluentdReadinessProbeExec;
            failureThreshold?: number;
            httpGet?: outputs.logging.v1beta1.LoggingSpecFluentdReadinessProbeHttpGet;
            initialDelaySeconds?: number;
            periodSeconds?: number;
            successThreshold?: number;
            tcpSocket?: outputs.logging.v1beta1.LoggingSpecFluentdReadinessProbeTcpSocket;
            timeoutSeconds?: number;
        }

        export interface LoggingSpecFluentdReadinessProbeExec {
            command?: string[];
        }

        export interface LoggingSpecFluentdReadinessProbeHttpGet {
            host?: string;
            httpHeaders?: outputs.logging.v1beta1.LoggingSpecFluentdReadinessProbeHttpGetHttpHeaders[];
            path?: string;
            port: outputs.logging.v1beta1.LoggingSpecFluentdReadinessProbeHttpGetPort;
            scheme?: string;
        }

        export interface LoggingSpecFluentdReadinessProbeHttpGetHttpHeaders {
            name: string;
            value: string;
        }

        export interface LoggingSpecFluentdReadinessProbeHttpGetPort {
        }

        export interface LoggingSpecFluentdReadinessProbeTcpSocket {
            host?: string;
            port: outputs.logging.v1beta1.LoggingSpecFluentdReadinessProbeTcpSocketPort;
        }

        export interface LoggingSpecFluentdReadinessProbeTcpSocketPort {
        }

        export interface LoggingSpecFluentdResources {
            limits?: { [key: string]: string };
            requests?: { [key: string]: string };
        }

        export interface LoggingSpecFluentdScaling {
            podManagementPolicy?: string;
            replicas?: number;
        }

        export interface LoggingSpecFluentdSecurity {
            podSecurityContext?: outputs.logging.v1beta1.LoggingSpecFluentdSecurityPodSecurityContext;
            podSecurityPolicyCreate?: boolean;
            roleBasedAccessControlCreate?: boolean;
            securityContext?: outputs.logging.v1beta1.LoggingSpecFluentdSecuritySecurityContext;
            serviceAccount?: string;
        }

        export interface LoggingSpecFluentdSecurityPodSecurityContext {
            fsGroup?: number;
            fsGroupChangePolicy?: string;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.logging.v1beta1.LoggingSpecFluentdSecurityPodSecurityContextSeLinuxOptions;
            seccompProfile?: outputs.logging.v1beta1.LoggingSpecFluentdSecurityPodSecurityContextSeccompProfile;
            supplementalGroups?: number[];
            sysctls?: outputs.logging.v1beta1.LoggingSpecFluentdSecurityPodSecurityContextSysctls[];
            windowsOptions?: outputs.logging.v1beta1.LoggingSpecFluentdSecurityPodSecurityContextWindowsOptions;
        }

        export interface LoggingSpecFluentdSecurityPodSecurityContextSeLinuxOptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface LoggingSpecFluentdSecurityPodSecurityContextSeccompProfile {
            localhostProfile?: string;
            type: string;
        }

        export interface LoggingSpecFluentdSecurityPodSecurityContextSysctls {
            name: string;
            value: string;
        }

        export interface LoggingSpecFluentdSecurityPodSecurityContextWindowsOptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        export interface LoggingSpecFluentdSecuritySecurityContext {
            allowPrivilegeEscalation?: boolean;
            capabilities?: outputs.logging.v1beta1.LoggingSpecFluentdSecuritySecurityContextCapabilities;
            privileged?: boolean;
            procMount?: string;
            readOnlyRootFilesystem?: boolean;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.logging.v1beta1.LoggingSpecFluentdSecuritySecurityContextSeLinuxOptions;
            seccompProfile?: outputs.logging.v1beta1.LoggingSpecFluentdSecuritySecurityContextSeccompProfile;
            windowsOptions?: outputs.logging.v1beta1.LoggingSpecFluentdSecuritySecurityContextWindowsOptions;
        }

        export interface LoggingSpecFluentdSecuritySecurityContextCapabilities {
            add?: string[];
            drop?: string[];
        }

        export interface LoggingSpecFluentdSecuritySecurityContextSeLinuxOptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface LoggingSpecFluentdSecuritySecurityContextSeccompProfile {
            localhostProfile?: string;
            type: string;
        }

        export interface LoggingSpecFluentdSecuritySecurityContextWindowsOptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        export interface LoggingSpecFluentdTls {
            enabled: boolean;
            secretName?: string;
            sharedKey?: string;
        }

        export interface LoggingSpecFluentdTolerations {
            effect?: string;
            key?: string;
            operator?: string;
            tolerationSeconds?: number;
            value?: string;
        }

        export interface LoggingSpecFluentdVolumeModImage {
            imagePullSecrets?: outputs.logging.v1beta1.LoggingSpecFluentdVolumeModImageImagePullSecrets[];
            pullPolicy?: string;
            repository?: string;
            tag?: string;
        }

        export interface LoggingSpecFluentdVolumeModImageImagePullSecrets {
            name?: string;
        }

        export interface LoggingStatus {
            configCheckResults?: { [key: string]: boolean };
        }

        export interface OutputSpec {
            awsElasticsearch?: outputs.logging.v1beta1.OutputSpecAwsElasticsearch;
            azurestorage?: outputs.logging.v1beta1.OutputSpecAzurestorage;
            cloudwatch?: outputs.logging.v1beta1.OutputSpecCloudwatch;
            datadog?: outputs.logging.v1beta1.OutputSpecDatadog;
            elasticsearch?: outputs.logging.v1beta1.OutputSpecElasticsearch;
            file?: outputs.logging.v1beta1.OutputSpecFile;
            forward?: outputs.logging.v1beta1.OutputSpecForward;
            gcs?: outputs.logging.v1beta1.OutputSpecGcs;
            http?: outputs.logging.v1beta1.OutputSpecHttp;
            kafka?: outputs.logging.v1beta1.OutputSpecKafka;
            kinesisStream?: outputs.logging.v1beta1.OutputSpecKinesisStream;
            logdna?: outputs.logging.v1beta1.OutputSpecLogdna;
            loggingRef?: string;
            logz?: outputs.logging.v1beta1.OutputSpecLogz;
            loki?: outputs.logging.v1beta1.OutputSpecLoki;
            newrelic?: outputs.logging.v1beta1.OutputSpecNewrelic;
            nullout?: { [key: string]: any };
            oss?: outputs.logging.v1beta1.OutputSpecOss;
            redis?: outputs.logging.v1beta1.OutputSpecRedis;
            s3?: outputs.logging.v1beta1.OutputSpecS3;
            splunkHec?: outputs.logging.v1beta1.OutputSpecSplunkHec;
            sumologic?: outputs.logging.v1beta1.OutputSpecSumologic;
            syslog?: outputs.logging.v1beta1.OutputSpecSyslog;
        }

        export interface OutputSpecAwsElasticsearch {
            buffer?: outputs.logging.v1beta1.OutputSpecAwsElasticsearchBuffer;
            endpoint?: outputs.logging.v1beta1.OutputSpecAwsElasticsearchEndpoint;
            flush_interval?: string;
            format?: outputs.logging.v1beta1.OutputSpecAwsElasticsearchFormat;
            include_tag_key?: boolean;
            logstash_format?: boolean;
            tag_key?: string;
        }

        export interface OutputSpecAwsElasticsearchBuffer {
            chunk_full_threshold?: string;
            chunk_limit_records?: number;
            chunk_limit_size?: string;
            compress?: string;
            delayed_commit_timeout?: string;
            disable_chunk_backup?: boolean;
            flush_at_shutdown?: boolean;
            flush_interval?: string;
            flush_mode?: string;
            flush_thread_burst_interval?: string;
            flush_thread_count?: number;
            flush_thread_interval?: string;
            overflow_action?: string;
            path?: string;
            queue_limit_length?: number;
            queued_chunks_limit_size?: number;
            retry_exponential_backoff_base?: string;
            retry_forever?: boolean;
            retry_max_interval?: string;
            retry_max_times?: number;
            retry_randomize?: boolean;
            retry_secondary_threshold?: string;
            retry_timeout?: string;
            retry_type?: string;
            retry_wait?: string;
            tags?: string;
            timekey?: string;
            timekey_use_utc?: boolean;
            timekey_wait?: string;
            timekey_zone?: string;
            total_limit_size?: string;
            type?: string;
        }

        export interface OutputSpecAwsElasticsearchEndpoint {
            access_key_id?: outputs.logging.v1beta1.OutputSpecAwsElasticsearchEndpointAccess_key_id;
            assume_role_arn?: outputs.logging.v1beta1.OutputSpecAwsElasticsearchEndpointAssume_role_arn;
            assume_role_session_name?: outputs.logging.v1beta1.OutputSpecAwsElasticsearchEndpointAssume_role_session_name;
            assume_role_web_identity_token_file?: outputs.logging.v1beta1.OutputSpecAwsElasticsearchEndpointAssume_role_web_identity_token_file;
            ecs_container_credentials_relative_uri?: outputs.logging.v1beta1.OutputSpecAwsElasticsearchEndpointEcs_container_credentials_relative_uri;
            region?: string;
            secret_access_key?: outputs.logging.v1beta1.OutputSpecAwsElasticsearchEndpointSecret_access_key;
            sts_credentials_region?: outputs.logging.v1beta1.OutputSpecAwsElasticsearchEndpointSts_credentials_region;
            url?: string;
        }

        export interface OutputSpecAwsElasticsearchEndpointAccess_key_id {
            mountFrom?: outputs.logging.v1beta1.OutputSpecAwsElasticsearchEndpointAccess_key_idMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.OutputSpecAwsElasticsearchEndpointAccess_key_idValueFrom;
        }

        export interface OutputSpecAwsElasticsearchEndpointAccess_key_idMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecAwsElasticsearchEndpointAccess_key_idMountFromSecretKeyRef;
        }

        export interface OutputSpecAwsElasticsearchEndpointAccess_key_idMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecAwsElasticsearchEndpointAccess_key_idValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecAwsElasticsearchEndpointAccess_key_idValueFromSecretKeyRef;
        }

        export interface OutputSpecAwsElasticsearchEndpointAccess_key_idValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecAwsElasticsearchEndpointAssume_role_arn {
            mountFrom?: outputs.logging.v1beta1.OutputSpecAwsElasticsearchEndpointAssume_role_arnMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.OutputSpecAwsElasticsearchEndpointAssume_role_arnValueFrom;
        }

        export interface OutputSpecAwsElasticsearchEndpointAssume_role_arnMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecAwsElasticsearchEndpointAssume_role_arnMountFromSecretKeyRef;
        }

        export interface OutputSpecAwsElasticsearchEndpointAssume_role_arnMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecAwsElasticsearchEndpointAssume_role_arnValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecAwsElasticsearchEndpointAssume_role_arnValueFromSecretKeyRef;
        }

        export interface OutputSpecAwsElasticsearchEndpointAssume_role_arnValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecAwsElasticsearchEndpointAssume_role_session_name {
            mountFrom?: outputs.logging.v1beta1.OutputSpecAwsElasticsearchEndpointAssume_role_session_nameMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.OutputSpecAwsElasticsearchEndpointAssume_role_session_nameValueFrom;
        }

        export interface OutputSpecAwsElasticsearchEndpointAssume_role_session_nameMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecAwsElasticsearchEndpointAssume_role_session_nameMountFromSecretKeyRef;
        }

        export interface OutputSpecAwsElasticsearchEndpointAssume_role_session_nameMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecAwsElasticsearchEndpointAssume_role_session_nameValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecAwsElasticsearchEndpointAssume_role_session_nameValueFromSecretKeyRef;
        }

        export interface OutputSpecAwsElasticsearchEndpointAssume_role_session_nameValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecAwsElasticsearchEndpointAssume_role_web_identity_token_file {
            mountFrom?: outputs.logging.v1beta1.OutputSpecAwsElasticsearchEndpointAssume_role_web_identity_token_fileMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.OutputSpecAwsElasticsearchEndpointAssume_role_web_identity_token_fileValueFrom;
        }

        export interface OutputSpecAwsElasticsearchEndpointAssume_role_web_identity_token_fileMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecAwsElasticsearchEndpointAssume_role_web_identity_token_fileMountFromSecretKeyRef;
        }

        export interface OutputSpecAwsElasticsearchEndpointAssume_role_web_identity_token_fileMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecAwsElasticsearchEndpointAssume_role_web_identity_token_fileValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecAwsElasticsearchEndpointAssume_role_web_identity_token_fileValueFromSecretKeyRef;
        }

        export interface OutputSpecAwsElasticsearchEndpointAssume_role_web_identity_token_fileValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecAwsElasticsearchEndpointEcs_container_credentials_relative_uri {
            mountFrom?: outputs.logging.v1beta1.OutputSpecAwsElasticsearchEndpointEcs_container_credentials_relative_uriMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.OutputSpecAwsElasticsearchEndpointEcs_container_credentials_relative_uriValueFrom;
        }

        export interface OutputSpecAwsElasticsearchEndpointEcs_container_credentials_relative_uriMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecAwsElasticsearchEndpointEcs_container_credentials_relative_uriMountFromSecretKeyRef;
        }

        export interface OutputSpecAwsElasticsearchEndpointEcs_container_credentials_relative_uriMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecAwsElasticsearchEndpointEcs_container_credentials_relative_uriValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecAwsElasticsearchEndpointEcs_container_credentials_relative_uriValueFromSecretKeyRef;
        }

        export interface OutputSpecAwsElasticsearchEndpointEcs_container_credentials_relative_uriValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecAwsElasticsearchEndpointSecret_access_key {
            mountFrom?: outputs.logging.v1beta1.OutputSpecAwsElasticsearchEndpointSecret_access_keyMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.OutputSpecAwsElasticsearchEndpointSecret_access_keyValueFrom;
        }

        export interface OutputSpecAwsElasticsearchEndpointSecret_access_keyMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecAwsElasticsearchEndpointSecret_access_keyMountFromSecretKeyRef;
        }

        export interface OutputSpecAwsElasticsearchEndpointSecret_access_keyMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecAwsElasticsearchEndpointSecret_access_keyValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecAwsElasticsearchEndpointSecret_access_keyValueFromSecretKeyRef;
        }

        export interface OutputSpecAwsElasticsearchEndpointSecret_access_keyValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecAwsElasticsearchEndpointSts_credentials_region {
            mountFrom?: outputs.logging.v1beta1.OutputSpecAwsElasticsearchEndpointSts_credentials_regionMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.OutputSpecAwsElasticsearchEndpointSts_credentials_regionValueFrom;
        }

        export interface OutputSpecAwsElasticsearchEndpointSts_credentials_regionMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecAwsElasticsearchEndpointSts_credentials_regionMountFromSecretKeyRef;
        }

        export interface OutputSpecAwsElasticsearchEndpointSts_credentials_regionMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecAwsElasticsearchEndpointSts_credentials_regionValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecAwsElasticsearchEndpointSts_credentials_regionValueFromSecretKeyRef;
        }

        export interface OutputSpecAwsElasticsearchEndpointSts_credentials_regionValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecAwsElasticsearchFormat {
            add_newline?: boolean;
            message_key?: string;
            type?: string;
        }

        export interface OutputSpecAzurestorage {
            auto_create_container?: boolean;
            azure_container: string;
            azure_imds_api_version?: string;
            azure_object_key_format?: string;
            azure_storage_access_key: outputs.logging.v1beta1.OutputSpecAzurestorageAzure_storage_access_key;
            azure_storage_account: outputs.logging.v1beta1.OutputSpecAzurestorageAzure_storage_account;
            azure_storage_sas_token: outputs.logging.v1beta1.OutputSpecAzurestorageAzure_storage_sas_token;
            buffer?: outputs.logging.v1beta1.OutputSpecAzurestorageBuffer;
            format?: string;
            path?: string;
        }

        export interface OutputSpecAzurestorageAzure_storage_access_key {
            mountFrom?: outputs.logging.v1beta1.OutputSpecAzurestorageAzure_storage_access_keyMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.OutputSpecAzurestorageAzure_storage_access_keyValueFrom;
        }

        export interface OutputSpecAzurestorageAzure_storage_access_keyMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecAzurestorageAzure_storage_access_keyMountFromSecretKeyRef;
        }

        export interface OutputSpecAzurestorageAzure_storage_access_keyMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecAzurestorageAzure_storage_access_keyValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecAzurestorageAzure_storage_access_keyValueFromSecretKeyRef;
        }

        export interface OutputSpecAzurestorageAzure_storage_access_keyValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecAzurestorageAzure_storage_account {
            mountFrom?: outputs.logging.v1beta1.OutputSpecAzurestorageAzure_storage_accountMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.OutputSpecAzurestorageAzure_storage_accountValueFrom;
        }

        export interface OutputSpecAzurestorageAzure_storage_accountMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecAzurestorageAzure_storage_accountMountFromSecretKeyRef;
        }

        export interface OutputSpecAzurestorageAzure_storage_accountMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecAzurestorageAzure_storage_accountValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecAzurestorageAzure_storage_accountValueFromSecretKeyRef;
        }

        export interface OutputSpecAzurestorageAzure_storage_accountValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecAzurestorageAzure_storage_sas_token {
            mountFrom?: outputs.logging.v1beta1.OutputSpecAzurestorageAzure_storage_sas_tokenMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.OutputSpecAzurestorageAzure_storage_sas_tokenValueFrom;
        }

        export interface OutputSpecAzurestorageAzure_storage_sas_tokenMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecAzurestorageAzure_storage_sas_tokenMountFromSecretKeyRef;
        }

        export interface OutputSpecAzurestorageAzure_storage_sas_tokenMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecAzurestorageAzure_storage_sas_tokenValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecAzurestorageAzure_storage_sas_tokenValueFromSecretKeyRef;
        }

        export interface OutputSpecAzurestorageAzure_storage_sas_tokenValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecAzurestorageBuffer {
            chunk_full_threshold?: string;
            chunk_limit_records?: number;
            chunk_limit_size?: string;
            compress?: string;
            delayed_commit_timeout?: string;
            disable_chunk_backup?: boolean;
            flush_at_shutdown?: boolean;
            flush_interval?: string;
            flush_mode?: string;
            flush_thread_burst_interval?: string;
            flush_thread_count?: number;
            flush_thread_interval?: string;
            overflow_action?: string;
            path?: string;
            queue_limit_length?: number;
            queued_chunks_limit_size?: number;
            retry_exponential_backoff_base?: string;
            retry_forever?: boolean;
            retry_max_interval?: string;
            retry_max_times?: number;
            retry_randomize?: boolean;
            retry_secondary_threshold?: string;
            retry_timeout?: string;
            retry_type?: string;
            retry_wait?: string;
            tags?: string;
            timekey?: string;
            timekey_use_utc?: boolean;
            timekey_wait?: string;
            timekey_zone?: string;
            total_limit_size?: string;
            type?: string;
        }

        export interface OutputSpecCloudwatch {
            auto_create_stream?: boolean;
            aws_instance_profile_credentials_retries?: number;
            aws_key_id?: outputs.logging.v1beta1.OutputSpecCloudwatchAws_key_id;
            aws_sec_key?: outputs.logging.v1beta1.OutputSpecCloudwatchAws_sec_key;
            aws_sts_role_arn?: string;
            aws_sts_session_name?: string;
            aws_use_sts?: boolean;
            buffer?: outputs.logging.v1beta1.OutputSpecCloudwatchBuffer;
            concurrency?: number;
            endpoint?: string;
            format?: outputs.logging.v1beta1.OutputSpecCloudwatchFormat;
            http_proxy?: string;
            include_time_key?: boolean;
            json_handler?: string;
            localtime?: boolean;
            log_group_aws_tags?: string;
            log_group_aws_tags_key?: string;
            log_group_name?: string;
            log_group_name_key?: string;
            log_rejected_request?: string;
            log_stream_name?: string;
            log_stream_name_key?: string;
            max_events_per_batch?: number;
            max_message_length?: number;
            message_keys?: string;
            put_log_events_disable_retry_limit?: boolean;
            put_log_events_retry_limit?: number;
            put_log_events_retry_wait?: string;
            region: string;
            remove_log_group_aws_tags_key?: string;
            remove_log_group_name_key?: string;
            remove_log_stream_name_key?: string;
            remove_retention_in_days?: string;
            retention_in_days?: string;
            retention_in_days_key?: string;
            use_tag_as_group?: boolean;
            use_tag_as_stream?: boolean;
        }

        export interface OutputSpecCloudwatchAws_key_id {
            mountFrom?: outputs.logging.v1beta1.OutputSpecCloudwatchAws_key_idMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.OutputSpecCloudwatchAws_key_idValueFrom;
        }

        export interface OutputSpecCloudwatchAws_key_idMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecCloudwatchAws_key_idMountFromSecretKeyRef;
        }

        export interface OutputSpecCloudwatchAws_key_idMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecCloudwatchAws_key_idValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecCloudwatchAws_key_idValueFromSecretKeyRef;
        }

        export interface OutputSpecCloudwatchAws_key_idValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecCloudwatchAws_sec_key {
            mountFrom?: outputs.logging.v1beta1.OutputSpecCloudwatchAws_sec_keyMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.OutputSpecCloudwatchAws_sec_keyValueFrom;
        }

        export interface OutputSpecCloudwatchAws_sec_keyMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecCloudwatchAws_sec_keyMountFromSecretKeyRef;
        }

        export interface OutputSpecCloudwatchAws_sec_keyMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecCloudwatchAws_sec_keyValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecCloudwatchAws_sec_keyValueFromSecretKeyRef;
        }

        export interface OutputSpecCloudwatchAws_sec_keyValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecCloudwatchBuffer {
            chunk_full_threshold?: string;
            chunk_limit_records?: number;
            chunk_limit_size?: string;
            compress?: string;
            delayed_commit_timeout?: string;
            disable_chunk_backup?: boolean;
            flush_at_shutdown?: boolean;
            flush_interval?: string;
            flush_mode?: string;
            flush_thread_burst_interval?: string;
            flush_thread_count?: number;
            flush_thread_interval?: string;
            overflow_action?: string;
            path?: string;
            queue_limit_length?: number;
            queued_chunks_limit_size?: number;
            retry_exponential_backoff_base?: string;
            retry_forever?: boolean;
            retry_max_interval?: string;
            retry_max_times?: number;
            retry_randomize?: boolean;
            retry_secondary_threshold?: string;
            retry_timeout?: string;
            retry_type?: string;
            retry_wait?: string;
            tags?: string;
            timekey?: string;
            timekey_use_utc?: boolean;
            timekey_wait?: string;
            timekey_zone?: string;
            total_limit_size?: string;
            type?: string;
        }

        export interface OutputSpecCloudwatchFormat {
            add_newline?: boolean;
            message_key?: string;
            type?: string;
        }

        export interface OutputSpecDatadog {
            api_key: outputs.logging.v1beta1.OutputSpecDatadogApi_key;
            buffer?: outputs.logging.v1beta1.OutputSpecDatadogBuffer;
            compression_level?: string;
            dd_hostname?: string;
            dd_source?: string;
            dd_sourcecategory?: string;
            dd_tags?: string;
            host?: string;
            include_tag_key?: boolean;
            max_backoff?: string;
            max_retries?: string;
            no_ssl_validation?: boolean;
            port?: string;
            service?: string;
            ssl_port?: string;
            tag_key?: string;
            timestamp_key?: string;
            use_compression?: boolean;
            use_http?: boolean;
            use_json?: boolean;
            use_ssl?: boolean;
        }

        export interface OutputSpecDatadogApi_key {
            mountFrom?: outputs.logging.v1beta1.OutputSpecDatadogApi_keyMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.OutputSpecDatadogApi_keyValueFrom;
        }

        export interface OutputSpecDatadogApi_keyMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecDatadogApi_keyMountFromSecretKeyRef;
        }

        export interface OutputSpecDatadogApi_keyMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecDatadogApi_keyValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecDatadogApi_keyValueFromSecretKeyRef;
        }

        export interface OutputSpecDatadogApi_keyValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecDatadogBuffer {
            chunk_full_threshold?: string;
            chunk_limit_records?: number;
            chunk_limit_size?: string;
            compress?: string;
            delayed_commit_timeout?: string;
            disable_chunk_backup?: boolean;
            flush_at_shutdown?: boolean;
            flush_interval?: string;
            flush_mode?: string;
            flush_thread_burst_interval?: string;
            flush_thread_count?: number;
            flush_thread_interval?: string;
            overflow_action?: string;
            path?: string;
            queue_limit_length?: number;
            queued_chunks_limit_size?: number;
            retry_exponential_backoff_base?: string;
            retry_forever?: boolean;
            retry_max_interval?: string;
            retry_max_times?: number;
            retry_randomize?: boolean;
            retry_secondary_threshold?: string;
            retry_timeout?: string;
            retry_type?: string;
            retry_wait?: string;
            tags?: string;
            timekey?: string;
            timekey_use_utc?: boolean;
            timekey_wait?: string;
            timekey_zone?: string;
            total_limit_size?: string;
            type?: string;
        }

        export interface OutputSpecElasticsearch {
            application_name?: string;
            buffer?: outputs.logging.v1beta1.OutputSpecElasticsearchBuffer;
            bulk_message_request_threshold?: string;
            ca_file?: outputs.logging.v1beta1.OutputSpecElasticsearchCa_file;
            client_cert?: outputs.logging.v1beta1.OutputSpecElasticsearchClient_cert;
            client_key?: outputs.logging.v1beta1.OutputSpecElasticsearchClient_key;
            client_key_pass?: outputs.logging.v1beta1.OutputSpecElasticsearchClient_key_pass;
            content_type?: string;
            custom_headers?: string;
            customize_template?: string;
            default_elasticsearch_version?: string;
            deflector_alias?: string;
            enable_ilm?: boolean;
            exception_backup?: boolean;
            fail_on_putting_template_retry_exceed?: boolean;
            flatten_hashes?: boolean;
            flatten_hashes_separator?: string;
            host?: string;
            hosts?: string;
            http_backend?: string;
            id_key?: string;
            ignore_exceptions?: string;
            ilm_policy?: string;
            ilm_policy_id?: string;
            ilm_policy_overwrite?: boolean;
            include_index_in_url?: boolean;
            include_tag_key?: boolean;
            include_timestamp?: boolean;
            index_date_pattern?: string;
            index_name?: string;
            index_prefix?: string;
            log_es_400_reason?: boolean;
            logstash_dateformat?: string;
            logstash_format?: boolean;
            logstash_prefix?: string;
            logstash_prefix_separator?: string;
            max_retry_get_es_version?: string;
            max_retry_putting_template?: string;
            password?: outputs.logging.v1beta1.OutputSpecElasticsearchPassword;
            path?: string;
            pipeline?: string;
            port?: number;
            prefer_oj_serializer?: boolean;
            reconnect_on_error?: boolean;
            reload_after?: string;
            reload_connections?: boolean;
            reload_on_failure?: boolean;
            remove_keys_on_update?: string;
            remove_keys_on_update_key?: string;
            request_timeout?: string;
            resurrect_after?: string;
            retry_tag?: string;
            rollover_index?: boolean;
            routing_key?: string;
            scheme?: string;
            sniffer_class_name?: string;
            ssl_max_version?: string;
            ssl_min_version?: string;
            ssl_verify?: boolean;
            ssl_version?: string;
            suppress_doc_wrap?: boolean;
            suppress_type_name?: boolean;
            tag_key?: string;
            target_index_key?: string;
            target_type_key?: string;
            template_file?: outputs.logging.v1beta1.OutputSpecElasticsearchTemplate_file;
            template_name?: string;
            template_overwrite?: boolean;
            templates?: string;
            time_key?: string;
            time_key_format?: string;
            time_parse_error_tag?: string;
            time_precision?: string;
            type_name?: string;
            unrecoverable_error_types?: string;
            user?: string;
            utc_index?: boolean;
            validate_client_version?: boolean;
            verify_es_version_at_startup?: boolean;
            with_transporter_log?: boolean;
            write_operation?: string;
        }

        export interface OutputSpecElasticsearchBuffer {
            chunk_full_threshold?: string;
            chunk_limit_records?: number;
            chunk_limit_size?: string;
            compress?: string;
            delayed_commit_timeout?: string;
            disable_chunk_backup?: boolean;
            flush_at_shutdown?: boolean;
            flush_interval?: string;
            flush_mode?: string;
            flush_thread_burst_interval?: string;
            flush_thread_count?: number;
            flush_thread_interval?: string;
            overflow_action?: string;
            path?: string;
            queue_limit_length?: number;
            queued_chunks_limit_size?: number;
            retry_exponential_backoff_base?: string;
            retry_forever?: boolean;
            retry_max_interval?: string;
            retry_max_times?: number;
            retry_randomize?: boolean;
            retry_secondary_threshold?: string;
            retry_timeout?: string;
            retry_type?: string;
            retry_wait?: string;
            tags?: string;
            timekey?: string;
            timekey_use_utc?: boolean;
            timekey_wait?: string;
            timekey_zone?: string;
            total_limit_size?: string;
            type?: string;
        }

        export interface OutputSpecElasticsearchCa_file {
            mountFrom?: outputs.logging.v1beta1.OutputSpecElasticsearchCa_fileMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.OutputSpecElasticsearchCa_fileValueFrom;
        }

        export interface OutputSpecElasticsearchCa_fileMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecElasticsearchCa_fileMountFromSecretKeyRef;
        }

        export interface OutputSpecElasticsearchCa_fileMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecElasticsearchCa_fileValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecElasticsearchCa_fileValueFromSecretKeyRef;
        }

        export interface OutputSpecElasticsearchCa_fileValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecElasticsearchClient_cert {
            mountFrom?: outputs.logging.v1beta1.OutputSpecElasticsearchClient_certMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.OutputSpecElasticsearchClient_certValueFrom;
        }

        export interface OutputSpecElasticsearchClient_certMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecElasticsearchClient_certMountFromSecretKeyRef;
        }

        export interface OutputSpecElasticsearchClient_certMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecElasticsearchClient_certValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecElasticsearchClient_certValueFromSecretKeyRef;
        }

        export interface OutputSpecElasticsearchClient_certValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecElasticsearchClient_key {
            mountFrom?: outputs.logging.v1beta1.OutputSpecElasticsearchClient_keyMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.OutputSpecElasticsearchClient_keyValueFrom;
        }

        export interface OutputSpecElasticsearchClient_keyMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecElasticsearchClient_keyMountFromSecretKeyRef;
        }

        export interface OutputSpecElasticsearchClient_keyMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecElasticsearchClient_keyValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecElasticsearchClient_keyValueFromSecretKeyRef;
        }

        export interface OutputSpecElasticsearchClient_keyValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecElasticsearchClient_key_pass {
            mountFrom?: outputs.logging.v1beta1.OutputSpecElasticsearchClient_key_passMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.OutputSpecElasticsearchClient_key_passValueFrom;
        }

        export interface OutputSpecElasticsearchClient_key_passMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecElasticsearchClient_key_passMountFromSecretKeyRef;
        }

        export interface OutputSpecElasticsearchClient_key_passMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecElasticsearchClient_key_passValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecElasticsearchClient_key_passValueFromSecretKeyRef;
        }

        export interface OutputSpecElasticsearchClient_key_passValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecElasticsearchPassword {
            mountFrom?: outputs.logging.v1beta1.OutputSpecElasticsearchPasswordMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.OutputSpecElasticsearchPasswordValueFrom;
        }

        export interface OutputSpecElasticsearchPasswordMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecElasticsearchPasswordMountFromSecretKeyRef;
        }

        export interface OutputSpecElasticsearchPasswordMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecElasticsearchPasswordValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecElasticsearchPasswordValueFromSecretKeyRef;
        }

        export interface OutputSpecElasticsearchPasswordValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecElasticsearchTemplate_file {
            mountFrom?: outputs.logging.v1beta1.OutputSpecElasticsearchTemplate_fileMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.OutputSpecElasticsearchTemplate_fileValueFrom;
        }

        export interface OutputSpecElasticsearchTemplate_fileMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecElasticsearchTemplate_fileMountFromSecretKeyRef;
        }

        export interface OutputSpecElasticsearchTemplate_fileMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecElasticsearchTemplate_fileValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecElasticsearchTemplate_fileValueFromSecretKeyRef;
        }

        export interface OutputSpecElasticsearchTemplate_fileValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecFile {
            add_path_suffix?: boolean;
            append?: boolean;
            buffer?: outputs.logging.v1beta1.OutputSpecFileBuffer;
            format?: outputs.logging.v1beta1.OutputSpecFileFormat;
            path: string;
            path_suffix?: string;
            symlink_path?: boolean;
        }

        export interface OutputSpecFileBuffer {
            chunk_full_threshold?: string;
            chunk_limit_records?: number;
            chunk_limit_size?: string;
            compress?: string;
            delayed_commit_timeout?: string;
            disable_chunk_backup?: boolean;
            flush_at_shutdown?: boolean;
            flush_interval?: string;
            flush_mode?: string;
            flush_thread_burst_interval?: string;
            flush_thread_count?: number;
            flush_thread_interval?: string;
            overflow_action?: string;
            path?: string;
            queue_limit_length?: number;
            queued_chunks_limit_size?: number;
            retry_exponential_backoff_base?: string;
            retry_forever?: boolean;
            retry_max_interval?: string;
            retry_max_times?: number;
            retry_randomize?: boolean;
            retry_secondary_threshold?: string;
            retry_timeout?: string;
            retry_type?: string;
            retry_wait?: string;
            tags?: string;
            timekey?: string;
            timekey_use_utc?: boolean;
            timekey_wait?: string;
            timekey_zone?: string;
            total_limit_size?: string;
            type?: string;
        }

        export interface OutputSpecFileFormat {
            add_newline?: boolean;
            message_key?: string;
            type?: string;
        }

        export interface OutputSpecForward {
            ack_response_timeout?: number;
            buffer?: outputs.logging.v1beta1.OutputSpecForwardBuffer;
            connect_timeout?: number;
            dns_round_robin?: boolean;
            expire_dns_cache?: number;
            hard_timeout?: number;
            heartbeat_interval?: number;
            heartbeat_type?: string;
            ignore_network_errors_at_startup?: boolean;
            keepalive?: boolean;
            keepalive_timeout?: number;
            phi_failure_detector?: boolean;
            phi_threshold?: number;
            recover_wait?: number;
            require_ack_response?: boolean;
            security?: outputs.logging.v1beta1.OutputSpecForwardSecurity;
            send_timeout?: number;
            servers: outputs.logging.v1beta1.OutputSpecForwardServers[];
            tls_allow_self_signed_cert?: boolean;
            tls_cert_logical_store_name?: string;
            tls_cert_path?: outputs.logging.v1beta1.OutputSpecForwardTls_cert_path;
            tls_cert_thumbprint?: string;
            tls_cert_use_enterprise_store?: boolean;
            tls_ciphers?: string;
            tls_client_cert_path?: outputs.logging.v1beta1.OutputSpecForwardTls_client_cert_path;
            tls_client_private_key_passphrase?: outputs.logging.v1beta1.OutputSpecForwardTls_client_private_key_passphrase;
            tls_client_private_key_path?: outputs.logging.v1beta1.OutputSpecForwardTls_client_private_key_path;
            tls_insecure_mode?: boolean;
            tls_verify_hostname?: boolean;
            tls_version?: string;
            verify_connection_at_startup?: boolean;
        }

        export interface OutputSpecForwardBuffer {
            chunk_full_threshold?: string;
            chunk_limit_records?: number;
            chunk_limit_size?: string;
            compress?: string;
            delayed_commit_timeout?: string;
            disable_chunk_backup?: boolean;
            flush_at_shutdown?: boolean;
            flush_interval?: string;
            flush_mode?: string;
            flush_thread_burst_interval?: string;
            flush_thread_count?: number;
            flush_thread_interval?: string;
            overflow_action?: string;
            path?: string;
            queue_limit_length?: number;
            queued_chunks_limit_size?: number;
            retry_exponential_backoff_base?: string;
            retry_forever?: boolean;
            retry_max_interval?: string;
            retry_max_times?: number;
            retry_randomize?: boolean;
            retry_secondary_threshold?: string;
            retry_timeout?: string;
            retry_type?: string;
            retry_wait?: string;
            tags?: string;
            timekey?: string;
            timekey_use_utc?: boolean;
            timekey_wait?: string;
            timekey_zone?: string;
            total_limit_size?: string;
            type?: string;
        }

        export interface OutputSpecForwardSecurity {
            allow_anonymous_source?: boolean;
            self_hostname: string;
            shared_key: string;
            user_auth?: boolean;
        }

        export interface OutputSpecForwardServers {
            host: string;
            name?: string;
            password?: outputs.logging.v1beta1.OutputSpecForwardServersPassword;
            port?: number;
            shared_key?: outputs.logging.v1beta1.OutputSpecForwardServersShared_key;
            standby?: boolean;
            username?: outputs.logging.v1beta1.OutputSpecForwardServersUsername;
            weight?: number;
        }

        export interface OutputSpecForwardServersPassword {
            mountFrom?: outputs.logging.v1beta1.OutputSpecForwardServersPasswordMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.OutputSpecForwardServersPasswordValueFrom;
        }

        export interface OutputSpecForwardServersPasswordMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecForwardServersPasswordMountFromSecretKeyRef;
        }

        export interface OutputSpecForwardServersPasswordMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecForwardServersPasswordValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecForwardServersPasswordValueFromSecretKeyRef;
        }

        export interface OutputSpecForwardServersPasswordValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecForwardServersShared_key {
            mountFrom?: outputs.logging.v1beta1.OutputSpecForwardServersShared_keyMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.OutputSpecForwardServersShared_keyValueFrom;
        }

        export interface OutputSpecForwardServersShared_keyMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecForwardServersShared_keyMountFromSecretKeyRef;
        }

        export interface OutputSpecForwardServersShared_keyMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecForwardServersShared_keyValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecForwardServersShared_keyValueFromSecretKeyRef;
        }

        export interface OutputSpecForwardServersShared_keyValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecForwardServersUsername {
            mountFrom?: outputs.logging.v1beta1.OutputSpecForwardServersUsernameMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.OutputSpecForwardServersUsernameValueFrom;
        }

        export interface OutputSpecForwardServersUsernameMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecForwardServersUsernameMountFromSecretKeyRef;
        }

        export interface OutputSpecForwardServersUsernameMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecForwardServersUsernameValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecForwardServersUsernameValueFromSecretKeyRef;
        }

        export interface OutputSpecForwardServersUsernameValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecForwardTls_cert_path {
            mountFrom?: outputs.logging.v1beta1.OutputSpecForwardTls_cert_pathMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.OutputSpecForwardTls_cert_pathValueFrom;
        }

        export interface OutputSpecForwardTls_cert_pathMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecForwardTls_cert_pathMountFromSecretKeyRef;
        }

        export interface OutputSpecForwardTls_cert_pathMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecForwardTls_cert_pathValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecForwardTls_cert_pathValueFromSecretKeyRef;
        }

        export interface OutputSpecForwardTls_cert_pathValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecForwardTls_client_cert_path {
            mountFrom?: outputs.logging.v1beta1.OutputSpecForwardTls_client_cert_pathMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.OutputSpecForwardTls_client_cert_pathValueFrom;
        }

        export interface OutputSpecForwardTls_client_cert_pathMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecForwardTls_client_cert_pathMountFromSecretKeyRef;
        }

        export interface OutputSpecForwardTls_client_cert_pathMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecForwardTls_client_cert_pathValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecForwardTls_client_cert_pathValueFromSecretKeyRef;
        }

        export interface OutputSpecForwardTls_client_cert_pathValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecForwardTls_client_private_key_passphrase {
            mountFrom?: outputs.logging.v1beta1.OutputSpecForwardTls_client_private_key_passphraseMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.OutputSpecForwardTls_client_private_key_passphraseValueFrom;
        }

        export interface OutputSpecForwardTls_client_private_key_passphraseMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecForwardTls_client_private_key_passphraseMountFromSecretKeyRef;
        }

        export interface OutputSpecForwardTls_client_private_key_passphraseMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecForwardTls_client_private_key_passphraseValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecForwardTls_client_private_key_passphraseValueFromSecretKeyRef;
        }

        export interface OutputSpecForwardTls_client_private_key_passphraseValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecForwardTls_client_private_key_path {
            mountFrom?: outputs.logging.v1beta1.OutputSpecForwardTls_client_private_key_pathMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.OutputSpecForwardTls_client_private_key_pathValueFrom;
        }

        export interface OutputSpecForwardTls_client_private_key_pathMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecForwardTls_client_private_key_pathMountFromSecretKeyRef;
        }

        export interface OutputSpecForwardTls_client_private_key_pathMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecForwardTls_client_private_key_pathValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecForwardTls_client_private_key_pathValueFromSecretKeyRef;
        }

        export interface OutputSpecForwardTls_client_private_key_pathValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecGcs {
            acl?: string;
            auto_create_bucket?: boolean;
            bucket: string;
            buffer?: outputs.logging.v1beta1.OutputSpecGcsBuffer;
            client_retries?: number;
            client_timeout?: number;
            credentials_json?: outputs.logging.v1beta1.OutputSpecGcsCredentials_json;
            encryption_key?: string;
            format?: outputs.logging.v1beta1.OutputSpecGcsFormat;
            hex_random_length?: number;
            keyfile?: string;
            object_key_format?: string;
            object_metadata?: outputs.logging.v1beta1.OutputSpecGcsObject_metadata[];
            overwrite?: boolean;
            path?: string;
            project: string;
            storage_class?: string;
            store_as?: string;
            transcoding?: boolean;
        }

        export interface OutputSpecGcsBuffer {
            chunk_full_threshold?: string;
            chunk_limit_records?: number;
            chunk_limit_size?: string;
            compress?: string;
            delayed_commit_timeout?: string;
            disable_chunk_backup?: boolean;
            flush_at_shutdown?: boolean;
            flush_interval?: string;
            flush_mode?: string;
            flush_thread_burst_interval?: string;
            flush_thread_count?: number;
            flush_thread_interval?: string;
            overflow_action?: string;
            path?: string;
            queue_limit_length?: number;
            queued_chunks_limit_size?: number;
            retry_exponential_backoff_base?: string;
            retry_forever?: boolean;
            retry_max_interval?: string;
            retry_max_times?: number;
            retry_randomize?: boolean;
            retry_secondary_threshold?: string;
            retry_timeout?: string;
            retry_type?: string;
            retry_wait?: string;
            tags?: string;
            timekey?: string;
            timekey_use_utc?: boolean;
            timekey_wait?: string;
            timekey_zone?: string;
            total_limit_size?: string;
            type?: string;
        }

        export interface OutputSpecGcsCredentials_json {
            mountFrom?: outputs.logging.v1beta1.OutputSpecGcsCredentials_jsonMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.OutputSpecGcsCredentials_jsonValueFrom;
        }

        export interface OutputSpecGcsCredentials_jsonMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecGcsCredentials_jsonMountFromSecretKeyRef;
        }

        export interface OutputSpecGcsCredentials_jsonMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecGcsCredentials_jsonValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecGcsCredentials_jsonValueFromSecretKeyRef;
        }

        export interface OutputSpecGcsCredentials_jsonValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecGcsFormat {
            add_newline?: boolean;
            message_key?: string;
            type?: string;
        }

        export interface OutputSpecGcsObject_metadata {
            key: string;
            value: string;
        }

        export interface OutputSpecHttp {
            auth?: outputs.logging.v1beta1.OutputSpecHttpAuth;
            buffer?: outputs.logging.v1beta1.OutputSpecHttpBuffer;
            content_type?: string;
            endpoint: string;
            error_response_as_unrecoverable?: boolean;
            format?: outputs.logging.v1beta1.OutputSpecHttpFormat;
            headers?: { [key: string]: string };
            http_method?: string;
            json_array?: boolean;
            open_timeout?: number;
            proxy?: string;
            read_timeout?: number;
            retryable_response_codes?: number[];
            ssl_timeout?: number;
            tls_ca_cert_path?: outputs.logging.v1beta1.OutputSpecHttpTls_ca_cert_path;
            tls_ciphers?: string;
            tls_client_cert_path?: outputs.logging.v1beta1.OutputSpecHttpTls_client_cert_path;
            tls_private_key_passphrase?: outputs.logging.v1beta1.OutputSpecHttpTls_private_key_passphrase;
            tls_private_key_path?: outputs.logging.v1beta1.OutputSpecHttpTls_private_key_path;
            tls_verify_mode?: string;
            tls_version?: string;
        }

        export interface OutputSpecHttpAuth {
            password: outputs.logging.v1beta1.OutputSpecHttpAuthPassword;
            username: outputs.logging.v1beta1.OutputSpecHttpAuthUsername;
        }

        export interface OutputSpecHttpAuthPassword {
            mountFrom?: outputs.logging.v1beta1.OutputSpecHttpAuthPasswordMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.OutputSpecHttpAuthPasswordValueFrom;
        }

        export interface OutputSpecHttpAuthPasswordMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecHttpAuthPasswordMountFromSecretKeyRef;
        }

        export interface OutputSpecHttpAuthPasswordMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecHttpAuthPasswordValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecHttpAuthPasswordValueFromSecretKeyRef;
        }

        export interface OutputSpecHttpAuthPasswordValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecHttpAuthUsername {
            mountFrom?: outputs.logging.v1beta1.OutputSpecHttpAuthUsernameMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.OutputSpecHttpAuthUsernameValueFrom;
        }

        export interface OutputSpecHttpAuthUsernameMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecHttpAuthUsernameMountFromSecretKeyRef;
        }

        export interface OutputSpecHttpAuthUsernameMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecHttpAuthUsernameValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecHttpAuthUsernameValueFromSecretKeyRef;
        }

        export interface OutputSpecHttpAuthUsernameValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecHttpBuffer {
            chunk_full_threshold?: string;
            chunk_limit_records?: number;
            chunk_limit_size?: string;
            compress?: string;
            delayed_commit_timeout?: string;
            disable_chunk_backup?: boolean;
            flush_at_shutdown?: boolean;
            flush_interval?: string;
            flush_mode?: string;
            flush_thread_burst_interval?: string;
            flush_thread_count?: number;
            flush_thread_interval?: string;
            overflow_action?: string;
            path?: string;
            queue_limit_length?: number;
            queued_chunks_limit_size?: number;
            retry_exponential_backoff_base?: string;
            retry_forever?: boolean;
            retry_max_interval?: string;
            retry_max_times?: number;
            retry_randomize?: boolean;
            retry_secondary_threshold?: string;
            retry_timeout?: string;
            retry_type?: string;
            retry_wait?: string;
            tags?: string;
            timekey?: string;
            timekey_use_utc?: boolean;
            timekey_wait?: string;
            timekey_zone?: string;
            total_limit_size?: string;
            type?: string;
        }

        export interface OutputSpecHttpFormat {
            add_newline?: boolean;
            message_key?: string;
            type?: string;
        }

        export interface OutputSpecHttpTls_ca_cert_path {
            mountFrom?: outputs.logging.v1beta1.OutputSpecHttpTls_ca_cert_pathMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.OutputSpecHttpTls_ca_cert_pathValueFrom;
        }

        export interface OutputSpecHttpTls_ca_cert_pathMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecHttpTls_ca_cert_pathMountFromSecretKeyRef;
        }

        export interface OutputSpecHttpTls_ca_cert_pathMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecHttpTls_ca_cert_pathValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecHttpTls_ca_cert_pathValueFromSecretKeyRef;
        }

        export interface OutputSpecHttpTls_ca_cert_pathValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecHttpTls_client_cert_path {
            mountFrom?: outputs.logging.v1beta1.OutputSpecHttpTls_client_cert_pathMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.OutputSpecHttpTls_client_cert_pathValueFrom;
        }

        export interface OutputSpecHttpTls_client_cert_pathMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecHttpTls_client_cert_pathMountFromSecretKeyRef;
        }

        export interface OutputSpecHttpTls_client_cert_pathMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecHttpTls_client_cert_pathValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecHttpTls_client_cert_pathValueFromSecretKeyRef;
        }

        export interface OutputSpecHttpTls_client_cert_pathValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecHttpTls_private_key_passphrase {
            mountFrom?: outputs.logging.v1beta1.OutputSpecHttpTls_private_key_passphraseMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.OutputSpecHttpTls_private_key_passphraseValueFrom;
        }

        export interface OutputSpecHttpTls_private_key_passphraseMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecHttpTls_private_key_passphraseMountFromSecretKeyRef;
        }

        export interface OutputSpecHttpTls_private_key_passphraseMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecHttpTls_private_key_passphraseValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecHttpTls_private_key_passphraseValueFromSecretKeyRef;
        }

        export interface OutputSpecHttpTls_private_key_passphraseValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecHttpTls_private_key_path {
            mountFrom?: outputs.logging.v1beta1.OutputSpecHttpTls_private_key_pathMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.OutputSpecHttpTls_private_key_pathValueFrom;
        }

        export interface OutputSpecHttpTls_private_key_pathMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecHttpTls_private_key_pathMountFromSecretKeyRef;
        }

        export interface OutputSpecHttpTls_private_key_pathMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecHttpTls_private_key_pathValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecHttpTls_private_key_pathValueFromSecretKeyRef;
        }

        export interface OutputSpecHttpTls_private_key_pathValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecKafka {
            ack_timeout?: number;
            brokers: string;
            buffer?: outputs.logging.v1beta1.OutputSpecKafkaBuffer;
            compression_codec?: string;
            default_message_key?: string;
            default_partition_key?: string;
            default_topic?: string;
            exclude_partion_key?: boolean;
            exclude_topic_key?: boolean;
            format: outputs.logging.v1beta1.OutputSpecKafkaFormat;
            get_kafka_client_log?: boolean;
            headers?: { [key: string]: string };
            headers_from_record?: { [key: string]: string };
            idempotent?: boolean;
            max_send_retries?: number;
            message_key_key?: string;
            partition_key?: string;
            partition_key_key?: string;
            password?: outputs.logging.v1beta1.OutputSpecKafkaPassword;
            required_acks?: number;
            sasl_over_ssl?: boolean;
            scram_mechanism?: string;
            ssl_ca_cert?: outputs.logging.v1beta1.OutputSpecKafkaSsl_ca_cert;
            ssl_ca_certs_from_system?: boolean;
            ssl_client_cert?: outputs.logging.v1beta1.OutputSpecKafkaSsl_client_cert;
            ssl_client_cert_chain?: outputs.logging.v1beta1.OutputSpecKafkaSsl_client_cert_chain;
            ssl_client_cert_key?: outputs.logging.v1beta1.OutputSpecKafkaSsl_client_cert_key;
            ssl_verify_hostname?: boolean;
            topic_key?: string;
            use_default_for_unknown_topic?: boolean;
            username?: outputs.logging.v1beta1.OutputSpecKafkaUsername;
        }

        export interface OutputSpecKafkaBuffer {
            chunk_full_threshold?: string;
            chunk_limit_records?: number;
            chunk_limit_size?: string;
            compress?: string;
            delayed_commit_timeout?: string;
            disable_chunk_backup?: boolean;
            flush_at_shutdown?: boolean;
            flush_interval?: string;
            flush_mode?: string;
            flush_thread_burst_interval?: string;
            flush_thread_count?: number;
            flush_thread_interval?: string;
            overflow_action?: string;
            path?: string;
            queue_limit_length?: number;
            queued_chunks_limit_size?: number;
            retry_exponential_backoff_base?: string;
            retry_forever?: boolean;
            retry_max_interval?: string;
            retry_max_times?: number;
            retry_randomize?: boolean;
            retry_secondary_threshold?: string;
            retry_timeout?: string;
            retry_type?: string;
            retry_wait?: string;
            tags?: string;
            timekey?: string;
            timekey_use_utc?: boolean;
            timekey_wait?: string;
            timekey_zone?: string;
            total_limit_size?: string;
            type?: string;
        }

        export interface OutputSpecKafkaFormat {
            add_newline?: boolean;
            message_key?: string;
            type?: string;
        }

        export interface OutputSpecKafkaPassword {
            mountFrom?: outputs.logging.v1beta1.OutputSpecKafkaPasswordMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.OutputSpecKafkaPasswordValueFrom;
        }

        export interface OutputSpecKafkaPasswordMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecKafkaPasswordMountFromSecretKeyRef;
        }

        export interface OutputSpecKafkaPasswordMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecKafkaPasswordValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecKafkaPasswordValueFromSecretKeyRef;
        }

        export interface OutputSpecKafkaPasswordValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecKafkaSsl_ca_cert {
            mountFrom?: outputs.logging.v1beta1.OutputSpecKafkaSsl_ca_certMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.OutputSpecKafkaSsl_ca_certValueFrom;
        }

        export interface OutputSpecKafkaSsl_ca_certMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecKafkaSsl_ca_certMountFromSecretKeyRef;
        }

        export interface OutputSpecKafkaSsl_ca_certMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecKafkaSsl_ca_certValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecKafkaSsl_ca_certValueFromSecretKeyRef;
        }

        export interface OutputSpecKafkaSsl_ca_certValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecKafkaSsl_client_cert {
            mountFrom?: outputs.logging.v1beta1.OutputSpecKafkaSsl_client_certMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.OutputSpecKafkaSsl_client_certValueFrom;
        }

        export interface OutputSpecKafkaSsl_client_certMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecKafkaSsl_client_certMountFromSecretKeyRef;
        }

        export interface OutputSpecKafkaSsl_client_certMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecKafkaSsl_client_certValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecKafkaSsl_client_certValueFromSecretKeyRef;
        }

        export interface OutputSpecKafkaSsl_client_certValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecKafkaSsl_client_cert_chain {
            mountFrom?: outputs.logging.v1beta1.OutputSpecKafkaSsl_client_cert_chainMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.OutputSpecKafkaSsl_client_cert_chainValueFrom;
        }

        export interface OutputSpecKafkaSsl_client_cert_chainMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecKafkaSsl_client_cert_chainMountFromSecretKeyRef;
        }

        export interface OutputSpecKafkaSsl_client_cert_chainMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecKafkaSsl_client_cert_chainValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecKafkaSsl_client_cert_chainValueFromSecretKeyRef;
        }

        export interface OutputSpecKafkaSsl_client_cert_chainValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecKafkaSsl_client_cert_key {
            mountFrom?: outputs.logging.v1beta1.OutputSpecKafkaSsl_client_cert_keyMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.OutputSpecKafkaSsl_client_cert_keyValueFrom;
        }

        export interface OutputSpecKafkaSsl_client_cert_keyMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecKafkaSsl_client_cert_keyMountFromSecretKeyRef;
        }

        export interface OutputSpecKafkaSsl_client_cert_keyMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecKafkaSsl_client_cert_keyValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecKafkaSsl_client_cert_keyValueFromSecretKeyRef;
        }

        export interface OutputSpecKafkaSsl_client_cert_keyValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecKafkaUsername {
            mountFrom?: outputs.logging.v1beta1.OutputSpecKafkaUsernameMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.OutputSpecKafkaUsernameValueFrom;
        }

        export interface OutputSpecKafkaUsernameMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecKafkaUsernameMountFromSecretKeyRef;
        }

        export interface OutputSpecKafkaUsernameMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecKafkaUsernameValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecKafkaUsernameValueFromSecretKeyRef;
        }

        export interface OutputSpecKafkaUsernameValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecKinesisStream {
            assume_role_credentials?: outputs.logging.v1beta1.OutputSpecKinesisStreamAssume_role_credentials;
            aws_iam_retries?: number;
            aws_key_id?: outputs.logging.v1beta1.OutputSpecKinesisStreamAws_key_id;
            aws_sec_key?: outputs.logging.v1beta1.OutputSpecKinesisStreamAws_sec_key;
            aws_ses_token?: outputs.logging.v1beta1.OutputSpecKinesisStreamAws_ses_token;
            batch_request_max_count?: number;
            batch_request_max_size?: number;
            buffer?: outputs.logging.v1beta1.OutputSpecKinesisStreamBuffer;
            format?: outputs.logging.v1beta1.OutputSpecKinesisStreamFormat;
            partition_key?: string;
            process_credentials?: outputs.logging.v1beta1.OutputSpecKinesisStreamProcess_credentials;
            region?: string;
            reset_backoff_if_success?: boolean;
            retries_on_batch_request?: number;
            stream_name: string;
        }

        export interface OutputSpecKinesisStreamAssume_role_credentials {
            duration_seconds?: string;
            external_id?: string;
            policy?: string;
            role_arn: string;
            role_session_name: string;
        }

        export interface OutputSpecKinesisStreamAws_key_id {
            mountFrom?: outputs.logging.v1beta1.OutputSpecKinesisStreamAws_key_idMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.OutputSpecKinesisStreamAws_key_idValueFrom;
        }

        export interface OutputSpecKinesisStreamAws_key_idMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecKinesisStreamAws_key_idMountFromSecretKeyRef;
        }

        export interface OutputSpecKinesisStreamAws_key_idMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecKinesisStreamAws_key_idValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecKinesisStreamAws_key_idValueFromSecretKeyRef;
        }

        export interface OutputSpecKinesisStreamAws_key_idValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecKinesisStreamAws_sec_key {
            mountFrom?: outputs.logging.v1beta1.OutputSpecKinesisStreamAws_sec_keyMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.OutputSpecKinesisStreamAws_sec_keyValueFrom;
        }

        export interface OutputSpecKinesisStreamAws_sec_keyMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecKinesisStreamAws_sec_keyMountFromSecretKeyRef;
        }

        export interface OutputSpecKinesisStreamAws_sec_keyMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecKinesisStreamAws_sec_keyValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecKinesisStreamAws_sec_keyValueFromSecretKeyRef;
        }

        export interface OutputSpecKinesisStreamAws_sec_keyValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecKinesisStreamAws_ses_token {
            mountFrom?: outputs.logging.v1beta1.OutputSpecKinesisStreamAws_ses_tokenMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.OutputSpecKinesisStreamAws_ses_tokenValueFrom;
        }

        export interface OutputSpecKinesisStreamAws_ses_tokenMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecKinesisStreamAws_ses_tokenMountFromSecretKeyRef;
        }

        export interface OutputSpecKinesisStreamAws_ses_tokenMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecKinesisStreamAws_ses_tokenValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecKinesisStreamAws_ses_tokenValueFromSecretKeyRef;
        }

        export interface OutputSpecKinesisStreamAws_ses_tokenValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecKinesisStreamBuffer {
            chunk_full_threshold?: string;
            chunk_limit_records?: number;
            chunk_limit_size?: string;
            compress?: string;
            delayed_commit_timeout?: string;
            disable_chunk_backup?: boolean;
            flush_at_shutdown?: boolean;
            flush_interval?: string;
            flush_mode?: string;
            flush_thread_burst_interval?: string;
            flush_thread_count?: number;
            flush_thread_interval?: string;
            overflow_action?: string;
            path?: string;
            queue_limit_length?: number;
            queued_chunks_limit_size?: number;
            retry_exponential_backoff_base?: string;
            retry_forever?: boolean;
            retry_max_interval?: string;
            retry_max_times?: number;
            retry_randomize?: boolean;
            retry_secondary_threshold?: string;
            retry_timeout?: string;
            retry_type?: string;
            retry_wait?: string;
            tags?: string;
            timekey?: string;
            timekey_use_utc?: boolean;
            timekey_wait?: string;
            timekey_zone?: string;
            total_limit_size?: string;
            type?: string;
        }

        export interface OutputSpecKinesisStreamFormat {
            add_newline?: boolean;
            message_key?: string;
            type?: string;
        }

        export interface OutputSpecKinesisStreamProcess_credentials {
            process: string;
        }

        export interface OutputSpecLogdna {
            api_key: string;
            app?: string;
            buffer_chunk_limit?: string;
            hostname: string;
        }

        export interface OutputSpecLogz {
            buffer?: outputs.logging.v1beta1.OutputSpecLogzBuffer;
            endpoint: outputs.logging.v1beta1.OutputSpecLogzEndpoint;
            gzip?: boolean;
            http_idle_timeout?: number;
            output_include_tags?: boolean;
            output_include_time?: boolean;
            retry_count?: number;
            retry_sleep?: number;
        }

        export interface OutputSpecLogzBuffer {
            chunk_full_threshold?: string;
            chunk_limit_records?: number;
            chunk_limit_size?: string;
            compress?: string;
            delayed_commit_timeout?: string;
            disable_chunk_backup?: boolean;
            flush_at_shutdown?: boolean;
            flush_interval?: string;
            flush_mode?: string;
            flush_thread_burst_interval?: string;
            flush_thread_count?: number;
            flush_thread_interval?: string;
            overflow_action?: string;
            path?: string;
            queue_limit_length?: number;
            queued_chunks_limit_size?: number;
            retry_exponential_backoff_base?: string;
            retry_forever?: boolean;
            retry_max_interval?: string;
            retry_max_times?: number;
            retry_randomize?: boolean;
            retry_secondary_threshold?: string;
            retry_timeout?: string;
            retry_type?: string;
            retry_wait?: string;
            tags?: string;
            timekey?: string;
            timekey_use_utc?: boolean;
            timekey_wait?: string;
            timekey_zone?: string;
            total_limit_size?: string;
            type?: string;
        }

        export interface OutputSpecLogzEndpoint {
            port?: number;
            token?: outputs.logging.v1beta1.OutputSpecLogzEndpointToken;
            url?: string;
        }

        export interface OutputSpecLogzEndpointToken {
            mountFrom?: outputs.logging.v1beta1.OutputSpecLogzEndpointTokenMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.OutputSpecLogzEndpointTokenValueFrom;
        }

        export interface OutputSpecLogzEndpointTokenMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecLogzEndpointTokenMountFromSecretKeyRef;
        }

        export interface OutputSpecLogzEndpointTokenMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecLogzEndpointTokenValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecLogzEndpointTokenValueFromSecretKeyRef;
        }

        export interface OutputSpecLogzEndpointTokenValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecLoki {
            buffer?: outputs.logging.v1beta1.OutputSpecLokiBuffer;
            ca_cert?: outputs.logging.v1beta1.OutputSpecLokiCa_cert;
            cert?: outputs.logging.v1beta1.OutputSpecLokiCert;
            configure_kubernetes_labels?: boolean;
            drop_single_key?: boolean;
            extra_labels?: { [key: string]: string };
            extract_kubernetes_labels?: boolean;
            insecure_tls?: boolean;
            key?: outputs.logging.v1beta1.OutputSpecLokiKey;
            labels?: { [key: string]: string };
            line_format?: string;
            password?: outputs.logging.v1beta1.OutputSpecLokiPassword;
            remove_keys?: string[];
            tenant?: string;
            url?: string;
            username?: outputs.logging.v1beta1.OutputSpecLokiUsername;
        }

        export interface OutputSpecLokiBuffer {
            chunk_full_threshold?: string;
            chunk_limit_records?: number;
            chunk_limit_size?: string;
            compress?: string;
            delayed_commit_timeout?: string;
            disable_chunk_backup?: boolean;
            flush_at_shutdown?: boolean;
            flush_interval?: string;
            flush_mode?: string;
            flush_thread_burst_interval?: string;
            flush_thread_count?: number;
            flush_thread_interval?: string;
            overflow_action?: string;
            path?: string;
            queue_limit_length?: number;
            queued_chunks_limit_size?: number;
            retry_exponential_backoff_base?: string;
            retry_forever?: boolean;
            retry_max_interval?: string;
            retry_max_times?: number;
            retry_randomize?: boolean;
            retry_secondary_threshold?: string;
            retry_timeout?: string;
            retry_type?: string;
            retry_wait?: string;
            tags?: string;
            timekey?: string;
            timekey_use_utc?: boolean;
            timekey_wait?: string;
            timekey_zone?: string;
            total_limit_size?: string;
            type?: string;
        }

        export interface OutputSpecLokiCa_cert {
            mountFrom?: outputs.logging.v1beta1.OutputSpecLokiCa_certMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.OutputSpecLokiCa_certValueFrom;
        }

        export interface OutputSpecLokiCa_certMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecLokiCa_certMountFromSecretKeyRef;
        }

        export interface OutputSpecLokiCa_certMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecLokiCa_certValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecLokiCa_certValueFromSecretKeyRef;
        }

        export interface OutputSpecLokiCa_certValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecLokiCert {
            mountFrom?: outputs.logging.v1beta1.OutputSpecLokiCertMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.OutputSpecLokiCertValueFrom;
        }

        export interface OutputSpecLokiCertMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecLokiCertMountFromSecretKeyRef;
        }

        export interface OutputSpecLokiCertMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecLokiCertValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecLokiCertValueFromSecretKeyRef;
        }

        export interface OutputSpecLokiCertValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecLokiKey {
            mountFrom?: outputs.logging.v1beta1.OutputSpecLokiKeyMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.OutputSpecLokiKeyValueFrom;
        }

        export interface OutputSpecLokiKeyMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecLokiKeyMountFromSecretKeyRef;
        }

        export interface OutputSpecLokiKeyMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecLokiKeyValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecLokiKeyValueFromSecretKeyRef;
        }

        export interface OutputSpecLokiKeyValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecLokiPassword {
            mountFrom?: outputs.logging.v1beta1.OutputSpecLokiPasswordMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.OutputSpecLokiPasswordValueFrom;
        }

        export interface OutputSpecLokiPasswordMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecLokiPasswordMountFromSecretKeyRef;
        }

        export interface OutputSpecLokiPasswordMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecLokiPasswordValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecLokiPasswordValueFromSecretKeyRef;
        }

        export interface OutputSpecLokiPasswordValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecLokiUsername {
            mountFrom?: outputs.logging.v1beta1.OutputSpecLokiUsernameMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.OutputSpecLokiUsernameValueFrom;
        }

        export interface OutputSpecLokiUsernameMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecLokiUsernameMountFromSecretKeyRef;
        }

        export interface OutputSpecLokiUsernameMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecLokiUsernameValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecLokiUsernameValueFromSecretKeyRef;
        }

        export interface OutputSpecLokiUsernameValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecNewrelic {
            api_key?: outputs.logging.v1beta1.OutputSpecNewrelicApi_key;
            base_uri?: string;
            license_key?: outputs.logging.v1beta1.OutputSpecNewrelicLicense_key;
        }

        export interface OutputSpecNewrelicApi_key {
            mountFrom?: outputs.logging.v1beta1.OutputSpecNewrelicApi_keyMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.OutputSpecNewrelicApi_keyValueFrom;
        }

        export interface OutputSpecNewrelicApi_keyMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecNewrelicApi_keyMountFromSecretKeyRef;
        }

        export interface OutputSpecNewrelicApi_keyMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecNewrelicApi_keyValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecNewrelicApi_keyValueFromSecretKeyRef;
        }

        export interface OutputSpecNewrelicApi_keyValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecNewrelicLicense_key {
            mountFrom?: outputs.logging.v1beta1.OutputSpecNewrelicLicense_keyMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.OutputSpecNewrelicLicense_keyValueFrom;
        }

        export interface OutputSpecNewrelicLicense_keyMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecNewrelicLicense_keyMountFromSecretKeyRef;
        }

        export interface OutputSpecNewrelicLicense_keyMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecNewrelicLicense_keyValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecNewrelicLicense_keyValueFromSecretKeyRef;
        }

        export interface OutputSpecNewrelicLicense_keyValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecOss {
            aaccess_key_secret: outputs.logging.v1beta1.OutputSpecOssAaccess_key_secret;
            access_key_id: outputs.logging.v1beta1.OutputSpecOssAccess_key_id;
            auto_create_bucket?: boolean;
            bucket: string;
            buffer?: outputs.logging.v1beta1.OutputSpecOssBuffer;
            check_bucket?: boolean;
            check_object?: boolean;
            download_crc_enable?: boolean;
            endpoint: string;
            format?: outputs.logging.v1beta1.OutputSpecOssFormat;
            hex_random_length?: number;
            index_format?: string;
            key_format?: string;
            open_timeout?: number;
            oss_sdk_log_dir?: string;
            overwrite?: boolean;
            path?: string;
            read_timeout?: number;
            store_as?: string;
            upload_crc_enable?: boolean;
            warn_for_delay?: string;
        }

        export interface OutputSpecOssAaccess_key_secret {
            mountFrom?: outputs.logging.v1beta1.OutputSpecOssAaccess_key_secretMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.OutputSpecOssAaccess_key_secretValueFrom;
        }

        export interface OutputSpecOssAaccess_key_secretMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecOssAaccess_key_secretMountFromSecretKeyRef;
        }

        export interface OutputSpecOssAaccess_key_secretMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecOssAaccess_key_secretValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecOssAaccess_key_secretValueFromSecretKeyRef;
        }

        export interface OutputSpecOssAaccess_key_secretValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecOssAccess_key_id {
            mountFrom?: outputs.logging.v1beta1.OutputSpecOssAccess_key_idMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.OutputSpecOssAccess_key_idValueFrom;
        }

        export interface OutputSpecOssAccess_key_idMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecOssAccess_key_idMountFromSecretKeyRef;
        }

        export interface OutputSpecOssAccess_key_idMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecOssAccess_key_idValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecOssAccess_key_idValueFromSecretKeyRef;
        }

        export interface OutputSpecOssAccess_key_idValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecOssBuffer {
            chunk_full_threshold?: string;
            chunk_limit_records?: number;
            chunk_limit_size?: string;
            compress?: string;
            delayed_commit_timeout?: string;
            disable_chunk_backup?: boolean;
            flush_at_shutdown?: boolean;
            flush_interval?: string;
            flush_mode?: string;
            flush_thread_burst_interval?: string;
            flush_thread_count?: number;
            flush_thread_interval?: string;
            overflow_action?: string;
            path?: string;
            queue_limit_length?: number;
            queued_chunks_limit_size?: number;
            retry_exponential_backoff_base?: string;
            retry_forever?: boolean;
            retry_max_interval?: string;
            retry_max_times?: number;
            retry_randomize?: boolean;
            retry_secondary_threshold?: string;
            retry_timeout?: string;
            retry_type?: string;
            retry_wait?: string;
            tags?: string;
            timekey?: string;
            timekey_use_utc?: boolean;
            timekey_wait?: string;
            timekey_zone?: string;
            total_limit_size?: string;
            type?: string;
        }

        export interface OutputSpecOssFormat {
            add_newline?: boolean;
            message_key?: string;
            type?: string;
        }

        export interface OutputSpecRedis {
            allow_duplicate_key?: boolean;
            buffer?: outputs.logging.v1beta1.OutputSpecRedisBuffer;
            db_number?: number;
            format?: outputs.logging.v1beta1.OutputSpecRedisFormat;
            host?: string;
            insert_key_prefix?: string;
            password?: outputs.logging.v1beta1.OutputSpecRedisPassword;
            port?: number;
            strftime_format?: string;
            ttl?: number;
        }

        export interface OutputSpecRedisBuffer {
            chunk_full_threshold?: string;
            chunk_limit_records?: number;
            chunk_limit_size?: string;
            compress?: string;
            delayed_commit_timeout?: string;
            disable_chunk_backup?: boolean;
            flush_at_shutdown?: boolean;
            flush_interval?: string;
            flush_mode?: string;
            flush_thread_burst_interval?: string;
            flush_thread_count?: number;
            flush_thread_interval?: string;
            overflow_action?: string;
            path?: string;
            queue_limit_length?: number;
            queued_chunks_limit_size?: number;
            retry_exponential_backoff_base?: string;
            retry_forever?: boolean;
            retry_max_interval?: string;
            retry_max_times?: number;
            retry_randomize?: boolean;
            retry_secondary_threshold?: string;
            retry_timeout?: string;
            retry_type?: string;
            retry_wait?: string;
            tags?: string;
            timekey?: string;
            timekey_use_utc?: boolean;
            timekey_wait?: string;
            timekey_zone?: string;
            total_limit_size?: string;
            type?: string;
        }

        export interface OutputSpecRedisFormat {
            add_newline?: boolean;
            message_key?: string;
            type?: string;
        }

        export interface OutputSpecRedisPassword {
            mountFrom?: outputs.logging.v1beta1.OutputSpecRedisPasswordMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.OutputSpecRedisPasswordValueFrom;
        }

        export interface OutputSpecRedisPasswordMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecRedisPasswordMountFromSecretKeyRef;
        }

        export interface OutputSpecRedisPasswordMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecRedisPasswordValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecRedisPasswordValueFromSecretKeyRef;
        }

        export interface OutputSpecRedisPasswordValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecS3 {
            acl?: string;
            assume_role_credentials?: outputs.logging.v1beta1.OutputSpecS3Assume_role_credentials;
            auto_create_bucket?: string;
            aws_iam_retries?: string;
            aws_key_id?: outputs.logging.v1beta1.OutputSpecS3Aws_key_id;
            aws_sec_key?: outputs.logging.v1beta1.OutputSpecS3Aws_sec_key;
            buffer?: outputs.logging.v1beta1.OutputSpecS3Buffer;
            check_apikey_on_start?: string;
            check_bucket?: string;
            check_object?: string;
            clustername?: string;
            compute_checksums?: string;
            enable_transfer_acceleration?: string;
            force_path_style?: string;
            format?: outputs.logging.v1beta1.OutputSpecS3Format;
            grant_full_control?: string;
            grant_read?: string;
            grant_read_acp?: string;
            grant_write_acp?: string;
            hex_random_length?: string;
            index_format?: string;
            instance_profile_credentials?: outputs.logging.v1beta1.OutputSpecS3Instance_profile_credentials;
            oneeye_format?: boolean;
            overwrite?: string;
            path?: string;
            proxy_uri?: string;
            s3_bucket: string;
            s3_endpoint?: string;
            s3_metadata?: string;
            s3_object_key_format?: string;
            s3_region?: string;
            shared_credentials?: outputs.logging.v1beta1.OutputSpecS3Shared_credentials;
            signature_version?: string;
            sse_customer_algorithm?: string;
            sse_customer_key?: string;
            sse_customer_key_md5?: string;
            ssekms_key_id?: string;
            ssl_verify_peer?: string;
            storage_class?: string;
            store_as?: string;
            use_bundled_cert?: string;
            use_server_side_encryption?: string;
            warn_for_delay?: string;
        }

        export interface OutputSpecS3Assume_role_credentials {
            duration_seconds?: string;
            external_id?: string;
            policy?: string;
            role_arn: string;
            role_session_name: string;
        }

        export interface OutputSpecS3Aws_key_id {
            mountFrom?: outputs.logging.v1beta1.OutputSpecS3Aws_key_idMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.OutputSpecS3Aws_key_idValueFrom;
        }

        export interface OutputSpecS3Aws_key_idMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecS3Aws_key_idMountFromSecretKeyRef;
        }

        export interface OutputSpecS3Aws_key_idMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecS3Aws_key_idValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecS3Aws_key_idValueFromSecretKeyRef;
        }

        export interface OutputSpecS3Aws_key_idValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecS3Aws_sec_key {
            mountFrom?: outputs.logging.v1beta1.OutputSpecS3Aws_sec_keyMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.OutputSpecS3Aws_sec_keyValueFrom;
        }

        export interface OutputSpecS3Aws_sec_keyMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecS3Aws_sec_keyMountFromSecretKeyRef;
        }

        export interface OutputSpecS3Aws_sec_keyMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecS3Aws_sec_keyValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecS3Aws_sec_keyValueFromSecretKeyRef;
        }

        export interface OutputSpecS3Aws_sec_keyValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecS3Buffer {
            chunk_full_threshold?: string;
            chunk_limit_records?: number;
            chunk_limit_size?: string;
            compress?: string;
            delayed_commit_timeout?: string;
            disable_chunk_backup?: boolean;
            flush_at_shutdown?: boolean;
            flush_interval?: string;
            flush_mode?: string;
            flush_thread_burst_interval?: string;
            flush_thread_count?: number;
            flush_thread_interval?: string;
            overflow_action?: string;
            path?: string;
            queue_limit_length?: number;
            queued_chunks_limit_size?: number;
            retry_exponential_backoff_base?: string;
            retry_forever?: boolean;
            retry_max_interval?: string;
            retry_max_times?: number;
            retry_randomize?: boolean;
            retry_secondary_threshold?: string;
            retry_timeout?: string;
            retry_type?: string;
            retry_wait?: string;
            tags?: string;
            timekey?: string;
            timekey_use_utc?: boolean;
            timekey_wait?: string;
            timekey_zone?: string;
            total_limit_size?: string;
            type?: string;
        }

        export interface OutputSpecS3Format {
            add_newline?: boolean;
            message_key?: string;
            type?: string;
        }

        export interface OutputSpecS3Instance_profile_credentials {
            http_open_timeout?: string;
            http_read_timeout?: string;
            ip_address?: string;
            port?: string;
            retries?: string;
        }

        export interface OutputSpecS3Shared_credentials {
            path?: string;
            profile_name?: string;
        }

        export interface OutputSpecSplunkHec {
            buffer?: outputs.logging.v1beta1.OutputSpecSplunkHecBuffer;
            ca_file?: outputs.logging.v1beta1.OutputSpecSplunkHecCa_file;
            ca_path?: outputs.logging.v1beta1.OutputSpecSplunkHecCa_path;
            client_cert?: outputs.logging.v1beta1.OutputSpecSplunkHecClient_cert;
            client_key?: outputs.logging.v1beta1.OutputSpecSplunkHecClient_key;
            coerce_to_utf8?: boolean;
            data_type?: string;
            fields?: { [key: string]: string };
            format?: outputs.logging.v1beta1.OutputSpecSplunkHecFormat;
            hec_host: string;
            hec_port?: number;
            hec_token: outputs.logging.v1beta1.OutputSpecSplunkHecHec_token;
            host?: string;
            host_key?: string;
            idle_timeout?: number;
            index?: string;
            index_key?: string;
            insecure_ssl?: boolean;
            keep_keys?: boolean;
            metric_name_key?: string;
            metric_value_key?: string;
            metrics_from_event?: boolean;
            non_utf8_replacement_string?: string;
            open_timeout?: number;
            protocol?: string;
            read_timeout?: number;
            source?: string;
            source_key?: string;
            sourcetype?: string;
            sourcetype_key?: string;
            ssl_ciphers?: string;
        }

        export interface OutputSpecSplunkHecBuffer {
            chunk_full_threshold?: string;
            chunk_limit_records?: number;
            chunk_limit_size?: string;
            compress?: string;
            delayed_commit_timeout?: string;
            disable_chunk_backup?: boolean;
            flush_at_shutdown?: boolean;
            flush_interval?: string;
            flush_mode?: string;
            flush_thread_burst_interval?: string;
            flush_thread_count?: number;
            flush_thread_interval?: string;
            overflow_action?: string;
            path?: string;
            queue_limit_length?: number;
            queued_chunks_limit_size?: number;
            retry_exponential_backoff_base?: string;
            retry_forever?: boolean;
            retry_max_interval?: string;
            retry_max_times?: number;
            retry_randomize?: boolean;
            retry_secondary_threshold?: string;
            retry_timeout?: string;
            retry_type?: string;
            retry_wait?: string;
            tags?: string;
            timekey?: string;
            timekey_use_utc?: boolean;
            timekey_wait?: string;
            timekey_zone?: string;
            total_limit_size?: string;
            type?: string;
        }

        export interface OutputSpecSplunkHecCa_file {
            mountFrom?: outputs.logging.v1beta1.OutputSpecSplunkHecCa_fileMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.OutputSpecSplunkHecCa_fileValueFrom;
        }

        export interface OutputSpecSplunkHecCa_fileMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecSplunkHecCa_fileMountFromSecretKeyRef;
        }

        export interface OutputSpecSplunkHecCa_fileMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecSplunkHecCa_fileValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecSplunkHecCa_fileValueFromSecretKeyRef;
        }

        export interface OutputSpecSplunkHecCa_fileValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecSplunkHecCa_path {
            mountFrom?: outputs.logging.v1beta1.OutputSpecSplunkHecCa_pathMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.OutputSpecSplunkHecCa_pathValueFrom;
        }

        export interface OutputSpecSplunkHecCa_pathMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecSplunkHecCa_pathMountFromSecretKeyRef;
        }

        export interface OutputSpecSplunkHecCa_pathMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecSplunkHecCa_pathValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecSplunkHecCa_pathValueFromSecretKeyRef;
        }

        export interface OutputSpecSplunkHecCa_pathValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecSplunkHecClient_cert {
            mountFrom?: outputs.logging.v1beta1.OutputSpecSplunkHecClient_certMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.OutputSpecSplunkHecClient_certValueFrom;
        }

        export interface OutputSpecSplunkHecClient_certMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecSplunkHecClient_certMountFromSecretKeyRef;
        }

        export interface OutputSpecSplunkHecClient_certMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecSplunkHecClient_certValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecSplunkHecClient_certValueFromSecretKeyRef;
        }

        export interface OutputSpecSplunkHecClient_certValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecSplunkHecClient_key {
            mountFrom?: outputs.logging.v1beta1.OutputSpecSplunkHecClient_keyMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.OutputSpecSplunkHecClient_keyValueFrom;
        }

        export interface OutputSpecSplunkHecClient_keyMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecSplunkHecClient_keyMountFromSecretKeyRef;
        }

        export interface OutputSpecSplunkHecClient_keyMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecSplunkHecClient_keyValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecSplunkHecClient_keyValueFromSecretKeyRef;
        }

        export interface OutputSpecSplunkHecClient_keyValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecSplunkHecFormat {
            add_newline?: boolean;
            message_key?: string;
            type?: string;
        }

        export interface OutputSpecSplunkHecHec_token {
            mountFrom?: outputs.logging.v1beta1.OutputSpecSplunkHecHec_tokenMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.OutputSpecSplunkHecHec_tokenValueFrom;
        }

        export interface OutputSpecSplunkHecHec_tokenMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecSplunkHecHec_tokenMountFromSecretKeyRef;
        }

        export interface OutputSpecSplunkHecHec_tokenMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecSplunkHecHec_tokenValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecSplunkHecHec_tokenValueFromSecretKeyRef;
        }

        export interface OutputSpecSplunkHecHec_tokenValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecSumologic {
            add_timestamp?: boolean;
            buffer?: outputs.logging.v1beta1.OutputSpecSumologicBuffer;
            compress?: boolean;
            compress_encoding?: string;
            custom_dimensions?: string;
            custom_fields?: string[];
            data_type?: string;
            delimiter?: string;
            disable_cookies?: boolean;
            endpoint: outputs.logging.v1beta1.OutputSpecSumologicEndpoint;
            log_format?: string;
            log_key?: string;
            metric_data_format?: string;
            open_timeout?: number;
            proxy_uri?: string;
            source_category?: string;
            source_host?: string;
            source_name: string;
            source_name_key?: string;
            sumo_client?: string;
            timestamp_key?: string;
            verify_ssl?: boolean;
        }

        export interface OutputSpecSumologicBuffer {
            chunk_full_threshold?: string;
            chunk_limit_records?: number;
            chunk_limit_size?: string;
            compress?: string;
            delayed_commit_timeout?: string;
            disable_chunk_backup?: boolean;
            flush_at_shutdown?: boolean;
            flush_interval?: string;
            flush_mode?: string;
            flush_thread_burst_interval?: string;
            flush_thread_count?: number;
            flush_thread_interval?: string;
            overflow_action?: string;
            path?: string;
            queue_limit_length?: number;
            queued_chunks_limit_size?: number;
            retry_exponential_backoff_base?: string;
            retry_forever?: boolean;
            retry_max_interval?: string;
            retry_max_times?: number;
            retry_randomize?: boolean;
            retry_secondary_threshold?: string;
            retry_timeout?: string;
            retry_type?: string;
            retry_wait?: string;
            tags?: string;
            timekey?: string;
            timekey_use_utc?: boolean;
            timekey_wait?: string;
            timekey_zone?: string;
            total_limit_size?: string;
            type?: string;
        }

        export interface OutputSpecSumologicEndpoint {
            mountFrom?: outputs.logging.v1beta1.OutputSpecSumologicEndpointMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.OutputSpecSumologicEndpointValueFrom;
        }

        export interface OutputSpecSumologicEndpointMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecSumologicEndpointMountFromSecretKeyRef;
        }

        export interface OutputSpecSumologicEndpointMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecSumologicEndpointValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecSumologicEndpointValueFromSecretKeyRef;
        }

        export interface OutputSpecSumologicEndpointValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecSyslog {
            buffer?: outputs.logging.v1beta1.OutputSpecSyslogBuffer;
            format?: outputs.logging.v1beta1.OutputSpecSyslogFormat;
            host: string;
            insecure?: boolean;
            port?: number;
            transport?: string;
            trusted_ca_path?: outputs.logging.v1beta1.OutputSpecSyslogTrusted_ca_path;
        }

        export interface OutputSpecSyslogBuffer {
            chunk_full_threshold?: string;
            chunk_limit_records?: number;
            chunk_limit_size?: string;
            compress?: string;
            delayed_commit_timeout?: string;
            disable_chunk_backup?: boolean;
            flush_at_shutdown?: boolean;
            flush_interval?: string;
            flush_mode?: string;
            flush_thread_burst_interval?: string;
            flush_thread_count?: number;
            flush_thread_interval?: string;
            overflow_action?: string;
            path?: string;
            queue_limit_length?: number;
            queued_chunks_limit_size?: number;
            retry_exponential_backoff_base?: string;
            retry_forever?: boolean;
            retry_max_interval?: string;
            retry_max_times?: number;
            retry_randomize?: boolean;
            retry_secondary_threshold?: string;
            retry_timeout?: string;
            retry_type?: string;
            retry_wait?: string;
            tags?: string;
            timekey?: string;
            timekey_use_utc?: boolean;
            timekey_wait?: string;
            timekey_zone?: string;
            total_limit_size?: string;
            type?: string;
        }

        export interface OutputSpecSyslogFormat {
            app_name_field?: string;
            hostname_field?: string;
            log_field?: string;
            message_id_field?: string;
            proc_id_field?: string;
            rfc6587_message_size?: boolean;
            structured_data_field?: string;
            type?: string;
        }

        export interface OutputSpecSyslogTrusted_ca_path {
            mountFrom?: outputs.logging.v1beta1.OutputSpecSyslogTrusted_ca_pathMountFrom;
            value?: string;
            valueFrom?: outputs.logging.v1beta1.OutputSpecSyslogTrusted_ca_pathValueFrom;
        }

        export interface OutputSpecSyslogTrusted_ca_pathMountFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecSyslogTrusted_ca_pathMountFromSecretKeyRef;
        }

        export interface OutputSpecSyslogTrusted_ca_pathMountFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputSpecSyslogTrusted_ca_pathValueFrom {
            secretKeyRef?: outputs.logging.v1beta1.OutputSpecSyslogTrusted_ca_pathValueFromSecretKeyRef;
        }

        export interface OutputSpecSyslogTrusted_ca_pathValueFromSecretKeyRef {
            key: string;
            name?: string;
            optional?: boolean;
        }

        export interface OutputStatus {
            active?: boolean;
            problems?: string[];
            problemsCount?: number;
        }
    }
}

export namespace monitoring {
    export namespace v1 {
        /**
         * Specification of the desired behavior of the Alertmanager cluster. More info: https://github.com/kubernetes/community/blob/master/contributors/devel/sig-architecture/api-conventions.md#spec-and-status
         */
        export interface AlertmanagerSpec {
            /**
             * AdditionalPeers allows injecting a set of additional Alertmanagers to peer with to form a highly available cluster.
             */
            additionalPeers?: string[];
            /**
             * If specified, the pod's scheduling constraints.
             */
            affinity?: outputs.monitoring.v1.AlertmanagerSpecAffinity;
            /**
             * Namespaces to be selected for AlertmanagerConfig discovery. If nil, only check own namespace.
             */
            alertmanagerConfigNamespaceSelector?: outputs.monitoring.v1.AlertmanagerSpecAlertmanagerConfigNamespaceSelector;
            /**
             * AlertmanagerConfigs to be selected for to merge and configure Alertmanager with.
             */
            alertmanagerConfigSelector?: outputs.monitoring.v1.AlertmanagerSpecAlertmanagerConfigSelector;
            /**
             * Base image that is used to deploy pods, without tag. Deprecated: use 'image' instead
             */
            baseImage?: string;
            /**
             * ClusterAdvertiseAddress is the explicit address to advertise in cluster. Needs to be provided for non RFC1918 [1] (public) addresses. [1] RFC1918: https://tools.ietf.org/html/rfc1918
             */
            clusterAdvertiseAddress?: string;
            /**
             * Interval between gossip attempts.
             */
            clusterGossipInterval?: string;
            /**
             * Timeout for cluster peering.
             */
            clusterPeerTimeout?: string;
            /**
             * Interval between pushpull attempts.
             */
            clusterPushpullInterval?: string;
            /**
             * ConfigMaps is a list of ConfigMaps in the same namespace as the Alertmanager object, which shall be mounted into the Alertmanager Pods. The ConfigMaps are mounted into /etc/alertmanager/configmaps/<configmap-name>.
             */
            configMaps?: string[];
            /**
             * ConfigSecret is the name of a Kubernetes Secret in the same namespace as the Alertmanager object, which contains configuration for this Alertmanager instance. Defaults to 'alertmanager-<alertmanager-name>' The secret is mounted into /etc/alertmanager/config.
             */
            configSecret?: string;
            /**
             * Containers allows injecting additional containers. This is meant to allow adding an authentication proxy to an Alertmanager pod. Containers described here modify an operator generated container if they share the same name and modifications are done via a strategic merge patch. The current container names are: `alertmanager` and `config-reloader`. Overriding containers is entirely outside the scope of what the maintainers will support and by doing so, you accept that this behaviour may break at any time without notice.
             */
            containers?: outputs.monitoring.v1.AlertmanagerSpecContainers[];
            /**
             * The external URL the Alertmanager instances will be available under. This is necessary to generate correct URLs. This is necessary if Alertmanager is not served from root of a DNS name.
             */
            externalUrl?: string;
            /**
             * ForceEnableClusterMode ensures Alertmanager does not deactivate the cluster mode when running with a single replica. Use case is e.g. spanning an Alertmanager cluster across Kubernetes clusters with a single replica in each.
             */
            forceEnableClusterMode?: boolean;
            /**
             * Image if specified has precedence over baseImage, tag and sha combinations. Specifying the version is still necessary to ensure the Prometheus Operator knows what version of Alertmanager is being configured.
             */
            image?: string;
            /**
             * An optional list of references to secrets in the same namespace to use for pulling prometheus and alertmanager images from registries see http://kubernetes.io/docs/user-guide/images#specifying-imagepullsecrets-on-a-pod
             */
            imagePullSecrets?: outputs.monitoring.v1.AlertmanagerSpecImagePullSecrets[];
            /**
             * InitContainers allows adding initContainers to the pod definition. Those can be used to e.g. fetch secrets for injection into the Alertmanager configuration from external sources. Any errors during the execution of an initContainer will lead to a restart of the Pod. More info: https://kubernetes.io/docs/concepts/workloads/pods/init-containers/ Using initContainers for any use case other then secret fetching is entirely outside the scope of what the maintainers will support and by doing so, you accept that this behaviour may break at any time without notice.
             */
            initContainers?: outputs.monitoring.v1.AlertmanagerSpecInitContainers[];
            /**
             * ListenLocal makes the Alertmanager server listen on loopback, so that it does not bind against the Pod IP. Note this is only for the Alertmanager UI, not the gossip communication.
             */
            listenLocal?: boolean;
            /**
             * Log format for Alertmanager to be configured with.
             */
            logFormat?: string;
            /**
             * Log level for Alertmanager to be configured with.
             */
            logLevel?: string;
            /**
             * Define which Nodes the Pods are scheduled on.
             */
            nodeSelector?: {[key: string]: string};
            /**
             * If set to true all actions on the underlying managed objects are not goint to be performed, except for delete actions.
             */
            paused?: boolean;
            /**
             * PodMetadata configures Labels and Annotations which are propagated to the alertmanager pods.
             */
            podMetadata?: outputs.monitoring.v1.AlertmanagerSpecPodMetadata;
            /**
             * Port name used for the pods and governing service. This defaults to web
             */
            portName?: string;
            /**
             * Priority class assigned to the Pods
             */
            priorityClassName?: string;
            /**
             * Size is the expected size of the alertmanager cluster. The controller will eventually make the size of the running cluster equal to the expected size.
             */
            replicas?: number;
            /**
             * Define resources requests and limits for single Pods.
             */
            resources?: outputs.monitoring.v1.AlertmanagerSpecResources;
            /**
             * Time duration Alertmanager shall retain data for. Default is '120h', and must match the regular expression `[0-9]+(ms|s|m|h)` (milliseconds seconds minutes hours).
             */
            retention?: string;
            /**
             * The route prefix Alertmanager registers HTTP handlers for. This is useful, if using ExternalURL and a proxy is rewriting HTTP routes of a request, and the actual ExternalURL is still true, but the server serves requests under a different route prefix. For example for use with `kubectl proxy`.
             */
            routePrefix?: string;
            /**
             * Secrets is a list of Secrets in the same namespace as the Alertmanager object, which shall be mounted into the Alertmanager Pods. The Secrets are mounted into /etc/alertmanager/secrets/<secret-name>.
             */
            secrets?: string[];
            /**
             * SecurityContext holds pod-level security attributes and common container settings. This defaults to the default PodSecurityContext.
             */
            securityContext?: outputs.monitoring.v1.AlertmanagerSpecSecurityContext;
            /**
             * ServiceAccountName is the name of the ServiceAccount to use to run the Prometheus Pods.
             */
            serviceAccountName?: string;
            /**
             * SHA of Alertmanager container image to be deployed. Defaults to the value of `version`. Similar to a tag, but the SHA explicitly deploys an immutable container image. Version and Tag are ignored if SHA is set. Deprecated: use 'image' instead.  The image digest can be specified as part of the image URL.
             */
            sha?: string;
            /**
             * Storage is the definition of how storage will be used by the Alertmanager instances.
             */
            storage?: outputs.monitoring.v1.AlertmanagerSpecStorage;
            /**
             * Tag of Alertmanager container image to be deployed. Defaults to the value of `version`. Version is ignored if Tag is set. Deprecated: use 'image' instead.  The image tag can be specified as part of the image URL.
             */
            tag?: string;
            /**
             * If specified, the pod's tolerations.
             */
            tolerations?: outputs.monitoring.v1.AlertmanagerSpecTolerations[];
            /**
             * If specified, the pod's topology spread constraints.
             */
            topologySpreadConstraints?: outputs.monitoring.v1.AlertmanagerSpecTopologySpreadConstraints[];
            /**
             * Version the cluster should be on.
             */
            version?: string;
            /**
             * VolumeMounts allows configuration of additional VolumeMounts on the output StatefulSet definition. VolumeMounts specified will be appended to other VolumeMounts in the alertmanager container, that are generated as a result of StorageSpec objects.
             */
            volumeMounts?: outputs.monitoring.v1.AlertmanagerSpecVolumeMounts[];
            /**
             * Volumes allows configuration of additional volumes on the output StatefulSet definition. Volumes specified will be appended to other volumes that are generated as a result of StorageSpec objects.
             */
            volumes?: outputs.monitoring.v1.AlertmanagerSpecVolumes[];
        }

        /**
         * If specified, the pod's scheduling constraints.
         */
        export interface AlertmanagerSpecAffinity {
            /**
             * Describes node affinity scheduling rules for the pod.
             */
            nodeAffinity?: outputs.monitoring.v1.AlertmanagerSpecAffinityNodeAffinity;
            /**
             * Describes pod affinity scheduling rules (e.g. co-locate this pod in the same node, zone, etc. as some other pod(s)).
             */
            podAffinity?: outputs.monitoring.v1.AlertmanagerSpecAffinityPodAffinity;
            /**
             * Describes pod anti-affinity scheduling rules (e.g. avoid putting this pod in the same node, zone, etc. as some other pod(s)).
             */
            podAntiAffinity?: outputs.monitoring.v1.AlertmanagerSpecAffinityPodAntiAffinity;
        }

        /**
         * Describes node affinity scheduling rules for the pod.
         */
        export interface AlertmanagerSpecAffinityNodeAffinity {
            /**
             * The scheduler will prefer to schedule pods to nodes that satisfy the affinity expressions specified by this field, but it may choose a node that violates one or more of the expressions. The node that is most preferred is the one with the greatest sum of weights, i.e. for each node that meets all of the scheduling requirements (resource request, requiredDuringScheduling affinity expressions, etc.), compute a sum by iterating through the elements of this field and adding "weight" to the sum if the node matches the corresponding matchExpressions; the node(s) with the highest sum are the most preferred.
             */
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.monitoring.v1.AlertmanagerSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            /**
             * If the affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to an update), the system may or may not try to eventually evict the pod from its node.
             */
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.monitoring.v1.AlertmanagerSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution;
        }

        /**
         * An empty preferred scheduling term matches all objects with implicit weight 0 (i.e. it's a no-op). A null preferred scheduling term matches no objects (i.e. is also a no-op).
         */
        export interface AlertmanagerSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            /**
             * A node selector term, associated with the corresponding weight.
             */
            preference: outputs.monitoring.v1.AlertmanagerSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference;
            /**
             * Weight associated with matching the corresponding nodeSelectorTerm, in the range 1-100.
             */
            weight: number;
        }

        /**
         * A node selector term, associated with the corresponding weight.
         */
        export interface AlertmanagerSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference {
            /**
             * A list of node selector requirements by node's labels.
             */
            matchExpressions?: outputs.monitoring.v1.AlertmanagerSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions[];
            /**
             * A list of node selector requirements by node's fields.
             */
            matchFields?: outputs.monitoring.v1.AlertmanagerSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields[];
        }

        /**
         * A node selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface AlertmanagerSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions {
            /**
             * The label key that the selector applies to.
             */
            key: string;
            /**
             * Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
             */
            operator: string;
            /**
             * An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * A node selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface AlertmanagerSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields {
            /**
             * The label key that the selector applies to.
             */
            key: string;
            /**
             * Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
             */
            operator: string;
            /**
             * An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * If the affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to an update), the system may or may not try to eventually evict the pod from its node.
         */
        export interface AlertmanagerSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            /**
             * Required. A list of node selector terms. The terms are ORed.
             */
            nodeSelectorTerms: outputs.monitoring.v1.AlertmanagerSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms[];
        }

        /**
         * A null or empty node selector term matches no objects. The requirements of them are ANDed. The TopologySelectorTerm type implements a subset of the NodeSelectorTerm.
         */
        export interface AlertmanagerSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms {
            /**
             * A list of node selector requirements by node's labels.
             */
            matchExpressions?: outputs.monitoring.v1.AlertmanagerSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions[];
            /**
             * A list of node selector requirements by node's fields.
             */
            matchFields?: outputs.monitoring.v1.AlertmanagerSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields[];
        }

        /**
         * A node selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface AlertmanagerSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions {
            /**
             * The label key that the selector applies to.
             */
            key: string;
            /**
             * Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
             */
            operator: string;
            /**
             * An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * A node selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface AlertmanagerSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields {
            /**
             * The label key that the selector applies to.
             */
            key: string;
            /**
             * Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
             */
            operator: string;
            /**
             * An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Describes pod affinity scheduling rules (e.g. co-locate this pod in the same node, zone, etc. as some other pod(s)).
         */
        export interface AlertmanagerSpecAffinityPodAffinity {
            /**
             * The scheduler will prefer to schedule pods to nodes that satisfy the affinity expressions specified by this field, but it may choose a node that violates one or more of the expressions. The node that is most preferred is the one with the greatest sum of weights, i.e. for each node that meets all of the scheduling requirements (resource request, requiredDuringScheduling affinity expressions, etc.), compute a sum by iterating through the elements of this field and adding "weight" to the sum if the node has pods which matches the corresponding podAffinityTerm; the node(s) with the highest sum are the most preferred.
             */
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.monitoring.v1.AlertmanagerSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            /**
             * If the affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to a pod label update), the system may or may not try to eventually evict the pod from its node. When there are multiple elements, the lists of nodes corresponding to each podAffinityTerm are intersected, i.e. all terms must be satisfied.
             */
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.monitoring.v1.AlertmanagerSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        /**
         * The weights of all of the matched WeightedPodAffinityTerm fields are added per-node to find the most preferred node(s)
         */
        export interface AlertmanagerSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            /**
             * Required. A pod affinity term, associated with the corresponding weight.
             */
            podAffinityTerm: outputs.monitoring.v1.AlertmanagerSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            /**
             * weight associated with matching the corresponding podAffinityTerm, in the range 1-100.
             */
            weight: number;
        }

        /**
         * Required. A pod affinity term, associated with the corresponding weight.
         */
        export interface AlertmanagerSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            /**
             * A label query over a set of resources, in this case pods.
             */
            labelSelector?: outputs.monitoring.v1.AlertmanagerSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            /**
             * namespaces specifies which namespaces the labelSelector applies to (matches against); null or empty list means "this pod's namespace"
             */
            namespaces?: string[];
            /**
             * This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed.
             */
            topologyKey: string;
        }

        /**
         * A label query over a set of resources, in this case pods.
         */
        export interface AlertmanagerSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.monitoring.v1.AlertmanagerSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface AlertmanagerSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Defines a set of pods (namely those matching the labelSelector relative to the given namespace(s)) that this pod should be co-located (affinity) or not co-located (anti-affinity) with, where co-located is defined as running on a node whose value of the label with key <topologyKey> matches that of any node on which a pod of the set of pods is running
         */
        export interface AlertmanagerSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            /**
             * A label query over a set of resources, in this case pods.
             */
            labelSelector?: outputs.monitoring.v1.AlertmanagerSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            /**
             * namespaces specifies which namespaces the labelSelector applies to (matches against); null or empty list means "this pod's namespace"
             */
            namespaces?: string[];
            /**
             * This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed.
             */
            topologyKey: string;
        }

        /**
         * A label query over a set of resources, in this case pods.
         */
        export interface AlertmanagerSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.monitoring.v1.AlertmanagerSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface AlertmanagerSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Describes pod anti-affinity scheduling rules (e.g. avoid putting this pod in the same node, zone, etc. as some other pod(s)).
         */
        export interface AlertmanagerSpecAffinityPodAntiAffinity {
            /**
             * The scheduler will prefer to schedule pods to nodes that satisfy the anti-affinity expressions specified by this field, but it may choose a node that violates one or more of the expressions. The node that is most preferred is the one with the greatest sum of weights, i.e. for each node that meets all of the scheduling requirements (resource request, requiredDuringScheduling anti-affinity expressions, etc.), compute a sum by iterating through the elements of this field and adding "weight" to the sum if the node has pods which matches the corresponding podAffinityTerm; the node(s) with the highest sum are the most preferred.
             */
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.monitoring.v1.AlertmanagerSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            /**
             * If the anti-affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the anti-affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to a pod label update), the system may or may not try to eventually evict the pod from its node. When there are multiple elements, the lists of nodes corresponding to each podAffinityTerm are intersected, i.e. all terms must be satisfied.
             */
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.monitoring.v1.AlertmanagerSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        /**
         * The weights of all of the matched WeightedPodAffinityTerm fields are added per-node to find the most preferred node(s)
         */
        export interface AlertmanagerSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            /**
             * Required. A pod affinity term, associated with the corresponding weight.
             */
            podAffinityTerm: outputs.monitoring.v1.AlertmanagerSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            /**
             * weight associated with matching the corresponding podAffinityTerm, in the range 1-100.
             */
            weight: number;
        }

        /**
         * Required. A pod affinity term, associated with the corresponding weight.
         */
        export interface AlertmanagerSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            /**
             * A label query over a set of resources, in this case pods.
             */
            labelSelector?: outputs.monitoring.v1.AlertmanagerSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            /**
             * namespaces specifies which namespaces the labelSelector applies to (matches against); null or empty list means "this pod's namespace"
             */
            namespaces?: string[];
            /**
             * This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed.
             */
            topologyKey: string;
        }

        /**
         * A label query over a set of resources, in this case pods.
         */
        export interface AlertmanagerSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.monitoring.v1.AlertmanagerSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface AlertmanagerSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Defines a set of pods (namely those matching the labelSelector relative to the given namespace(s)) that this pod should be co-located (affinity) or not co-located (anti-affinity) with, where co-located is defined as running on a node whose value of the label with key <topologyKey> matches that of any node on which a pod of the set of pods is running
         */
        export interface AlertmanagerSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            /**
             * A label query over a set of resources, in this case pods.
             */
            labelSelector?: outputs.monitoring.v1.AlertmanagerSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            /**
             * namespaces specifies which namespaces the labelSelector applies to (matches against); null or empty list means "this pod's namespace"
             */
            namespaces?: string[];
            /**
             * This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed.
             */
            topologyKey: string;
        }

        /**
         * A label query over a set of resources, in this case pods.
         */
        export interface AlertmanagerSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.monitoring.v1.AlertmanagerSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface AlertmanagerSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Namespaces to be selected for AlertmanagerConfig discovery. If nil, only check own namespace.
         */
        export interface AlertmanagerSpecAlertmanagerConfigNamespaceSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.monitoring.v1.AlertmanagerSpecAlertmanagerConfigNamespaceSelectorMatchExpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface AlertmanagerSpecAlertmanagerConfigNamespaceSelectorMatchExpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * AlertmanagerConfigs to be selected for to merge and configure Alertmanager with.
         */
        export interface AlertmanagerSpecAlertmanagerConfigSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.monitoring.v1.AlertmanagerSpecAlertmanagerConfigSelectorMatchExpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface AlertmanagerSpecAlertmanagerConfigSelectorMatchExpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * A single application container that you want to run within a pod.
         */
        export interface AlertmanagerSpecContainers {
            /**
             * Arguments to the entrypoint. The docker image's CMD is used if this is not provided. Variable references $(VAR_NAME) are expanded using the container's environment. If a variable cannot be resolved, the reference in the input string will be unchanged. The $(VAR_NAME) syntax can be escaped with a double $$, ie: $$(VAR_NAME). Escaped references will never be expanded, regardless of whether the variable exists or not. Cannot be updated. More info: https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#running-a-command-in-a-shell
             */
            args?: string[];
            /**
             * Entrypoint array. Not executed within a shell. The docker image's ENTRYPOINT is used if this is not provided. Variable references $(VAR_NAME) are expanded using the container's environment. If a variable cannot be resolved, the reference in the input string will be unchanged. The $(VAR_NAME) syntax can be escaped with a double $$, ie: $$(VAR_NAME). Escaped references will never be expanded, regardless of whether the variable exists or not. Cannot be updated. More info: https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#running-a-command-in-a-shell
             */
            command?: string[];
            /**
             * List of environment variables to set in the container. Cannot be updated.
             */
            env?: outputs.monitoring.v1.AlertmanagerSpecContainersEnv[];
            /**
             * List of sources to populate environment variables in the container. The keys defined within a source must be a C_IDENTIFIER. All invalid keys will be reported as an event when the container is starting. When a key exists in multiple sources, the value associated with the last source will take precedence. Values defined by an Env with a duplicate key will take precedence. Cannot be updated.
             */
            envFrom?: outputs.monitoring.v1.AlertmanagerSpecContainersEnvFrom[];
            /**
             * Docker image name. More info: https://kubernetes.io/docs/concepts/containers/images This field is optional to allow higher level config management to default or override container images in workload controllers like Deployments and StatefulSets.
             */
            image?: string;
            /**
             * Image pull policy. One of Always, Never, IfNotPresent. Defaults to Always if :latest tag is specified, or IfNotPresent otherwise. Cannot be updated. More info: https://kubernetes.io/docs/concepts/containers/images#updating-images
             */
            imagePullPolicy?: string;
            /**
             * Actions that the management system should take in response to container lifecycle events. Cannot be updated.
             */
            lifecycle?: outputs.monitoring.v1.AlertmanagerSpecContainersLifecycle;
            /**
             * Periodic probe of container liveness. Container will be restarted if the probe fails. Cannot be updated. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
             */
            livenessProbe?: outputs.monitoring.v1.AlertmanagerSpecContainersLivenessProbe;
            /**
             * Name of the container specified as a DNS_LABEL. Each container in a pod must have a unique name (DNS_LABEL). Cannot be updated.
             */
            name: string;
            /**
             * List of ports to expose from the container. Exposing a port here gives the system additional information about the network connections a container uses, but is primarily informational. Not specifying a port here DOES NOT prevent that port from being exposed. Any port which is listening on the default "0.0.0.0" address inside a container will be accessible from the network. Cannot be updated.
             */
            ports?: outputs.monitoring.v1.AlertmanagerSpecContainersPorts[];
            /**
             * Periodic probe of container service readiness. Container will be removed from service endpoints if the probe fails. Cannot be updated. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
             */
            readinessProbe?: outputs.monitoring.v1.AlertmanagerSpecContainersReadinessProbe;
            /**
             * Compute Resources required by this container. Cannot be updated. More info: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
             */
            resources?: outputs.monitoring.v1.AlertmanagerSpecContainersResources;
            /**
             * Security options the pod should run with. More info: https://kubernetes.io/docs/concepts/policy/security-context/ More info: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/
             */
            securityContext?: outputs.monitoring.v1.AlertmanagerSpecContainersSecurityContext;
            /**
             * StartupProbe indicates that the Pod has successfully initialized. If specified, no other probes are executed until this completes successfully. If this probe fails, the Pod will be restarted, just as if the livenessProbe failed. This can be used to provide different probe parameters at the beginning of a Pod's lifecycle, when it might take a long time to load data or warm a cache, than during steady-state operation. This cannot be updated. This is a beta feature enabled by the StartupProbe feature flag. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
             */
            startupProbe?: outputs.monitoring.v1.AlertmanagerSpecContainersStartupProbe;
            /**
             * Whether this container should allocate a buffer for stdin in the container runtime. If this is not set, reads from stdin in the container will always result in EOF. Default is false.
             */
            stdin?: boolean;
            /**
             * Whether the container runtime should close the stdin channel after it has been opened by a single attach. When stdin is true the stdin stream will remain open across multiple attach sessions. If stdinOnce is set to true, stdin is opened on container start, is empty until the first client attaches to stdin, and then remains open and accepts data until the client disconnects, at which time stdin is closed and remains closed until the container is restarted. If this flag is false, a container processes that reads from stdin will never receive an EOF. Default is false
             */
            stdinOnce?: boolean;
            /**
             * Optional: Path at which the file to which the container's termination message will be written is mounted into the container's filesystem. Message written is intended to be brief final status, such as an assertion failure message. Will be truncated by the node if greater than 4096 bytes. The total message length across all containers will be limited to 12kb. Defaults to /dev/termination-log. Cannot be updated.
             */
            terminationMessagePath?: string;
            /**
             * Indicate how the termination message should be populated. File will use the contents of terminationMessagePath to populate the container status message on both success and failure. FallbackToLogsOnError will use the last chunk of container log output if the termination message file is empty and the container exited with an error. The log output is limited to 2048 bytes or 80 lines, whichever is smaller. Defaults to File. Cannot be updated.
             */
            terminationMessagePolicy?: string;
            /**
             * Whether this container should allocate a TTY for itself, also requires 'stdin' to be true. Default is false.
             */
            tty?: boolean;
            /**
             * volumeDevices is the list of block devices to be used by the container.
             */
            volumeDevices?: outputs.monitoring.v1.AlertmanagerSpecContainersVolumeDevices[];
            /**
             * Pod volumes to mount into the container's filesystem. Cannot be updated.
             */
            volumeMounts?: outputs.monitoring.v1.AlertmanagerSpecContainersVolumeMounts[];
            /**
             * Container's working directory. If not specified, the container runtime's default will be used, which might be configured in the container image. Cannot be updated.
             */
            workingDir?: string;
        }

        /**
         * EnvVar represents an environment variable present in a Container.
         */
        export interface AlertmanagerSpecContainersEnv {
            /**
             * Name of the environment variable. Must be a C_IDENTIFIER.
             */
            name: string;
            /**
             * Variable references $(VAR_NAME) are expanded using the previous defined environment variables in the container and any service environment variables. If a variable cannot be resolved, the reference in the input string will be unchanged. The $(VAR_NAME) syntax can be escaped with a double $$, ie: $$(VAR_NAME). Escaped references will never be expanded, regardless of whether the variable exists or not. Defaults to "".
             */
            value?: string;
            /**
             * Source for the environment variable's value. Cannot be used if value is not empty.
             */
            valueFrom?: outputs.monitoring.v1.AlertmanagerSpecContainersEnvValueFrom;
        }

        /**
         * EnvFromSource represents the source of a set of ConfigMaps
         */
        export interface AlertmanagerSpecContainersEnvFrom {
            /**
             * The ConfigMap to select from
             */
            configMapRef?: outputs.monitoring.v1.AlertmanagerSpecContainersEnvFromConfigMapRef;
            /**
             * An optional identifier to prepend to each key in the ConfigMap. Must be a C_IDENTIFIER.
             */
            prefix?: string;
            /**
             * The Secret to select from
             */
            secretRef?: outputs.monitoring.v1.AlertmanagerSpecContainersEnvFromSecretRef;
        }

        /**
         * The ConfigMap to select from
         */
        export interface AlertmanagerSpecContainersEnvFromConfigMapRef {
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the ConfigMap must be defined
             */
            optional?: boolean;
        }

        /**
         * The Secret to select from
         */
        export interface AlertmanagerSpecContainersEnvFromSecretRef {
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret must be defined
             */
            optional?: boolean;
        }

        /**
         * Source for the environment variable's value. Cannot be used if value is not empty.
         */
        export interface AlertmanagerSpecContainersEnvValueFrom {
            /**
             * Selects a key of a ConfigMap.
             */
            configMapKeyRef?: outputs.monitoring.v1.AlertmanagerSpecContainersEnvValueFromConfigMapKeyRef;
            /**
             * Selects a field of the pod: supports metadata.name, metadata.namespace, metadata.labels, metadata.annotations, spec.nodeName, spec.serviceAccountName, status.hostIP, status.podIP, status.podIPs.
             */
            fieldRef?: outputs.monitoring.v1.AlertmanagerSpecContainersEnvValueFromFieldRef;
            /**
             * Selects a resource of the container: only resources limits and requests (limits.cpu, limits.memory, limits.ephemeral-storage, requests.cpu, requests.memory and requests.ephemeral-storage) are currently supported.
             */
            resourceFieldRef?: outputs.monitoring.v1.AlertmanagerSpecContainersEnvValueFromResourceFieldRef;
            /**
             * Selects a key of a secret in the pod's namespace
             */
            secretKeyRef?: outputs.monitoring.v1.AlertmanagerSpecContainersEnvValueFromSecretKeyRef;
        }

        /**
         * Selects a key of a ConfigMap.
         */
        export interface AlertmanagerSpecContainersEnvValueFromConfigMapKeyRef {
            /**
             * The key to select.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the ConfigMap or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Selects a field of the pod: supports metadata.name, metadata.namespace, metadata.labels, metadata.annotations, spec.nodeName, spec.serviceAccountName, status.hostIP, status.podIP, status.podIPs.
         */
        export interface AlertmanagerSpecContainersEnvValueFromFieldRef {
            /**
             * Version of the schema the FieldPath is written in terms of, defaults to "v1".
             */
            apiVersion?: string;
            /**
             * Path of the field to select in the specified API version.
             */
            fieldPath: string;
        }

        /**
         * Selects a resource of the container: only resources limits and requests (limits.cpu, limits.memory, limits.ephemeral-storage, requests.cpu, requests.memory and requests.ephemeral-storage) are currently supported.
         */
        export interface AlertmanagerSpecContainersEnvValueFromResourceFieldRef {
            /**
             * Container name: required for volumes, optional for env vars
             */
            containerName?: string;
            /**
             * Specifies the output format of the exposed resources, defaults to "1"
             */
            divisor?: outputs.monitoring.v1.AlertmanagerSpecContainersEnvValueFromResourceFieldRefDivisor;
            /**
             * Required: resource to select
             */
            resource: string;
        }

        export interface AlertmanagerSpecContainersEnvValueFromResourceFieldRefDivisor {
        }

        /**
         * Selects a key of a secret in the pod's namespace
         */
        export interface AlertmanagerSpecContainersEnvValueFromSecretKeyRef {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Actions that the management system should take in response to container lifecycle events. Cannot be updated.
         */
        export interface AlertmanagerSpecContainersLifecycle {
            /**
             * PostStart is called immediately after a container is created. If the handler fails, the container is terminated and restarted according to its restart policy. Other management of the container blocks until the hook completes. More info: https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks/#container-hooks
             */
            postStart?: outputs.monitoring.v1.AlertmanagerSpecContainersLifecyclePostStart;
            /**
             * PreStop is called immediately before a container is terminated due to an API request or management event such as liveness/startup probe failure, preemption, resource contention, etc. The handler is not called if the container crashes or exits. The reason for termination is passed to the handler. The Pod's termination grace period countdown begins before the PreStop hooked is executed. Regardless of the outcome of the handler, the container will eventually terminate within the Pod's termination grace period. Other management of the container blocks until the hook completes or until the termination grace period is reached. More info: https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks/#container-hooks
             */
            preStop?: outputs.monitoring.v1.AlertmanagerSpecContainersLifecyclePreStop;
        }

        /**
         * PostStart is called immediately after a container is created. If the handler fails, the container is terminated and restarted according to its restart policy. Other management of the container blocks until the hook completes. More info: https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks/#container-hooks
         */
        export interface AlertmanagerSpecContainersLifecyclePostStart {
            /**
             * One and only one of the following should be specified. Exec specifies the action to take.
             */
            exec?: outputs.monitoring.v1.AlertmanagerSpecContainersLifecyclePostStartExec;
            /**
             * HTTPGet specifies the http request to perform.
             */
            httpGet?: outputs.monitoring.v1.AlertmanagerSpecContainersLifecyclePostStartHttpGet;
            /**
             * TCPSocket specifies an action involving a TCP port. TCP hooks not yet supported TODO: implement a realistic TCP lifecycle hook
             */
            tcpSocket?: outputs.monitoring.v1.AlertmanagerSpecContainersLifecyclePostStartTcpSocket;
        }

        /**
         * One and only one of the following should be specified. Exec specifies the action to take.
         */
        export interface AlertmanagerSpecContainersLifecyclePostStartExec {
            /**
             * Command is the command line to execute inside the container, the working directory for the command  is root ('/') in the container's filesystem. The command is simply exec'd, it is not run inside a shell, so traditional shell instructions ('|', etc) won't work. To use a shell, you need to explicitly call out to that shell. Exit status of 0 is treated as live/healthy and non-zero is unhealthy.
             */
            command?: string[];
        }

        /**
         * HTTPGet specifies the http request to perform.
         */
        export interface AlertmanagerSpecContainersLifecyclePostStartHttpGet {
            /**
             * Host name to connect to, defaults to the pod IP. You probably want to set "Host" in httpHeaders instead.
             */
            host?: string;
            /**
             * Custom headers to set in the request. HTTP allows repeated headers.
             */
            httpHeaders?: outputs.monitoring.v1.AlertmanagerSpecContainersLifecyclePostStartHttpGetHttpHeaders[];
            /**
             * Path to access on the HTTP server.
             */
            path?: string;
            /**
             * Name or number of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME.
             */
            port: outputs.monitoring.v1.AlertmanagerSpecContainersLifecyclePostStartHttpGetPort;
            /**
             * Scheme to use for connecting to the host. Defaults to HTTP.
             */
            scheme?: string;
        }

        /**
         * HTTPHeader describes a custom header to be used in HTTP probes
         */
        export interface AlertmanagerSpecContainersLifecyclePostStartHttpGetHttpHeaders {
            /**
             * The header field name
             */
            name: string;
            /**
             * The header field value
             */
            value: string;
        }

        export interface AlertmanagerSpecContainersLifecyclePostStartHttpGetPort {
        }

        /**
         * TCPSocket specifies an action involving a TCP port. TCP hooks not yet supported TODO: implement a realistic TCP lifecycle hook
         */
        export interface AlertmanagerSpecContainersLifecyclePostStartTcpSocket {
            /**
             * Optional: Host name to connect to, defaults to the pod IP.
             */
            host?: string;
            /**
             * Number or name of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME.
             */
            port: outputs.monitoring.v1.AlertmanagerSpecContainersLifecyclePostStartTcpSocketPort;
        }

        export interface AlertmanagerSpecContainersLifecyclePostStartTcpSocketPort {
        }

        /**
         * PreStop is called immediately before a container is terminated due to an API request or management event such as liveness/startup probe failure, preemption, resource contention, etc. The handler is not called if the container crashes or exits. The reason for termination is passed to the handler. The Pod's termination grace period countdown begins before the PreStop hooked is executed. Regardless of the outcome of the handler, the container will eventually terminate within the Pod's termination grace period. Other management of the container blocks until the hook completes or until the termination grace period is reached. More info: https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks/#container-hooks
         */
        export interface AlertmanagerSpecContainersLifecyclePreStop {
            /**
             * One and only one of the following should be specified. Exec specifies the action to take.
             */
            exec?: outputs.monitoring.v1.AlertmanagerSpecContainersLifecyclePreStopExec;
            /**
             * HTTPGet specifies the http request to perform.
             */
            httpGet?: outputs.monitoring.v1.AlertmanagerSpecContainersLifecyclePreStopHttpGet;
            /**
             * TCPSocket specifies an action involving a TCP port. TCP hooks not yet supported TODO: implement a realistic TCP lifecycle hook
             */
            tcpSocket?: outputs.monitoring.v1.AlertmanagerSpecContainersLifecyclePreStopTcpSocket;
        }

        /**
         * One and only one of the following should be specified. Exec specifies the action to take.
         */
        export interface AlertmanagerSpecContainersLifecyclePreStopExec {
            /**
             * Command is the command line to execute inside the container, the working directory for the command  is root ('/') in the container's filesystem. The command is simply exec'd, it is not run inside a shell, so traditional shell instructions ('|', etc) won't work. To use a shell, you need to explicitly call out to that shell. Exit status of 0 is treated as live/healthy and non-zero is unhealthy.
             */
            command?: string[];
        }

        /**
         * HTTPGet specifies the http request to perform.
         */
        export interface AlertmanagerSpecContainersLifecyclePreStopHttpGet {
            /**
             * Host name to connect to, defaults to the pod IP. You probably want to set "Host" in httpHeaders instead.
             */
            host?: string;
            /**
             * Custom headers to set in the request. HTTP allows repeated headers.
             */
            httpHeaders?: outputs.monitoring.v1.AlertmanagerSpecContainersLifecyclePreStopHttpGetHttpHeaders[];
            /**
             * Path to access on the HTTP server.
             */
            path?: string;
            /**
             * Name or number of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME.
             */
            port: outputs.monitoring.v1.AlertmanagerSpecContainersLifecyclePreStopHttpGetPort;
            /**
             * Scheme to use for connecting to the host. Defaults to HTTP.
             */
            scheme?: string;
        }

        /**
         * HTTPHeader describes a custom header to be used in HTTP probes
         */
        export interface AlertmanagerSpecContainersLifecyclePreStopHttpGetHttpHeaders {
            /**
             * The header field name
             */
            name: string;
            /**
             * The header field value
             */
            value: string;
        }

        export interface AlertmanagerSpecContainersLifecyclePreStopHttpGetPort {
        }

        /**
         * TCPSocket specifies an action involving a TCP port. TCP hooks not yet supported TODO: implement a realistic TCP lifecycle hook
         */
        export interface AlertmanagerSpecContainersLifecyclePreStopTcpSocket {
            /**
             * Optional: Host name to connect to, defaults to the pod IP.
             */
            host?: string;
            /**
             * Number or name of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME.
             */
            port: outputs.monitoring.v1.AlertmanagerSpecContainersLifecyclePreStopTcpSocketPort;
        }

        export interface AlertmanagerSpecContainersLifecyclePreStopTcpSocketPort {
        }

        /**
         * Periodic probe of container liveness. Container will be restarted if the probe fails. Cannot be updated. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
         */
        export interface AlertmanagerSpecContainersLivenessProbe {
            /**
             * One and only one of the following should be specified. Exec specifies the action to take.
             */
            exec?: outputs.monitoring.v1.AlertmanagerSpecContainersLivenessProbeExec;
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * HTTPGet specifies the http request to perform.
             */
            httpGet?: outputs.monitoring.v1.AlertmanagerSpecContainersLivenessProbeHttpGet;
            /**
             * Number of seconds after the container has started before liveness probes are initiated. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness and startup. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * TCPSocket specifies an action involving a TCP port. TCP hooks not yet supported TODO: implement a realistic TCP lifecycle hook
             */
            tcpSocket?: outputs.monitoring.v1.AlertmanagerSpecContainersLivenessProbeTcpSocket;
            /**
             * Number of seconds after which the probe times out. Defaults to 1 second. Minimum value is 1. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
             */
            timeoutSeconds?: number;
        }

        /**
         * One and only one of the following should be specified. Exec specifies the action to take.
         */
        export interface AlertmanagerSpecContainersLivenessProbeExec {
            /**
             * Command is the command line to execute inside the container, the working directory for the command  is root ('/') in the container's filesystem. The command is simply exec'd, it is not run inside a shell, so traditional shell instructions ('|', etc) won't work. To use a shell, you need to explicitly call out to that shell. Exit status of 0 is treated as live/healthy and non-zero is unhealthy.
             */
            command?: string[];
        }

        /**
         * HTTPGet specifies the http request to perform.
         */
        export interface AlertmanagerSpecContainersLivenessProbeHttpGet {
            /**
             * Host name to connect to, defaults to the pod IP. You probably want to set "Host" in httpHeaders instead.
             */
            host?: string;
            /**
             * Custom headers to set in the request. HTTP allows repeated headers.
             */
            httpHeaders?: outputs.monitoring.v1.AlertmanagerSpecContainersLivenessProbeHttpGetHttpHeaders[];
            /**
             * Path to access on the HTTP server.
             */
            path?: string;
            /**
             * Name or number of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME.
             */
            port: outputs.monitoring.v1.AlertmanagerSpecContainersLivenessProbeHttpGetPort;
            /**
             * Scheme to use for connecting to the host. Defaults to HTTP.
             */
            scheme?: string;
        }

        /**
         * HTTPHeader describes a custom header to be used in HTTP probes
         */
        export interface AlertmanagerSpecContainersLivenessProbeHttpGetHttpHeaders {
            /**
             * The header field name
             */
            name: string;
            /**
             * The header field value
             */
            value: string;
        }

        export interface AlertmanagerSpecContainersLivenessProbeHttpGetPort {
        }

        /**
         * TCPSocket specifies an action involving a TCP port. TCP hooks not yet supported TODO: implement a realistic TCP lifecycle hook
         */
        export interface AlertmanagerSpecContainersLivenessProbeTcpSocket {
            /**
             * Optional: Host name to connect to, defaults to the pod IP.
             */
            host?: string;
            /**
             * Number or name of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME.
             */
            port: outputs.monitoring.v1.AlertmanagerSpecContainersLivenessProbeTcpSocketPort;
        }

        export interface AlertmanagerSpecContainersLivenessProbeTcpSocketPort {
        }

        /**
         * ContainerPort represents a network port in a single container.
         */
        export interface AlertmanagerSpecContainersPorts {
            /**
             * Number of port to expose on the pod's IP address. This must be a valid port number, 0 < x < 65536.
             */
            containerPort: number;
            /**
             * What host IP to bind the external port to.
             */
            hostIP?: string;
            /**
             * Number of port to expose on the host. If specified, this must be a valid port number, 0 < x < 65536. If HostNetwork is specified, this must match ContainerPort. Most containers do not need this.
             */
            hostPort?: number;
            /**
             * If specified, this must be an IANA_SVC_NAME and unique within the pod. Each named port in a pod must have a unique name. Name for the port that can be referred to by services.
             */
            name?: string;
            /**
             * Protocol for port. Must be UDP, TCP, or SCTP. Defaults to "TCP".
             */
            protocol?: string;
        }

        /**
         * Periodic probe of container service readiness. Container will be removed from service endpoints if the probe fails. Cannot be updated. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
         */
        export interface AlertmanagerSpecContainersReadinessProbe {
            /**
             * One and only one of the following should be specified. Exec specifies the action to take.
             */
            exec?: outputs.monitoring.v1.AlertmanagerSpecContainersReadinessProbeExec;
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * HTTPGet specifies the http request to perform.
             */
            httpGet?: outputs.monitoring.v1.AlertmanagerSpecContainersReadinessProbeHttpGet;
            /**
             * Number of seconds after the container has started before liveness probes are initiated. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness and startup. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * TCPSocket specifies an action involving a TCP port. TCP hooks not yet supported TODO: implement a realistic TCP lifecycle hook
             */
            tcpSocket?: outputs.monitoring.v1.AlertmanagerSpecContainersReadinessProbeTcpSocket;
            /**
             * Number of seconds after which the probe times out. Defaults to 1 second. Minimum value is 1. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
             */
            timeoutSeconds?: number;
        }

        /**
         * One and only one of the following should be specified. Exec specifies the action to take.
         */
        export interface AlertmanagerSpecContainersReadinessProbeExec {
            /**
             * Command is the command line to execute inside the container, the working directory for the command  is root ('/') in the container's filesystem. The command is simply exec'd, it is not run inside a shell, so traditional shell instructions ('|', etc) won't work. To use a shell, you need to explicitly call out to that shell. Exit status of 0 is treated as live/healthy and non-zero is unhealthy.
             */
            command?: string[];
        }

        /**
         * HTTPGet specifies the http request to perform.
         */
        export interface AlertmanagerSpecContainersReadinessProbeHttpGet {
            /**
             * Host name to connect to, defaults to the pod IP. You probably want to set "Host" in httpHeaders instead.
             */
            host?: string;
            /**
             * Custom headers to set in the request. HTTP allows repeated headers.
             */
            httpHeaders?: outputs.monitoring.v1.AlertmanagerSpecContainersReadinessProbeHttpGetHttpHeaders[];
            /**
             * Path to access on the HTTP server.
             */
            path?: string;
            /**
             * Name or number of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME.
             */
            port: outputs.monitoring.v1.AlertmanagerSpecContainersReadinessProbeHttpGetPort;
            /**
             * Scheme to use for connecting to the host. Defaults to HTTP.
             */
            scheme?: string;
        }

        /**
         * HTTPHeader describes a custom header to be used in HTTP probes
         */
        export interface AlertmanagerSpecContainersReadinessProbeHttpGetHttpHeaders {
            /**
             * The header field name
             */
            name: string;
            /**
             * The header field value
             */
            value: string;
        }

        export interface AlertmanagerSpecContainersReadinessProbeHttpGetPort {
        }

        /**
         * TCPSocket specifies an action involving a TCP port. TCP hooks not yet supported TODO: implement a realistic TCP lifecycle hook
         */
        export interface AlertmanagerSpecContainersReadinessProbeTcpSocket {
            /**
             * Optional: Host name to connect to, defaults to the pod IP.
             */
            host?: string;
            /**
             * Number or name of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME.
             */
            port: outputs.monitoring.v1.AlertmanagerSpecContainersReadinessProbeTcpSocketPort;
        }

        export interface AlertmanagerSpecContainersReadinessProbeTcpSocketPort {
        }

        /**
         * Compute Resources required by this container. Cannot be updated. More info: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
         */
        export interface AlertmanagerSpecContainersResources {
            /**
             * Limits describes the maximum amount of compute resources allowed. More info: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
             */
            limits?: {[key: string]: outputs.monitoring.v1.AlertmanagerSpecContainersResourcesLimits};
            /**
             * Requests describes the minimum amount of compute resources required. If Requests is omitted for a container, it defaults to Limits if that is explicitly specified, otherwise to an implementation-defined value. More info: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
             */
            requests?: {[key: string]: outputs.monitoring.v1.AlertmanagerSpecContainersResourcesRequests};
        }

        export interface AlertmanagerSpecContainersResourcesLimits {
        }

        export interface AlertmanagerSpecContainersResourcesRequests {
        }

        /**
         * Security options the pod should run with. More info: https://kubernetes.io/docs/concepts/policy/security-context/ More info: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/
         */
        export interface AlertmanagerSpecContainersSecurityContext {
            /**
             * AllowPrivilegeEscalation controls whether a process can gain more privileges than its parent process. This bool directly controls if the no_new_privs flag will be set on the container process. AllowPrivilegeEscalation is true always when the container is: 1) run as Privileged 2) has CAP_SYS_ADMIN
             */
            allowPrivilegeEscalation?: boolean;
            /**
             * The capabilities to add/drop when running containers. Defaults to the default set of capabilities granted by the container runtime.
             */
            capabilities?: outputs.monitoring.v1.AlertmanagerSpecContainersSecurityContextCapabilities;
            /**
             * Run container in privileged mode. Processes in privileged containers are essentially equivalent to root on the host. Defaults to false.
             */
            privileged?: boolean;
            /**
             * procMount denotes the type of proc mount to use for the containers. The default is DefaultProcMount which uses the container runtime defaults for readonly paths and masked paths. This requires the ProcMountType feature flag to be enabled.
             */
            procMount?: string;
            /**
             * Whether this container has a read-only root filesystem. Default is false.
             */
            readOnlyRootFilesystem?: boolean;
            /**
             * The GID to run the entrypoint of the container process. Uses runtime default if unset. May also be set in PodSecurityContext.  If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.
             */
            runAsGroup?: number;
            /**
             * Indicates that the container must run as a non-root user. If true, the Kubelet will validate the image at runtime to ensure that it does not run as UID 0 (root) and fail to start the container if it does. If unset or false, no such validation will be performed. May also be set in PodSecurityContext.  If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.
             */
            runAsNonRoot?: boolean;
            /**
             * The UID to run the entrypoint of the container process. Defaults to user specified in image metadata if unspecified. May also be set in PodSecurityContext.  If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.
             */
            runAsUser?: number;
            /**
             * The SELinux context to be applied to the container. If unspecified, the container runtime will allocate a random SELinux context for each container.  May also be set in PodSecurityContext.  If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.
             */
            seLinuxOptions?: outputs.monitoring.v1.AlertmanagerSpecContainersSecurityContextSeLinuxOptions;
            /**
             * The Windows specific settings applied to all containers. If unspecified, the options from the PodSecurityContext will be used. If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.
             */
            windowsOptions?: outputs.monitoring.v1.AlertmanagerSpecContainersSecurityContextWindowsOptions;
        }

        /**
         * The capabilities to add/drop when running containers. Defaults to the default set of capabilities granted by the container runtime.
         */
        export interface AlertmanagerSpecContainersSecurityContextCapabilities {
            /**
             * Added capabilities
             */
            add?: string[];
            /**
             * Removed capabilities
             */
            drop?: string[];
        }

        /**
         * The SELinux context to be applied to the container. If unspecified, the container runtime will allocate a random SELinux context for each container.  May also be set in PodSecurityContext.  If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.
         */
        export interface AlertmanagerSpecContainersSecurityContextSeLinuxOptions {
            /**
             * Level is SELinux level label that applies to the container.
             */
            level?: string;
            /**
             * Role is a SELinux role label that applies to the container.
             */
            role?: string;
            /**
             * Type is a SELinux type label that applies to the container.
             */
            type?: string;
            /**
             * User is a SELinux user label that applies to the container.
             */
            user?: string;
        }

        /**
         * The Windows specific settings applied to all containers. If unspecified, the options from the PodSecurityContext will be used. If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.
         */
        export interface AlertmanagerSpecContainersSecurityContextWindowsOptions {
            /**
             * GMSACredentialSpec is where the GMSA admission webhook (https://github.com/kubernetes-sigs/windows-gmsa) inlines the contents of the GMSA credential spec named by the GMSACredentialSpecName field.
             */
            gmsaCredentialSpec?: string;
            /**
             * GMSACredentialSpecName is the name of the GMSA credential spec to use.
             */
            gmsaCredentialSpecName?: string;
            /**
             * The UserName in Windows to run the entrypoint of the container process. Defaults to the user specified in image metadata if unspecified. May also be set in PodSecurityContext. If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.
             */
            runAsUserName?: string;
        }

        /**
         * StartupProbe indicates that the Pod has successfully initialized. If specified, no other probes are executed until this completes successfully. If this probe fails, the Pod will be restarted, just as if the livenessProbe failed. This can be used to provide different probe parameters at the beginning of a Pod's lifecycle, when it might take a long time to load data or warm a cache, than during steady-state operation. This cannot be updated. This is a beta feature enabled by the StartupProbe feature flag. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
         */
        export interface AlertmanagerSpecContainersStartupProbe {
            /**
             * One and only one of the following should be specified. Exec specifies the action to take.
             */
            exec?: outputs.monitoring.v1.AlertmanagerSpecContainersStartupProbeExec;
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * HTTPGet specifies the http request to perform.
             */
            httpGet?: outputs.monitoring.v1.AlertmanagerSpecContainersStartupProbeHttpGet;
            /**
             * Number of seconds after the container has started before liveness probes are initiated. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness and startup. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * TCPSocket specifies an action involving a TCP port. TCP hooks not yet supported TODO: implement a realistic TCP lifecycle hook
             */
            tcpSocket?: outputs.monitoring.v1.AlertmanagerSpecContainersStartupProbeTcpSocket;
            /**
             * Number of seconds after which the probe times out. Defaults to 1 second. Minimum value is 1. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
             */
            timeoutSeconds?: number;
        }

        /**
         * One and only one of the following should be specified. Exec specifies the action to take.
         */
        export interface AlertmanagerSpecContainersStartupProbeExec {
            /**
             * Command is the command line to execute inside the container, the working directory for the command  is root ('/') in the container's filesystem. The command is simply exec'd, it is not run inside a shell, so traditional shell instructions ('|', etc) won't work. To use a shell, you need to explicitly call out to that shell. Exit status of 0 is treated as live/healthy and non-zero is unhealthy.
             */
            command?: string[];
        }

        /**
         * HTTPGet specifies the http request to perform.
         */
        export interface AlertmanagerSpecContainersStartupProbeHttpGet {
            /**
             * Host name to connect to, defaults to the pod IP. You probably want to set "Host" in httpHeaders instead.
             */
            host?: string;
            /**
             * Custom headers to set in the request. HTTP allows repeated headers.
             */
            httpHeaders?: outputs.monitoring.v1.AlertmanagerSpecContainersStartupProbeHttpGetHttpHeaders[];
            /**
             * Path to access on the HTTP server.
             */
            path?: string;
            /**
             * Name or number of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME.
             */
            port: outputs.monitoring.v1.AlertmanagerSpecContainersStartupProbeHttpGetPort;
            /**
             * Scheme to use for connecting to the host. Defaults to HTTP.
             */
            scheme?: string;
        }

        /**
         * HTTPHeader describes a custom header to be used in HTTP probes
         */
        export interface AlertmanagerSpecContainersStartupProbeHttpGetHttpHeaders {
            /**
             * The header field name
             */
            name: string;
            /**
             * The header field value
             */
            value: string;
        }

        export interface AlertmanagerSpecContainersStartupProbeHttpGetPort {
        }

        /**
         * TCPSocket specifies an action involving a TCP port. TCP hooks not yet supported TODO: implement a realistic TCP lifecycle hook
         */
        export interface AlertmanagerSpecContainersStartupProbeTcpSocket {
            /**
             * Optional: Host name to connect to, defaults to the pod IP.
             */
            host?: string;
            /**
             * Number or name of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME.
             */
            port: outputs.monitoring.v1.AlertmanagerSpecContainersStartupProbeTcpSocketPort;
        }

        export interface AlertmanagerSpecContainersStartupProbeTcpSocketPort {
        }

        /**
         * volumeDevice describes a mapping of a raw block device within a container.
         */
        export interface AlertmanagerSpecContainersVolumeDevices {
            /**
             * devicePath is the path inside of the container that the device will be mapped to.
             */
            devicePath: string;
            /**
             * name must match the name of a persistentVolumeClaim in the pod
             */
            name: string;
        }

        /**
         * VolumeMount describes a mounting of a Volume within a container.
         */
        export interface AlertmanagerSpecContainersVolumeMounts {
            /**
             * Path within the container at which the volume should be mounted.  Must not contain ':'.
             */
            mountPath: string;
            /**
             * mountPropagation determines how mounts are propagated from the host to container and the other way around. When not set, MountPropagationNone is used. This field is beta in 1.10.
             */
            mountPropagation?: string;
            /**
             * This must match the Name of a Volume.
             */
            name: string;
            /**
             * Mounted read-only if true, read-write otherwise (false or unspecified). Defaults to false.
             */
            readOnly?: boolean;
            /**
             * Path within the volume from which the container's volume should be mounted. Defaults to "" (volume's root).
             */
            subPath?: string;
            /**
             * Expanded path within the volume from which the container's volume should be mounted. Behaves similarly to SubPath but environment variable references $(VAR_NAME) are expanded using the container's environment. Defaults to "" (volume's root). SubPathExpr and SubPath are mutually exclusive.
             */
            subPathExpr?: string;
        }

        /**
         * LocalObjectReference contains enough information to let you locate the referenced object inside the same namespace.
         */
        export interface AlertmanagerSpecImagePullSecrets {
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
        }

        /**
         * A single application container that you want to run within a pod.
         */
        export interface AlertmanagerSpecInitContainers {
            /**
             * Arguments to the entrypoint. The docker image's CMD is used if this is not provided. Variable references $(VAR_NAME) are expanded using the container's environment. If a variable cannot be resolved, the reference in the input string will be unchanged. The $(VAR_NAME) syntax can be escaped with a double $$, ie: $$(VAR_NAME). Escaped references will never be expanded, regardless of whether the variable exists or not. Cannot be updated. More info: https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#running-a-command-in-a-shell
             */
            args?: string[];
            /**
             * Entrypoint array. Not executed within a shell. The docker image's ENTRYPOINT is used if this is not provided. Variable references $(VAR_NAME) are expanded using the container's environment. If a variable cannot be resolved, the reference in the input string will be unchanged. The $(VAR_NAME) syntax can be escaped with a double $$, ie: $$(VAR_NAME). Escaped references will never be expanded, regardless of whether the variable exists or not. Cannot be updated. More info: https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#running-a-command-in-a-shell
             */
            command?: string[];
            /**
             * List of environment variables to set in the container. Cannot be updated.
             */
            env?: outputs.monitoring.v1.AlertmanagerSpecInitContainersEnv[];
            /**
             * List of sources to populate environment variables in the container. The keys defined within a source must be a C_IDENTIFIER. All invalid keys will be reported as an event when the container is starting. When a key exists in multiple sources, the value associated with the last source will take precedence. Values defined by an Env with a duplicate key will take precedence. Cannot be updated.
             */
            envFrom?: outputs.monitoring.v1.AlertmanagerSpecInitContainersEnvFrom[];
            /**
             * Docker image name. More info: https://kubernetes.io/docs/concepts/containers/images This field is optional to allow higher level config management to default or override container images in workload controllers like Deployments and StatefulSets.
             */
            image?: string;
            /**
             * Image pull policy. One of Always, Never, IfNotPresent. Defaults to Always if :latest tag is specified, or IfNotPresent otherwise. Cannot be updated. More info: https://kubernetes.io/docs/concepts/containers/images#updating-images
             */
            imagePullPolicy?: string;
            /**
             * Actions that the management system should take in response to container lifecycle events. Cannot be updated.
             */
            lifecycle?: outputs.monitoring.v1.AlertmanagerSpecInitContainersLifecycle;
            /**
             * Periodic probe of container liveness. Container will be restarted if the probe fails. Cannot be updated. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
             */
            livenessProbe?: outputs.monitoring.v1.AlertmanagerSpecInitContainersLivenessProbe;
            /**
             * Name of the container specified as a DNS_LABEL. Each container in a pod must have a unique name (DNS_LABEL). Cannot be updated.
             */
            name: string;
            /**
             * List of ports to expose from the container. Exposing a port here gives the system additional information about the network connections a container uses, but is primarily informational. Not specifying a port here DOES NOT prevent that port from being exposed. Any port which is listening on the default "0.0.0.0" address inside a container will be accessible from the network. Cannot be updated.
             */
            ports?: outputs.monitoring.v1.AlertmanagerSpecInitContainersPorts[];
            /**
             * Periodic probe of container service readiness. Container will be removed from service endpoints if the probe fails. Cannot be updated. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
             */
            readinessProbe?: outputs.monitoring.v1.AlertmanagerSpecInitContainersReadinessProbe;
            /**
             * Compute Resources required by this container. Cannot be updated. More info: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
             */
            resources?: outputs.monitoring.v1.AlertmanagerSpecInitContainersResources;
            /**
             * Security options the pod should run with. More info: https://kubernetes.io/docs/concepts/policy/security-context/ More info: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/
             */
            securityContext?: outputs.monitoring.v1.AlertmanagerSpecInitContainersSecurityContext;
            /**
             * StartupProbe indicates that the Pod has successfully initialized. If specified, no other probes are executed until this completes successfully. If this probe fails, the Pod will be restarted, just as if the livenessProbe failed. This can be used to provide different probe parameters at the beginning of a Pod's lifecycle, when it might take a long time to load data or warm a cache, than during steady-state operation. This cannot be updated. This is a beta feature enabled by the StartupProbe feature flag. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
             */
            startupProbe?: outputs.monitoring.v1.AlertmanagerSpecInitContainersStartupProbe;
            /**
             * Whether this container should allocate a buffer for stdin in the container runtime. If this is not set, reads from stdin in the container will always result in EOF. Default is false.
             */
            stdin?: boolean;
            /**
             * Whether the container runtime should close the stdin channel after it has been opened by a single attach. When stdin is true the stdin stream will remain open across multiple attach sessions. If stdinOnce is set to true, stdin is opened on container start, is empty until the first client attaches to stdin, and then remains open and accepts data until the client disconnects, at which time stdin is closed and remains closed until the container is restarted. If this flag is false, a container processes that reads from stdin will never receive an EOF. Default is false
             */
            stdinOnce?: boolean;
            /**
             * Optional: Path at which the file to which the container's termination message will be written is mounted into the container's filesystem. Message written is intended to be brief final status, such as an assertion failure message. Will be truncated by the node if greater than 4096 bytes. The total message length across all containers will be limited to 12kb. Defaults to /dev/termination-log. Cannot be updated.
             */
            terminationMessagePath?: string;
            /**
             * Indicate how the termination message should be populated. File will use the contents of terminationMessagePath to populate the container status message on both success and failure. FallbackToLogsOnError will use the last chunk of container log output if the termination message file is empty and the container exited with an error. The log output is limited to 2048 bytes or 80 lines, whichever is smaller. Defaults to File. Cannot be updated.
             */
            terminationMessagePolicy?: string;
            /**
             * Whether this container should allocate a TTY for itself, also requires 'stdin' to be true. Default is false.
             */
            tty?: boolean;
            /**
             * volumeDevices is the list of block devices to be used by the container.
             */
            volumeDevices?: outputs.monitoring.v1.AlertmanagerSpecInitContainersVolumeDevices[];
            /**
             * Pod volumes to mount into the container's filesystem. Cannot be updated.
             */
            volumeMounts?: outputs.monitoring.v1.AlertmanagerSpecInitContainersVolumeMounts[];
            /**
             * Container's working directory. If not specified, the container runtime's default will be used, which might be configured in the container image. Cannot be updated.
             */
            workingDir?: string;
        }

        /**
         * EnvVar represents an environment variable present in a Container.
         */
        export interface AlertmanagerSpecInitContainersEnv {
            /**
             * Name of the environment variable. Must be a C_IDENTIFIER.
             */
            name: string;
            /**
             * Variable references $(VAR_NAME) are expanded using the previous defined environment variables in the container and any service environment variables. If a variable cannot be resolved, the reference in the input string will be unchanged. The $(VAR_NAME) syntax can be escaped with a double $$, ie: $$(VAR_NAME). Escaped references will never be expanded, regardless of whether the variable exists or not. Defaults to "".
             */
            value?: string;
            /**
             * Source for the environment variable's value. Cannot be used if value is not empty.
             */
            valueFrom?: outputs.monitoring.v1.AlertmanagerSpecInitContainersEnvValueFrom;
        }

        /**
         * EnvFromSource represents the source of a set of ConfigMaps
         */
        export interface AlertmanagerSpecInitContainersEnvFrom {
            /**
             * The ConfigMap to select from
             */
            configMapRef?: outputs.monitoring.v1.AlertmanagerSpecInitContainersEnvFromConfigMapRef;
            /**
             * An optional identifier to prepend to each key in the ConfigMap. Must be a C_IDENTIFIER.
             */
            prefix?: string;
            /**
             * The Secret to select from
             */
            secretRef?: outputs.monitoring.v1.AlertmanagerSpecInitContainersEnvFromSecretRef;
        }

        /**
         * The ConfigMap to select from
         */
        export interface AlertmanagerSpecInitContainersEnvFromConfigMapRef {
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the ConfigMap must be defined
             */
            optional?: boolean;
        }

        /**
         * The Secret to select from
         */
        export interface AlertmanagerSpecInitContainersEnvFromSecretRef {
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret must be defined
             */
            optional?: boolean;
        }

        /**
         * Source for the environment variable's value. Cannot be used if value is not empty.
         */
        export interface AlertmanagerSpecInitContainersEnvValueFrom {
            /**
             * Selects a key of a ConfigMap.
             */
            configMapKeyRef?: outputs.monitoring.v1.AlertmanagerSpecInitContainersEnvValueFromConfigMapKeyRef;
            /**
             * Selects a field of the pod: supports metadata.name, metadata.namespace, metadata.labels, metadata.annotations, spec.nodeName, spec.serviceAccountName, status.hostIP, status.podIP, status.podIPs.
             */
            fieldRef?: outputs.monitoring.v1.AlertmanagerSpecInitContainersEnvValueFromFieldRef;
            /**
             * Selects a resource of the container: only resources limits and requests (limits.cpu, limits.memory, limits.ephemeral-storage, requests.cpu, requests.memory and requests.ephemeral-storage) are currently supported.
             */
            resourceFieldRef?: outputs.monitoring.v1.AlertmanagerSpecInitContainersEnvValueFromResourceFieldRef;
            /**
             * Selects a key of a secret in the pod's namespace
             */
            secretKeyRef?: outputs.monitoring.v1.AlertmanagerSpecInitContainersEnvValueFromSecretKeyRef;
        }

        /**
         * Selects a key of a ConfigMap.
         */
        export interface AlertmanagerSpecInitContainersEnvValueFromConfigMapKeyRef {
            /**
             * The key to select.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the ConfigMap or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Selects a field of the pod: supports metadata.name, metadata.namespace, metadata.labels, metadata.annotations, spec.nodeName, spec.serviceAccountName, status.hostIP, status.podIP, status.podIPs.
         */
        export interface AlertmanagerSpecInitContainersEnvValueFromFieldRef {
            /**
             * Version of the schema the FieldPath is written in terms of, defaults to "v1".
             */
            apiVersion?: string;
            /**
             * Path of the field to select in the specified API version.
             */
            fieldPath: string;
        }

        /**
         * Selects a resource of the container: only resources limits and requests (limits.cpu, limits.memory, limits.ephemeral-storage, requests.cpu, requests.memory and requests.ephemeral-storage) are currently supported.
         */
        export interface AlertmanagerSpecInitContainersEnvValueFromResourceFieldRef {
            /**
             * Container name: required for volumes, optional for env vars
             */
            containerName?: string;
            /**
             * Specifies the output format of the exposed resources, defaults to "1"
             */
            divisor?: outputs.monitoring.v1.AlertmanagerSpecInitContainersEnvValueFromResourceFieldRefDivisor;
            /**
             * Required: resource to select
             */
            resource: string;
        }

        export interface AlertmanagerSpecInitContainersEnvValueFromResourceFieldRefDivisor {
        }

        /**
         * Selects a key of a secret in the pod's namespace
         */
        export interface AlertmanagerSpecInitContainersEnvValueFromSecretKeyRef {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Actions that the management system should take in response to container lifecycle events. Cannot be updated.
         */
        export interface AlertmanagerSpecInitContainersLifecycle {
            /**
             * PostStart is called immediately after a container is created. If the handler fails, the container is terminated and restarted according to its restart policy. Other management of the container blocks until the hook completes. More info: https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks/#container-hooks
             */
            postStart?: outputs.monitoring.v1.AlertmanagerSpecInitContainersLifecyclePostStart;
            /**
             * PreStop is called immediately before a container is terminated due to an API request or management event such as liveness/startup probe failure, preemption, resource contention, etc. The handler is not called if the container crashes or exits. The reason for termination is passed to the handler. The Pod's termination grace period countdown begins before the PreStop hooked is executed. Regardless of the outcome of the handler, the container will eventually terminate within the Pod's termination grace period. Other management of the container blocks until the hook completes or until the termination grace period is reached. More info: https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks/#container-hooks
             */
            preStop?: outputs.monitoring.v1.AlertmanagerSpecInitContainersLifecyclePreStop;
        }

        /**
         * PostStart is called immediately after a container is created. If the handler fails, the container is terminated and restarted according to its restart policy. Other management of the container blocks until the hook completes. More info: https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks/#container-hooks
         */
        export interface AlertmanagerSpecInitContainersLifecyclePostStart {
            /**
             * One and only one of the following should be specified. Exec specifies the action to take.
             */
            exec?: outputs.monitoring.v1.AlertmanagerSpecInitContainersLifecyclePostStartExec;
            /**
             * HTTPGet specifies the http request to perform.
             */
            httpGet?: outputs.monitoring.v1.AlertmanagerSpecInitContainersLifecyclePostStartHttpGet;
            /**
             * TCPSocket specifies an action involving a TCP port. TCP hooks not yet supported TODO: implement a realistic TCP lifecycle hook
             */
            tcpSocket?: outputs.monitoring.v1.AlertmanagerSpecInitContainersLifecyclePostStartTcpSocket;
        }

        /**
         * One and only one of the following should be specified. Exec specifies the action to take.
         */
        export interface AlertmanagerSpecInitContainersLifecyclePostStartExec {
            /**
             * Command is the command line to execute inside the container, the working directory for the command  is root ('/') in the container's filesystem. The command is simply exec'd, it is not run inside a shell, so traditional shell instructions ('|', etc) won't work. To use a shell, you need to explicitly call out to that shell. Exit status of 0 is treated as live/healthy and non-zero is unhealthy.
             */
            command?: string[];
        }

        /**
         * HTTPGet specifies the http request to perform.
         */
        export interface AlertmanagerSpecInitContainersLifecyclePostStartHttpGet {
            /**
             * Host name to connect to, defaults to the pod IP. You probably want to set "Host" in httpHeaders instead.
             */
            host?: string;
            /**
             * Custom headers to set in the request. HTTP allows repeated headers.
             */
            httpHeaders?: outputs.monitoring.v1.AlertmanagerSpecInitContainersLifecyclePostStartHttpGetHttpHeaders[];
            /**
             * Path to access on the HTTP server.
             */
            path?: string;
            /**
             * Name or number of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME.
             */
            port: outputs.monitoring.v1.AlertmanagerSpecInitContainersLifecyclePostStartHttpGetPort;
            /**
             * Scheme to use for connecting to the host. Defaults to HTTP.
             */
            scheme?: string;
        }

        /**
         * HTTPHeader describes a custom header to be used in HTTP probes
         */
        export interface AlertmanagerSpecInitContainersLifecyclePostStartHttpGetHttpHeaders {
            /**
             * The header field name
             */
            name: string;
            /**
             * The header field value
             */
            value: string;
        }

        export interface AlertmanagerSpecInitContainersLifecyclePostStartHttpGetPort {
        }

        /**
         * TCPSocket specifies an action involving a TCP port. TCP hooks not yet supported TODO: implement a realistic TCP lifecycle hook
         */
        export interface AlertmanagerSpecInitContainersLifecyclePostStartTcpSocket {
            /**
             * Optional: Host name to connect to, defaults to the pod IP.
             */
            host?: string;
            /**
             * Number or name of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME.
             */
            port: outputs.monitoring.v1.AlertmanagerSpecInitContainersLifecyclePostStartTcpSocketPort;
        }

        export interface AlertmanagerSpecInitContainersLifecyclePostStartTcpSocketPort {
        }

        /**
         * PreStop is called immediately before a container is terminated due to an API request or management event such as liveness/startup probe failure, preemption, resource contention, etc. The handler is not called if the container crashes or exits. The reason for termination is passed to the handler. The Pod's termination grace period countdown begins before the PreStop hooked is executed. Regardless of the outcome of the handler, the container will eventually terminate within the Pod's termination grace period. Other management of the container blocks until the hook completes or until the termination grace period is reached. More info: https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks/#container-hooks
         */
        export interface AlertmanagerSpecInitContainersLifecyclePreStop {
            /**
             * One and only one of the following should be specified. Exec specifies the action to take.
             */
            exec?: outputs.monitoring.v1.AlertmanagerSpecInitContainersLifecyclePreStopExec;
            /**
             * HTTPGet specifies the http request to perform.
             */
            httpGet?: outputs.monitoring.v1.AlertmanagerSpecInitContainersLifecyclePreStopHttpGet;
            /**
             * TCPSocket specifies an action involving a TCP port. TCP hooks not yet supported TODO: implement a realistic TCP lifecycle hook
             */
            tcpSocket?: outputs.monitoring.v1.AlertmanagerSpecInitContainersLifecyclePreStopTcpSocket;
        }

        /**
         * One and only one of the following should be specified. Exec specifies the action to take.
         */
        export interface AlertmanagerSpecInitContainersLifecyclePreStopExec {
            /**
             * Command is the command line to execute inside the container, the working directory for the command  is root ('/') in the container's filesystem. The command is simply exec'd, it is not run inside a shell, so traditional shell instructions ('|', etc) won't work. To use a shell, you need to explicitly call out to that shell. Exit status of 0 is treated as live/healthy and non-zero is unhealthy.
             */
            command?: string[];
        }

        /**
         * HTTPGet specifies the http request to perform.
         */
        export interface AlertmanagerSpecInitContainersLifecyclePreStopHttpGet {
            /**
             * Host name to connect to, defaults to the pod IP. You probably want to set "Host" in httpHeaders instead.
             */
            host?: string;
            /**
             * Custom headers to set in the request. HTTP allows repeated headers.
             */
            httpHeaders?: outputs.monitoring.v1.AlertmanagerSpecInitContainersLifecyclePreStopHttpGetHttpHeaders[];
            /**
             * Path to access on the HTTP server.
             */
            path?: string;
            /**
             * Name or number of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME.
             */
            port: outputs.monitoring.v1.AlertmanagerSpecInitContainersLifecyclePreStopHttpGetPort;
            /**
             * Scheme to use for connecting to the host. Defaults to HTTP.
             */
            scheme?: string;
        }

        /**
         * HTTPHeader describes a custom header to be used in HTTP probes
         */
        export interface AlertmanagerSpecInitContainersLifecyclePreStopHttpGetHttpHeaders {
            /**
             * The header field name
             */
            name: string;
            /**
             * The header field value
             */
            value: string;
        }

        export interface AlertmanagerSpecInitContainersLifecyclePreStopHttpGetPort {
        }

        /**
         * TCPSocket specifies an action involving a TCP port. TCP hooks not yet supported TODO: implement a realistic TCP lifecycle hook
         */
        export interface AlertmanagerSpecInitContainersLifecyclePreStopTcpSocket {
            /**
             * Optional: Host name to connect to, defaults to the pod IP.
             */
            host?: string;
            /**
             * Number or name of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME.
             */
            port: outputs.monitoring.v1.AlertmanagerSpecInitContainersLifecyclePreStopTcpSocketPort;
        }

        export interface AlertmanagerSpecInitContainersLifecyclePreStopTcpSocketPort {
        }

        /**
         * Periodic probe of container liveness. Container will be restarted if the probe fails. Cannot be updated. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
         */
        export interface AlertmanagerSpecInitContainersLivenessProbe {
            /**
             * One and only one of the following should be specified. Exec specifies the action to take.
             */
            exec?: outputs.monitoring.v1.AlertmanagerSpecInitContainersLivenessProbeExec;
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * HTTPGet specifies the http request to perform.
             */
            httpGet?: outputs.monitoring.v1.AlertmanagerSpecInitContainersLivenessProbeHttpGet;
            /**
             * Number of seconds after the container has started before liveness probes are initiated. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness and startup. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * TCPSocket specifies an action involving a TCP port. TCP hooks not yet supported TODO: implement a realistic TCP lifecycle hook
             */
            tcpSocket?: outputs.monitoring.v1.AlertmanagerSpecInitContainersLivenessProbeTcpSocket;
            /**
             * Number of seconds after which the probe times out. Defaults to 1 second. Minimum value is 1. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
             */
            timeoutSeconds?: number;
        }

        /**
         * One and only one of the following should be specified. Exec specifies the action to take.
         */
        export interface AlertmanagerSpecInitContainersLivenessProbeExec {
            /**
             * Command is the command line to execute inside the container, the working directory for the command  is root ('/') in the container's filesystem. The command is simply exec'd, it is not run inside a shell, so traditional shell instructions ('|', etc) won't work. To use a shell, you need to explicitly call out to that shell. Exit status of 0 is treated as live/healthy and non-zero is unhealthy.
             */
            command?: string[];
        }

        /**
         * HTTPGet specifies the http request to perform.
         */
        export interface AlertmanagerSpecInitContainersLivenessProbeHttpGet {
            /**
             * Host name to connect to, defaults to the pod IP. You probably want to set "Host" in httpHeaders instead.
             */
            host?: string;
            /**
             * Custom headers to set in the request. HTTP allows repeated headers.
             */
            httpHeaders?: outputs.monitoring.v1.AlertmanagerSpecInitContainersLivenessProbeHttpGetHttpHeaders[];
            /**
             * Path to access on the HTTP server.
             */
            path?: string;
            /**
             * Name or number of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME.
             */
            port: outputs.monitoring.v1.AlertmanagerSpecInitContainersLivenessProbeHttpGetPort;
            /**
             * Scheme to use for connecting to the host. Defaults to HTTP.
             */
            scheme?: string;
        }

        /**
         * HTTPHeader describes a custom header to be used in HTTP probes
         */
        export interface AlertmanagerSpecInitContainersLivenessProbeHttpGetHttpHeaders {
            /**
             * The header field name
             */
            name: string;
            /**
             * The header field value
             */
            value: string;
        }

        export interface AlertmanagerSpecInitContainersLivenessProbeHttpGetPort {
        }

        /**
         * TCPSocket specifies an action involving a TCP port. TCP hooks not yet supported TODO: implement a realistic TCP lifecycle hook
         */
        export interface AlertmanagerSpecInitContainersLivenessProbeTcpSocket {
            /**
             * Optional: Host name to connect to, defaults to the pod IP.
             */
            host?: string;
            /**
             * Number or name of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME.
             */
            port: outputs.monitoring.v1.AlertmanagerSpecInitContainersLivenessProbeTcpSocketPort;
        }

        export interface AlertmanagerSpecInitContainersLivenessProbeTcpSocketPort {
        }

        /**
         * ContainerPort represents a network port in a single container.
         */
        export interface AlertmanagerSpecInitContainersPorts {
            /**
             * Number of port to expose on the pod's IP address. This must be a valid port number, 0 < x < 65536.
             */
            containerPort: number;
            /**
             * What host IP to bind the external port to.
             */
            hostIP?: string;
            /**
             * Number of port to expose on the host. If specified, this must be a valid port number, 0 < x < 65536. If HostNetwork is specified, this must match ContainerPort. Most containers do not need this.
             */
            hostPort?: number;
            /**
             * If specified, this must be an IANA_SVC_NAME and unique within the pod. Each named port in a pod must have a unique name. Name for the port that can be referred to by services.
             */
            name?: string;
            /**
             * Protocol for port. Must be UDP, TCP, or SCTP. Defaults to "TCP".
             */
            protocol?: string;
        }

        /**
         * Periodic probe of container service readiness. Container will be removed from service endpoints if the probe fails. Cannot be updated. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
         */
        export interface AlertmanagerSpecInitContainersReadinessProbe {
            /**
             * One and only one of the following should be specified. Exec specifies the action to take.
             */
            exec?: outputs.monitoring.v1.AlertmanagerSpecInitContainersReadinessProbeExec;
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * HTTPGet specifies the http request to perform.
             */
            httpGet?: outputs.monitoring.v1.AlertmanagerSpecInitContainersReadinessProbeHttpGet;
            /**
             * Number of seconds after the container has started before liveness probes are initiated. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness and startup. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * TCPSocket specifies an action involving a TCP port. TCP hooks not yet supported TODO: implement a realistic TCP lifecycle hook
             */
            tcpSocket?: outputs.monitoring.v1.AlertmanagerSpecInitContainersReadinessProbeTcpSocket;
            /**
             * Number of seconds after which the probe times out. Defaults to 1 second. Minimum value is 1. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
             */
            timeoutSeconds?: number;
        }

        /**
         * One and only one of the following should be specified. Exec specifies the action to take.
         */
        export interface AlertmanagerSpecInitContainersReadinessProbeExec {
            /**
             * Command is the command line to execute inside the container, the working directory for the command  is root ('/') in the container's filesystem. The command is simply exec'd, it is not run inside a shell, so traditional shell instructions ('|', etc) won't work. To use a shell, you need to explicitly call out to that shell. Exit status of 0 is treated as live/healthy and non-zero is unhealthy.
             */
            command?: string[];
        }

        /**
         * HTTPGet specifies the http request to perform.
         */
        export interface AlertmanagerSpecInitContainersReadinessProbeHttpGet {
            /**
             * Host name to connect to, defaults to the pod IP. You probably want to set "Host" in httpHeaders instead.
             */
            host?: string;
            /**
             * Custom headers to set in the request. HTTP allows repeated headers.
             */
            httpHeaders?: outputs.monitoring.v1.AlertmanagerSpecInitContainersReadinessProbeHttpGetHttpHeaders[];
            /**
             * Path to access on the HTTP server.
             */
            path?: string;
            /**
             * Name or number of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME.
             */
            port: outputs.monitoring.v1.AlertmanagerSpecInitContainersReadinessProbeHttpGetPort;
            /**
             * Scheme to use for connecting to the host. Defaults to HTTP.
             */
            scheme?: string;
        }

        /**
         * HTTPHeader describes a custom header to be used in HTTP probes
         */
        export interface AlertmanagerSpecInitContainersReadinessProbeHttpGetHttpHeaders {
            /**
             * The header field name
             */
            name: string;
            /**
             * The header field value
             */
            value: string;
        }

        export interface AlertmanagerSpecInitContainersReadinessProbeHttpGetPort {
        }

        /**
         * TCPSocket specifies an action involving a TCP port. TCP hooks not yet supported TODO: implement a realistic TCP lifecycle hook
         */
        export interface AlertmanagerSpecInitContainersReadinessProbeTcpSocket {
            /**
             * Optional: Host name to connect to, defaults to the pod IP.
             */
            host?: string;
            /**
             * Number or name of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME.
             */
            port: outputs.monitoring.v1.AlertmanagerSpecInitContainersReadinessProbeTcpSocketPort;
        }

        export interface AlertmanagerSpecInitContainersReadinessProbeTcpSocketPort {
        }

        /**
         * Compute Resources required by this container. Cannot be updated. More info: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
         */
        export interface AlertmanagerSpecInitContainersResources {
            /**
             * Limits describes the maximum amount of compute resources allowed. More info: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
             */
            limits?: {[key: string]: outputs.monitoring.v1.AlertmanagerSpecInitContainersResourcesLimits};
            /**
             * Requests describes the minimum amount of compute resources required. If Requests is omitted for a container, it defaults to Limits if that is explicitly specified, otherwise to an implementation-defined value. More info: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
             */
            requests?: {[key: string]: outputs.monitoring.v1.AlertmanagerSpecInitContainersResourcesRequests};
        }

        export interface AlertmanagerSpecInitContainersResourcesLimits {
        }

        export interface AlertmanagerSpecInitContainersResourcesRequests {
        }

        /**
         * Security options the pod should run with. More info: https://kubernetes.io/docs/concepts/policy/security-context/ More info: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/
         */
        export interface AlertmanagerSpecInitContainersSecurityContext {
            /**
             * AllowPrivilegeEscalation controls whether a process can gain more privileges than its parent process. This bool directly controls if the no_new_privs flag will be set on the container process. AllowPrivilegeEscalation is true always when the container is: 1) run as Privileged 2) has CAP_SYS_ADMIN
             */
            allowPrivilegeEscalation?: boolean;
            /**
             * The capabilities to add/drop when running containers. Defaults to the default set of capabilities granted by the container runtime.
             */
            capabilities?: outputs.monitoring.v1.AlertmanagerSpecInitContainersSecurityContextCapabilities;
            /**
             * Run container in privileged mode. Processes in privileged containers are essentially equivalent to root on the host. Defaults to false.
             */
            privileged?: boolean;
            /**
             * procMount denotes the type of proc mount to use for the containers. The default is DefaultProcMount which uses the container runtime defaults for readonly paths and masked paths. This requires the ProcMountType feature flag to be enabled.
             */
            procMount?: string;
            /**
             * Whether this container has a read-only root filesystem. Default is false.
             */
            readOnlyRootFilesystem?: boolean;
            /**
             * The GID to run the entrypoint of the container process. Uses runtime default if unset. May also be set in PodSecurityContext.  If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.
             */
            runAsGroup?: number;
            /**
             * Indicates that the container must run as a non-root user. If true, the Kubelet will validate the image at runtime to ensure that it does not run as UID 0 (root) and fail to start the container if it does. If unset or false, no such validation will be performed. May also be set in PodSecurityContext.  If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.
             */
            runAsNonRoot?: boolean;
            /**
             * The UID to run the entrypoint of the container process. Defaults to user specified in image metadata if unspecified. May also be set in PodSecurityContext.  If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.
             */
            runAsUser?: number;
            /**
             * The SELinux context to be applied to the container. If unspecified, the container runtime will allocate a random SELinux context for each container.  May also be set in PodSecurityContext.  If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.
             */
            seLinuxOptions?: outputs.monitoring.v1.AlertmanagerSpecInitContainersSecurityContextSeLinuxOptions;
            /**
             * The Windows specific settings applied to all containers. If unspecified, the options from the PodSecurityContext will be used. If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.
             */
            windowsOptions?: outputs.monitoring.v1.AlertmanagerSpecInitContainersSecurityContextWindowsOptions;
        }

        /**
         * The capabilities to add/drop when running containers. Defaults to the default set of capabilities granted by the container runtime.
         */
        export interface AlertmanagerSpecInitContainersSecurityContextCapabilities {
            /**
             * Added capabilities
             */
            add?: string[];
            /**
             * Removed capabilities
             */
            drop?: string[];
        }

        /**
         * The SELinux context to be applied to the container. If unspecified, the container runtime will allocate a random SELinux context for each container.  May also be set in PodSecurityContext.  If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.
         */
        export interface AlertmanagerSpecInitContainersSecurityContextSeLinuxOptions {
            /**
             * Level is SELinux level label that applies to the container.
             */
            level?: string;
            /**
             * Role is a SELinux role label that applies to the container.
             */
            role?: string;
            /**
             * Type is a SELinux type label that applies to the container.
             */
            type?: string;
            /**
             * User is a SELinux user label that applies to the container.
             */
            user?: string;
        }

        /**
         * The Windows specific settings applied to all containers. If unspecified, the options from the PodSecurityContext will be used. If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.
         */
        export interface AlertmanagerSpecInitContainersSecurityContextWindowsOptions {
            /**
             * GMSACredentialSpec is where the GMSA admission webhook (https://github.com/kubernetes-sigs/windows-gmsa) inlines the contents of the GMSA credential spec named by the GMSACredentialSpecName field.
             */
            gmsaCredentialSpec?: string;
            /**
             * GMSACredentialSpecName is the name of the GMSA credential spec to use.
             */
            gmsaCredentialSpecName?: string;
            /**
             * The UserName in Windows to run the entrypoint of the container process. Defaults to the user specified in image metadata if unspecified. May also be set in PodSecurityContext. If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.
             */
            runAsUserName?: string;
        }

        /**
         * StartupProbe indicates that the Pod has successfully initialized. If specified, no other probes are executed until this completes successfully. If this probe fails, the Pod will be restarted, just as if the livenessProbe failed. This can be used to provide different probe parameters at the beginning of a Pod's lifecycle, when it might take a long time to load data or warm a cache, than during steady-state operation. This cannot be updated. This is a beta feature enabled by the StartupProbe feature flag. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
         */
        export interface AlertmanagerSpecInitContainersStartupProbe {
            /**
             * One and only one of the following should be specified. Exec specifies the action to take.
             */
            exec?: outputs.monitoring.v1.AlertmanagerSpecInitContainersStartupProbeExec;
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * HTTPGet specifies the http request to perform.
             */
            httpGet?: outputs.monitoring.v1.AlertmanagerSpecInitContainersStartupProbeHttpGet;
            /**
             * Number of seconds after the container has started before liveness probes are initiated. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness and startup. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * TCPSocket specifies an action involving a TCP port. TCP hooks not yet supported TODO: implement a realistic TCP lifecycle hook
             */
            tcpSocket?: outputs.monitoring.v1.AlertmanagerSpecInitContainersStartupProbeTcpSocket;
            /**
             * Number of seconds after which the probe times out. Defaults to 1 second. Minimum value is 1. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
             */
            timeoutSeconds?: number;
        }

        /**
         * One and only one of the following should be specified. Exec specifies the action to take.
         */
        export interface AlertmanagerSpecInitContainersStartupProbeExec {
            /**
             * Command is the command line to execute inside the container, the working directory for the command  is root ('/') in the container's filesystem. The command is simply exec'd, it is not run inside a shell, so traditional shell instructions ('|', etc) won't work. To use a shell, you need to explicitly call out to that shell. Exit status of 0 is treated as live/healthy and non-zero is unhealthy.
             */
            command?: string[];
        }

        /**
         * HTTPGet specifies the http request to perform.
         */
        export interface AlertmanagerSpecInitContainersStartupProbeHttpGet {
            /**
             * Host name to connect to, defaults to the pod IP. You probably want to set "Host" in httpHeaders instead.
             */
            host?: string;
            /**
             * Custom headers to set in the request. HTTP allows repeated headers.
             */
            httpHeaders?: outputs.monitoring.v1.AlertmanagerSpecInitContainersStartupProbeHttpGetHttpHeaders[];
            /**
             * Path to access on the HTTP server.
             */
            path?: string;
            /**
             * Name or number of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME.
             */
            port: outputs.monitoring.v1.AlertmanagerSpecInitContainersStartupProbeHttpGetPort;
            /**
             * Scheme to use for connecting to the host. Defaults to HTTP.
             */
            scheme?: string;
        }

        /**
         * HTTPHeader describes a custom header to be used in HTTP probes
         */
        export interface AlertmanagerSpecInitContainersStartupProbeHttpGetHttpHeaders {
            /**
             * The header field name
             */
            name: string;
            /**
             * The header field value
             */
            value: string;
        }

        export interface AlertmanagerSpecInitContainersStartupProbeHttpGetPort {
        }

        /**
         * TCPSocket specifies an action involving a TCP port. TCP hooks not yet supported TODO: implement a realistic TCP lifecycle hook
         */
        export interface AlertmanagerSpecInitContainersStartupProbeTcpSocket {
            /**
             * Optional: Host name to connect to, defaults to the pod IP.
             */
            host?: string;
            /**
             * Number or name of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME.
             */
            port: outputs.monitoring.v1.AlertmanagerSpecInitContainersStartupProbeTcpSocketPort;
        }

        export interface AlertmanagerSpecInitContainersStartupProbeTcpSocketPort {
        }

        /**
         * volumeDevice describes a mapping of a raw block device within a container.
         */
        export interface AlertmanagerSpecInitContainersVolumeDevices {
            /**
             * devicePath is the path inside of the container that the device will be mapped to.
             */
            devicePath: string;
            /**
             * name must match the name of a persistentVolumeClaim in the pod
             */
            name: string;
        }

        /**
         * VolumeMount describes a mounting of a Volume within a container.
         */
        export interface AlertmanagerSpecInitContainersVolumeMounts {
            /**
             * Path within the container at which the volume should be mounted.  Must not contain ':'.
             */
            mountPath: string;
            /**
             * mountPropagation determines how mounts are propagated from the host to container and the other way around. When not set, MountPropagationNone is used. This field is beta in 1.10.
             */
            mountPropagation?: string;
            /**
             * This must match the Name of a Volume.
             */
            name: string;
            /**
             * Mounted read-only if true, read-write otherwise (false or unspecified). Defaults to false.
             */
            readOnly?: boolean;
            /**
             * Path within the volume from which the container's volume should be mounted. Defaults to "" (volume's root).
             */
            subPath?: string;
            /**
             * Expanded path within the volume from which the container's volume should be mounted. Behaves similarly to SubPath but environment variable references $(VAR_NAME) are expanded using the container's environment. Defaults to "" (volume's root). SubPathExpr and SubPath are mutually exclusive.
             */
            subPathExpr?: string;
        }

        /**
         * PodMetadata configures Labels and Annotations which are propagated to the alertmanager pods.
         */
        export interface AlertmanagerSpecPodMetadata {
            /**
             * Annotations is an unstructured key value map stored with a resource that may be set by external tools to store and retrieve arbitrary metadata. They are not queryable and should be preserved when modifying objects. More info: http://kubernetes.io/docs/user-guide/annotations
             */
            annotations?: {[key: string]: string};
            /**
             * Map of string keys and values that can be used to organize and categorize (scope and select) objects. May match selectors of replication controllers and services. More info: http://kubernetes.io/docs/user-guide/labels
             */
            labels?: {[key: string]: string};
            /**
             * Name must be unique within a namespace. Is required when creating resources, although some resources may allow a client to request the generation of an appropriate name automatically. Name is primarily intended for creation idempotence and configuration definition. Cannot be updated. More info: http://kubernetes.io/docs/user-guide/identifiers#names
             */
            name?: string;
        }

        /**
         * Define resources requests and limits for single Pods.
         */
        export interface AlertmanagerSpecResources {
            /**
             * Limits describes the maximum amount of compute resources allowed. More info: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
             */
            limits?: {[key: string]: outputs.monitoring.v1.AlertmanagerSpecResourcesLimits};
            /**
             * Requests describes the minimum amount of compute resources required. If Requests is omitted for a container, it defaults to Limits if that is explicitly specified, otherwise to an implementation-defined value. More info: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
             */
            requests?: {[key: string]: outputs.monitoring.v1.AlertmanagerSpecResourcesRequests};
        }

        export interface AlertmanagerSpecResourcesLimits {
        }

        export interface AlertmanagerSpecResourcesRequests {
        }

        /**
         * SecurityContext holds pod-level security attributes and common container settings. This defaults to the default PodSecurityContext.
         */
        export interface AlertmanagerSpecSecurityContext {
            /**
             * A special supplemental group that applies to all containers in a pod. Some volume types allow the Kubelet to change the ownership of that volume to be owned by the pod: 
             *  1. The owning GID will be the FSGroup 2. The setgid bit is set (new files created in the volume will be owned by FSGroup) 3. The permission bits are OR'd with rw-rw---- 
             *  If unset, the Kubelet will not modify the ownership and permissions of any volume.
             */
            fsGroup?: number;
            /**
             * fsGroupChangePolicy defines behavior of changing ownership and permission of the volume before being exposed inside Pod. This field will only apply to volume types which support fsGroup based ownership(and permissions). It will have no effect on ephemeral volume types such as: secret, configmaps and emptydir. Valid values are "OnRootMismatch" and "Always". If not specified defaults to "Always".
             */
            fsGroupChangePolicy?: string;
            /**
             * The GID to run the entrypoint of the container process. Uses runtime default if unset. May also be set in SecurityContext.  If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence for that container.
             */
            runAsGroup?: number;
            /**
             * Indicates that the container must run as a non-root user. If true, the Kubelet will validate the image at runtime to ensure that it does not run as UID 0 (root) and fail to start the container if it does. If unset or false, no such validation will be performed. May also be set in SecurityContext.  If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.
             */
            runAsNonRoot?: boolean;
            /**
             * The UID to run the entrypoint of the container process. Defaults to user specified in image metadata if unspecified. May also be set in SecurityContext.  If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence for that container.
             */
            runAsUser?: number;
            /**
             * The SELinux context to be applied to all containers. If unspecified, the container runtime will allocate a random SELinux context for each container.  May also be set in SecurityContext.  If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence for that container.
             */
            seLinuxOptions?: outputs.monitoring.v1.AlertmanagerSpecSecurityContextSeLinuxOptions;
            /**
             * A list of groups applied to the first process run in each container, in addition to the container's primary GID.  If unspecified, no groups will be added to any container.
             */
            supplementalGroups?: number[];
            /**
             * Sysctls hold a list of namespaced sysctls used for the pod. Pods with unsupported sysctls (by the container runtime) might fail to launch.
             */
            sysctls?: outputs.monitoring.v1.AlertmanagerSpecSecurityContextSysctls[];
            /**
             * The Windows specific settings applied to all containers. If unspecified, the options within a container's SecurityContext will be used. If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.
             */
            windowsOptions?: outputs.monitoring.v1.AlertmanagerSpecSecurityContextWindowsOptions;
        }

        /**
         * The SELinux context to be applied to all containers. If unspecified, the container runtime will allocate a random SELinux context for each container.  May also be set in SecurityContext.  If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence for that container.
         */
        export interface AlertmanagerSpecSecurityContextSeLinuxOptions {
            /**
             * Level is SELinux level label that applies to the container.
             */
            level?: string;
            /**
             * Role is a SELinux role label that applies to the container.
             */
            role?: string;
            /**
             * Type is a SELinux type label that applies to the container.
             */
            type?: string;
            /**
             * User is a SELinux user label that applies to the container.
             */
            user?: string;
        }

        /**
         * Sysctl defines a kernel parameter to be set
         */
        export interface AlertmanagerSpecSecurityContextSysctls {
            /**
             * Name of a property to set
             */
            name: string;
            /**
             * Value of a property to set
             */
            value: string;
        }

        /**
         * The Windows specific settings applied to all containers. If unspecified, the options within a container's SecurityContext will be used. If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.
         */
        export interface AlertmanagerSpecSecurityContextWindowsOptions {
            /**
             * GMSACredentialSpec is where the GMSA admission webhook (https://github.com/kubernetes-sigs/windows-gmsa) inlines the contents of the GMSA credential spec named by the GMSACredentialSpecName field.
             */
            gmsaCredentialSpec?: string;
            /**
             * GMSACredentialSpecName is the name of the GMSA credential spec to use.
             */
            gmsaCredentialSpecName?: string;
            /**
             * The UserName in Windows to run the entrypoint of the container process. Defaults to the user specified in image metadata if unspecified. May also be set in PodSecurityContext. If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.
             */
            runAsUserName?: string;
        }

        /**
         * Storage is the definition of how storage will be used by the Alertmanager instances.
         */
        export interface AlertmanagerSpecStorage {
            /**
             * Deprecated: subPath usage will be disabled by default in a future release, this option will become unnecessary. DisableMountSubPath allows to remove any subPath usage in volume mounts.
             */
            disableMountSubPath?: boolean;
            /**
             * EmptyDirVolumeSource to be used by the Prometheus StatefulSets. If specified, used in place of any volumeClaimTemplate. More info: https://kubernetes.io/docs/concepts/storage/volumes/#emptydir
             */
            emptyDir?: outputs.monitoring.v1.AlertmanagerSpecStorageEmptyDir;
            /**
             * A PVC spec to be used by the Prometheus StatefulSets.
             */
            volumeClaimTemplate?: outputs.monitoring.v1.AlertmanagerSpecStorageVolumeClaimTemplate;
        }

        /**
         * EmptyDirVolumeSource to be used by the Prometheus StatefulSets. If specified, used in place of any volumeClaimTemplate. More info: https://kubernetes.io/docs/concepts/storage/volumes/#emptydir
         */
        export interface AlertmanagerSpecStorageEmptyDir {
            /**
             * What type of storage medium should back this directory. The default is "" which means to use the node's default medium. Must be an empty string (default) or Memory. More info: https://kubernetes.io/docs/concepts/storage/volumes#emptydir
             */
            medium?: string;
            /**
             * Total amount of local storage required for this EmptyDir volume. The size limit is also applicable for memory medium. The maximum usage on memory medium EmptyDir would be the minimum value between the SizeLimit specified here and the sum of memory limits of all containers in a pod. The default is nil which means that the limit is undefined. More info: http://kubernetes.io/docs/user-guide/volumes#emptydir
             */
            sizeLimit?: outputs.monitoring.v1.AlertmanagerSpecStorageEmptyDirSizeLimit;
        }

        export interface AlertmanagerSpecStorageEmptyDirSizeLimit {
        }

        /**
         * A PVC spec to be used by the Prometheus StatefulSets.
         */
        export interface AlertmanagerSpecStorageVolumeClaimTemplate {
            /**
             * APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources
             */
            apiVersion?: string;
            /**
             * Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
             */
            kind?: string;
            /**
             * EmbeddedMetadata contains metadata relevant to an EmbeddedResource.
             */
            metadata?: outputs.monitoring.v1.AlertmanagerSpecStorageVolumeClaimTemplateMetadata;
            /**
             * Spec defines the desired characteristics of a volume requested by a pod author. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#persistentvolumeclaims
             */
            spec?: outputs.monitoring.v1.AlertmanagerSpecStorageVolumeClaimTemplateSpec;
            /**
             * Status represents the current information/status of a persistent volume claim. Read-only. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#persistentvolumeclaims
             */
            status?: outputs.monitoring.v1.AlertmanagerSpecStorageVolumeClaimTemplateStatus;
        }

        /**
         * EmbeddedMetadata contains metadata relevant to an EmbeddedResource.
         */
        export interface AlertmanagerSpecStorageVolumeClaimTemplateMetadata {
            /**
             * Annotations is an unstructured key value map stored with a resource that may be set by external tools to store and retrieve arbitrary metadata. They are not queryable and should be preserved when modifying objects. More info: http://kubernetes.io/docs/user-guide/annotations
             */
            annotations?: {[key: string]: string};
            /**
             * Map of string keys and values that can be used to organize and categorize (scope and select) objects. May match selectors of replication controllers and services. More info: http://kubernetes.io/docs/user-guide/labels
             */
            labels?: {[key: string]: string};
            /**
             * Name must be unique within a namespace. Is required when creating resources, although some resources may allow a client to request the generation of an appropriate name automatically. Name is primarily intended for creation idempotence and configuration definition. Cannot be updated. More info: http://kubernetes.io/docs/user-guide/identifiers#names
             */
            name?: string;
        }

        /**
         * Spec defines the desired characteristics of a volume requested by a pod author. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#persistentvolumeclaims
         */
        export interface AlertmanagerSpecStorageVolumeClaimTemplateSpec {
            /**
             * AccessModes contains the desired access modes the volume should have. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#access-modes-1
             */
            accessModes?: string[];
            /**
             * This field can be used to specify either: * An existing VolumeSnapshot object (snapshot.storage.k8s.io/VolumeSnapshot - Beta) * An existing PVC (PersistentVolumeClaim) * An existing custom resource/object that implements data population (Alpha) In order to use VolumeSnapshot object types, the appropriate feature gate must be enabled (VolumeSnapshotDataSource or AnyVolumeDataSource) If the provisioner or an external controller can support the specified data source, it will create a new volume based on the contents of the specified data source. If the specified data source is not supported, the volume will not be created and the failure will be reported as an event. In the future, we plan to support more data source types and the behavior of the provisioner may change.
             */
            dataSource?: outputs.monitoring.v1.AlertmanagerSpecStorageVolumeClaimTemplateSpecDataSource;
            /**
             * Resources represents the minimum resources the volume should have. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#resources
             */
            resources?: outputs.monitoring.v1.AlertmanagerSpecStorageVolumeClaimTemplateSpecResources;
            /**
             * A label query over volumes to consider for binding.
             */
            selector?: outputs.monitoring.v1.AlertmanagerSpecStorageVolumeClaimTemplateSpecSelector;
            /**
             * Name of the StorageClass required by the claim. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#class-1
             */
            storageClassName?: string;
            /**
             * volumeMode defines what type of volume is required by the claim. Value of Filesystem is implied when not included in claim spec.
             */
            volumeMode?: string;
            /**
             * VolumeName is the binding reference to the PersistentVolume backing this claim.
             */
            volumeName?: string;
        }

        /**
         * This field can be used to specify either: * An existing VolumeSnapshot object (snapshot.storage.k8s.io/VolumeSnapshot - Beta) * An existing PVC (PersistentVolumeClaim) * An existing custom resource/object that implements data population (Alpha) In order to use VolumeSnapshot object types, the appropriate feature gate must be enabled (VolumeSnapshotDataSource or AnyVolumeDataSource) If the provisioner or an external controller can support the specified data source, it will create a new volume based on the contents of the specified data source. If the specified data source is not supported, the volume will not be created and the failure will be reported as an event. In the future, we plan to support more data source types and the behavior of the provisioner may change.
         */
        export interface AlertmanagerSpecStorageVolumeClaimTemplateSpecDataSource {
            /**
             * APIGroup is the group for the resource being referenced. If APIGroup is not specified, the specified Kind must be in the core API group. For any other third-party types, APIGroup is required.
             */
            apiGroup?: string;
            /**
             * Kind is the type of resource being referenced
             */
            kind: string;
            /**
             * Name is the name of resource being referenced
             */
            name: string;
        }

        /**
         * Resources represents the minimum resources the volume should have. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#resources
         */
        export interface AlertmanagerSpecStorageVolumeClaimTemplateSpecResources {
            /**
             * Limits describes the maximum amount of compute resources allowed. More info: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
             */
            limits?: {[key: string]: outputs.monitoring.v1.AlertmanagerSpecStorageVolumeClaimTemplateSpecResourcesLimits};
            /**
             * Requests describes the minimum amount of compute resources required. If Requests is omitted for a container, it defaults to Limits if that is explicitly specified, otherwise to an implementation-defined value. More info: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
             */
            requests?: {[key: string]: outputs.monitoring.v1.AlertmanagerSpecStorageVolumeClaimTemplateSpecResourcesRequests};
        }

        export interface AlertmanagerSpecStorageVolumeClaimTemplateSpecResourcesLimits {
        }

        export interface AlertmanagerSpecStorageVolumeClaimTemplateSpecResourcesRequests {
        }

        /**
         * A label query over volumes to consider for binding.
         */
        export interface AlertmanagerSpecStorageVolumeClaimTemplateSpecSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.monitoring.v1.AlertmanagerSpecStorageVolumeClaimTemplateSpecSelectorMatchExpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface AlertmanagerSpecStorageVolumeClaimTemplateSpecSelectorMatchExpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Status represents the current information/status of a persistent volume claim. Read-only. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#persistentvolumeclaims
         */
        export interface AlertmanagerSpecStorageVolumeClaimTemplateStatus {
            /**
             * AccessModes contains the actual access modes the volume backing the PVC has. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#access-modes-1
             */
            accessModes?: string[];
            /**
             * Represents the actual resources of the underlying volume.
             */
            capacity?: {[key: string]: outputs.monitoring.v1.AlertmanagerSpecStorageVolumeClaimTemplateStatusCapacity};
            /**
             * Current Condition of persistent volume claim. If underlying persistent volume is being resized then the Condition will be set to 'ResizeStarted'.
             */
            conditions?: outputs.monitoring.v1.AlertmanagerSpecStorageVolumeClaimTemplateStatusConditions[];
            /**
             * Phase represents the current phase of PersistentVolumeClaim.
             */
            phase?: string;
        }

        export interface AlertmanagerSpecStorageVolumeClaimTemplateStatusCapacity {
        }

        /**
         * PersistentVolumeClaimCondition contails details about state of pvc
         */
        export interface AlertmanagerSpecStorageVolumeClaimTemplateStatusConditions {
            /**
             * Last time we probed the condition.
             */
            lastProbeTime?: string;
            /**
             * Last time the condition transitioned from one status to another.
             */
            lastTransitionTime?: string;
            /**
             * Human-readable message indicating details about last transition.
             */
            message?: string;
            /**
             * Unique, this should be a short, machine understandable string that gives the reason for condition's last transition. If it reports "ResizeStarted" that means the underlying persistent volume is being resized.
             */
            reason?: string;
            status: string;
            /**
             * PersistentVolumeClaimConditionType is a valid value of PersistentVolumeClaimCondition.Type
             */
            type: string;
        }

        /**
         * The pod this Toleration is attached to tolerates any taint that matches the triple <key,value,effect> using the matching operator <operator>.
         */
        export interface AlertmanagerSpecTolerations {
            /**
             * Effect indicates the taint effect to match. Empty means match all taint effects. When specified, allowed values are NoSchedule, PreferNoSchedule and NoExecute.
             */
            effect?: string;
            /**
             * Key is the taint key that the toleration applies to. Empty means match all taint keys. If the key is empty, operator must be Exists; this combination means to match all values and all keys.
             */
            key?: string;
            /**
             * Operator represents a key's relationship to the value. Valid operators are Exists and Equal. Defaults to Equal. Exists is equivalent to wildcard for value, so that a pod can tolerate all taints of a particular category.
             */
            operator?: string;
            /**
             * TolerationSeconds represents the period of time the toleration (which must be of effect NoExecute, otherwise this field is ignored) tolerates the taint. By default, it is not set, which means tolerate the taint forever (do not evict). Zero and negative values will be treated as 0 (evict immediately) by the system.
             */
            tolerationSeconds?: number;
            /**
             * Value is the taint value the toleration matches to. If the operator is Exists, the value should be empty, otherwise just a regular string.
             */
            value?: string;
        }

        /**
         * TopologySpreadConstraint specifies how to spread matching pods among the given topology.
         */
        export interface AlertmanagerSpecTopologySpreadConstraints {
            /**
             * LabelSelector is used to find matching pods. Pods that match this label selector are counted to determine the number of pods in their corresponding topology domain.
             */
            labelSelector?: outputs.monitoring.v1.AlertmanagerSpecTopologySpreadConstraintsLabelSelector;
            /**
             * MaxSkew describes the degree to which pods may be unevenly distributed. It's the maximum permitted difference between the number of matching pods in any two topology domains of a given topology type. For example, in a 3-zone cluster, MaxSkew is set to 1, and pods with the same labelSelector spread as 1/1/0: | zone1 | zone2 | zone3 | |   P   |   P   |       | - if MaxSkew is 1, incoming pod can only be scheduled to zone3 to become 1/1/1; scheduling it onto zone1(zone2) would make the ActualSkew(2-0) on zone1(zone2) violate MaxSkew(1). - if MaxSkew is 2, incoming pod can be scheduled onto any zone. It's a required field. Default value is 1 and 0 is not allowed.
             */
            maxSkew: number;
            /**
             * TopologyKey is the key of node labels. Nodes that have a label with this key and identical values are considered to be in the same topology. We consider each <key, value> as a "bucket", and try to put balanced number of pods into each bucket. It's a required field.
             */
            topologyKey: string;
            /**
             * WhenUnsatisfiable indicates how to deal with a pod if it doesn't satisfy the spread constraint. - DoNotSchedule (default) tells the scheduler not to schedule it - ScheduleAnyway tells the scheduler to still schedule it It's considered as "Unsatisfiable" if and only if placing incoming pod on any topology violates "MaxSkew". For example, in a 3-zone cluster, MaxSkew is set to 1, and pods with the same labelSelector spread as 3/1/1: | zone1 | zone2 | zone3 | | P P P |   P   |   P   | If WhenUnsatisfiable is set to DoNotSchedule, incoming pod can only be scheduled to zone2(zone3) to become 3/2/1(3/1/2) as ActualSkew(2-1) on zone2(zone3) satisfies MaxSkew(1). In other words, the cluster can still be imbalanced, but scheduler won't make it *more* imbalanced. It's a required field.
             */
            whenUnsatisfiable: string;
        }

        /**
         * LabelSelector is used to find matching pods. Pods that match this label selector are counted to determine the number of pods in their corresponding topology domain.
         */
        export interface AlertmanagerSpecTopologySpreadConstraintsLabelSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.monitoring.v1.AlertmanagerSpecTopologySpreadConstraintsLabelSelectorMatchExpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface AlertmanagerSpecTopologySpreadConstraintsLabelSelectorMatchExpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * VolumeMount describes a mounting of a Volume within a container.
         */
        export interface AlertmanagerSpecVolumeMounts {
            /**
             * Path within the container at which the volume should be mounted.  Must not contain ':'.
             */
            mountPath: string;
            /**
             * mountPropagation determines how mounts are propagated from the host to container and the other way around. When not set, MountPropagationNone is used. This field is beta in 1.10.
             */
            mountPropagation?: string;
            /**
             * This must match the Name of a Volume.
             */
            name: string;
            /**
             * Mounted read-only if true, read-write otherwise (false or unspecified). Defaults to false.
             */
            readOnly?: boolean;
            /**
             * Path within the volume from which the container's volume should be mounted. Defaults to "" (volume's root).
             */
            subPath?: string;
            /**
             * Expanded path within the volume from which the container's volume should be mounted. Behaves similarly to SubPath but environment variable references $(VAR_NAME) are expanded using the container's environment. Defaults to "" (volume's root). SubPathExpr and SubPath are mutually exclusive.
             */
            subPathExpr?: string;
        }

        /**
         * Volume represents a named volume in a pod that may be accessed by any container in the pod.
         */
        export interface AlertmanagerSpecVolumes {
            /**
             * AWSElasticBlockStore represents an AWS Disk resource that is attached to a kubelet's host machine and then exposed to the pod. More info: https://kubernetes.io/docs/concepts/storage/volumes#awselasticblockstore
             */
            awsElasticBlockStore?: outputs.monitoring.v1.AlertmanagerSpecVolumesAwsElasticBlockStore;
            /**
             * AzureDisk represents an Azure Data Disk mount on the host and bind mount to the pod.
             */
            azureDisk?: outputs.monitoring.v1.AlertmanagerSpecVolumesAzureDisk;
            /**
             * AzureFile represents an Azure File Service mount on the host and bind mount to the pod.
             */
            azureFile?: outputs.monitoring.v1.AlertmanagerSpecVolumesAzureFile;
            /**
             * CephFS represents a Ceph FS mount on the host that shares a pod's lifetime
             */
            cephfs?: outputs.monitoring.v1.AlertmanagerSpecVolumesCephfs;
            /**
             * Cinder represents a cinder volume attached and mounted on kubelets host machine. More info: https://examples.k8s.io/mysql-cinder-pd/README.md
             */
            cinder?: outputs.monitoring.v1.AlertmanagerSpecVolumesCinder;
            /**
             * ConfigMap represents a configMap that should populate this volume
             */
            configMap?: outputs.monitoring.v1.AlertmanagerSpecVolumesConfigMap;
            /**
             * CSI (Container Storage Interface) represents storage that is handled by an external CSI driver (Alpha feature).
             */
            csi?: outputs.monitoring.v1.AlertmanagerSpecVolumesCsi;
            /**
             * DownwardAPI represents downward API about the pod that should populate this volume
             */
            downwardAPI?: outputs.monitoring.v1.AlertmanagerSpecVolumesDownwardAPI;
            /**
             * EmptyDir represents a temporary directory that shares a pod's lifetime. More info: https://kubernetes.io/docs/concepts/storage/volumes#emptydir
             */
            emptyDir?: outputs.monitoring.v1.AlertmanagerSpecVolumesEmptyDir;
            /**
             * FC represents a Fibre Channel resource that is attached to a kubelet's host machine and then exposed to the pod.
             */
            fc?: outputs.monitoring.v1.AlertmanagerSpecVolumesFc;
            /**
             * FlexVolume represents a generic volume resource that is provisioned/attached using an exec based plugin.
             */
            flexVolume?: outputs.monitoring.v1.AlertmanagerSpecVolumesFlexVolume;
            /**
             * Flocker represents a Flocker volume attached to a kubelet's host machine. This depends on the Flocker control service being running
             */
            flocker?: outputs.monitoring.v1.AlertmanagerSpecVolumesFlocker;
            /**
             * GCEPersistentDisk represents a GCE Disk resource that is attached to a kubelet's host machine and then exposed to the pod. More info: https://kubernetes.io/docs/concepts/storage/volumes#gcepersistentdisk
             */
            gcePersistentDisk?: outputs.monitoring.v1.AlertmanagerSpecVolumesGcePersistentDisk;
            /**
             * GitRepo represents a git repository at a particular revision. DEPRECATED: GitRepo is deprecated. To provision a container with a git repo, mount an EmptyDir into an InitContainer that clones the repo using git, then mount the EmptyDir into the Pod's container.
             */
            gitRepo?: outputs.monitoring.v1.AlertmanagerSpecVolumesGitRepo;
            /**
             * Glusterfs represents a Glusterfs mount on the host that shares a pod's lifetime. More info: https://examples.k8s.io/volumes/glusterfs/README.md
             */
            glusterfs?: outputs.monitoring.v1.AlertmanagerSpecVolumesGlusterfs;
            /**
             * HostPath represents a pre-existing file or directory on the host machine that is directly exposed to the container. This is generally used for system agents or other privileged things that are allowed to see the host machine. Most containers will NOT need this. More info: https://kubernetes.io/docs/concepts/storage/volumes#hostpath --- TODO(jonesdl) We need to restrict who can use host directory mounts and who can/can not mount host directories as read/write.
             */
            hostPath?: outputs.monitoring.v1.AlertmanagerSpecVolumesHostPath;
            /**
             * ISCSI represents an ISCSI Disk resource that is attached to a kubelet's host machine and then exposed to the pod. More info: https://examples.k8s.io/volumes/iscsi/README.md
             */
            iscsi?: outputs.monitoring.v1.AlertmanagerSpecVolumesIscsi;
            /**
             * Volume's name. Must be a DNS_LABEL and unique within the pod. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
            /**
             * NFS represents an NFS mount on the host that shares a pod's lifetime More info: https://kubernetes.io/docs/concepts/storage/volumes#nfs
             */
            nfs?: outputs.monitoring.v1.AlertmanagerSpecVolumesNfs;
            /**
             * PersistentVolumeClaimVolumeSource represents a reference to a PersistentVolumeClaim in the same namespace. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#persistentvolumeclaims
             */
            persistentVolumeClaim?: outputs.monitoring.v1.AlertmanagerSpecVolumesPersistentVolumeClaim;
            /**
             * PhotonPersistentDisk represents a PhotonController persistent disk attached and mounted on kubelets host machine
             */
            photonPersistentDisk?: outputs.monitoring.v1.AlertmanagerSpecVolumesPhotonPersistentDisk;
            /**
             * PortworxVolume represents a portworx volume attached and mounted on kubelets host machine
             */
            portworxVolume?: outputs.monitoring.v1.AlertmanagerSpecVolumesPortworxVolume;
            /**
             * Items for all in one resources secrets, configmaps, and downward API
             */
            projected?: outputs.monitoring.v1.AlertmanagerSpecVolumesProjected;
            /**
             * Quobyte represents a Quobyte mount on the host that shares a pod's lifetime
             */
            quobyte?: outputs.monitoring.v1.AlertmanagerSpecVolumesQuobyte;
            /**
             * RBD represents a Rados Block Device mount on the host that shares a pod's lifetime. More info: https://examples.k8s.io/volumes/rbd/README.md
             */
            rbd?: outputs.monitoring.v1.AlertmanagerSpecVolumesRbd;
            /**
             * ScaleIO represents a ScaleIO persistent volume attached and mounted on Kubernetes nodes.
             */
            scaleIO?: outputs.monitoring.v1.AlertmanagerSpecVolumesScaleIO;
            /**
             * Secret represents a secret that should populate this volume. More info: https://kubernetes.io/docs/concepts/storage/volumes#secret
             */
            secret?: outputs.monitoring.v1.AlertmanagerSpecVolumesSecret;
            /**
             * StorageOS represents a StorageOS volume attached and mounted on Kubernetes nodes.
             */
            storageos?: outputs.monitoring.v1.AlertmanagerSpecVolumesStorageos;
            /**
             * VsphereVolume represents a vSphere volume attached and mounted on kubelets host machine
             */
            vsphereVolume?: outputs.monitoring.v1.AlertmanagerSpecVolumesVsphereVolume;
        }

        /**
         * AWSElasticBlockStore represents an AWS Disk resource that is attached to a kubelet's host machine and then exposed to the pod. More info: https://kubernetes.io/docs/concepts/storage/volumes#awselasticblockstore
         */
        export interface AlertmanagerSpecVolumesAwsElasticBlockStore {
            /**
             * Filesystem type of the volume that you want to mount. Tip: Ensure that the filesystem type is supported by the host operating system. Examples: "ext4", "xfs", "ntfs". Implicitly inferred to be "ext4" if unspecified. More info: https://kubernetes.io/docs/concepts/storage/volumes#awselasticblockstore TODO: how do we prevent errors in the filesystem from compromising the machine
             */
            fsType?: string;
            /**
             * The partition in the volume that you want to mount. If omitted, the default is to mount by volume name. Examples: For volume /dev/sda1, you specify the partition as "1". Similarly, the volume partition for /dev/sda is "0" (or you can leave the property empty).
             */
            partition?: number;
            /**
             * Specify "true" to force and set the ReadOnly property in VolumeMounts to "true". If omitted, the default is "false". More info: https://kubernetes.io/docs/concepts/storage/volumes#awselasticblockstore
             */
            readOnly?: boolean;
            /**
             * Unique ID of the persistent disk resource in AWS (Amazon EBS volume). More info: https://kubernetes.io/docs/concepts/storage/volumes#awselasticblockstore
             */
            volumeID: string;
        }

        /**
         * AzureDisk represents an Azure Data Disk mount on the host and bind mount to the pod.
         */
        export interface AlertmanagerSpecVolumesAzureDisk {
            /**
             * Host Caching mode: None, Read Only, Read Write.
             */
            cachingMode?: string;
            /**
             * The Name of the data disk in the blob storage
             */
            diskName: string;
            /**
             * The URI the data disk in the blob storage
             */
            diskURI: string;
            /**
             * Filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. "ext4", "xfs", "ntfs". Implicitly inferred to be "ext4" if unspecified.
             */
            fsType?: string;
            /**
             * Expected values Shared: multiple blob disks per storage account  Dedicated: single blob disk per storage account  Managed: azure managed data disk (only in managed availability set). defaults to shared
             */
            kind?: string;
            /**
             * Defaults to false (read/write). ReadOnly here will force the ReadOnly setting in VolumeMounts.
             */
            readOnly?: boolean;
        }

        /**
         * AzureFile represents an Azure File Service mount on the host and bind mount to the pod.
         */
        export interface AlertmanagerSpecVolumesAzureFile {
            /**
             * Defaults to false (read/write). ReadOnly here will force the ReadOnly setting in VolumeMounts.
             */
            readOnly?: boolean;
            /**
             * the name of secret that contains Azure Storage Account Name and Key
             */
            secretName: string;
            /**
             * Share Name
             */
            shareName: string;
        }

        /**
         * CephFS represents a Ceph FS mount on the host that shares a pod's lifetime
         */
        export interface AlertmanagerSpecVolumesCephfs {
            /**
             * Required: Monitors is a collection of Ceph monitors More info: https://examples.k8s.io/volumes/cephfs/README.md#how-to-use-it
             */
            monitors: string[];
            /**
             * Optional: Used as the mounted root, rather than the full Ceph tree, default is /
             */
            path?: string;
            /**
             * Optional: Defaults to false (read/write). ReadOnly here will force the ReadOnly setting in VolumeMounts. More info: https://examples.k8s.io/volumes/cephfs/README.md#how-to-use-it
             */
            readOnly?: boolean;
            /**
             * Optional: SecretFile is the path to key ring for User, default is /etc/ceph/user.secret More info: https://examples.k8s.io/volumes/cephfs/README.md#how-to-use-it
             */
            secretFile?: string;
            /**
             * Optional: SecretRef is reference to the authentication secret for User, default is empty. More info: https://examples.k8s.io/volumes/cephfs/README.md#how-to-use-it
             */
            secretRef?: outputs.monitoring.v1.AlertmanagerSpecVolumesCephfsSecretRef;
            /**
             * Optional: User is the rados user name, default is admin More info: https://examples.k8s.io/volumes/cephfs/README.md#how-to-use-it
             */
            user?: string;
        }

        /**
         * Optional: SecretRef is reference to the authentication secret for User, default is empty. More info: https://examples.k8s.io/volumes/cephfs/README.md#how-to-use-it
         */
        export interface AlertmanagerSpecVolumesCephfsSecretRef {
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
        }

        /**
         * Cinder represents a cinder volume attached and mounted on kubelets host machine. More info: https://examples.k8s.io/mysql-cinder-pd/README.md
         */
        export interface AlertmanagerSpecVolumesCinder {
            /**
             * Filesystem type to mount. Must be a filesystem type supported by the host operating system. Examples: "ext4", "xfs", "ntfs". Implicitly inferred to be "ext4" if unspecified. More info: https://examples.k8s.io/mysql-cinder-pd/README.md
             */
            fsType?: string;
            /**
             * Optional: Defaults to false (read/write). ReadOnly here will force the ReadOnly setting in VolumeMounts. More info: https://examples.k8s.io/mysql-cinder-pd/README.md
             */
            readOnly?: boolean;
            /**
             * Optional: points to a secret object containing parameters used to connect to OpenStack.
             */
            secretRef?: outputs.monitoring.v1.AlertmanagerSpecVolumesCinderSecretRef;
            /**
             * volume id used to identify the volume in cinder. More info: https://examples.k8s.io/mysql-cinder-pd/README.md
             */
            volumeID: string;
        }

        /**
         * Optional: points to a secret object containing parameters used to connect to OpenStack.
         */
        export interface AlertmanagerSpecVolumesCinderSecretRef {
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
        }

        /**
         * ConfigMap represents a configMap that should populate this volume
         */
        export interface AlertmanagerSpecVolumesConfigMap {
            /**
             * Optional: mode bits to use on created files by default. Must be a value between 0 and 0777. Defaults to 0644. Directories within the path are not affected by this setting. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set.
             */
            defaultMode?: number;
            /**
             * If unspecified, each key-value pair in the Data field of the referenced ConfigMap will be projected into the volume as a file whose name is the key and content is the value. If specified, the listed keys will be projected into the specified paths, and unlisted keys will not be present. If a key is specified which is not present in the ConfigMap, the volume setup will error unless it is marked optional. Paths must be relative and may not contain the '..' path or start with '..'.
             */
            items?: outputs.monitoring.v1.AlertmanagerSpecVolumesConfigMapItems[];
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the ConfigMap or its keys must be defined
             */
            optional?: boolean;
        }

        /**
         * Maps a string key to a path within a volume.
         */
        export interface AlertmanagerSpecVolumesConfigMapItems {
            /**
             * The key to project.
             */
            key: string;
            /**
             * Optional: mode bits to use on this file, must be a value between 0 and 0777. If not specified, the volume defaultMode will be used. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set.
             */
            mode?: number;
            /**
             * The relative path of the file to map the key to. May not be an absolute path. May not contain the path element '..'. May not start with the string '..'.
             */
            path: string;
        }

        /**
         * CSI (Container Storage Interface) represents storage that is handled by an external CSI driver (Alpha feature).
         */
        export interface AlertmanagerSpecVolumesCsi {
            /**
             * Driver is the name of the CSI driver that handles this volume. Consult with your admin for the correct name as registered in the cluster.
             */
            driver: string;
            /**
             * Filesystem type to mount. Ex. "ext4", "xfs", "ntfs". If not provided, the empty value is passed to the associated CSI driver which will determine the default filesystem to apply.
             */
            fsType?: string;
            /**
             * NodePublishSecretRef is a reference to the secret object containing sensitive information to pass to the CSI driver to complete the CSI NodePublishVolume and NodeUnpublishVolume calls. This field is optional, and  may be empty if no secret is required. If the secret object contains more than one secret, all secret references are passed.
             */
            nodePublishSecretRef?: outputs.monitoring.v1.AlertmanagerSpecVolumesCsiNodePublishSecretRef;
            /**
             * Specifies a read-only configuration for the volume. Defaults to false (read/write).
             */
            readOnly?: boolean;
            /**
             * VolumeAttributes stores driver-specific properties that are passed to the CSI driver. Consult your driver's documentation for supported values.
             */
            volumeAttributes?: {[key: string]: string};
        }

        /**
         * NodePublishSecretRef is a reference to the secret object containing sensitive information to pass to the CSI driver to complete the CSI NodePublishVolume and NodeUnpublishVolume calls. This field is optional, and  may be empty if no secret is required. If the secret object contains more than one secret, all secret references are passed.
         */
        export interface AlertmanagerSpecVolumesCsiNodePublishSecretRef {
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
        }

        /**
         * DownwardAPI represents downward API about the pod that should populate this volume
         */
        export interface AlertmanagerSpecVolumesDownwardAPI {
            /**
             * Optional: mode bits to use on created files by default. Must be a value between 0 and 0777. Defaults to 0644. Directories within the path are not affected by this setting. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set.
             */
            defaultMode?: number;
            /**
             * Items is a list of downward API volume file
             */
            items?: outputs.monitoring.v1.AlertmanagerSpecVolumesDownwardAPIItems[];
        }

        /**
         * DownwardAPIVolumeFile represents information to create the file containing the pod field
         */
        export interface AlertmanagerSpecVolumesDownwardAPIItems {
            /**
             * Required: Selects a field of the pod: only annotations, labels, name and namespace are supported.
             */
            fieldRef?: outputs.monitoring.v1.AlertmanagerSpecVolumesDownwardAPIItemsFieldRef;
            /**
             * Optional: mode bits to use on this file, must be a value between 0 and 0777. If not specified, the volume defaultMode will be used. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set.
             */
            mode?: number;
            /**
             * Required: Path is  the relative path name of the file to be created. Must not be absolute or contain the '..' path. Must be utf-8 encoded. The first item of the relative path must not start with '..'
             */
            path: string;
            /**
             * Selects a resource of the container: only resources limits and requests (limits.cpu, limits.memory, requests.cpu and requests.memory) are currently supported.
             */
            resourceFieldRef?: outputs.monitoring.v1.AlertmanagerSpecVolumesDownwardAPIItemsResourceFieldRef;
        }

        /**
         * Required: Selects a field of the pod: only annotations, labels, name and namespace are supported.
         */
        export interface AlertmanagerSpecVolumesDownwardAPIItemsFieldRef {
            /**
             * Version of the schema the FieldPath is written in terms of, defaults to "v1".
             */
            apiVersion?: string;
            /**
             * Path of the field to select in the specified API version.
             */
            fieldPath: string;
        }

        /**
         * Selects a resource of the container: only resources limits and requests (limits.cpu, limits.memory, requests.cpu and requests.memory) are currently supported.
         */
        export interface AlertmanagerSpecVolumesDownwardAPIItemsResourceFieldRef {
            /**
             * Container name: required for volumes, optional for env vars
             */
            containerName?: string;
            /**
             * Specifies the output format of the exposed resources, defaults to "1"
             */
            divisor?: outputs.monitoring.v1.AlertmanagerSpecVolumesDownwardAPIItemsResourceFieldRefDivisor;
            /**
             * Required: resource to select
             */
            resource: string;
        }

        export interface AlertmanagerSpecVolumesDownwardAPIItemsResourceFieldRefDivisor {
        }

        /**
         * EmptyDir represents a temporary directory that shares a pod's lifetime. More info: https://kubernetes.io/docs/concepts/storage/volumes#emptydir
         */
        export interface AlertmanagerSpecVolumesEmptyDir {
            /**
             * What type of storage medium should back this directory. The default is "" which means to use the node's default medium. Must be an empty string (default) or Memory. More info: https://kubernetes.io/docs/concepts/storage/volumes#emptydir
             */
            medium?: string;
            /**
             * Total amount of local storage required for this EmptyDir volume. The size limit is also applicable for memory medium. The maximum usage on memory medium EmptyDir would be the minimum value between the SizeLimit specified here and the sum of memory limits of all containers in a pod. The default is nil which means that the limit is undefined. More info: http://kubernetes.io/docs/user-guide/volumes#emptydir
             */
            sizeLimit?: outputs.monitoring.v1.AlertmanagerSpecVolumesEmptyDirSizeLimit;
        }

        export interface AlertmanagerSpecVolumesEmptyDirSizeLimit {
        }

        /**
         * FC represents a Fibre Channel resource that is attached to a kubelet's host machine and then exposed to the pod.
         */
        export interface AlertmanagerSpecVolumesFc {
            /**
             * Filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. "ext4", "xfs", "ntfs". Implicitly inferred to be "ext4" if unspecified. TODO: how do we prevent errors in the filesystem from compromising the machine
             */
            fsType?: string;
            /**
             * Optional: FC target lun number
             */
            lun?: number;
            /**
             * Optional: Defaults to false (read/write). ReadOnly here will force the ReadOnly setting in VolumeMounts.
             */
            readOnly?: boolean;
            /**
             * Optional: FC target worldwide names (WWNs)
             */
            targetWWNs?: string[];
            /**
             * Optional: FC volume world wide identifiers (wwids) Either wwids or combination of targetWWNs and lun must be set, but not both simultaneously.
             */
            wwids?: string[];
        }

        /**
         * FlexVolume represents a generic volume resource that is provisioned/attached using an exec based plugin.
         */
        export interface AlertmanagerSpecVolumesFlexVolume {
            /**
             * Driver is the name of the driver to use for this volume.
             */
            driver: string;
            /**
             * Filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. "ext4", "xfs", "ntfs". The default filesystem depends on FlexVolume script.
             */
            fsType?: string;
            /**
             * Optional: Extra command options if any.
             */
            options?: {[key: string]: string};
            /**
             * Optional: Defaults to false (read/write). ReadOnly here will force the ReadOnly setting in VolumeMounts.
             */
            readOnly?: boolean;
            /**
             * Optional: SecretRef is reference to the secret object containing sensitive information to pass to the plugin scripts. This may be empty if no secret object is specified. If the secret object contains more than one secret, all secrets are passed to the plugin scripts.
             */
            secretRef?: outputs.monitoring.v1.AlertmanagerSpecVolumesFlexVolumeSecretRef;
        }

        /**
         * Optional: SecretRef is reference to the secret object containing sensitive information to pass to the plugin scripts. This may be empty if no secret object is specified. If the secret object contains more than one secret, all secrets are passed to the plugin scripts.
         */
        export interface AlertmanagerSpecVolumesFlexVolumeSecretRef {
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
        }

        /**
         * Flocker represents a Flocker volume attached to a kubelet's host machine. This depends on the Flocker control service being running
         */
        export interface AlertmanagerSpecVolumesFlocker {
            /**
             * Name of the dataset stored as metadata -> name on the dataset for Flocker should be considered as deprecated
             */
            datasetName?: string;
            /**
             * UUID of the dataset. This is unique identifier of a Flocker dataset
             */
            datasetUUID?: string;
        }

        /**
         * GCEPersistentDisk represents a GCE Disk resource that is attached to a kubelet's host machine and then exposed to the pod. More info: https://kubernetes.io/docs/concepts/storage/volumes#gcepersistentdisk
         */
        export interface AlertmanagerSpecVolumesGcePersistentDisk {
            /**
             * Filesystem type of the volume that you want to mount. Tip: Ensure that the filesystem type is supported by the host operating system. Examples: "ext4", "xfs", "ntfs". Implicitly inferred to be "ext4" if unspecified. More info: https://kubernetes.io/docs/concepts/storage/volumes#gcepersistentdisk TODO: how do we prevent errors in the filesystem from compromising the machine
             */
            fsType?: string;
            /**
             * The partition in the volume that you want to mount. If omitted, the default is to mount by volume name. Examples: For volume /dev/sda1, you specify the partition as "1". Similarly, the volume partition for /dev/sda is "0" (or you can leave the property empty). More info: https://kubernetes.io/docs/concepts/storage/volumes#gcepersistentdisk
             */
            partition?: number;
            /**
             * Unique name of the PD resource in GCE. Used to identify the disk in GCE. More info: https://kubernetes.io/docs/concepts/storage/volumes#gcepersistentdisk
             */
            pdName: string;
            /**
             * ReadOnly here will force the ReadOnly setting in VolumeMounts. Defaults to false. More info: https://kubernetes.io/docs/concepts/storage/volumes#gcepersistentdisk
             */
            readOnly?: boolean;
        }

        /**
         * GitRepo represents a git repository at a particular revision. DEPRECATED: GitRepo is deprecated. To provision a container with a git repo, mount an EmptyDir into an InitContainer that clones the repo using git, then mount the EmptyDir into the Pod's container.
         */
        export interface AlertmanagerSpecVolumesGitRepo {
            /**
             * Target directory name. Must not contain or start with '..'.  If '.' is supplied, the volume directory will be the git repository.  Otherwise, if specified, the volume will contain the git repository in the subdirectory with the given name.
             */
            directory?: string;
            /**
             * Repository URL
             */
            repository: string;
            /**
             * Commit hash for the specified revision.
             */
            revision?: string;
        }

        /**
         * Glusterfs represents a Glusterfs mount on the host that shares a pod's lifetime. More info: https://examples.k8s.io/volumes/glusterfs/README.md
         */
        export interface AlertmanagerSpecVolumesGlusterfs {
            /**
             * EndpointsName is the endpoint name that details Glusterfs topology. More info: https://examples.k8s.io/volumes/glusterfs/README.md#create-a-pod
             */
            endpoints: string;
            /**
             * Path is the Glusterfs volume path. More info: https://examples.k8s.io/volumes/glusterfs/README.md#create-a-pod
             */
            path: string;
            /**
             * ReadOnly here will force the Glusterfs volume to be mounted with read-only permissions. Defaults to false. More info: https://examples.k8s.io/volumes/glusterfs/README.md#create-a-pod
             */
            readOnly?: boolean;
        }

        /**
         * HostPath represents a pre-existing file or directory on the host machine that is directly exposed to the container. This is generally used for system agents or other privileged things that are allowed to see the host machine. Most containers will NOT need this. More info: https://kubernetes.io/docs/concepts/storage/volumes#hostpath --- TODO(jonesdl) We need to restrict who can use host directory mounts and who can/can not mount host directories as read/write.
         */
        export interface AlertmanagerSpecVolumesHostPath {
            /**
             * Path of the directory on the host. If the path is a symlink, it will follow the link to the real path. More info: https://kubernetes.io/docs/concepts/storage/volumes#hostpath
             */
            path: string;
            /**
             * Type for HostPath Volume Defaults to "" More info: https://kubernetes.io/docs/concepts/storage/volumes#hostpath
             */
            type?: string;
        }

        /**
         * ISCSI represents an ISCSI Disk resource that is attached to a kubelet's host machine and then exposed to the pod. More info: https://examples.k8s.io/volumes/iscsi/README.md
         */
        export interface AlertmanagerSpecVolumesIscsi {
            /**
             * whether support iSCSI Discovery CHAP authentication
             */
            chapAuthDiscovery?: boolean;
            /**
             * whether support iSCSI Session CHAP authentication
             */
            chapAuthSession?: boolean;
            /**
             * Filesystem type of the volume that you want to mount. Tip: Ensure that the filesystem type is supported by the host operating system. Examples: "ext4", "xfs", "ntfs". Implicitly inferred to be "ext4" if unspecified. More info: https://kubernetes.io/docs/concepts/storage/volumes#iscsi TODO: how do we prevent errors in the filesystem from compromising the machine
             */
            fsType?: string;
            /**
             * Custom iSCSI Initiator Name. If initiatorName is specified with iscsiInterface simultaneously, new iSCSI interface <target portal>:<volume name> will be created for the connection.
             */
            initiatorName?: string;
            /**
             * Target iSCSI Qualified Name.
             */
            iqn: string;
            /**
             * iSCSI Interface Name that uses an iSCSI transport. Defaults to 'default' (tcp).
             */
            iscsiInterface?: string;
            /**
             * iSCSI Target Lun number.
             */
            lun: number;
            /**
             * iSCSI Target Portal List. The portal is either an IP or ip_addr:port if the port is other than default (typically TCP ports 860 and 3260).
             */
            portals?: string[];
            /**
             * ReadOnly here will force the ReadOnly setting in VolumeMounts. Defaults to false.
             */
            readOnly?: boolean;
            /**
             * CHAP Secret for iSCSI target and initiator authentication
             */
            secretRef?: outputs.monitoring.v1.AlertmanagerSpecVolumesIscsiSecretRef;
            /**
             * iSCSI Target Portal. The Portal is either an IP or ip_addr:port if the port is other than default (typically TCP ports 860 and 3260).
             */
            targetPortal: string;
        }

        /**
         * CHAP Secret for iSCSI target and initiator authentication
         */
        export interface AlertmanagerSpecVolumesIscsiSecretRef {
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
        }

        /**
         * NFS represents an NFS mount on the host that shares a pod's lifetime More info: https://kubernetes.io/docs/concepts/storage/volumes#nfs
         */
        export interface AlertmanagerSpecVolumesNfs {
            /**
             * Path that is exported by the NFS server. More info: https://kubernetes.io/docs/concepts/storage/volumes#nfs
             */
            path: string;
            /**
             * ReadOnly here will force the NFS export to be mounted with read-only permissions. Defaults to false. More info: https://kubernetes.io/docs/concepts/storage/volumes#nfs
             */
            readOnly?: boolean;
            /**
             * Server is the hostname or IP address of the NFS server. More info: https://kubernetes.io/docs/concepts/storage/volumes#nfs
             */
            server: string;
        }

        /**
         * PersistentVolumeClaimVolumeSource represents a reference to a PersistentVolumeClaim in the same namespace. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#persistentvolumeclaims
         */
        export interface AlertmanagerSpecVolumesPersistentVolumeClaim {
            /**
             * ClaimName is the name of a PersistentVolumeClaim in the same namespace as the pod using this volume. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#persistentvolumeclaims
             */
            claimName: string;
            /**
             * Will force the ReadOnly setting in VolumeMounts. Default false.
             */
            readOnly?: boolean;
        }

        /**
         * PhotonPersistentDisk represents a PhotonController persistent disk attached and mounted on kubelets host machine
         */
        export interface AlertmanagerSpecVolumesPhotonPersistentDisk {
            /**
             * Filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. "ext4", "xfs", "ntfs". Implicitly inferred to be "ext4" if unspecified.
             */
            fsType?: string;
            /**
             * ID that identifies Photon Controller persistent disk
             */
            pdID: string;
        }

        /**
         * PortworxVolume represents a portworx volume attached and mounted on kubelets host machine
         */
        export interface AlertmanagerSpecVolumesPortworxVolume {
            /**
             * FSType represents the filesystem type to mount Must be a filesystem type supported by the host operating system. Ex. "ext4", "xfs". Implicitly inferred to be "ext4" if unspecified.
             */
            fsType?: string;
            /**
             * Defaults to false (read/write). ReadOnly here will force the ReadOnly setting in VolumeMounts.
             */
            readOnly?: boolean;
            /**
             * VolumeID uniquely identifies a Portworx volume
             */
            volumeID: string;
        }

        /**
         * Items for all in one resources secrets, configmaps, and downward API
         */
        export interface AlertmanagerSpecVolumesProjected {
            /**
             * Mode bits to use on created files by default. Must be a value between 0 and 0777. Directories within the path are not affected by this setting. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set.
             */
            defaultMode?: number;
            /**
             * list of volume projections
             */
            sources: outputs.monitoring.v1.AlertmanagerSpecVolumesProjectedSources[];
        }

        /**
         * Projection that may be projected along with other supported volume types
         */
        export interface AlertmanagerSpecVolumesProjectedSources {
            /**
             * information about the configMap data to project
             */
            configMap?: outputs.monitoring.v1.AlertmanagerSpecVolumesProjectedSourcesConfigMap;
            /**
             * information about the downwardAPI data to project
             */
            downwardAPI?: outputs.monitoring.v1.AlertmanagerSpecVolumesProjectedSourcesDownwardAPI;
            /**
             * information about the secret data to project
             */
            secret?: outputs.monitoring.v1.AlertmanagerSpecVolumesProjectedSourcesSecret;
            /**
             * information about the serviceAccountToken data to project
             */
            serviceAccountToken?: outputs.monitoring.v1.AlertmanagerSpecVolumesProjectedSourcesServiceAccountToken;
        }

        /**
         * information about the configMap data to project
         */
        export interface AlertmanagerSpecVolumesProjectedSourcesConfigMap {
            /**
             * If unspecified, each key-value pair in the Data field of the referenced ConfigMap will be projected into the volume as a file whose name is the key and content is the value. If specified, the listed keys will be projected into the specified paths, and unlisted keys will not be present. If a key is specified which is not present in the ConfigMap, the volume setup will error unless it is marked optional. Paths must be relative and may not contain the '..' path or start with '..'.
             */
            items?: outputs.monitoring.v1.AlertmanagerSpecVolumesProjectedSourcesConfigMapItems[];
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the ConfigMap or its keys must be defined
             */
            optional?: boolean;
        }

        /**
         * Maps a string key to a path within a volume.
         */
        export interface AlertmanagerSpecVolumesProjectedSourcesConfigMapItems {
            /**
             * The key to project.
             */
            key: string;
            /**
             * Optional: mode bits to use on this file, must be a value between 0 and 0777. If not specified, the volume defaultMode will be used. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set.
             */
            mode?: number;
            /**
             * The relative path of the file to map the key to. May not be an absolute path. May not contain the path element '..'. May not start with the string '..'.
             */
            path: string;
        }

        /**
         * information about the downwardAPI data to project
         */
        export interface AlertmanagerSpecVolumesProjectedSourcesDownwardAPI {
            /**
             * Items is a list of DownwardAPIVolume file
             */
            items?: outputs.monitoring.v1.AlertmanagerSpecVolumesProjectedSourcesDownwardAPIItems[];
        }

        /**
         * DownwardAPIVolumeFile represents information to create the file containing the pod field
         */
        export interface AlertmanagerSpecVolumesProjectedSourcesDownwardAPIItems {
            /**
             * Required: Selects a field of the pod: only annotations, labels, name and namespace are supported.
             */
            fieldRef?: outputs.monitoring.v1.AlertmanagerSpecVolumesProjectedSourcesDownwardAPIItemsFieldRef;
            /**
             * Optional: mode bits to use on this file, must be a value between 0 and 0777. If not specified, the volume defaultMode will be used. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set.
             */
            mode?: number;
            /**
             * Required: Path is  the relative path name of the file to be created. Must not be absolute or contain the '..' path. Must be utf-8 encoded. The first item of the relative path must not start with '..'
             */
            path: string;
            /**
             * Selects a resource of the container: only resources limits and requests (limits.cpu, limits.memory, requests.cpu and requests.memory) are currently supported.
             */
            resourceFieldRef?: outputs.monitoring.v1.AlertmanagerSpecVolumesProjectedSourcesDownwardAPIItemsResourceFieldRef;
        }

        /**
         * Required: Selects a field of the pod: only annotations, labels, name and namespace are supported.
         */
        export interface AlertmanagerSpecVolumesProjectedSourcesDownwardAPIItemsFieldRef {
            /**
             * Version of the schema the FieldPath is written in terms of, defaults to "v1".
             */
            apiVersion?: string;
            /**
             * Path of the field to select in the specified API version.
             */
            fieldPath: string;
        }

        /**
         * Selects a resource of the container: only resources limits and requests (limits.cpu, limits.memory, requests.cpu and requests.memory) are currently supported.
         */
        export interface AlertmanagerSpecVolumesProjectedSourcesDownwardAPIItemsResourceFieldRef {
            /**
             * Container name: required for volumes, optional for env vars
             */
            containerName?: string;
            /**
             * Specifies the output format of the exposed resources, defaults to "1"
             */
            divisor?: outputs.monitoring.v1.AlertmanagerSpecVolumesProjectedSourcesDownwardAPIItemsResourceFieldRefDivisor;
            /**
             * Required: resource to select
             */
            resource: string;
        }

        export interface AlertmanagerSpecVolumesProjectedSourcesDownwardAPIItemsResourceFieldRefDivisor {
        }

        /**
         * information about the secret data to project
         */
        export interface AlertmanagerSpecVolumesProjectedSourcesSecret {
            /**
             * If unspecified, each key-value pair in the Data field of the referenced Secret will be projected into the volume as a file whose name is the key and content is the value. If specified, the listed keys will be projected into the specified paths, and unlisted keys will not be present. If a key is specified which is not present in the Secret, the volume setup will error unless it is marked optional. Paths must be relative and may not contain the '..' path or start with '..'.
             */
            items?: outputs.monitoring.v1.AlertmanagerSpecVolumesProjectedSourcesSecretItems[];
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Maps a string key to a path within a volume.
         */
        export interface AlertmanagerSpecVolumesProjectedSourcesSecretItems {
            /**
             * The key to project.
             */
            key: string;
            /**
             * Optional: mode bits to use on this file, must be a value between 0 and 0777. If not specified, the volume defaultMode will be used. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set.
             */
            mode?: number;
            /**
             * The relative path of the file to map the key to. May not be an absolute path. May not contain the path element '..'. May not start with the string '..'.
             */
            path: string;
        }

        /**
         * information about the serviceAccountToken data to project
         */
        export interface AlertmanagerSpecVolumesProjectedSourcesServiceAccountToken {
            /**
             * Audience is the intended audience of the token. A recipient of a token must identify itself with an identifier specified in the audience of the token, and otherwise should reject the token. The audience defaults to the identifier of the apiserver.
             */
            audience?: string;
            /**
             * ExpirationSeconds is the requested duration of validity of the service account token. As the token approaches expiration, the kubelet volume plugin will proactively rotate the service account token. The kubelet will start trying to rotate the token if the token is older than 80 percent of its time to live or if the token is older than 24 hours.Defaults to 1 hour and must be at least 10 minutes.
             */
            expirationSeconds?: number;
            /**
             * Path is the path relative to the mount point of the file to project the token into.
             */
            path: string;
        }

        /**
         * Quobyte represents a Quobyte mount on the host that shares a pod's lifetime
         */
        export interface AlertmanagerSpecVolumesQuobyte {
            /**
             * Group to map volume access to Default is no group
             */
            group?: string;
            /**
             * ReadOnly here will force the Quobyte volume to be mounted with read-only permissions. Defaults to false.
             */
            readOnly?: boolean;
            /**
             * Registry represents a single or multiple Quobyte Registry services specified as a string as host:port pair (multiple entries are separated with commas) which acts as the central registry for volumes
             */
            registry: string;
            /**
             * Tenant owning the given Quobyte volume in the Backend Used with dynamically provisioned Quobyte volumes, value is set by the plugin
             */
            tenant?: string;
            /**
             * User to map volume access to Defaults to serivceaccount user
             */
            user?: string;
            /**
             * Volume is a string that references an already created Quobyte volume by name.
             */
            volume: string;
        }

        /**
         * RBD represents a Rados Block Device mount on the host that shares a pod's lifetime. More info: https://examples.k8s.io/volumes/rbd/README.md
         */
        export interface AlertmanagerSpecVolumesRbd {
            /**
             * Filesystem type of the volume that you want to mount. Tip: Ensure that the filesystem type is supported by the host operating system. Examples: "ext4", "xfs", "ntfs". Implicitly inferred to be "ext4" if unspecified. More info: https://kubernetes.io/docs/concepts/storage/volumes#rbd TODO: how do we prevent errors in the filesystem from compromising the machine
             */
            fsType?: string;
            /**
             * The rados image name. More info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it
             */
            image: string;
            /**
             * Keyring is the path to key ring for RBDUser. Default is /etc/ceph/keyring. More info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it
             */
            keyring?: string;
            /**
             * A collection of Ceph monitors. More info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it
             */
            monitors: string[];
            /**
             * The rados pool name. Default is rbd. More info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it
             */
            pool?: string;
            /**
             * ReadOnly here will force the ReadOnly setting in VolumeMounts. Defaults to false. More info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it
             */
            readOnly?: boolean;
            /**
             * SecretRef is name of the authentication secret for RBDUser. If provided overrides keyring. Default is nil. More info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it
             */
            secretRef?: outputs.monitoring.v1.AlertmanagerSpecVolumesRbdSecretRef;
            /**
             * The rados user name. Default is admin. More info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it
             */
            user?: string;
        }

        /**
         * SecretRef is name of the authentication secret for RBDUser. If provided overrides keyring. Default is nil. More info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it
         */
        export interface AlertmanagerSpecVolumesRbdSecretRef {
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
        }

        /**
         * ScaleIO represents a ScaleIO persistent volume attached and mounted on Kubernetes nodes.
         */
        export interface AlertmanagerSpecVolumesScaleIO {
            /**
             * Filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. "ext4", "xfs", "ntfs". Default is "xfs".
             */
            fsType?: string;
            /**
             * The host address of the ScaleIO API Gateway.
             */
            gateway: string;
            /**
             * The name of the ScaleIO Protection Domain for the configured storage.
             */
            protectionDomain?: string;
            /**
             * Defaults to false (read/write). ReadOnly here will force the ReadOnly setting in VolumeMounts.
             */
            readOnly?: boolean;
            /**
             * SecretRef references to the secret for ScaleIO user and other sensitive information. If this is not provided, Login operation will fail.
             */
            secretRef: outputs.monitoring.v1.AlertmanagerSpecVolumesScaleIOSecretRef;
            /**
             * Flag to enable/disable SSL communication with Gateway, default false
             */
            sslEnabled?: boolean;
            /**
             * Indicates whether the storage for a volume should be ThickProvisioned or ThinProvisioned. Default is ThinProvisioned.
             */
            storageMode?: string;
            /**
             * The ScaleIO Storage Pool associated with the protection domain.
             */
            storagePool?: string;
            /**
             * The name of the storage system as configured in ScaleIO.
             */
            system: string;
            /**
             * The name of a volume already created in the ScaleIO system that is associated with this volume source.
             */
            volumeName?: string;
        }

        /**
         * SecretRef references to the secret for ScaleIO user and other sensitive information. If this is not provided, Login operation will fail.
         */
        export interface AlertmanagerSpecVolumesScaleIOSecretRef {
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
        }

        /**
         * Secret represents a secret that should populate this volume. More info: https://kubernetes.io/docs/concepts/storage/volumes#secret
         */
        export interface AlertmanagerSpecVolumesSecret {
            /**
             * Optional: mode bits to use on created files by default. Must be a value between 0 and 0777. Defaults to 0644. Directories within the path are not affected by this setting. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set.
             */
            defaultMode?: number;
            /**
             * If unspecified, each key-value pair in the Data field of the referenced Secret will be projected into the volume as a file whose name is the key and content is the value. If specified, the listed keys will be projected into the specified paths, and unlisted keys will not be present. If a key is specified which is not present in the Secret, the volume setup will error unless it is marked optional. Paths must be relative and may not contain the '..' path or start with '..'.
             */
            items?: outputs.monitoring.v1.AlertmanagerSpecVolumesSecretItems[];
            /**
             * Specify whether the Secret or its keys must be defined
             */
            optional?: boolean;
            /**
             * Name of the secret in the pod's namespace to use. More info: https://kubernetes.io/docs/concepts/storage/volumes#secret
             */
            secretName?: string;
        }

        /**
         * Maps a string key to a path within a volume.
         */
        export interface AlertmanagerSpecVolumesSecretItems {
            /**
             * The key to project.
             */
            key: string;
            /**
             * Optional: mode bits to use on this file, must be a value between 0 and 0777. If not specified, the volume defaultMode will be used. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set.
             */
            mode?: number;
            /**
             * The relative path of the file to map the key to. May not be an absolute path. May not contain the path element '..'. May not start with the string '..'.
             */
            path: string;
        }

        /**
         * StorageOS represents a StorageOS volume attached and mounted on Kubernetes nodes.
         */
        export interface AlertmanagerSpecVolumesStorageos {
            /**
             * Filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. "ext4", "xfs", "ntfs". Implicitly inferred to be "ext4" if unspecified.
             */
            fsType?: string;
            /**
             * Defaults to false (read/write). ReadOnly here will force the ReadOnly setting in VolumeMounts.
             */
            readOnly?: boolean;
            /**
             * SecretRef specifies the secret to use for obtaining the StorageOS API credentials.  If not specified, default values will be attempted.
             */
            secretRef?: outputs.monitoring.v1.AlertmanagerSpecVolumesStorageosSecretRef;
            /**
             * VolumeName is the human-readable name of the StorageOS volume.  Volume names are only unique within a namespace.
             */
            volumeName?: string;
            /**
             * VolumeNamespace specifies the scope of the volume within StorageOS.  If no namespace is specified then the Pod's namespace will be used.  This allows the Kubernetes name scoping to be mirrored within StorageOS for tighter integration. Set VolumeName to any name to override the default behaviour. Set to "default" if you are not using namespaces within StorageOS. Namespaces that do not pre-exist within StorageOS will be created.
             */
            volumeNamespace?: string;
        }

        /**
         * SecretRef specifies the secret to use for obtaining the StorageOS API credentials.  If not specified, default values will be attempted.
         */
        export interface AlertmanagerSpecVolumesStorageosSecretRef {
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
        }

        /**
         * VsphereVolume represents a vSphere volume attached and mounted on kubelets host machine
         */
        export interface AlertmanagerSpecVolumesVsphereVolume {
            /**
             * Filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. "ext4", "xfs", "ntfs". Implicitly inferred to be "ext4" if unspecified.
             */
            fsType?: string;
            /**
             * Storage Policy Based Management (SPBM) profile ID associated with the StoragePolicyName.
             */
            storagePolicyID?: string;
            /**
             * Storage Policy Based Management (SPBM) profile name.
             */
            storagePolicyName?: string;
            /**
             * Path that identifies vSphere volume vmdk
             */
            volumePath: string;
        }

        /**
         * Most recent observed status of the Alertmanager cluster. Read-only. Not included when requesting from the apiserver, only from the Prometheus Operator API itself. More info: https://github.com/kubernetes/community/blob/master/contributors/devel/sig-architecture/api-conventions.md#spec-and-status
         */
        export interface AlertmanagerStatus {
            /**
             * Total number of available pods (ready for at least minReadySeconds) targeted by this Alertmanager cluster.
             */
            availableReplicas: number;
            /**
             * Represents whether any actions on the underlying managed objects are being performed. Only delete actions will be performed.
             */
            paused: boolean;
            /**
             * Total number of non-terminated pods targeted by this Alertmanager cluster (their labels match the selector).
             */
            replicas: number;
            /**
             * Total number of unavailable pods targeted by this Alertmanager cluster.
             */
            unavailableReplicas: number;
            /**
             * Total number of non-terminated pods targeted by this Alertmanager cluster that have the desired version spec.
             */
            updatedReplicas: number;
        }

        /**
         * Specification of desired Pod selection for target discovery by Prometheus.
         */
        export interface PodMonitorSpec {
            /**
             * The label to use to retrieve the job name from.
             */
            jobLabel?: string;
            /**
             * Selector to select which namespaces the Endpoints objects are discovered from.
             */
            namespaceSelector?: outputs.monitoring.v1.PodMonitorSpecNamespaceSelector;
            /**
             * A list of endpoints allowed as part of this PodMonitor.
             */
            podMetricsEndpoints: outputs.monitoring.v1.PodMonitorSpecPodMetricsEndpoints[];
            /**
             * PodTargetLabels transfers labels on the Kubernetes Pod onto the target.
             */
            podTargetLabels?: string[];
            /**
             * SampleLimit defines per-scrape limit on number of scraped samples that will be accepted.
             */
            sampleLimit?: number;
            /**
             * Selector to select Pod objects.
             */
            selector: outputs.monitoring.v1.PodMonitorSpecSelector;
            /**
             * TargetLimit defines a limit on the number of scraped targets that will be accepted.
             */
            targetLimit?: number;
        }

        /**
         * Selector to select which namespaces the Endpoints objects are discovered from.
         */
        export interface PodMonitorSpecNamespaceSelector {
            /**
             * Boolean describing whether all namespaces are selected in contrast to a list restricting them.
             */
            any?: boolean;
            /**
             * List of namespace names.
             */
            matchNames?: string[];
        }

        /**
         * PodMetricsEndpoint defines a scrapeable endpoint of a Kubernetes Pod serving Prometheus metrics.
         */
        export interface PodMonitorSpecPodMetricsEndpoints {
            /**
             * BasicAuth allow an endpoint to authenticate over basic authentication. More info: https://prometheus.io/docs/operating/configuration/#endpoint
             */
            basicAuth?: outputs.monitoring.v1.PodMonitorSpecPodMetricsEndpointsBasicAuth;
            /**
             * Secret to mount to read bearer token for scraping targets. The secret needs to be in the same namespace as the pod monitor and accessible by the Prometheus Operator.
             */
            bearerTokenSecret?: outputs.monitoring.v1.PodMonitorSpecPodMetricsEndpointsBearerTokenSecret;
            /**
             * HonorLabels chooses the metric's labels on collisions with target labels.
             */
            honorLabels?: boolean;
            /**
             * HonorTimestamps controls whether Prometheus respects the timestamps present in scraped data.
             */
            honorTimestamps?: boolean;
            /**
             * Interval at which metrics should be scraped
             */
            interval?: string;
            /**
             * MetricRelabelConfigs to apply to samples before ingestion.
             */
            metricRelabelings?: outputs.monitoring.v1.PodMonitorSpecPodMetricsEndpointsMetricRelabelings[];
            /**
             * Optional HTTP URL parameters
             */
            params?: {[key: string]: string[]};
            /**
             * HTTP path to scrape for metrics.
             */
            path?: string;
            /**
             * Name of the pod port this endpoint refers to. Mutually exclusive with targetPort.
             */
            port?: string;
            /**
             * ProxyURL eg http://proxyserver:2195 Directs scrapes to proxy through this endpoint.
             */
            proxyUrl?: string;
            /**
             * RelabelConfigs to apply to samples before ingestion. More info: https://prometheus.io/docs/prometheus/latest/configuration/configuration/#relabel_config
             */
            relabelings?: outputs.monitoring.v1.PodMonitorSpecPodMetricsEndpointsRelabelings[];
            /**
             * HTTP scheme to use for scraping.
             */
            scheme?: string;
            /**
             * Timeout after which the scrape is ended
             */
            scrapeTimeout?: string;
            /**
             * Deprecated: Use 'port' instead.
             */
            targetPort?: outputs.monitoring.v1.PodMonitorSpecPodMetricsEndpointsTargetPort;
            /**
             * TLS configuration to use when scraping the endpoint.
             */
            tlsConfig?: outputs.monitoring.v1.PodMonitorSpecPodMetricsEndpointsTlsConfig;
        }

        /**
         * BasicAuth allow an endpoint to authenticate over basic authentication. More info: https://prometheus.io/docs/operating/configuration/#endpoint
         */
        export interface PodMonitorSpecPodMetricsEndpointsBasicAuth {
            /**
             * The secret in the service monitor namespace that contains the password for authentication.
             */
            password?: outputs.monitoring.v1.PodMonitorSpecPodMetricsEndpointsBasicAuthPassword;
            /**
             * The secret in the service monitor namespace that contains the username for authentication.
             */
            username?: outputs.monitoring.v1.PodMonitorSpecPodMetricsEndpointsBasicAuthUsername;
        }

        /**
         * The secret in the service monitor namespace that contains the password for authentication.
         */
        export interface PodMonitorSpecPodMetricsEndpointsBasicAuthPassword {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * The secret in the service monitor namespace that contains the username for authentication.
         */
        export interface PodMonitorSpecPodMetricsEndpointsBasicAuthUsername {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Secret to mount to read bearer token for scraping targets. The secret needs to be in the same namespace as the pod monitor and accessible by the Prometheus Operator.
         */
        export interface PodMonitorSpecPodMetricsEndpointsBearerTokenSecret {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * RelabelConfig allows dynamic rewriting of the label set, being applied to samples before ingestion. It defines `<metric_relabel_configs>`-section of Prometheus configuration. More info: https://prometheus.io/docs/prometheus/latest/configuration/configuration/#metric_relabel_configs
         */
        export interface PodMonitorSpecPodMetricsEndpointsMetricRelabelings {
            /**
             * Action to perform based on regex matching. Default is 'replace'
             */
            action?: string;
            /**
             * Modulus to take of the hash of the source label values.
             */
            modulus?: number;
            /**
             * Regular expression against which the extracted value is matched. Default is '(.*)'
             */
            regex?: string;
            /**
             * Replacement value against which a regex replace is performed if the regular expression matches. Regex capture groups are available. Default is '$1'
             */
            replacement?: string;
            /**
             * Separator placed between concatenated source label values. default is ';'.
             */
            separator?: string;
            /**
             * The source labels select values from existing labels. Their content is concatenated using the configured separator and matched against the configured regular expression for the replace, keep, and drop actions.
             */
            sourceLabels?: string[];
            /**
             * Label to which the resulting value is written in a replace action. It is mandatory for replace actions. Regex capture groups are available.
             */
            targetLabel?: string;
        }

        /**
         * RelabelConfig allows dynamic rewriting of the label set, being applied to samples before ingestion. It defines `<metric_relabel_configs>`-section of Prometheus configuration. More info: https://prometheus.io/docs/prometheus/latest/configuration/configuration/#metric_relabel_configs
         */
        export interface PodMonitorSpecPodMetricsEndpointsRelabelings {
            /**
             * Action to perform based on regex matching. Default is 'replace'
             */
            action?: string;
            /**
             * Modulus to take of the hash of the source label values.
             */
            modulus?: number;
            /**
             * Regular expression against which the extracted value is matched. Default is '(.*)'
             */
            regex?: string;
            /**
             * Replacement value against which a regex replace is performed if the regular expression matches. Regex capture groups are available. Default is '$1'
             */
            replacement?: string;
            /**
             * Separator placed between concatenated source label values. default is ';'.
             */
            separator?: string;
            /**
             * The source labels select values from existing labels. Their content is concatenated using the configured separator and matched against the configured regular expression for the replace, keep, and drop actions.
             */
            sourceLabels?: string[];
            /**
             * Label to which the resulting value is written in a replace action. It is mandatory for replace actions. Regex capture groups are available.
             */
            targetLabel?: string;
        }

        export interface PodMonitorSpecPodMetricsEndpointsTargetPort {
        }

        /**
         * TLS configuration to use when scraping the endpoint.
         */
        export interface PodMonitorSpecPodMetricsEndpointsTlsConfig {
            /**
             * Struct containing the CA cert to use for the targets.
             */
            ca?: outputs.monitoring.v1.PodMonitorSpecPodMetricsEndpointsTlsConfigCa;
            /**
             * Struct containing the client cert file for the targets.
             */
            cert?: outputs.monitoring.v1.PodMonitorSpecPodMetricsEndpointsTlsConfigCert;
            /**
             * Disable target certificate validation.
             */
            insecureSkipVerify?: boolean;
            /**
             * Secret containing the client key file for the targets.
             */
            keySecret?: outputs.monitoring.v1.PodMonitorSpecPodMetricsEndpointsTlsConfigKeySecret;
            /**
             * Used to verify the hostname for the targets.
             */
            serverName?: string;
        }

        /**
         * Struct containing the CA cert to use for the targets.
         */
        export interface PodMonitorSpecPodMetricsEndpointsTlsConfigCa {
            /**
             * ConfigMap containing data to use for the targets.
             */
            configMap?: outputs.monitoring.v1.PodMonitorSpecPodMetricsEndpointsTlsConfigCaConfigMap;
            /**
             * Secret containing data to use for the targets.
             */
            secret?: outputs.monitoring.v1.PodMonitorSpecPodMetricsEndpointsTlsConfigCaSecret;
        }

        /**
         * ConfigMap containing data to use for the targets.
         */
        export interface PodMonitorSpecPodMetricsEndpointsTlsConfigCaConfigMap {
            /**
             * The key to select.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the ConfigMap or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Secret containing data to use for the targets.
         */
        export interface PodMonitorSpecPodMetricsEndpointsTlsConfigCaSecret {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Struct containing the client cert file for the targets.
         */
        export interface PodMonitorSpecPodMetricsEndpointsTlsConfigCert {
            /**
             * ConfigMap containing data to use for the targets.
             */
            configMap?: outputs.monitoring.v1.PodMonitorSpecPodMetricsEndpointsTlsConfigCertConfigMap;
            /**
             * Secret containing data to use for the targets.
             */
            secret?: outputs.monitoring.v1.PodMonitorSpecPodMetricsEndpointsTlsConfigCertSecret;
        }

        /**
         * ConfigMap containing data to use for the targets.
         */
        export interface PodMonitorSpecPodMetricsEndpointsTlsConfigCertConfigMap {
            /**
             * The key to select.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the ConfigMap or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Secret containing data to use for the targets.
         */
        export interface PodMonitorSpecPodMetricsEndpointsTlsConfigCertSecret {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Secret containing the client key file for the targets.
         */
        export interface PodMonitorSpecPodMetricsEndpointsTlsConfigKeySecret {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Selector to select Pod objects.
         */
        export interface PodMonitorSpecSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.monitoring.v1.PodMonitorSpecSelectorMatchExpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface PodMonitorSpecSelectorMatchExpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Specification of desired Ingress selection for target discovery by Prometheus.
         */
        export interface ProbeSpec {
            /**
             * Interval at which targets are probed using the configured prober. If not specified Prometheus' global scrape interval is used.
             */
            interval?: string;
            /**
             * The job name assigned to scraped metrics by default.
             */
            jobName?: string;
            /**
             * The module to use for probing specifying how to probe the target. Example module configuring in the blackbox exporter: https://github.com/prometheus/blackbox_exporter/blob/master/example.yml
             */
            module?: string;
            /**
             * Specification for the prober to use for probing targets. The prober.URL parameter is required. Targets cannot be probed if left empty.
             */
            prober?: outputs.monitoring.v1.ProbeSpecProber;
            /**
             * Timeout for scraping metrics from the Prometheus exporter.
             */
            scrapeTimeout?: string;
            /**
             * Targets defines a set of static and/or dynamically discovered targets to be probed using the prober.
             */
            targets?: outputs.monitoring.v1.ProbeSpecTargets;
        }

        /**
         * Specification for the prober to use for probing targets. The prober.URL parameter is required. Targets cannot be probed if left empty.
         */
        export interface ProbeSpecProber {
            /**
             * Path to collect metrics from. Defaults to `/probe`.
             */
            path?: string;
            /**
             * HTTP scheme to use for scraping. Defaults to `http`.
             */
            scheme?: string;
            /**
             * Mandatory URL of the prober.
             */
            url: string;
        }

        /**
         * Targets defines a set of static and/or dynamically discovered targets to be probed using the prober.
         */
        export interface ProbeSpecTargets {
            /**
             * Ingress defines the set of dynamically discovered ingress objects which hosts are considered for probing.
             */
            ingress?: outputs.monitoring.v1.ProbeSpecTargetsIngress;
            /**
             * StaticConfig defines static targets which are considers for probing. More info: https://prometheus.io/docs/prometheus/latest/configuration/configuration/#static_config.
             */
            staticConfig?: outputs.monitoring.v1.ProbeSpecTargetsStaticConfig;
        }

        /**
         * Ingress defines the set of dynamically discovered ingress objects which hosts are considered for probing.
         */
        export interface ProbeSpecTargetsIngress {
            /**
             * Select Ingress objects by namespace.
             */
            namespaceSelector?: outputs.monitoring.v1.ProbeSpecTargetsIngressNamespaceSelector;
            /**
             * RelabelConfigs to apply to samples before ingestion. More info: https://prometheus.io/docs/prometheus/latest/configuration/configuration/#relabel_config
             */
            relabelingConfigs?: outputs.monitoring.v1.ProbeSpecTargetsIngressRelabelingConfigs[];
            /**
             * Select Ingress objects by labels.
             */
            selector?: outputs.monitoring.v1.ProbeSpecTargetsIngressSelector;
        }

        /**
         * Select Ingress objects by namespace.
         */
        export interface ProbeSpecTargetsIngressNamespaceSelector {
            /**
             * Boolean describing whether all namespaces are selected in contrast to a list restricting them.
             */
            any?: boolean;
            /**
             * List of namespace names.
             */
            matchNames?: string[];
        }

        /**
         * RelabelConfig allows dynamic rewriting of the label set, being applied to samples before ingestion. It defines `<metric_relabel_configs>`-section of Prometheus configuration. More info: https://prometheus.io/docs/prometheus/latest/configuration/configuration/#metric_relabel_configs
         */
        export interface ProbeSpecTargetsIngressRelabelingConfigs {
            /**
             * Action to perform based on regex matching. Default is 'replace'
             */
            action?: string;
            /**
             * Modulus to take of the hash of the source label values.
             */
            modulus?: number;
            /**
             * Regular expression against which the extracted value is matched. Default is '(.*)'
             */
            regex?: string;
            /**
             * Replacement value against which a regex replace is performed if the regular expression matches. Regex capture groups are available. Default is '$1'
             */
            replacement?: string;
            /**
             * Separator placed between concatenated source label values. default is ';'.
             */
            separator?: string;
            /**
             * The source labels select values from existing labels. Their content is concatenated using the configured separator and matched against the configured regular expression for the replace, keep, and drop actions.
             */
            sourceLabels?: string[];
            /**
             * Label to which the resulting value is written in a replace action. It is mandatory for replace actions. Regex capture groups are available.
             */
            targetLabel?: string;
        }

        /**
         * Select Ingress objects by labels.
         */
        export interface ProbeSpecTargetsIngressSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.monitoring.v1.ProbeSpecTargetsIngressSelectorMatchExpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ProbeSpecTargetsIngressSelectorMatchExpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * StaticConfig defines static targets which are considers for probing. More info: https://prometheus.io/docs/prometheus/latest/configuration/configuration/#static_config.
         */
        export interface ProbeSpecTargetsStaticConfig {
            /**
             * Labels assigned to all metrics scraped from the targets.
             */
            labels?: {[key: string]: string};
            /**
             * Targets is a list of URLs to probe using the configured prober.
             */
            static?: string[];
        }

        /**
         * Specification of desired alerting rule definitions for Prometheus.
         */
        export interface PrometheusRuleSpec {
            /**
             * Content of Prometheus rule file
             */
            groups?: outputs.monitoring.v1.PrometheusRuleSpecGroups[];
        }

        /**
         * RuleGroup is a list of sequentially evaluated recording and alerting rules. Note: PartialResponseStrategy is only used by ThanosRuler and will be ignored by Prometheus instances.  Valid values for this field are 'warn' or 'abort'.  More info: https://github.com/thanos-io/thanos/blob/master/docs/components/rule.md#partial-response
         */
        export interface PrometheusRuleSpecGroups {
            interval?: string;
            name: string;
            partial_response_strategy?: string;
            rules: outputs.monitoring.v1.PrometheusRuleSpecGroupsRules[];
        }

        /**
         * Rule describes an alerting or recording rule.
         */
        export interface PrometheusRuleSpecGroupsRules {
            alert?: string;
            annotations?: {[key: string]: string};
            expr: outputs.monitoring.v1.PrometheusRuleSpecGroupsRulesExpr;
            for?: string;
            labels?: {[key: string]: string};
            record?: string;
        }

        export interface PrometheusRuleSpecGroupsRulesExpr {
        }

        /**
         * Specification of the desired behavior of the Prometheus cluster. More info: https://github.com/kubernetes/community/blob/master/contributors/devel/sig-architecture/api-conventions.md#spec-and-status
         */
        export interface PrometheusSpec {
            /**
             * AdditionalAlertManagerConfigs allows specifying a key of a Secret containing additional Prometheus AlertManager configurations. AlertManager configurations specified are appended to the configurations generated by the Prometheus Operator. Job configurations specified must have the form as specified in the official Prometheus documentation: https://prometheus.io/docs/prometheus/latest/configuration/configuration/#alertmanager_config. As AlertManager configs are appended, the user is responsible to make sure it is valid. Note that using this feature may expose the possibility to break upgrades of Prometheus. It is advised to review Prometheus release notes to ensure that no incompatible AlertManager configs are going to break Prometheus after the upgrade.
             */
            additionalAlertManagerConfigs?: outputs.monitoring.v1.PrometheusSpecAdditionalAlertManagerConfigs;
            /**
             * AdditionalAlertRelabelConfigs allows specifying a key of a Secret containing additional Prometheus alert relabel configurations. Alert relabel configurations specified are appended to the configurations generated by the Prometheus Operator. Alert relabel configurations specified must have the form as specified in the official Prometheus documentation: https://prometheus.io/docs/prometheus/latest/configuration/configuration/#alert_relabel_configs. As alert relabel configs are appended, the user is responsible to make sure it is valid. Note that using this feature may expose the possibility to break upgrades of Prometheus. It is advised to review Prometheus release notes to ensure that no incompatible alert relabel configs are going to break Prometheus after the upgrade.
             */
            additionalAlertRelabelConfigs?: outputs.monitoring.v1.PrometheusSpecAdditionalAlertRelabelConfigs;
            /**
             * AdditionalScrapeConfigs allows specifying a key of a Secret containing additional Prometheus scrape configurations. Scrape configurations specified are appended to the configurations generated by the Prometheus Operator. Job configurations specified must have the form as specified in the official Prometheus documentation: https://prometheus.io/docs/prometheus/latest/configuration/configuration/#scrape_config. As scrape configs are appended, the user is responsible to make sure it is valid. Note that using this feature may expose the possibility to break upgrades of Prometheus. It is advised to review Prometheus release notes to ensure that no incompatible scrape configs are going to break Prometheus after the upgrade.
             */
            additionalScrapeConfigs?: outputs.monitoring.v1.PrometheusSpecAdditionalScrapeConfigs;
            /**
             * If specified, the pod's scheduling constraints.
             */
            affinity?: outputs.monitoring.v1.PrometheusSpecAffinity;
            /**
             * Define details regarding alerting.
             */
            alerting?: outputs.monitoring.v1.PrometheusSpecAlerting;
            /**
             * AllowOverlappingBlocks enables vertical compaction and vertical query merge in Prometheus. This is still experimental in Prometheus so it may change in any upcoming release.
             */
            allowOverlappingBlocks?: boolean;
            /**
             * APIServerConfig allows specifying a host and auth methods to access apiserver. If left empty, Prometheus is assumed to run inside of the cluster and will discover API servers automatically and use the pod's CA certificate and bearer token file at /var/run/secrets/kubernetes.io/serviceaccount/.
             */
            apiserverConfig?: outputs.monitoring.v1.PrometheusSpecApiserverConfig;
            /**
             * ArbitraryFSAccessThroughSMs configures whether configuration based on a service monitor can access arbitrary files on the file system of the Prometheus container e.g. bearer token files.
             */
            arbitraryFSAccessThroughSMs?: outputs.monitoring.v1.PrometheusSpecArbitraryFSAccessThroughSMs;
            /**
             * Base image to use for a Prometheus deployment. Deprecated: use 'image' instead
             */
            baseImage?: string;
            /**
             * ConfigMaps is a list of ConfigMaps in the same namespace as the Prometheus object, which shall be mounted into the Prometheus Pods. The ConfigMaps are mounted into /etc/prometheus/configmaps/<configmap-name>.
             */
            configMaps?: string[];
            /**
             * Containers allows injecting additional containers or modifying operator generated containers. This can be used to allow adding an authentication proxy to a Prometheus pod or to change the behavior of an operator generated container. Containers described here modify an operator generated container if they share the same name and modifications are done via a strategic merge patch. The current container names are: `prometheus`, `config-reloader`, and `thanos-sidecar`. Overriding containers is entirely outside the scope of what the maintainers will support and by doing so, you accept that this behaviour may break at any time without notice.
             */
            containers?: outputs.monitoring.v1.PrometheusSpecContainers[];
            /**
             * Disable prometheus compaction.
             */
            disableCompaction?: boolean;
            /**
             * Enable access to prometheus web admin API. Defaults to the value of `false`. WARNING: Enabling the admin APIs enables mutating endpoints, to delete data, shutdown Prometheus, and more. Enabling this should be done with care and the user is advised to add additional authentication authorization via a proxy to ensure only clients authorized to perform these actions can do so. For more information see https://prometheus.io/docs/prometheus/latest/querying/api/#tsdb-admin-apis
             */
            enableAdminAPI?: boolean;
            /**
             * EnforcedNamespaceLabel enforces adding a namespace label of origin for each alert and metric that is user created. The label value will always be the namespace of the object that is being created.
             */
            enforcedNamespaceLabel?: string;
            /**
             * EnforcedSampleLimit defines global limit on number of scraped samples that will be accepted. This overrides any SampleLimit set per ServiceMonitor or/and PodMonitor. It is meant to be used by admins to enforce the SampleLimit to keep overall number of samples/series under the desired limit. Note that if SampleLimit is lower that value will be taken instead.
             */
            enforcedSampleLimit?: number;
            /**
             * EnforcedTargetLimit defines a global limit on the number of scraped targets. This overrides any TargetLimit set per ServiceMonitor or/and PodMonitor. It is meant to be used by admins to enforce the TargetLimit to keep overall number of targets under the desired limit. Note that if TargetLimit is higher that value will be taken instead.
             */
            enforcedTargetLimit?: number;
            /**
             * Interval between consecutive evaluations.
             */
            evaluationInterval?: string;
            /**
             * The labels to add to any time series or alerts when communicating with external systems (federation, remote storage, Alertmanager).
             */
            externalLabels?: {[key: string]: string};
            /**
             * The external URL the Prometheus instances will be available under. This is necessary to generate correct URLs. This is necessary if Prometheus is not served from root of a DNS name.
             */
            externalUrl?: string;
            /**
             * IgnoreNamespaceSelectors if set to true will ignore NamespaceSelector settings from the podmonitor and servicemonitor configs, and they will only discover endpoints within their current namespace.  Defaults to false.
             */
            ignoreNamespaceSelectors?: boolean;
            /**
             * Image if specified has precedence over baseImage, tag and sha combinations. Specifying the version is still necessary to ensure the Prometheus Operator knows what version of Prometheus is being configured.
             */
            image?: string;
            /**
             * An optional list of references to secrets in the same namespace to use for pulling prometheus and alertmanager images from registries see http://kubernetes.io/docs/user-guide/images#specifying-imagepullsecrets-on-a-pod
             */
            imagePullSecrets?: outputs.monitoring.v1.PrometheusSpecImagePullSecrets[];
            /**
             * InitContainers allows adding initContainers to the pod definition. Those can be used to e.g. fetch secrets for injection into the Prometheus configuration from external sources. Any errors during the execution of an initContainer will lead to a restart of the Pod. More info: https://kubernetes.io/docs/concepts/workloads/pods/init-containers/ Using initContainers for any use case other then secret fetching is entirely outside the scope of what the maintainers will support and by doing so, you accept that this behaviour may break at any time without notice.
             */
            initContainers?: outputs.monitoring.v1.PrometheusSpecInitContainers[];
            /**
             * ListenLocal makes the Prometheus server listen on loopback, so that it does not bind against the Pod IP.
             */
            listenLocal?: boolean;
            /**
             * Log format for Prometheus to be configured with.
             */
            logFormat?: string;
            /**
             * Log level for Prometheus to be configured with.
             */
            logLevel?: string;
            /**
             * Define which Nodes the Pods are scheduled on.
             */
            nodeSelector?: {[key: string]: string};
            /**
             * OverrideHonorLabels if set to true overrides all user configured honor_labels. If HonorLabels is set in ServiceMonitor or PodMonitor to true, this overrides honor_labels to false.
             */
            overrideHonorLabels?: boolean;
            /**
             * OverrideHonorTimestamps allows to globally enforce honoring timestamps in all scrape configs.
             */
            overrideHonorTimestamps?: boolean;
            /**
             * When a Prometheus deployment is paused, no actions except for deletion will be performed on the underlying objects.
             */
            paused?: boolean;
            /**
             * PodMetadata configures Labels and Annotations which are propagated to the prometheus pods.
             */
            podMetadata?: outputs.monitoring.v1.PrometheusSpecPodMetadata;
            /**
             * Namespaces to be selected for PodMonitor discovery. If nil, only check own namespace.
             */
            podMonitorNamespaceSelector?: outputs.monitoring.v1.PrometheusSpecPodMonitorNamespaceSelector;
            /**
             * *Experimental* PodMonitors to be selected for target discovery. *Deprecated:* if neither this nor serviceMonitorSelector are specified, configuration is unmanaged.
             */
            podMonitorSelector?: outputs.monitoring.v1.PrometheusSpecPodMonitorSelector;
            /**
             * Port name used for the pods and governing service. This defaults to web
             */
            portName?: string;
            /**
             * Priority class assigned to the Pods
             */
            priorityClassName?: string;
            /**
             * *Experimental* Namespaces to be selected for Probe discovery. If nil, only check own namespace.
             */
            probeNamespaceSelector?: outputs.monitoring.v1.PrometheusSpecProbeNamespaceSelector;
            /**
             * *Experimental* Probes to be selected for target discovery.
             */
            probeSelector?: outputs.monitoring.v1.PrometheusSpecProbeSelector;
            /**
             * Name of Prometheus external label used to denote Prometheus instance name. Defaults to the value of `prometheus`. External label will _not_ be added when value is set to empty string (`""`).
             */
            prometheusExternalLabelName?: string;
            /**
             * PrometheusRulesExcludedFromEnforce - list of prometheus rules to be excluded from enforcing of adding namespace labels. Works only if enforcedNamespaceLabel set to true. Make sure both ruleNamespace and ruleName are set for each pair
             */
            prometheusRulesExcludedFromEnforce?: outputs.monitoring.v1.PrometheusSpecPrometheusRulesExcludedFromEnforce[];
            /**
             * QuerySpec defines the query command line flags when starting Prometheus.
             */
            query?: outputs.monitoring.v1.PrometheusSpecQuery;
            /**
             * QueryLogFile specifies the file to which PromQL queries are logged. Note that this location must be writable, and can be persisted using an attached volume. Alternatively, the location can be set to a stdout location such as `/dev/stdout` to log querie information to the default Prometheus log stream. This is only available in versions of Prometheus >= 2.16.0. For more details, see the Prometheus docs (https://prometheus.io/docs/guides/query-log/)
             */
            queryLogFile?: string;
            /**
             * If specified, the remote_read spec. This is an experimental feature, it may change in any upcoming release in a breaking way.
             */
            remoteRead?: outputs.monitoring.v1.PrometheusSpecRemoteRead[];
            /**
             * If specified, the remote_write spec. This is an experimental feature, it may change in any upcoming release in a breaking way.
             */
            remoteWrite?: outputs.monitoring.v1.PrometheusSpecRemoteWrite[];
            /**
             * Name of Prometheus external label used to denote replica name. Defaults to the value of `prometheus_replica`. External label will _not_ be added when value is set to empty string (`""`).
             */
            replicaExternalLabelName?: string;
            /**
             * Number of replicas of each shard to deploy for a Prometheus deployment. Number of replicas multiplied by shards is the total number of Pods created.
             */
            replicas?: number;
            /**
             * Define resources requests and limits for single Pods.
             */
            resources?: outputs.monitoring.v1.PrometheusSpecResources;
            /**
             * Time duration Prometheus shall retain data for. Default is '24h', and must match the regular expression `[0-9]+(ms|s|m|h|d|w|y)` (milliseconds seconds minutes hours days weeks years).
             */
            retention?: string;
            /**
             * Maximum amount of disk space used by blocks.
             */
            retentionSize?: string;
            /**
             * The route prefix Prometheus registers HTTP handlers for. This is useful, if using ExternalURL and a proxy is rewriting HTTP routes of a request, and the actual ExternalURL is still true, but the server serves requests under a different route prefix. For example for use with `kubectl proxy`.
             */
            routePrefix?: string;
            /**
             * Namespaces to be selected for PrometheusRules discovery. If unspecified, only the same namespace as the Prometheus object is in is used.
             */
            ruleNamespaceSelector?: outputs.monitoring.v1.PrometheusSpecRuleNamespaceSelector;
            /**
             * A selector to select which PrometheusRules to mount for loading alerting/recording rules from. Until (excluding) Prometheus Operator v0.24.0 Prometheus Operator will migrate any legacy rule ConfigMaps to PrometheusRule custom resources selected by RuleSelector. Make sure it does not match any config maps that you do not want to be migrated.
             */
            ruleSelector?: outputs.monitoring.v1.PrometheusSpecRuleSelector;
            /**
             * /--rules.*&#47; command-line arguments.
             */
            rules?: outputs.monitoring.v1.PrometheusSpecRules;
            /**
             * Interval between consecutive scrapes.
             */
            scrapeInterval?: string;
            /**
             * Number of seconds to wait for target to respond before erroring.
             */
            scrapeTimeout?: string;
            /**
             * Secrets is a list of Secrets in the same namespace as the Prometheus object, which shall be mounted into the Prometheus Pods. The Secrets are mounted into /etc/prometheus/secrets/<secret-name>.
             */
            secrets?: string[];
            /**
             * SecurityContext holds pod-level security attributes and common container settings. This defaults to the default PodSecurityContext.
             */
            securityContext?: outputs.monitoring.v1.PrometheusSpecSecurityContext;
            /**
             * ServiceAccountName is the name of the ServiceAccount to use to run the Prometheus Pods.
             */
            serviceAccountName?: string;
            /**
             * Namespaces to be selected for ServiceMonitor discovery. If nil, only check own namespace.
             */
            serviceMonitorNamespaceSelector?: outputs.monitoring.v1.PrometheusSpecServiceMonitorNamespaceSelector;
            /**
             * ServiceMonitors to be selected for target discovery. *Deprecated:* if neither this nor podMonitorSelector are specified, configuration is unmanaged.
             */
            serviceMonitorSelector?: outputs.monitoring.v1.PrometheusSpecServiceMonitorSelector;
            /**
             * SHA of Prometheus container image to be deployed. Defaults to the value of `version`. Similar to a tag, but the SHA explicitly deploys an immutable container image. Version and Tag are ignored if SHA is set. Deprecated: use 'image' instead.  The image digest can be specified as part of the image URL.
             */
            sha?: string;
            /**
             * EXPERIMENTAL: Number of shards to distribute targets onto. Number of replicas multiplied by shards is the total number of Pods created. Note that scaling down shards will not reshard data onto remaining instances, it must be manually moved. Increasing shards will not reshard data either but it will continue to be available from the same instances. To query globally use Thanos sidecar and Thanos querier or remote write data to a central location. Sharding is done on the content of the `__address__` target meta-label.
             */
            shards?: number;
            /**
             * Storage spec to specify how storage shall be used.
             */
            storage?: outputs.monitoring.v1.PrometheusSpecStorage;
            /**
             * Tag of Prometheus container image to be deployed. Defaults to the value of `version`. Version is ignored if Tag is set. Deprecated: use 'image' instead.  The image tag can be specified as part of the image URL.
             */
            tag?: string;
            /**
             * Thanos configuration allows configuring various aspects of a Prometheus server in a Thanos environment. 
             *  This section is experimental, it may change significantly without deprecation notice in any release. 
             *  This is experimental and may change significantly without backward compatibility in any release.
             */
            thanos?: outputs.monitoring.v1.PrometheusSpecThanos;
            /**
             * If specified, the pod's tolerations.
             */
            tolerations?: outputs.monitoring.v1.PrometheusSpecTolerations[];
            /**
             * If specified, the pod's topology spread constraints.
             */
            topologySpreadConstraints?: outputs.monitoring.v1.PrometheusSpecTopologySpreadConstraints[];
            /**
             * Version of Prometheus to be deployed.
             */
            version?: string;
            /**
             * VolumeMounts allows configuration of additional VolumeMounts on the output StatefulSet definition. VolumeMounts specified will be appended to other VolumeMounts in the prometheus container, that are generated as a result of StorageSpec objects.
             */
            volumeMounts?: outputs.monitoring.v1.PrometheusSpecVolumeMounts[];
            /**
             * Volumes allows configuration of additional volumes on the output StatefulSet definition. Volumes specified will be appended to other volumes that are generated as a result of StorageSpec objects.
             */
            volumes?: outputs.monitoring.v1.PrometheusSpecVolumes[];
            /**
             * Enable compression of the write-ahead log using Snappy. This flag is only available in versions of Prometheus >= 2.11.0.
             */
            walCompression?: boolean;
            /**
             * WebSpec defines the web command line flags when starting Prometheus.
             */
            web?: outputs.monitoring.v1.PrometheusSpecWeb;
        }

        /**
         * AdditionalAlertManagerConfigs allows specifying a key of a Secret containing additional Prometheus AlertManager configurations. AlertManager configurations specified are appended to the configurations generated by the Prometheus Operator. Job configurations specified must have the form as specified in the official Prometheus documentation: https://prometheus.io/docs/prometheus/latest/configuration/configuration/#alertmanager_config. As AlertManager configs are appended, the user is responsible to make sure it is valid. Note that using this feature may expose the possibility to break upgrades of Prometheus. It is advised to review Prometheus release notes to ensure that no incompatible AlertManager configs are going to break Prometheus after the upgrade.
         */
        export interface PrometheusSpecAdditionalAlertManagerConfigs {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * AdditionalAlertRelabelConfigs allows specifying a key of a Secret containing additional Prometheus alert relabel configurations. Alert relabel configurations specified are appended to the configurations generated by the Prometheus Operator. Alert relabel configurations specified must have the form as specified in the official Prometheus documentation: https://prometheus.io/docs/prometheus/latest/configuration/configuration/#alert_relabel_configs. As alert relabel configs are appended, the user is responsible to make sure it is valid. Note that using this feature may expose the possibility to break upgrades of Prometheus. It is advised to review Prometheus release notes to ensure that no incompatible alert relabel configs are going to break Prometheus after the upgrade.
         */
        export interface PrometheusSpecAdditionalAlertRelabelConfigs {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * AdditionalScrapeConfigs allows specifying a key of a Secret containing additional Prometheus scrape configurations. Scrape configurations specified are appended to the configurations generated by the Prometheus Operator. Job configurations specified must have the form as specified in the official Prometheus documentation: https://prometheus.io/docs/prometheus/latest/configuration/configuration/#scrape_config. As scrape configs are appended, the user is responsible to make sure it is valid. Note that using this feature may expose the possibility to break upgrades of Prometheus. It is advised to review Prometheus release notes to ensure that no incompatible scrape configs are going to break Prometheus after the upgrade.
         */
        export interface PrometheusSpecAdditionalScrapeConfigs {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * If specified, the pod's scheduling constraints.
         */
        export interface PrometheusSpecAffinity {
            /**
             * Describes node affinity scheduling rules for the pod.
             */
            nodeAffinity?: outputs.monitoring.v1.PrometheusSpecAffinityNodeAffinity;
            /**
             * Describes pod affinity scheduling rules (e.g. co-locate this pod in the same node, zone, etc. as some other pod(s)).
             */
            podAffinity?: outputs.monitoring.v1.PrometheusSpecAffinityPodAffinity;
            /**
             * Describes pod anti-affinity scheduling rules (e.g. avoid putting this pod in the same node, zone, etc. as some other pod(s)).
             */
            podAntiAffinity?: outputs.monitoring.v1.PrometheusSpecAffinityPodAntiAffinity;
        }

        /**
         * Describes node affinity scheduling rules for the pod.
         */
        export interface PrometheusSpecAffinityNodeAffinity {
            /**
             * The scheduler will prefer to schedule pods to nodes that satisfy the affinity expressions specified by this field, but it may choose a node that violates one or more of the expressions. The node that is most preferred is the one with the greatest sum of weights, i.e. for each node that meets all of the scheduling requirements (resource request, requiredDuringScheduling affinity expressions, etc.), compute a sum by iterating through the elements of this field and adding "weight" to the sum if the node matches the corresponding matchExpressions; the node(s) with the highest sum are the most preferred.
             */
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.monitoring.v1.PrometheusSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            /**
             * If the affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to an update), the system may or may not try to eventually evict the pod from its node.
             */
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.monitoring.v1.PrometheusSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution;
        }

        /**
         * An empty preferred scheduling term matches all objects with implicit weight 0 (i.e. it's a no-op). A null preferred scheduling term matches no objects (i.e. is also a no-op).
         */
        export interface PrometheusSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            /**
             * A node selector term, associated with the corresponding weight.
             */
            preference: outputs.monitoring.v1.PrometheusSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference;
            /**
             * Weight associated with matching the corresponding nodeSelectorTerm, in the range 1-100.
             */
            weight: number;
        }

        /**
         * A node selector term, associated with the corresponding weight.
         */
        export interface PrometheusSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference {
            /**
             * A list of node selector requirements by node's labels.
             */
            matchExpressions?: outputs.monitoring.v1.PrometheusSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions[];
            /**
             * A list of node selector requirements by node's fields.
             */
            matchFields?: outputs.monitoring.v1.PrometheusSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields[];
        }

        /**
         * A node selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface PrometheusSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions {
            /**
             * The label key that the selector applies to.
             */
            key: string;
            /**
             * Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
             */
            operator: string;
            /**
             * An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * A node selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface PrometheusSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields {
            /**
             * The label key that the selector applies to.
             */
            key: string;
            /**
             * Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
             */
            operator: string;
            /**
             * An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * If the affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to an update), the system may or may not try to eventually evict the pod from its node.
         */
        export interface PrometheusSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            /**
             * Required. A list of node selector terms. The terms are ORed.
             */
            nodeSelectorTerms: outputs.monitoring.v1.PrometheusSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms[];
        }

        /**
         * A null or empty node selector term matches no objects. The requirements of them are ANDed. The TopologySelectorTerm type implements a subset of the NodeSelectorTerm.
         */
        export interface PrometheusSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms {
            /**
             * A list of node selector requirements by node's labels.
             */
            matchExpressions?: outputs.monitoring.v1.PrometheusSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions[];
            /**
             * A list of node selector requirements by node's fields.
             */
            matchFields?: outputs.monitoring.v1.PrometheusSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields[];
        }

        /**
         * A node selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface PrometheusSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions {
            /**
             * The label key that the selector applies to.
             */
            key: string;
            /**
             * Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
             */
            operator: string;
            /**
             * An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * A node selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface PrometheusSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields {
            /**
             * The label key that the selector applies to.
             */
            key: string;
            /**
             * Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
             */
            operator: string;
            /**
             * An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Describes pod affinity scheduling rules (e.g. co-locate this pod in the same node, zone, etc. as some other pod(s)).
         */
        export interface PrometheusSpecAffinityPodAffinity {
            /**
             * The scheduler will prefer to schedule pods to nodes that satisfy the affinity expressions specified by this field, but it may choose a node that violates one or more of the expressions. The node that is most preferred is the one with the greatest sum of weights, i.e. for each node that meets all of the scheduling requirements (resource request, requiredDuringScheduling affinity expressions, etc.), compute a sum by iterating through the elements of this field and adding "weight" to the sum if the node has pods which matches the corresponding podAffinityTerm; the node(s) with the highest sum are the most preferred.
             */
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.monitoring.v1.PrometheusSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            /**
             * If the affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to a pod label update), the system may or may not try to eventually evict the pod from its node. When there are multiple elements, the lists of nodes corresponding to each podAffinityTerm are intersected, i.e. all terms must be satisfied.
             */
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.monitoring.v1.PrometheusSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        /**
         * The weights of all of the matched WeightedPodAffinityTerm fields are added per-node to find the most preferred node(s)
         */
        export interface PrometheusSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            /**
             * Required. A pod affinity term, associated with the corresponding weight.
             */
            podAffinityTerm: outputs.monitoring.v1.PrometheusSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            /**
             * weight associated with matching the corresponding podAffinityTerm, in the range 1-100.
             */
            weight: number;
        }

        /**
         * Required. A pod affinity term, associated with the corresponding weight.
         */
        export interface PrometheusSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            /**
             * A label query over a set of resources, in this case pods.
             */
            labelSelector?: outputs.monitoring.v1.PrometheusSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            /**
             * namespaces specifies which namespaces the labelSelector applies to (matches against); null or empty list means "this pod's namespace"
             */
            namespaces?: string[];
            /**
             * This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed.
             */
            topologyKey: string;
        }

        /**
         * A label query over a set of resources, in this case pods.
         */
        export interface PrometheusSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.monitoring.v1.PrometheusSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface PrometheusSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Defines a set of pods (namely those matching the labelSelector relative to the given namespace(s)) that this pod should be co-located (affinity) or not co-located (anti-affinity) with, where co-located is defined as running on a node whose value of the label with key <topologyKey> matches that of any node on which a pod of the set of pods is running
         */
        export interface PrometheusSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            /**
             * A label query over a set of resources, in this case pods.
             */
            labelSelector?: outputs.monitoring.v1.PrometheusSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            /**
             * namespaces specifies which namespaces the labelSelector applies to (matches against); null or empty list means "this pod's namespace"
             */
            namespaces?: string[];
            /**
             * This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed.
             */
            topologyKey: string;
        }

        /**
         * A label query over a set of resources, in this case pods.
         */
        export interface PrometheusSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.monitoring.v1.PrometheusSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface PrometheusSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Describes pod anti-affinity scheduling rules (e.g. avoid putting this pod in the same node, zone, etc. as some other pod(s)).
         */
        export interface PrometheusSpecAffinityPodAntiAffinity {
            /**
             * The scheduler will prefer to schedule pods to nodes that satisfy the anti-affinity expressions specified by this field, but it may choose a node that violates one or more of the expressions. The node that is most preferred is the one with the greatest sum of weights, i.e. for each node that meets all of the scheduling requirements (resource request, requiredDuringScheduling anti-affinity expressions, etc.), compute a sum by iterating through the elements of this field and adding "weight" to the sum if the node has pods which matches the corresponding podAffinityTerm; the node(s) with the highest sum are the most preferred.
             */
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.monitoring.v1.PrometheusSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            /**
             * If the anti-affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the anti-affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to a pod label update), the system may or may not try to eventually evict the pod from its node. When there are multiple elements, the lists of nodes corresponding to each podAffinityTerm are intersected, i.e. all terms must be satisfied.
             */
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.monitoring.v1.PrometheusSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        /**
         * The weights of all of the matched WeightedPodAffinityTerm fields are added per-node to find the most preferred node(s)
         */
        export interface PrometheusSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            /**
             * Required. A pod affinity term, associated with the corresponding weight.
             */
            podAffinityTerm: outputs.monitoring.v1.PrometheusSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            /**
             * weight associated with matching the corresponding podAffinityTerm, in the range 1-100.
             */
            weight: number;
        }

        /**
         * Required. A pod affinity term, associated with the corresponding weight.
         */
        export interface PrometheusSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            /**
             * A label query over a set of resources, in this case pods.
             */
            labelSelector?: outputs.monitoring.v1.PrometheusSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            /**
             * namespaces specifies which namespaces the labelSelector applies to (matches against); null or empty list means "this pod's namespace"
             */
            namespaces?: string[];
            /**
             * This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed.
             */
            topologyKey: string;
        }

        /**
         * A label query over a set of resources, in this case pods.
         */
        export interface PrometheusSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.monitoring.v1.PrometheusSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface PrometheusSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Defines a set of pods (namely those matching the labelSelector relative to the given namespace(s)) that this pod should be co-located (affinity) or not co-located (anti-affinity) with, where co-located is defined as running on a node whose value of the label with key <topologyKey> matches that of any node on which a pod of the set of pods is running
         */
        export interface PrometheusSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            /**
             * A label query over a set of resources, in this case pods.
             */
            labelSelector?: outputs.monitoring.v1.PrometheusSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            /**
             * namespaces specifies which namespaces the labelSelector applies to (matches against); null or empty list means "this pod's namespace"
             */
            namespaces?: string[];
            /**
             * This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed.
             */
            topologyKey: string;
        }

        /**
         * A label query over a set of resources, in this case pods.
         */
        export interface PrometheusSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.monitoring.v1.PrometheusSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface PrometheusSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Define details regarding alerting.
         */
        export interface PrometheusSpecAlerting {
            /**
             * AlertmanagerEndpoints Prometheus should fire alerts against.
             */
            alertmanagers: outputs.monitoring.v1.PrometheusSpecAlertingAlertmanagers[];
        }

        /**
         * AlertmanagerEndpoints defines a selection of a single Endpoints object containing alertmanager IPs to fire alerts against.
         */
        export interface PrometheusSpecAlertingAlertmanagers {
            /**
             * Version of the Alertmanager API that Prometheus uses to send alerts. It can be "v1" or "v2".
             */
            apiVersion?: string;
            /**
             * BearerTokenFile to read from filesystem to use when authenticating to Alertmanager.
             */
            bearerTokenFile?: string;
            /**
             * Name of Endpoints object in Namespace.
             */
            name: string;
            /**
             * Namespace of Endpoints object.
             */
            namespace: string;
            /**
             * Prefix for the HTTP path alerts are pushed to.
             */
            pathPrefix?: string;
            /**
             * Port the Alertmanager API is exposed on.
             */
            port: outputs.monitoring.v1.PrometheusSpecAlertingAlertmanagersPort;
            /**
             * Scheme to use when firing alerts.
             */
            scheme?: string;
            /**
             * Timeout is a per-target Alertmanager timeout when pushing alerts.
             */
            timeout?: string;
            /**
             * TLS Config to use for alertmanager connection.
             */
            tlsConfig?: outputs.monitoring.v1.PrometheusSpecAlertingAlertmanagersTlsConfig;
        }

        export interface PrometheusSpecAlertingAlertmanagersPort {
        }

        /**
         * TLS Config to use for alertmanager connection.
         */
        export interface PrometheusSpecAlertingAlertmanagersTlsConfig {
            /**
             * Struct containing the CA cert to use for the targets.
             */
            ca?: outputs.monitoring.v1.PrometheusSpecAlertingAlertmanagersTlsConfigCa;
            /**
             * Path to the CA cert in the Prometheus container to use for the targets.
             */
            caFile?: string;
            /**
             * Struct containing the client cert file for the targets.
             */
            cert?: outputs.monitoring.v1.PrometheusSpecAlertingAlertmanagersTlsConfigCert;
            /**
             * Path to the client cert file in the Prometheus container for the targets.
             */
            certFile?: string;
            /**
             * Disable target certificate validation.
             */
            insecureSkipVerify?: boolean;
            /**
             * Path to the client key file in the Prometheus container for the targets.
             */
            keyFile?: string;
            /**
             * Secret containing the client key file for the targets.
             */
            keySecret?: outputs.monitoring.v1.PrometheusSpecAlertingAlertmanagersTlsConfigKeySecret;
            /**
             * Used to verify the hostname for the targets.
             */
            serverName?: string;
        }

        /**
         * Struct containing the CA cert to use for the targets.
         */
        export interface PrometheusSpecAlertingAlertmanagersTlsConfigCa {
            /**
             * ConfigMap containing data to use for the targets.
             */
            configMap?: outputs.monitoring.v1.PrometheusSpecAlertingAlertmanagersTlsConfigCaConfigMap;
            /**
             * Secret containing data to use for the targets.
             */
            secret?: outputs.monitoring.v1.PrometheusSpecAlertingAlertmanagersTlsConfigCaSecret;
        }

        /**
         * ConfigMap containing data to use for the targets.
         */
        export interface PrometheusSpecAlertingAlertmanagersTlsConfigCaConfigMap {
            /**
             * The key to select.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the ConfigMap or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Secret containing data to use for the targets.
         */
        export interface PrometheusSpecAlertingAlertmanagersTlsConfigCaSecret {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Struct containing the client cert file for the targets.
         */
        export interface PrometheusSpecAlertingAlertmanagersTlsConfigCert {
            /**
             * ConfigMap containing data to use for the targets.
             */
            configMap?: outputs.monitoring.v1.PrometheusSpecAlertingAlertmanagersTlsConfigCertConfigMap;
            /**
             * Secret containing data to use for the targets.
             */
            secret?: outputs.monitoring.v1.PrometheusSpecAlertingAlertmanagersTlsConfigCertSecret;
        }

        /**
         * ConfigMap containing data to use for the targets.
         */
        export interface PrometheusSpecAlertingAlertmanagersTlsConfigCertConfigMap {
            /**
             * The key to select.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the ConfigMap or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Secret containing data to use for the targets.
         */
        export interface PrometheusSpecAlertingAlertmanagersTlsConfigCertSecret {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Secret containing the client key file for the targets.
         */
        export interface PrometheusSpecAlertingAlertmanagersTlsConfigKeySecret {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * APIServerConfig allows specifying a host and auth methods to access apiserver. If left empty, Prometheus is assumed to run inside of the cluster and will discover API servers automatically and use the pod's CA certificate and bearer token file at /var/run/secrets/kubernetes.io/serviceaccount/.
         */
        export interface PrometheusSpecApiserverConfig {
            /**
             * BasicAuth allow an endpoint to authenticate over basic authentication
             */
            basicAuth?: outputs.monitoring.v1.PrometheusSpecApiserverConfigBasicAuth;
            /**
             * Bearer token for accessing apiserver.
             */
            bearerToken?: string;
            /**
             * File to read bearer token for accessing apiserver.
             */
            bearerTokenFile?: string;
            /**
             * Host of apiserver. A valid string consisting of a hostname or IP followed by an optional port number
             */
            host: string;
            /**
             * TLS Config to use for accessing apiserver.
             */
            tlsConfig?: outputs.monitoring.v1.PrometheusSpecApiserverConfigTlsConfig;
        }

        /**
         * BasicAuth allow an endpoint to authenticate over basic authentication
         */
        export interface PrometheusSpecApiserverConfigBasicAuth {
            /**
             * The secret in the service monitor namespace that contains the password for authentication.
             */
            password?: outputs.monitoring.v1.PrometheusSpecApiserverConfigBasicAuthPassword;
            /**
             * The secret in the service monitor namespace that contains the username for authentication.
             */
            username?: outputs.monitoring.v1.PrometheusSpecApiserverConfigBasicAuthUsername;
        }

        /**
         * The secret in the service monitor namespace that contains the password for authentication.
         */
        export interface PrometheusSpecApiserverConfigBasicAuthPassword {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * The secret in the service monitor namespace that contains the username for authentication.
         */
        export interface PrometheusSpecApiserverConfigBasicAuthUsername {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * TLS Config to use for accessing apiserver.
         */
        export interface PrometheusSpecApiserverConfigTlsConfig {
            /**
             * Struct containing the CA cert to use for the targets.
             */
            ca?: outputs.monitoring.v1.PrometheusSpecApiserverConfigTlsConfigCa;
            /**
             * Path to the CA cert in the Prometheus container to use for the targets.
             */
            caFile?: string;
            /**
             * Struct containing the client cert file for the targets.
             */
            cert?: outputs.monitoring.v1.PrometheusSpecApiserverConfigTlsConfigCert;
            /**
             * Path to the client cert file in the Prometheus container for the targets.
             */
            certFile?: string;
            /**
             * Disable target certificate validation.
             */
            insecureSkipVerify?: boolean;
            /**
             * Path to the client key file in the Prometheus container for the targets.
             */
            keyFile?: string;
            /**
             * Secret containing the client key file for the targets.
             */
            keySecret?: outputs.monitoring.v1.PrometheusSpecApiserverConfigTlsConfigKeySecret;
            /**
             * Used to verify the hostname for the targets.
             */
            serverName?: string;
        }

        /**
         * Struct containing the CA cert to use for the targets.
         */
        export interface PrometheusSpecApiserverConfigTlsConfigCa {
            /**
             * ConfigMap containing data to use for the targets.
             */
            configMap?: outputs.monitoring.v1.PrometheusSpecApiserverConfigTlsConfigCaConfigMap;
            /**
             * Secret containing data to use for the targets.
             */
            secret?: outputs.monitoring.v1.PrometheusSpecApiserverConfigTlsConfigCaSecret;
        }

        /**
         * ConfigMap containing data to use for the targets.
         */
        export interface PrometheusSpecApiserverConfigTlsConfigCaConfigMap {
            /**
             * The key to select.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the ConfigMap or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Secret containing data to use for the targets.
         */
        export interface PrometheusSpecApiserverConfigTlsConfigCaSecret {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Struct containing the client cert file for the targets.
         */
        export interface PrometheusSpecApiserverConfigTlsConfigCert {
            /**
             * ConfigMap containing data to use for the targets.
             */
            configMap?: outputs.monitoring.v1.PrometheusSpecApiserverConfigTlsConfigCertConfigMap;
            /**
             * Secret containing data to use for the targets.
             */
            secret?: outputs.monitoring.v1.PrometheusSpecApiserverConfigTlsConfigCertSecret;
        }

        /**
         * ConfigMap containing data to use for the targets.
         */
        export interface PrometheusSpecApiserverConfigTlsConfigCertConfigMap {
            /**
             * The key to select.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the ConfigMap or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Secret containing data to use for the targets.
         */
        export interface PrometheusSpecApiserverConfigTlsConfigCertSecret {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Secret containing the client key file for the targets.
         */
        export interface PrometheusSpecApiserverConfigTlsConfigKeySecret {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * ArbitraryFSAccessThroughSMs configures whether configuration based on a service monitor can access arbitrary files on the file system of the Prometheus container e.g. bearer token files.
         */
        export interface PrometheusSpecArbitraryFSAccessThroughSMs {
            deny?: boolean;
        }

        /**
         * A single application container that you want to run within a pod.
         */
        export interface PrometheusSpecContainers {
            /**
             * Arguments to the entrypoint. The docker image's CMD is used if this is not provided. Variable references $(VAR_NAME) are expanded using the container's environment. If a variable cannot be resolved, the reference in the input string will be unchanged. The $(VAR_NAME) syntax can be escaped with a double $$, ie: $$(VAR_NAME). Escaped references will never be expanded, regardless of whether the variable exists or not. Cannot be updated. More info: https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#running-a-command-in-a-shell
             */
            args?: string[];
            /**
             * Entrypoint array. Not executed within a shell. The docker image's ENTRYPOINT is used if this is not provided. Variable references $(VAR_NAME) are expanded using the container's environment. If a variable cannot be resolved, the reference in the input string will be unchanged. The $(VAR_NAME) syntax can be escaped with a double $$, ie: $$(VAR_NAME). Escaped references will never be expanded, regardless of whether the variable exists or not. Cannot be updated. More info: https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#running-a-command-in-a-shell
             */
            command?: string[];
            /**
             * List of environment variables to set in the container. Cannot be updated.
             */
            env?: outputs.monitoring.v1.PrometheusSpecContainersEnv[];
            /**
             * List of sources to populate environment variables in the container. The keys defined within a source must be a C_IDENTIFIER. All invalid keys will be reported as an event when the container is starting. When a key exists in multiple sources, the value associated with the last source will take precedence. Values defined by an Env with a duplicate key will take precedence. Cannot be updated.
             */
            envFrom?: outputs.monitoring.v1.PrometheusSpecContainersEnvFrom[];
            /**
             * Docker image name. More info: https://kubernetes.io/docs/concepts/containers/images This field is optional to allow higher level config management to default or override container images in workload controllers like Deployments and StatefulSets.
             */
            image?: string;
            /**
             * Image pull policy. One of Always, Never, IfNotPresent. Defaults to Always if :latest tag is specified, or IfNotPresent otherwise. Cannot be updated. More info: https://kubernetes.io/docs/concepts/containers/images#updating-images
             */
            imagePullPolicy?: string;
            /**
             * Actions that the management system should take in response to container lifecycle events. Cannot be updated.
             */
            lifecycle?: outputs.monitoring.v1.PrometheusSpecContainersLifecycle;
            /**
             * Periodic probe of container liveness. Container will be restarted if the probe fails. Cannot be updated. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
             */
            livenessProbe?: outputs.monitoring.v1.PrometheusSpecContainersLivenessProbe;
            /**
             * Name of the container specified as a DNS_LABEL. Each container in a pod must have a unique name (DNS_LABEL). Cannot be updated.
             */
            name: string;
            /**
             * List of ports to expose from the container. Exposing a port here gives the system additional information about the network connections a container uses, but is primarily informational. Not specifying a port here DOES NOT prevent that port from being exposed. Any port which is listening on the default "0.0.0.0" address inside a container will be accessible from the network. Cannot be updated.
             */
            ports?: outputs.monitoring.v1.PrometheusSpecContainersPorts[];
            /**
             * Periodic probe of container service readiness. Container will be removed from service endpoints if the probe fails. Cannot be updated. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
             */
            readinessProbe?: outputs.monitoring.v1.PrometheusSpecContainersReadinessProbe;
            /**
             * Compute Resources required by this container. Cannot be updated. More info: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
             */
            resources?: outputs.monitoring.v1.PrometheusSpecContainersResources;
            /**
             * Security options the pod should run with. More info: https://kubernetes.io/docs/concepts/policy/security-context/ More info: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/
             */
            securityContext?: outputs.monitoring.v1.PrometheusSpecContainersSecurityContext;
            /**
             * StartupProbe indicates that the Pod has successfully initialized. If specified, no other probes are executed until this completes successfully. If this probe fails, the Pod will be restarted, just as if the livenessProbe failed. This can be used to provide different probe parameters at the beginning of a Pod's lifecycle, when it might take a long time to load data or warm a cache, than during steady-state operation. This cannot be updated. This is a beta feature enabled by the StartupProbe feature flag. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
             */
            startupProbe?: outputs.monitoring.v1.PrometheusSpecContainersStartupProbe;
            /**
             * Whether this container should allocate a buffer for stdin in the container runtime. If this is not set, reads from stdin in the container will always result in EOF. Default is false.
             */
            stdin?: boolean;
            /**
             * Whether the container runtime should close the stdin channel after it has been opened by a single attach. When stdin is true the stdin stream will remain open across multiple attach sessions. If stdinOnce is set to true, stdin is opened on container start, is empty until the first client attaches to stdin, and then remains open and accepts data until the client disconnects, at which time stdin is closed and remains closed until the container is restarted. If this flag is false, a container processes that reads from stdin will never receive an EOF. Default is false
             */
            stdinOnce?: boolean;
            /**
             * Optional: Path at which the file to which the container's termination message will be written is mounted into the container's filesystem. Message written is intended to be brief final status, such as an assertion failure message. Will be truncated by the node if greater than 4096 bytes. The total message length across all containers will be limited to 12kb. Defaults to /dev/termination-log. Cannot be updated.
             */
            terminationMessagePath?: string;
            /**
             * Indicate how the termination message should be populated. File will use the contents of terminationMessagePath to populate the container status message on both success and failure. FallbackToLogsOnError will use the last chunk of container log output if the termination message file is empty and the container exited with an error. The log output is limited to 2048 bytes or 80 lines, whichever is smaller. Defaults to File. Cannot be updated.
             */
            terminationMessagePolicy?: string;
            /**
             * Whether this container should allocate a TTY for itself, also requires 'stdin' to be true. Default is false.
             */
            tty?: boolean;
            /**
             * volumeDevices is the list of block devices to be used by the container.
             */
            volumeDevices?: outputs.monitoring.v1.PrometheusSpecContainersVolumeDevices[];
            /**
             * Pod volumes to mount into the container's filesystem. Cannot be updated.
             */
            volumeMounts?: outputs.monitoring.v1.PrometheusSpecContainersVolumeMounts[];
            /**
             * Container's working directory. If not specified, the container runtime's default will be used, which might be configured in the container image. Cannot be updated.
             */
            workingDir?: string;
        }

        /**
         * EnvVar represents an environment variable present in a Container.
         */
        export interface PrometheusSpecContainersEnv {
            /**
             * Name of the environment variable. Must be a C_IDENTIFIER.
             */
            name: string;
            /**
             * Variable references $(VAR_NAME) are expanded using the previous defined environment variables in the container and any service environment variables. If a variable cannot be resolved, the reference in the input string will be unchanged. The $(VAR_NAME) syntax can be escaped with a double $$, ie: $$(VAR_NAME). Escaped references will never be expanded, regardless of whether the variable exists or not. Defaults to "".
             */
            value?: string;
            /**
             * Source for the environment variable's value. Cannot be used if value is not empty.
             */
            valueFrom?: outputs.monitoring.v1.PrometheusSpecContainersEnvValueFrom;
        }

        /**
         * EnvFromSource represents the source of a set of ConfigMaps
         */
        export interface PrometheusSpecContainersEnvFrom {
            /**
             * The ConfigMap to select from
             */
            configMapRef?: outputs.monitoring.v1.PrometheusSpecContainersEnvFromConfigMapRef;
            /**
             * An optional identifier to prepend to each key in the ConfigMap. Must be a C_IDENTIFIER.
             */
            prefix?: string;
            /**
             * The Secret to select from
             */
            secretRef?: outputs.monitoring.v1.PrometheusSpecContainersEnvFromSecretRef;
        }

        /**
         * The ConfigMap to select from
         */
        export interface PrometheusSpecContainersEnvFromConfigMapRef {
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the ConfigMap must be defined
             */
            optional?: boolean;
        }

        /**
         * The Secret to select from
         */
        export interface PrometheusSpecContainersEnvFromSecretRef {
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret must be defined
             */
            optional?: boolean;
        }

        /**
         * Source for the environment variable's value. Cannot be used if value is not empty.
         */
        export interface PrometheusSpecContainersEnvValueFrom {
            /**
             * Selects a key of a ConfigMap.
             */
            configMapKeyRef?: outputs.monitoring.v1.PrometheusSpecContainersEnvValueFromConfigMapKeyRef;
            /**
             * Selects a field of the pod: supports metadata.name, metadata.namespace, metadata.labels, metadata.annotations, spec.nodeName, spec.serviceAccountName, status.hostIP, status.podIP, status.podIPs.
             */
            fieldRef?: outputs.monitoring.v1.PrometheusSpecContainersEnvValueFromFieldRef;
            /**
             * Selects a resource of the container: only resources limits and requests (limits.cpu, limits.memory, limits.ephemeral-storage, requests.cpu, requests.memory and requests.ephemeral-storage) are currently supported.
             */
            resourceFieldRef?: outputs.monitoring.v1.PrometheusSpecContainersEnvValueFromResourceFieldRef;
            /**
             * Selects a key of a secret in the pod's namespace
             */
            secretKeyRef?: outputs.monitoring.v1.PrometheusSpecContainersEnvValueFromSecretKeyRef;
        }

        /**
         * Selects a key of a ConfigMap.
         */
        export interface PrometheusSpecContainersEnvValueFromConfigMapKeyRef {
            /**
             * The key to select.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the ConfigMap or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Selects a field of the pod: supports metadata.name, metadata.namespace, metadata.labels, metadata.annotations, spec.nodeName, spec.serviceAccountName, status.hostIP, status.podIP, status.podIPs.
         */
        export interface PrometheusSpecContainersEnvValueFromFieldRef {
            /**
             * Version of the schema the FieldPath is written in terms of, defaults to "v1".
             */
            apiVersion?: string;
            /**
             * Path of the field to select in the specified API version.
             */
            fieldPath: string;
        }

        /**
         * Selects a resource of the container: only resources limits and requests (limits.cpu, limits.memory, limits.ephemeral-storage, requests.cpu, requests.memory and requests.ephemeral-storage) are currently supported.
         */
        export interface PrometheusSpecContainersEnvValueFromResourceFieldRef {
            /**
             * Container name: required for volumes, optional for env vars
             */
            containerName?: string;
            /**
             * Specifies the output format of the exposed resources, defaults to "1"
             */
            divisor?: outputs.monitoring.v1.PrometheusSpecContainersEnvValueFromResourceFieldRefDivisor;
            /**
             * Required: resource to select
             */
            resource: string;
        }

        export interface PrometheusSpecContainersEnvValueFromResourceFieldRefDivisor {
        }

        /**
         * Selects a key of a secret in the pod's namespace
         */
        export interface PrometheusSpecContainersEnvValueFromSecretKeyRef {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Actions that the management system should take in response to container lifecycle events. Cannot be updated.
         */
        export interface PrometheusSpecContainersLifecycle {
            /**
             * PostStart is called immediately after a container is created. If the handler fails, the container is terminated and restarted according to its restart policy. Other management of the container blocks until the hook completes. More info: https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks/#container-hooks
             */
            postStart?: outputs.monitoring.v1.PrometheusSpecContainersLifecyclePostStart;
            /**
             * PreStop is called immediately before a container is terminated due to an API request or management event such as liveness/startup probe failure, preemption, resource contention, etc. The handler is not called if the container crashes or exits. The reason for termination is passed to the handler. The Pod's termination grace period countdown begins before the PreStop hooked is executed. Regardless of the outcome of the handler, the container will eventually terminate within the Pod's termination grace period. Other management of the container blocks until the hook completes or until the termination grace period is reached. More info: https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks/#container-hooks
             */
            preStop?: outputs.monitoring.v1.PrometheusSpecContainersLifecyclePreStop;
        }

        /**
         * PostStart is called immediately after a container is created. If the handler fails, the container is terminated and restarted according to its restart policy. Other management of the container blocks until the hook completes. More info: https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks/#container-hooks
         */
        export interface PrometheusSpecContainersLifecyclePostStart {
            /**
             * One and only one of the following should be specified. Exec specifies the action to take.
             */
            exec?: outputs.monitoring.v1.PrometheusSpecContainersLifecyclePostStartExec;
            /**
             * HTTPGet specifies the http request to perform.
             */
            httpGet?: outputs.monitoring.v1.PrometheusSpecContainersLifecyclePostStartHttpGet;
            /**
             * TCPSocket specifies an action involving a TCP port. TCP hooks not yet supported TODO: implement a realistic TCP lifecycle hook
             */
            tcpSocket?: outputs.monitoring.v1.PrometheusSpecContainersLifecyclePostStartTcpSocket;
        }

        /**
         * One and only one of the following should be specified. Exec specifies the action to take.
         */
        export interface PrometheusSpecContainersLifecyclePostStartExec {
            /**
             * Command is the command line to execute inside the container, the working directory for the command  is root ('/') in the container's filesystem. The command is simply exec'd, it is not run inside a shell, so traditional shell instructions ('|', etc) won't work. To use a shell, you need to explicitly call out to that shell. Exit status of 0 is treated as live/healthy and non-zero is unhealthy.
             */
            command?: string[];
        }

        /**
         * HTTPGet specifies the http request to perform.
         */
        export interface PrometheusSpecContainersLifecyclePostStartHttpGet {
            /**
             * Host name to connect to, defaults to the pod IP. You probably want to set "Host" in httpHeaders instead.
             */
            host?: string;
            /**
             * Custom headers to set in the request. HTTP allows repeated headers.
             */
            httpHeaders?: outputs.monitoring.v1.PrometheusSpecContainersLifecyclePostStartHttpGetHttpHeaders[];
            /**
             * Path to access on the HTTP server.
             */
            path?: string;
            /**
             * Name or number of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME.
             */
            port: outputs.monitoring.v1.PrometheusSpecContainersLifecyclePostStartHttpGetPort;
            /**
             * Scheme to use for connecting to the host. Defaults to HTTP.
             */
            scheme?: string;
        }

        /**
         * HTTPHeader describes a custom header to be used in HTTP probes
         */
        export interface PrometheusSpecContainersLifecyclePostStartHttpGetHttpHeaders {
            /**
             * The header field name
             */
            name: string;
            /**
             * The header field value
             */
            value: string;
        }

        export interface PrometheusSpecContainersLifecyclePostStartHttpGetPort {
        }

        /**
         * TCPSocket specifies an action involving a TCP port. TCP hooks not yet supported TODO: implement a realistic TCP lifecycle hook
         */
        export interface PrometheusSpecContainersLifecyclePostStartTcpSocket {
            /**
             * Optional: Host name to connect to, defaults to the pod IP.
             */
            host?: string;
            /**
             * Number or name of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME.
             */
            port: outputs.monitoring.v1.PrometheusSpecContainersLifecyclePostStartTcpSocketPort;
        }

        export interface PrometheusSpecContainersLifecyclePostStartTcpSocketPort {
        }

        /**
         * PreStop is called immediately before a container is terminated due to an API request or management event such as liveness/startup probe failure, preemption, resource contention, etc. The handler is not called if the container crashes or exits. The reason for termination is passed to the handler. The Pod's termination grace period countdown begins before the PreStop hooked is executed. Regardless of the outcome of the handler, the container will eventually terminate within the Pod's termination grace period. Other management of the container blocks until the hook completes or until the termination grace period is reached. More info: https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks/#container-hooks
         */
        export interface PrometheusSpecContainersLifecyclePreStop {
            /**
             * One and only one of the following should be specified. Exec specifies the action to take.
             */
            exec?: outputs.monitoring.v1.PrometheusSpecContainersLifecyclePreStopExec;
            /**
             * HTTPGet specifies the http request to perform.
             */
            httpGet?: outputs.monitoring.v1.PrometheusSpecContainersLifecyclePreStopHttpGet;
            /**
             * TCPSocket specifies an action involving a TCP port. TCP hooks not yet supported TODO: implement a realistic TCP lifecycle hook
             */
            tcpSocket?: outputs.monitoring.v1.PrometheusSpecContainersLifecyclePreStopTcpSocket;
        }

        /**
         * One and only one of the following should be specified. Exec specifies the action to take.
         */
        export interface PrometheusSpecContainersLifecyclePreStopExec {
            /**
             * Command is the command line to execute inside the container, the working directory for the command  is root ('/') in the container's filesystem. The command is simply exec'd, it is not run inside a shell, so traditional shell instructions ('|', etc) won't work. To use a shell, you need to explicitly call out to that shell. Exit status of 0 is treated as live/healthy and non-zero is unhealthy.
             */
            command?: string[];
        }

        /**
         * HTTPGet specifies the http request to perform.
         */
        export interface PrometheusSpecContainersLifecyclePreStopHttpGet {
            /**
             * Host name to connect to, defaults to the pod IP. You probably want to set "Host" in httpHeaders instead.
             */
            host?: string;
            /**
             * Custom headers to set in the request. HTTP allows repeated headers.
             */
            httpHeaders?: outputs.monitoring.v1.PrometheusSpecContainersLifecyclePreStopHttpGetHttpHeaders[];
            /**
             * Path to access on the HTTP server.
             */
            path?: string;
            /**
             * Name or number of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME.
             */
            port: outputs.monitoring.v1.PrometheusSpecContainersLifecyclePreStopHttpGetPort;
            /**
             * Scheme to use for connecting to the host. Defaults to HTTP.
             */
            scheme?: string;
        }

        /**
         * HTTPHeader describes a custom header to be used in HTTP probes
         */
        export interface PrometheusSpecContainersLifecyclePreStopHttpGetHttpHeaders {
            /**
             * The header field name
             */
            name: string;
            /**
             * The header field value
             */
            value: string;
        }

        export interface PrometheusSpecContainersLifecyclePreStopHttpGetPort {
        }

        /**
         * TCPSocket specifies an action involving a TCP port. TCP hooks not yet supported TODO: implement a realistic TCP lifecycle hook
         */
        export interface PrometheusSpecContainersLifecyclePreStopTcpSocket {
            /**
             * Optional: Host name to connect to, defaults to the pod IP.
             */
            host?: string;
            /**
             * Number or name of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME.
             */
            port: outputs.monitoring.v1.PrometheusSpecContainersLifecyclePreStopTcpSocketPort;
        }

        export interface PrometheusSpecContainersLifecyclePreStopTcpSocketPort {
        }

        /**
         * Periodic probe of container liveness. Container will be restarted if the probe fails. Cannot be updated. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
         */
        export interface PrometheusSpecContainersLivenessProbe {
            /**
             * One and only one of the following should be specified. Exec specifies the action to take.
             */
            exec?: outputs.monitoring.v1.PrometheusSpecContainersLivenessProbeExec;
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * HTTPGet specifies the http request to perform.
             */
            httpGet?: outputs.monitoring.v1.PrometheusSpecContainersLivenessProbeHttpGet;
            /**
             * Number of seconds after the container has started before liveness probes are initiated. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness and startup. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * TCPSocket specifies an action involving a TCP port. TCP hooks not yet supported TODO: implement a realistic TCP lifecycle hook
             */
            tcpSocket?: outputs.monitoring.v1.PrometheusSpecContainersLivenessProbeTcpSocket;
            /**
             * Number of seconds after which the probe times out. Defaults to 1 second. Minimum value is 1. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
             */
            timeoutSeconds?: number;
        }

        /**
         * One and only one of the following should be specified. Exec specifies the action to take.
         */
        export interface PrometheusSpecContainersLivenessProbeExec {
            /**
             * Command is the command line to execute inside the container, the working directory for the command  is root ('/') in the container's filesystem. The command is simply exec'd, it is not run inside a shell, so traditional shell instructions ('|', etc) won't work. To use a shell, you need to explicitly call out to that shell. Exit status of 0 is treated as live/healthy and non-zero is unhealthy.
             */
            command?: string[];
        }

        /**
         * HTTPGet specifies the http request to perform.
         */
        export interface PrometheusSpecContainersLivenessProbeHttpGet {
            /**
             * Host name to connect to, defaults to the pod IP. You probably want to set "Host" in httpHeaders instead.
             */
            host?: string;
            /**
             * Custom headers to set in the request. HTTP allows repeated headers.
             */
            httpHeaders?: outputs.monitoring.v1.PrometheusSpecContainersLivenessProbeHttpGetHttpHeaders[];
            /**
             * Path to access on the HTTP server.
             */
            path?: string;
            /**
             * Name or number of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME.
             */
            port: outputs.monitoring.v1.PrometheusSpecContainersLivenessProbeHttpGetPort;
            /**
             * Scheme to use for connecting to the host. Defaults to HTTP.
             */
            scheme?: string;
        }

        /**
         * HTTPHeader describes a custom header to be used in HTTP probes
         */
        export interface PrometheusSpecContainersLivenessProbeHttpGetHttpHeaders {
            /**
             * The header field name
             */
            name: string;
            /**
             * The header field value
             */
            value: string;
        }

        export interface PrometheusSpecContainersLivenessProbeHttpGetPort {
        }

        /**
         * TCPSocket specifies an action involving a TCP port. TCP hooks not yet supported TODO: implement a realistic TCP lifecycle hook
         */
        export interface PrometheusSpecContainersLivenessProbeTcpSocket {
            /**
             * Optional: Host name to connect to, defaults to the pod IP.
             */
            host?: string;
            /**
             * Number or name of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME.
             */
            port: outputs.monitoring.v1.PrometheusSpecContainersLivenessProbeTcpSocketPort;
        }

        export interface PrometheusSpecContainersLivenessProbeTcpSocketPort {
        }

        /**
         * ContainerPort represents a network port in a single container.
         */
        export interface PrometheusSpecContainersPorts {
            /**
             * Number of port to expose on the pod's IP address. This must be a valid port number, 0 < x < 65536.
             */
            containerPort: number;
            /**
             * What host IP to bind the external port to.
             */
            hostIP?: string;
            /**
             * Number of port to expose on the host. If specified, this must be a valid port number, 0 < x < 65536. If HostNetwork is specified, this must match ContainerPort. Most containers do not need this.
             */
            hostPort?: number;
            /**
             * If specified, this must be an IANA_SVC_NAME and unique within the pod. Each named port in a pod must have a unique name. Name for the port that can be referred to by services.
             */
            name?: string;
            /**
             * Protocol for port. Must be UDP, TCP, or SCTP. Defaults to "TCP".
             */
            protocol?: string;
        }

        /**
         * Periodic probe of container service readiness. Container will be removed from service endpoints if the probe fails. Cannot be updated. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
         */
        export interface PrometheusSpecContainersReadinessProbe {
            /**
             * One and only one of the following should be specified. Exec specifies the action to take.
             */
            exec?: outputs.monitoring.v1.PrometheusSpecContainersReadinessProbeExec;
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * HTTPGet specifies the http request to perform.
             */
            httpGet?: outputs.monitoring.v1.PrometheusSpecContainersReadinessProbeHttpGet;
            /**
             * Number of seconds after the container has started before liveness probes are initiated. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness and startup. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * TCPSocket specifies an action involving a TCP port. TCP hooks not yet supported TODO: implement a realistic TCP lifecycle hook
             */
            tcpSocket?: outputs.monitoring.v1.PrometheusSpecContainersReadinessProbeTcpSocket;
            /**
             * Number of seconds after which the probe times out. Defaults to 1 second. Minimum value is 1. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
             */
            timeoutSeconds?: number;
        }

        /**
         * One and only one of the following should be specified. Exec specifies the action to take.
         */
        export interface PrometheusSpecContainersReadinessProbeExec {
            /**
             * Command is the command line to execute inside the container, the working directory for the command  is root ('/') in the container's filesystem. The command is simply exec'd, it is not run inside a shell, so traditional shell instructions ('|', etc) won't work. To use a shell, you need to explicitly call out to that shell. Exit status of 0 is treated as live/healthy and non-zero is unhealthy.
             */
            command?: string[];
        }

        /**
         * HTTPGet specifies the http request to perform.
         */
        export interface PrometheusSpecContainersReadinessProbeHttpGet {
            /**
             * Host name to connect to, defaults to the pod IP. You probably want to set "Host" in httpHeaders instead.
             */
            host?: string;
            /**
             * Custom headers to set in the request. HTTP allows repeated headers.
             */
            httpHeaders?: outputs.monitoring.v1.PrometheusSpecContainersReadinessProbeHttpGetHttpHeaders[];
            /**
             * Path to access on the HTTP server.
             */
            path?: string;
            /**
             * Name or number of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME.
             */
            port: outputs.monitoring.v1.PrometheusSpecContainersReadinessProbeHttpGetPort;
            /**
             * Scheme to use for connecting to the host. Defaults to HTTP.
             */
            scheme?: string;
        }

        /**
         * HTTPHeader describes a custom header to be used in HTTP probes
         */
        export interface PrometheusSpecContainersReadinessProbeHttpGetHttpHeaders {
            /**
             * The header field name
             */
            name: string;
            /**
             * The header field value
             */
            value: string;
        }

        export interface PrometheusSpecContainersReadinessProbeHttpGetPort {
        }

        /**
         * TCPSocket specifies an action involving a TCP port. TCP hooks not yet supported TODO: implement a realistic TCP lifecycle hook
         */
        export interface PrometheusSpecContainersReadinessProbeTcpSocket {
            /**
             * Optional: Host name to connect to, defaults to the pod IP.
             */
            host?: string;
            /**
             * Number or name of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME.
             */
            port: outputs.monitoring.v1.PrometheusSpecContainersReadinessProbeTcpSocketPort;
        }

        export interface PrometheusSpecContainersReadinessProbeTcpSocketPort {
        }

        /**
         * Compute Resources required by this container. Cannot be updated. More info: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
         */
        export interface PrometheusSpecContainersResources {
            /**
             * Limits describes the maximum amount of compute resources allowed. More info: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
             */
            limits?: {[key: string]: outputs.monitoring.v1.PrometheusSpecContainersResourcesLimits};
            /**
             * Requests describes the minimum amount of compute resources required. If Requests is omitted for a container, it defaults to Limits if that is explicitly specified, otherwise to an implementation-defined value. More info: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
             */
            requests?: {[key: string]: outputs.monitoring.v1.PrometheusSpecContainersResourcesRequests};
        }

        export interface PrometheusSpecContainersResourcesLimits {
        }

        export interface PrometheusSpecContainersResourcesRequests {
        }

        /**
         * Security options the pod should run with. More info: https://kubernetes.io/docs/concepts/policy/security-context/ More info: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/
         */
        export interface PrometheusSpecContainersSecurityContext {
            /**
             * AllowPrivilegeEscalation controls whether a process can gain more privileges than its parent process. This bool directly controls if the no_new_privs flag will be set on the container process. AllowPrivilegeEscalation is true always when the container is: 1) run as Privileged 2) has CAP_SYS_ADMIN
             */
            allowPrivilegeEscalation?: boolean;
            /**
             * The capabilities to add/drop when running containers. Defaults to the default set of capabilities granted by the container runtime.
             */
            capabilities?: outputs.monitoring.v1.PrometheusSpecContainersSecurityContextCapabilities;
            /**
             * Run container in privileged mode. Processes in privileged containers are essentially equivalent to root on the host. Defaults to false.
             */
            privileged?: boolean;
            /**
             * procMount denotes the type of proc mount to use for the containers. The default is DefaultProcMount which uses the container runtime defaults for readonly paths and masked paths. This requires the ProcMountType feature flag to be enabled.
             */
            procMount?: string;
            /**
             * Whether this container has a read-only root filesystem. Default is false.
             */
            readOnlyRootFilesystem?: boolean;
            /**
             * The GID to run the entrypoint of the container process. Uses runtime default if unset. May also be set in PodSecurityContext.  If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.
             */
            runAsGroup?: number;
            /**
             * Indicates that the container must run as a non-root user. If true, the Kubelet will validate the image at runtime to ensure that it does not run as UID 0 (root) and fail to start the container if it does. If unset or false, no such validation will be performed. May also be set in PodSecurityContext.  If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.
             */
            runAsNonRoot?: boolean;
            /**
             * The UID to run the entrypoint of the container process. Defaults to user specified in image metadata if unspecified. May also be set in PodSecurityContext.  If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.
             */
            runAsUser?: number;
            /**
             * The SELinux context to be applied to the container. If unspecified, the container runtime will allocate a random SELinux context for each container.  May also be set in PodSecurityContext.  If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.
             */
            seLinuxOptions?: outputs.monitoring.v1.PrometheusSpecContainersSecurityContextSeLinuxOptions;
            /**
             * The Windows specific settings applied to all containers. If unspecified, the options from the PodSecurityContext will be used. If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.
             */
            windowsOptions?: outputs.monitoring.v1.PrometheusSpecContainersSecurityContextWindowsOptions;
        }

        /**
         * The capabilities to add/drop when running containers. Defaults to the default set of capabilities granted by the container runtime.
         */
        export interface PrometheusSpecContainersSecurityContextCapabilities {
            /**
             * Added capabilities
             */
            add?: string[];
            /**
             * Removed capabilities
             */
            drop?: string[];
        }

        /**
         * The SELinux context to be applied to the container. If unspecified, the container runtime will allocate a random SELinux context for each container.  May also be set in PodSecurityContext.  If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.
         */
        export interface PrometheusSpecContainersSecurityContextSeLinuxOptions {
            /**
             * Level is SELinux level label that applies to the container.
             */
            level?: string;
            /**
             * Role is a SELinux role label that applies to the container.
             */
            role?: string;
            /**
             * Type is a SELinux type label that applies to the container.
             */
            type?: string;
            /**
             * User is a SELinux user label that applies to the container.
             */
            user?: string;
        }

        /**
         * The Windows specific settings applied to all containers. If unspecified, the options from the PodSecurityContext will be used. If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.
         */
        export interface PrometheusSpecContainersSecurityContextWindowsOptions {
            /**
             * GMSACredentialSpec is where the GMSA admission webhook (https://github.com/kubernetes-sigs/windows-gmsa) inlines the contents of the GMSA credential spec named by the GMSACredentialSpecName field.
             */
            gmsaCredentialSpec?: string;
            /**
             * GMSACredentialSpecName is the name of the GMSA credential spec to use.
             */
            gmsaCredentialSpecName?: string;
            /**
             * The UserName in Windows to run the entrypoint of the container process. Defaults to the user specified in image metadata if unspecified. May also be set in PodSecurityContext. If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.
             */
            runAsUserName?: string;
        }

        /**
         * StartupProbe indicates that the Pod has successfully initialized. If specified, no other probes are executed until this completes successfully. If this probe fails, the Pod will be restarted, just as if the livenessProbe failed. This can be used to provide different probe parameters at the beginning of a Pod's lifecycle, when it might take a long time to load data or warm a cache, than during steady-state operation. This cannot be updated. This is a beta feature enabled by the StartupProbe feature flag. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
         */
        export interface PrometheusSpecContainersStartupProbe {
            /**
             * One and only one of the following should be specified. Exec specifies the action to take.
             */
            exec?: outputs.monitoring.v1.PrometheusSpecContainersStartupProbeExec;
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * HTTPGet specifies the http request to perform.
             */
            httpGet?: outputs.monitoring.v1.PrometheusSpecContainersStartupProbeHttpGet;
            /**
             * Number of seconds after the container has started before liveness probes are initiated. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness and startup. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * TCPSocket specifies an action involving a TCP port. TCP hooks not yet supported TODO: implement a realistic TCP lifecycle hook
             */
            tcpSocket?: outputs.monitoring.v1.PrometheusSpecContainersStartupProbeTcpSocket;
            /**
             * Number of seconds after which the probe times out. Defaults to 1 second. Minimum value is 1. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
             */
            timeoutSeconds?: number;
        }

        /**
         * One and only one of the following should be specified. Exec specifies the action to take.
         */
        export interface PrometheusSpecContainersStartupProbeExec {
            /**
             * Command is the command line to execute inside the container, the working directory for the command  is root ('/') in the container's filesystem. The command is simply exec'd, it is not run inside a shell, so traditional shell instructions ('|', etc) won't work. To use a shell, you need to explicitly call out to that shell. Exit status of 0 is treated as live/healthy and non-zero is unhealthy.
             */
            command?: string[];
        }

        /**
         * HTTPGet specifies the http request to perform.
         */
        export interface PrometheusSpecContainersStartupProbeHttpGet {
            /**
             * Host name to connect to, defaults to the pod IP. You probably want to set "Host" in httpHeaders instead.
             */
            host?: string;
            /**
             * Custom headers to set in the request. HTTP allows repeated headers.
             */
            httpHeaders?: outputs.monitoring.v1.PrometheusSpecContainersStartupProbeHttpGetHttpHeaders[];
            /**
             * Path to access on the HTTP server.
             */
            path?: string;
            /**
             * Name or number of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME.
             */
            port: outputs.monitoring.v1.PrometheusSpecContainersStartupProbeHttpGetPort;
            /**
             * Scheme to use for connecting to the host. Defaults to HTTP.
             */
            scheme?: string;
        }

        /**
         * HTTPHeader describes a custom header to be used in HTTP probes
         */
        export interface PrometheusSpecContainersStartupProbeHttpGetHttpHeaders {
            /**
             * The header field name
             */
            name: string;
            /**
             * The header field value
             */
            value: string;
        }

        export interface PrometheusSpecContainersStartupProbeHttpGetPort {
        }

        /**
         * TCPSocket specifies an action involving a TCP port. TCP hooks not yet supported TODO: implement a realistic TCP lifecycle hook
         */
        export interface PrometheusSpecContainersStartupProbeTcpSocket {
            /**
             * Optional: Host name to connect to, defaults to the pod IP.
             */
            host?: string;
            /**
             * Number or name of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME.
             */
            port: outputs.monitoring.v1.PrometheusSpecContainersStartupProbeTcpSocketPort;
        }

        export interface PrometheusSpecContainersStartupProbeTcpSocketPort {
        }

        /**
         * volumeDevice describes a mapping of a raw block device within a container.
         */
        export interface PrometheusSpecContainersVolumeDevices {
            /**
             * devicePath is the path inside of the container that the device will be mapped to.
             */
            devicePath: string;
            /**
             * name must match the name of a persistentVolumeClaim in the pod
             */
            name: string;
        }

        /**
         * VolumeMount describes a mounting of a Volume within a container.
         */
        export interface PrometheusSpecContainersVolumeMounts {
            /**
             * Path within the container at which the volume should be mounted.  Must not contain ':'.
             */
            mountPath: string;
            /**
             * mountPropagation determines how mounts are propagated from the host to container and the other way around. When not set, MountPropagationNone is used. This field is beta in 1.10.
             */
            mountPropagation?: string;
            /**
             * This must match the Name of a Volume.
             */
            name: string;
            /**
             * Mounted read-only if true, read-write otherwise (false or unspecified). Defaults to false.
             */
            readOnly?: boolean;
            /**
             * Path within the volume from which the container's volume should be mounted. Defaults to "" (volume's root).
             */
            subPath?: string;
            /**
             * Expanded path within the volume from which the container's volume should be mounted. Behaves similarly to SubPath but environment variable references $(VAR_NAME) are expanded using the container's environment. Defaults to "" (volume's root). SubPathExpr and SubPath are mutually exclusive.
             */
            subPathExpr?: string;
        }

        /**
         * LocalObjectReference contains enough information to let you locate the referenced object inside the same namespace.
         */
        export interface PrometheusSpecImagePullSecrets {
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
        }

        /**
         * A single application container that you want to run within a pod.
         */
        export interface PrometheusSpecInitContainers {
            /**
             * Arguments to the entrypoint. The docker image's CMD is used if this is not provided. Variable references $(VAR_NAME) are expanded using the container's environment. If a variable cannot be resolved, the reference in the input string will be unchanged. The $(VAR_NAME) syntax can be escaped with a double $$, ie: $$(VAR_NAME). Escaped references will never be expanded, regardless of whether the variable exists or not. Cannot be updated. More info: https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#running-a-command-in-a-shell
             */
            args?: string[];
            /**
             * Entrypoint array. Not executed within a shell. The docker image's ENTRYPOINT is used if this is not provided. Variable references $(VAR_NAME) are expanded using the container's environment. If a variable cannot be resolved, the reference in the input string will be unchanged. The $(VAR_NAME) syntax can be escaped with a double $$, ie: $$(VAR_NAME). Escaped references will never be expanded, regardless of whether the variable exists or not. Cannot be updated. More info: https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#running-a-command-in-a-shell
             */
            command?: string[];
            /**
             * List of environment variables to set in the container. Cannot be updated.
             */
            env?: outputs.monitoring.v1.PrometheusSpecInitContainersEnv[];
            /**
             * List of sources to populate environment variables in the container. The keys defined within a source must be a C_IDENTIFIER. All invalid keys will be reported as an event when the container is starting. When a key exists in multiple sources, the value associated with the last source will take precedence. Values defined by an Env with a duplicate key will take precedence. Cannot be updated.
             */
            envFrom?: outputs.monitoring.v1.PrometheusSpecInitContainersEnvFrom[];
            /**
             * Docker image name. More info: https://kubernetes.io/docs/concepts/containers/images This field is optional to allow higher level config management to default or override container images in workload controllers like Deployments and StatefulSets.
             */
            image?: string;
            /**
             * Image pull policy. One of Always, Never, IfNotPresent. Defaults to Always if :latest tag is specified, or IfNotPresent otherwise. Cannot be updated. More info: https://kubernetes.io/docs/concepts/containers/images#updating-images
             */
            imagePullPolicy?: string;
            /**
             * Actions that the management system should take in response to container lifecycle events. Cannot be updated.
             */
            lifecycle?: outputs.monitoring.v1.PrometheusSpecInitContainersLifecycle;
            /**
             * Periodic probe of container liveness. Container will be restarted if the probe fails. Cannot be updated. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
             */
            livenessProbe?: outputs.monitoring.v1.PrometheusSpecInitContainersLivenessProbe;
            /**
             * Name of the container specified as a DNS_LABEL. Each container in a pod must have a unique name (DNS_LABEL). Cannot be updated.
             */
            name: string;
            /**
             * List of ports to expose from the container. Exposing a port here gives the system additional information about the network connections a container uses, but is primarily informational. Not specifying a port here DOES NOT prevent that port from being exposed. Any port which is listening on the default "0.0.0.0" address inside a container will be accessible from the network. Cannot be updated.
             */
            ports?: outputs.monitoring.v1.PrometheusSpecInitContainersPorts[];
            /**
             * Periodic probe of container service readiness. Container will be removed from service endpoints if the probe fails. Cannot be updated. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
             */
            readinessProbe?: outputs.monitoring.v1.PrometheusSpecInitContainersReadinessProbe;
            /**
             * Compute Resources required by this container. Cannot be updated. More info: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
             */
            resources?: outputs.monitoring.v1.PrometheusSpecInitContainersResources;
            /**
             * Security options the pod should run with. More info: https://kubernetes.io/docs/concepts/policy/security-context/ More info: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/
             */
            securityContext?: outputs.monitoring.v1.PrometheusSpecInitContainersSecurityContext;
            /**
             * StartupProbe indicates that the Pod has successfully initialized. If specified, no other probes are executed until this completes successfully. If this probe fails, the Pod will be restarted, just as if the livenessProbe failed. This can be used to provide different probe parameters at the beginning of a Pod's lifecycle, when it might take a long time to load data or warm a cache, than during steady-state operation. This cannot be updated. This is a beta feature enabled by the StartupProbe feature flag. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
             */
            startupProbe?: outputs.monitoring.v1.PrometheusSpecInitContainersStartupProbe;
            /**
             * Whether this container should allocate a buffer for stdin in the container runtime. If this is not set, reads from stdin in the container will always result in EOF. Default is false.
             */
            stdin?: boolean;
            /**
             * Whether the container runtime should close the stdin channel after it has been opened by a single attach. When stdin is true the stdin stream will remain open across multiple attach sessions. If stdinOnce is set to true, stdin is opened on container start, is empty until the first client attaches to stdin, and then remains open and accepts data until the client disconnects, at which time stdin is closed and remains closed until the container is restarted. If this flag is false, a container processes that reads from stdin will never receive an EOF. Default is false
             */
            stdinOnce?: boolean;
            /**
             * Optional: Path at which the file to which the container's termination message will be written is mounted into the container's filesystem. Message written is intended to be brief final status, such as an assertion failure message. Will be truncated by the node if greater than 4096 bytes. The total message length across all containers will be limited to 12kb. Defaults to /dev/termination-log. Cannot be updated.
             */
            terminationMessagePath?: string;
            /**
             * Indicate how the termination message should be populated. File will use the contents of terminationMessagePath to populate the container status message on both success and failure. FallbackToLogsOnError will use the last chunk of container log output if the termination message file is empty and the container exited with an error. The log output is limited to 2048 bytes or 80 lines, whichever is smaller. Defaults to File. Cannot be updated.
             */
            terminationMessagePolicy?: string;
            /**
             * Whether this container should allocate a TTY for itself, also requires 'stdin' to be true. Default is false.
             */
            tty?: boolean;
            /**
             * volumeDevices is the list of block devices to be used by the container.
             */
            volumeDevices?: outputs.monitoring.v1.PrometheusSpecInitContainersVolumeDevices[];
            /**
             * Pod volumes to mount into the container's filesystem. Cannot be updated.
             */
            volumeMounts?: outputs.monitoring.v1.PrometheusSpecInitContainersVolumeMounts[];
            /**
             * Container's working directory. If not specified, the container runtime's default will be used, which might be configured in the container image. Cannot be updated.
             */
            workingDir?: string;
        }

        /**
         * EnvVar represents an environment variable present in a Container.
         */
        export interface PrometheusSpecInitContainersEnv {
            /**
             * Name of the environment variable. Must be a C_IDENTIFIER.
             */
            name: string;
            /**
             * Variable references $(VAR_NAME) are expanded using the previous defined environment variables in the container and any service environment variables. If a variable cannot be resolved, the reference in the input string will be unchanged. The $(VAR_NAME) syntax can be escaped with a double $$, ie: $$(VAR_NAME). Escaped references will never be expanded, regardless of whether the variable exists or not. Defaults to "".
             */
            value?: string;
            /**
             * Source for the environment variable's value. Cannot be used if value is not empty.
             */
            valueFrom?: outputs.monitoring.v1.PrometheusSpecInitContainersEnvValueFrom;
        }

        /**
         * EnvFromSource represents the source of a set of ConfigMaps
         */
        export interface PrometheusSpecInitContainersEnvFrom {
            /**
             * The ConfigMap to select from
             */
            configMapRef?: outputs.monitoring.v1.PrometheusSpecInitContainersEnvFromConfigMapRef;
            /**
             * An optional identifier to prepend to each key in the ConfigMap. Must be a C_IDENTIFIER.
             */
            prefix?: string;
            /**
             * The Secret to select from
             */
            secretRef?: outputs.monitoring.v1.PrometheusSpecInitContainersEnvFromSecretRef;
        }

        /**
         * The ConfigMap to select from
         */
        export interface PrometheusSpecInitContainersEnvFromConfigMapRef {
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the ConfigMap must be defined
             */
            optional?: boolean;
        }

        /**
         * The Secret to select from
         */
        export interface PrometheusSpecInitContainersEnvFromSecretRef {
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret must be defined
             */
            optional?: boolean;
        }

        /**
         * Source for the environment variable's value. Cannot be used if value is not empty.
         */
        export interface PrometheusSpecInitContainersEnvValueFrom {
            /**
             * Selects a key of a ConfigMap.
             */
            configMapKeyRef?: outputs.monitoring.v1.PrometheusSpecInitContainersEnvValueFromConfigMapKeyRef;
            /**
             * Selects a field of the pod: supports metadata.name, metadata.namespace, metadata.labels, metadata.annotations, spec.nodeName, spec.serviceAccountName, status.hostIP, status.podIP, status.podIPs.
             */
            fieldRef?: outputs.monitoring.v1.PrometheusSpecInitContainersEnvValueFromFieldRef;
            /**
             * Selects a resource of the container: only resources limits and requests (limits.cpu, limits.memory, limits.ephemeral-storage, requests.cpu, requests.memory and requests.ephemeral-storage) are currently supported.
             */
            resourceFieldRef?: outputs.monitoring.v1.PrometheusSpecInitContainersEnvValueFromResourceFieldRef;
            /**
             * Selects a key of a secret in the pod's namespace
             */
            secretKeyRef?: outputs.monitoring.v1.PrometheusSpecInitContainersEnvValueFromSecretKeyRef;
        }

        /**
         * Selects a key of a ConfigMap.
         */
        export interface PrometheusSpecInitContainersEnvValueFromConfigMapKeyRef {
            /**
             * The key to select.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the ConfigMap or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Selects a field of the pod: supports metadata.name, metadata.namespace, metadata.labels, metadata.annotations, spec.nodeName, spec.serviceAccountName, status.hostIP, status.podIP, status.podIPs.
         */
        export interface PrometheusSpecInitContainersEnvValueFromFieldRef {
            /**
             * Version of the schema the FieldPath is written in terms of, defaults to "v1".
             */
            apiVersion?: string;
            /**
             * Path of the field to select in the specified API version.
             */
            fieldPath: string;
        }

        /**
         * Selects a resource of the container: only resources limits and requests (limits.cpu, limits.memory, limits.ephemeral-storage, requests.cpu, requests.memory and requests.ephemeral-storage) are currently supported.
         */
        export interface PrometheusSpecInitContainersEnvValueFromResourceFieldRef {
            /**
             * Container name: required for volumes, optional for env vars
             */
            containerName?: string;
            /**
             * Specifies the output format of the exposed resources, defaults to "1"
             */
            divisor?: outputs.monitoring.v1.PrometheusSpecInitContainersEnvValueFromResourceFieldRefDivisor;
            /**
             * Required: resource to select
             */
            resource: string;
        }

        export interface PrometheusSpecInitContainersEnvValueFromResourceFieldRefDivisor {
        }

        /**
         * Selects a key of a secret in the pod's namespace
         */
        export interface PrometheusSpecInitContainersEnvValueFromSecretKeyRef {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Actions that the management system should take in response to container lifecycle events. Cannot be updated.
         */
        export interface PrometheusSpecInitContainersLifecycle {
            /**
             * PostStart is called immediately after a container is created. If the handler fails, the container is terminated and restarted according to its restart policy. Other management of the container blocks until the hook completes. More info: https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks/#container-hooks
             */
            postStart?: outputs.monitoring.v1.PrometheusSpecInitContainersLifecyclePostStart;
            /**
             * PreStop is called immediately before a container is terminated due to an API request or management event such as liveness/startup probe failure, preemption, resource contention, etc. The handler is not called if the container crashes or exits. The reason for termination is passed to the handler. The Pod's termination grace period countdown begins before the PreStop hooked is executed. Regardless of the outcome of the handler, the container will eventually terminate within the Pod's termination grace period. Other management of the container blocks until the hook completes or until the termination grace period is reached. More info: https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks/#container-hooks
             */
            preStop?: outputs.monitoring.v1.PrometheusSpecInitContainersLifecyclePreStop;
        }

        /**
         * PostStart is called immediately after a container is created. If the handler fails, the container is terminated and restarted according to its restart policy. Other management of the container blocks until the hook completes. More info: https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks/#container-hooks
         */
        export interface PrometheusSpecInitContainersLifecyclePostStart {
            /**
             * One and only one of the following should be specified. Exec specifies the action to take.
             */
            exec?: outputs.monitoring.v1.PrometheusSpecInitContainersLifecyclePostStartExec;
            /**
             * HTTPGet specifies the http request to perform.
             */
            httpGet?: outputs.monitoring.v1.PrometheusSpecInitContainersLifecyclePostStartHttpGet;
            /**
             * TCPSocket specifies an action involving a TCP port. TCP hooks not yet supported TODO: implement a realistic TCP lifecycle hook
             */
            tcpSocket?: outputs.monitoring.v1.PrometheusSpecInitContainersLifecyclePostStartTcpSocket;
        }

        /**
         * One and only one of the following should be specified. Exec specifies the action to take.
         */
        export interface PrometheusSpecInitContainersLifecyclePostStartExec {
            /**
             * Command is the command line to execute inside the container, the working directory for the command  is root ('/') in the container's filesystem. The command is simply exec'd, it is not run inside a shell, so traditional shell instructions ('|', etc) won't work. To use a shell, you need to explicitly call out to that shell. Exit status of 0 is treated as live/healthy and non-zero is unhealthy.
             */
            command?: string[];
        }

        /**
         * HTTPGet specifies the http request to perform.
         */
        export interface PrometheusSpecInitContainersLifecyclePostStartHttpGet {
            /**
             * Host name to connect to, defaults to the pod IP. You probably want to set "Host" in httpHeaders instead.
             */
            host?: string;
            /**
             * Custom headers to set in the request. HTTP allows repeated headers.
             */
            httpHeaders?: outputs.monitoring.v1.PrometheusSpecInitContainersLifecyclePostStartHttpGetHttpHeaders[];
            /**
             * Path to access on the HTTP server.
             */
            path?: string;
            /**
             * Name or number of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME.
             */
            port: outputs.monitoring.v1.PrometheusSpecInitContainersLifecyclePostStartHttpGetPort;
            /**
             * Scheme to use for connecting to the host. Defaults to HTTP.
             */
            scheme?: string;
        }

        /**
         * HTTPHeader describes a custom header to be used in HTTP probes
         */
        export interface PrometheusSpecInitContainersLifecyclePostStartHttpGetHttpHeaders {
            /**
             * The header field name
             */
            name: string;
            /**
             * The header field value
             */
            value: string;
        }

        export interface PrometheusSpecInitContainersLifecyclePostStartHttpGetPort {
        }

        /**
         * TCPSocket specifies an action involving a TCP port. TCP hooks not yet supported TODO: implement a realistic TCP lifecycle hook
         */
        export interface PrometheusSpecInitContainersLifecyclePostStartTcpSocket {
            /**
             * Optional: Host name to connect to, defaults to the pod IP.
             */
            host?: string;
            /**
             * Number or name of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME.
             */
            port: outputs.monitoring.v1.PrometheusSpecInitContainersLifecyclePostStartTcpSocketPort;
        }

        export interface PrometheusSpecInitContainersLifecyclePostStartTcpSocketPort {
        }

        /**
         * PreStop is called immediately before a container is terminated due to an API request or management event such as liveness/startup probe failure, preemption, resource contention, etc. The handler is not called if the container crashes or exits. The reason for termination is passed to the handler. The Pod's termination grace period countdown begins before the PreStop hooked is executed. Regardless of the outcome of the handler, the container will eventually terminate within the Pod's termination grace period. Other management of the container blocks until the hook completes or until the termination grace period is reached. More info: https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks/#container-hooks
         */
        export interface PrometheusSpecInitContainersLifecyclePreStop {
            /**
             * One and only one of the following should be specified. Exec specifies the action to take.
             */
            exec?: outputs.monitoring.v1.PrometheusSpecInitContainersLifecyclePreStopExec;
            /**
             * HTTPGet specifies the http request to perform.
             */
            httpGet?: outputs.monitoring.v1.PrometheusSpecInitContainersLifecyclePreStopHttpGet;
            /**
             * TCPSocket specifies an action involving a TCP port. TCP hooks not yet supported TODO: implement a realistic TCP lifecycle hook
             */
            tcpSocket?: outputs.monitoring.v1.PrometheusSpecInitContainersLifecyclePreStopTcpSocket;
        }

        /**
         * One and only one of the following should be specified. Exec specifies the action to take.
         */
        export interface PrometheusSpecInitContainersLifecyclePreStopExec {
            /**
             * Command is the command line to execute inside the container, the working directory for the command  is root ('/') in the container's filesystem. The command is simply exec'd, it is not run inside a shell, so traditional shell instructions ('|', etc) won't work. To use a shell, you need to explicitly call out to that shell. Exit status of 0 is treated as live/healthy and non-zero is unhealthy.
             */
            command?: string[];
        }

        /**
         * HTTPGet specifies the http request to perform.
         */
        export interface PrometheusSpecInitContainersLifecyclePreStopHttpGet {
            /**
             * Host name to connect to, defaults to the pod IP. You probably want to set "Host" in httpHeaders instead.
             */
            host?: string;
            /**
             * Custom headers to set in the request. HTTP allows repeated headers.
             */
            httpHeaders?: outputs.monitoring.v1.PrometheusSpecInitContainersLifecyclePreStopHttpGetHttpHeaders[];
            /**
             * Path to access on the HTTP server.
             */
            path?: string;
            /**
             * Name or number of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME.
             */
            port: outputs.monitoring.v1.PrometheusSpecInitContainersLifecyclePreStopHttpGetPort;
            /**
             * Scheme to use for connecting to the host. Defaults to HTTP.
             */
            scheme?: string;
        }

        /**
         * HTTPHeader describes a custom header to be used in HTTP probes
         */
        export interface PrometheusSpecInitContainersLifecyclePreStopHttpGetHttpHeaders {
            /**
             * The header field name
             */
            name: string;
            /**
             * The header field value
             */
            value: string;
        }

        export interface PrometheusSpecInitContainersLifecyclePreStopHttpGetPort {
        }

        /**
         * TCPSocket specifies an action involving a TCP port. TCP hooks not yet supported TODO: implement a realistic TCP lifecycle hook
         */
        export interface PrometheusSpecInitContainersLifecyclePreStopTcpSocket {
            /**
             * Optional: Host name to connect to, defaults to the pod IP.
             */
            host?: string;
            /**
             * Number or name of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME.
             */
            port: outputs.monitoring.v1.PrometheusSpecInitContainersLifecyclePreStopTcpSocketPort;
        }

        export interface PrometheusSpecInitContainersLifecyclePreStopTcpSocketPort {
        }

        /**
         * Periodic probe of container liveness. Container will be restarted if the probe fails. Cannot be updated. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
         */
        export interface PrometheusSpecInitContainersLivenessProbe {
            /**
             * One and only one of the following should be specified. Exec specifies the action to take.
             */
            exec?: outputs.monitoring.v1.PrometheusSpecInitContainersLivenessProbeExec;
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * HTTPGet specifies the http request to perform.
             */
            httpGet?: outputs.monitoring.v1.PrometheusSpecInitContainersLivenessProbeHttpGet;
            /**
             * Number of seconds after the container has started before liveness probes are initiated. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness and startup. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * TCPSocket specifies an action involving a TCP port. TCP hooks not yet supported TODO: implement a realistic TCP lifecycle hook
             */
            tcpSocket?: outputs.monitoring.v1.PrometheusSpecInitContainersLivenessProbeTcpSocket;
            /**
             * Number of seconds after which the probe times out. Defaults to 1 second. Minimum value is 1. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
             */
            timeoutSeconds?: number;
        }

        /**
         * One and only one of the following should be specified. Exec specifies the action to take.
         */
        export interface PrometheusSpecInitContainersLivenessProbeExec {
            /**
             * Command is the command line to execute inside the container, the working directory for the command  is root ('/') in the container's filesystem. The command is simply exec'd, it is not run inside a shell, so traditional shell instructions ('|', etc) won't work. To use a shell, you need to explicitly call out to that shell. Exit status of 0 is treated as live/healthy and non-zero is unhealthy.
             */
            command?: string[];
        }

        /**
         * HTTPGet specifies the http request to perform.
         */
        export interface PrometheusSpecInitContainersLivenessProbeHttpGet {
            /**
             * Host name to connect to, defaults to the pod IP. You probably want to set "Host" in httpHeaders instead.
             */
            host?: string;
            /**
             * Custom headers to set in the request. HTTP allows repeated headers.
             */
            httpHeaders?: outputs.monitoring.v1.PrometheusSpecInitContainersLivenessProbeHttpGetHttpHeaders[];
            /**
             * Path to access on the HTTP server.
             */
            path?: string;
            /**
             * Name or number of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME.
             */
            port: outputs.monitoring.v1.PrometheusSpecInitContainersLivenessProbeHttpGetPort;
            /**
             * Scheme to use for connecting to the host. Defaults to HTTP.
             */
            scheme?: string;
        }

        /**
         * HTTPHeader describes a custom header to be used in HTTP probes
         */
        export interface PrometheusSpecInitContainersLivenessProbeHttpGetHttpHeaders {
            /**
             * The header field name
             */
            name: string;
            /**
             * The header field value
             */
            value: string;
        }

        export interface PrometheusSpecInitContainersLivenessProbeHttpGetPort {
        }

        /**
         * TCPSocket specifies an action involving a TCP port. TCP hooks not yet supported TODO: implement a realistic TCP lifecycle hook
         */
        export interface PrometheusSpecInitContainersLivenessProbeTcpSocket {
            /**
             * Optional: Host name to connect to, defaults to the pod IP.
             */
            host?: string;
            /**
             * Number or name of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME.
             */
            port: outputs.monitoring.v1.PrometheusSpecInitContainersLivenessProbeTcpSocketPort;
        }

        export interface PrometheusSpecInitContainersLivenessProbeTcpSocketPort {
        }

        /**
         * ContainerPort represents a network port in a single container.
         */
        export interface PrometheusSpecInitContainersPorts {
            /**
             * Number of port to expose on the pod's IP address. This must be a valid port number, 0 < x < 65536.
             */
            containerPort: number;
            /**
             * What host IP to bind the external port to.
             */
            hostIP?: string;
            /**
             * Number of port to expose on the host. If specified, this must be a valid port number, 0 < x < 65536. If HostNetwork is specified, this must match ContainerPort. Most containers do not need this.
             */
            hostPort?: number;
            /**
             * If specified, this must be an IANA_SVC_NAME and unique within the pod. Each named port in a pod must have a unique name. Name for the port that can be referred to by services.
             */
            name?: string;
            /**
             * Protocol for port. Must be UDP, TCP, or SCTP. Defaults to "TCP".
             */
            protocol?: string;
        }

        /**
         * Periodic probe of container service readiness. Container will be removed from service endpoints if the probe fails. Cannot be updated. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
         */
        export interface PrometheusSpecInitContainersReadinessProbe {
            /**
             * One and only one of the following should be specified. Exec specifies the action to take.
             */
            exec?: outputs.monitoring.v1.PrometheusSpecInitContainersReadinessProbeExec;
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * HTTPGet specifies the http request to perform.
             */
            httpGet?: outputs.monitoring.v1.PrometheusSpecInitContainersReadinessProbeHttpGet;
            /**
             * Number of seconds after the container has started before liveness probes are initiated. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness and startup. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * TCPSocket specifies an action involving a TCP port. TCP hooks not yet supported TODO: implement a realistic TCP lifecycle hook
             */
            tcpSocket?: outputs.monitoring.v1.PrometheusSpecInitContainersReadinessProbeTcpSocket;
            /**
             * Number of seconds after which the probe times out. Defaults to 1 second. Minimum value is 1. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
             */
            timeoutSeconds?: number;
        }

        /**
         * One and only one of the following should be specified. Exec specifies the action to take.
         */
        export interface PrometheusSpecInitContainersReadinessProbeExec {
            /**
             * Command is the command line to execute inside the container, the working directory for the command  is root ('/') in the container's filesystem. The command is simply exec'd, it is not run inside a shell, so traditional shell instructions ('|', etc) won't work. To use a shell, you need to explicitly call out to that shell. Exit status of 0 is treated as live/healthy and non-zero is unhealthy.
             */
            command?: string[];
        }

        /**
         * HTTPGet specifies the http request to perform.
         */
        export interface PrometheusSpecInitContainersReadinessProbeHttpGet {
            /**
             * Host name to connect to, defaults to the pod IP. You probably want to set "Host" in httpHeaders instead.
             */
            host?: string;
            /**
             * Custom headers to set in the request. HTTP allows repeated headers.
             */
            httpHeaders?: outputs.monitoring.v1.PrometheusSpecInitContainersReadinessProbeHttpGetHttpHeaders[];
            /**
             * Path to access on the HTTP server.
             */
            path?: string;
            /**
             * Name or number of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME.
             */
            port: outputs.monitoring.v1.PrometheusSpecInitContainersReadinessProbeHttpGetPort;
            /**
             * Scheme to use for connecting to the host. Defaults to HTTP.
             */
            scheme?: string;
        }

        /**
         * HTTPHeader describes a custom header to be used in HTTP probes
         */
        export interface PrometheusSpecInitContainersReadinessProbeHttpGetHttpHeaders {
            /**
             * The header field name
             */
            name: string;
            /**
             * The header field value
             */
            value: string;
        }

        export interface PrometheusSpecInitContainersReadinessProbeHttpGetPort {
        }

        /**
         * TCPSocket specifies an action involving a TCP port. TCP hooks not yet supported TODO: implement a realistic TCP lifecycle hook
         */
        export interface PrometheusSpecInitContainersReadinessProbeTcpSocket {
            /**
             * Optional: Host name to connect to, defaults to the pod IP.
             */
            host?: string;
            /**
             * Number or name of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME.
             */
            port: outputs.monitoring.v1.PrometheusSpecInitContainersReadinessProbeTcpSocketPort;
        }

        export interface PrometheusSpecInitContainersReadinessProbeTcpSocketPort {
        }

        /**
         * Compute Resources required by this container. Cannot be updated. More info: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
         */
        export interface PrometheusSpecInitContainersResources {
            /**
             * Limits describes the maximum amount of compute resources allowed. More info: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
             */
            limits?: {[key: string]: outputs.monitoring.v1.PrometheusSpecInitContainersResourcesLimits};
            /**
             * Requests describes the minimum amount of compute resources required. If Requests is omitted for a container, it defaults to Limits if that is explicitly specified, otherwise to an implementation-defined value. More info: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
             */
            requests?: {[key: string]: outputs.monitoring.v1.PrometheusSpecInitContainersResourcesRequests};
        }

        export interface PrometheusSpecInitContainersResourcesLimits {
        }

        export interface PrometheusSpecInitContainersResourcesRequests {
        }

        /**
         * Security options the pod should run with. More info: https://kubernetes.io/docs/concepts/policy/security-context/ More info: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/
         */
        export interface PrometheusSpecInitContainersSecurityContext {
            /**
             * AllowPrivilegeEscalation controls whether a process can gain more privileges than its parent process. This bool directly controls if the no_new_privs flag will be set on the container process. AllowPrivilegeEscalation is true always when the container is: 1) run as Privileged 2) has CAP_SYS_ADMIN
             */
            allowPrivilegeEscalation?: boolean;
            /**
             * The capabilities to add/drop when running containers. Defaults to the default set of capabilities granted by the container runtime.
             */
            capabilities?: outputs.monitoring.v1.PrometheusSpecInitContainersSecurityContextCapabilities;
            /**
             * Run container in privileged mode. Processes in privileged containers are essentially equivalent to root on the host. Defaults to false.
             */
            privileged?: boolean;
            /**
             * procMount denotes the type of proc mount to use for the containers. The default is DefaultProcMount which uses the container runtime defaults for readonly paths and masked paths. This requires the ProcMountType feature flag to be enabled.
             */
            procMount?: string;
            /**
             * Whether this container has a read-only root filesystem. Default is false.
             */
            readOnlyRootFilesystem?: boolean;
            /**
             * The GID to run the entrypoint of the container process. Uses runtime default if unset. May also be set in PodSecurityContext.  If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.
             */
            runAsGroup?: number;
            /**
             * Indicates that the container must run as a non-root user. If true, the Kubelet will validate the image at runtime to ensure that it does not run as UID 0 (root) and fail to start the container if it does. If unset or false, no such validation will be performed. May also be set in PodSecurityContext.  If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.
             */
            runAsNonRoot?: boolean;
            /**
             * The UID to run the entrypoint of the container process. Defaults to user specified in image metadata if unspecified. May also be set in PodSecurityContext.  If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.
             */
            runAsUser?: number;
            /**
             * The SELinux context to be applied to the container. If unspecified, the container runtime will allocate a random SELinux context for each container.  May also be set in PodSecurityContext.  If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.
             */
            seLinuxOptions?: outputs.monitoring.v1.PrometheusSpecInitContainersSecurityContextSeLinuxOptions;
            /**
             * The Windows specific settings applied to all containers. If unspecified, the options from the PodSecurityContext will be used. If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.
             */
            windowsOptions?: outputs.monitoring.v1.PrometheusSpecInitContainersSecurityContextWindowsOptions;
        }

        /**
         * The capabilities to add/drop when running containers. Defaults to the default set of capabilities granted by the container runtime.
         */
        export interface PrometheusSpecInitContainersSecurityContextCapabilities {
            /**
             * Added capabilities
             */
            add?: string[];
            /**
             * Removed capabilities
             */
            drop?: string[];
        }

        /**
         * The SELinux context to be applied to the container. If unspecified, the container runtime will allocate a random SELinux context for each container.  May also be set in PodSecurityContext.  If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.
         */
        export interface PrometheusSpecInitContainersSecurityContextSeLinuxOptions {
            /**
             * Level is SELinux level label that applies to the container.
             */
            level?: string;
            /**
             * Role is a SELinux role label that applies to the container.
             */
            role?: string;
            /**
             * Type is a SELinux type label that applies to the container.
             */
            type?: string;
            /**
             * User is a SELinux user label that applies to the container.
             */
            user?: string;
        }

        /**
         * The Windows specific settings applied to all containers. If unspecified, the options from the PodSecurityContext will be used. If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.
         */
        export interface PrometheusSpecInitContainersSecurityContextWindowsOptions {
            /**
             * GMSACredentialSpec is where the GMSA admission webhook (https://github.com/kubernetes-sigs/windows-gmsa) inlines the contents of the GMSA credential spec named by the GMSACredentialSpecName field.
             */
            gmsaCredentialSpec?: string;
            /**
             * GMSACredentialSpecName is the name of the GMSA credential spec to use.
             */
            gmsaCredentialSpecName?: string;
            /**
             * The UserName in Windows to run the entrypoint of the container process. Defaults to the user specified in image metadata if unspecified. May also be set in PodSecurityContext. If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.
             */
            runAsUserName?: string;
        }

        /**
         * StartupProbe indicates that the Pod has successfully initialized. If specified, no other probes are executed until this completes successfully. If this probe fails, the Pod will be restarted, just as if the livenessProbe failed. This can be used to provide different probe parameters at the beginning of a Pod's lifecycle, when it might take a long time to load data or warm a cache, than during steady-state operation. This cannot be updated. This is a beta feature enabled by the StartupProbe feature flag. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
         */
        export interface PrometheusSpecInitContainersStartupProbe {
            /**
             * One and only one of the following should be specified. Exec specifies the action to take.
             */
            exec?: outputs.monitoring.v1.PrometheusSpecInitContainersStartupProbeExec;
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * HTTPGet specifies the http request to perform.
             */
            httpGet?: outputs.monitoring.v1.PrometheusSpecInitContainersStartupProbeHttpGet;
            /**
             * Number of seconds after the container has started before liveness probes are initiated. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness and startup. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * TCPSocket specifies an action involving a TCP port. TCP hooks not yet supported TODO: implement a realistic TCP lifecycle hook
             */
            tcpSocket?: outputs.monitoring.v1.PrometheusSpecInitContainersStartupProbeTcpSocket;
            /**
             * Number of seconds after which the probe times out. Defaults to 1 second. Minimum value is 1. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
             */
            timeoutSeconds?: number;
        }

        /**
         * One and only one of the following should be specified. Exec specifies the action to take.
         */
        export interface PrometheusSpecInitContainersStartupProbeExec {
            /**
             * Command is the command line to execute inside the container, the working directory for the command  is root ('/') in the container's filesystem. The command is simply exec'd, it is not run inside a shell, so traditional shell instructions ('|', etc) won't work. To use a shell, you need to explicitly call out to that shell. Exit status of 0 is treated as live/healthy and non-zero is unhealthy.
             */
            command?: string[];
        }

        /**
         * HTTPGet specifies the http request to perform.
         */
        export interface PrometheusSpecInitContainersStartupProbeHttpGet {
            /**
             * Host name to connect to, defaults to the pod IP. You probably want to set "Host" in httpHeaders instead.
             */
            host?: string;
            /**
             * Custom headers to set in the request. HTTP allows repeated headers.
             */
            httpHeaders?: outputs.monitoring.v1.PrometheusSpecInitContainersStartupProbeHttpGetHttpHeaders[];
            /**
             * Path to access on the HTTP server.
             */
            path?: string;
            /**
             * Name or number of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME.
             */
            port: outputs.monitoring.v1.PrometheusSpecInitContainersStartupProbeHttpGetPort;
            /**
             * Scheme to use for connecting to the host. Defaults to HTTP.
             */
            scheme?: string;
        }

        /**
         * HTTPHeader describes a custom header to be used in HTTP probes
         */
        export interface PrometheusSpecInitContainersStartupProbeHttpGetHttpHeaders {
            /**
             * The header field name
             */
            name: string;
            /**
             * The header field value
             */
            value: string;
        }

        export interface PrometheusSpecInitContainersStartupProbeHttpGetPort {
        }

        /**
         * TCPSocket specifies an action involving a TCP port. TCP hooks not yet supported TODO: implement a realistic TCP lifecycle hook
         */
        export interface PrometheusSpecInitContainersStartupProbeTcpSocket {
            /**
             * Optional: Host name to connect to, defaults to the pod IP.
             */
            host?: string;
            /**
             * Number or name of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME.
             */
            port: outputs.monitoring.v1.PrometheusSpecInitContainersStartupProbeTcpSocketPort;
        }

        export interface PrometheusSpecInitContainersStartupProbeTcpSocketPort {
        }

        /**
         * volumeDevice describes a mapping of a raw block device within a container.
         */
        export interface PrometheusSpecInitContainersVolumeDevices {
            /**
             * devicePath is the path inside of the container that the device will be mapped to.
             */
            devicePath: string;
            /**
             * name must match the name of a persistentVolumeClaim in the pod
             */
            name: string;
        }

        /**
         * VolumeMount describes a mounting of a Volume within a container.
         */
        export interface PrometheusSpecInitContainersVolumeMounts {
            /**
             * Path within the container at which the volume should be mounted.  Must not contain ':'.
             */
            mountPath: string;
            /**
             * mountPropagation determines how mounts are propagated from the host to container and the other way around. When not set, MountPropagationNone is used. This field is beta in 1.10.
             */
            mountPropagation?: string;
            /**
             * This must match the Name of a Volume.
             */
            name: string;
            /**
             * Mounted read-only if true, read-write otherwise (false or unspecified). Defaults to false.
             */
            readOnly?: boolean;
            /**
             * Path within the volume from which the container's volume should be mounted. Defaults to "" (volume's root).
             */
            subPath?: string;
            /**
             * Expanded path within the volume from which the container's volume should be mounted. Behaves similarly to SubPath but environment variable references $(VAR_NAME) are expanded using the container's environment. Defaults to "" (volume's root). SubPathExpr and SubPath are mutually exclusive.
             */
            subPathExpr?: string;
        }

        /**
         * PodMetadata configures Labels and Annotations which are propagated to the prometheus pods.
         */
        export interface PrometheusSpecPodMetadata {
            /**
             * Annotations is an unstructured key value map stored with a resource that may be set by external tools to store and retrieve arbitrary metadata. They are not queryable and should be preserved when modifying objects. More info: http://kubernetes.io/docs/user-guide/annotations
             */
            annotations?: {[key: string]: string};
            /**
             * Map of string keys and values that can be used to organize and categorize (scope and select) objects. May match selectors of replication controllers and services. More info: http://kubernetes.io/docs/user-guide/labels
             */
            labels?: {[key: string]: string};
            /**
             * Name must be unique within a namespace. Is required when creating resources, although some resources may allow a client to request the generation of an appropriate name automatically. Name is primarily intended for creation idempotence and configuration definition. Cannot be updated. More info: http://kubernetes.io/docs/user-guide/identifiers#names
             */
            name?: string;
        }

        /**
         * Namespaces to be selected for PodMonitor discovery. If nil, only check own namespace.
         */
        export interface PrometheusSpecPodMonitorNamespaceSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.monitoring.v1.PrometheusSpecPodMonitorNamespaceSelectorMatchExpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface PrometheusSpecPodMonitorNamespaceSelectorMatchExpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * *Experimental* PodMonitors to be selected for target discovery. *Deprecated:* if neither this nor serviceMonitorSelector are specified, configuration is unmanaged.
         */
        export interface PrometheusSpecPodMonitorSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.monitoring.v1.PrometheusSpecPodMonitorSelectorMatchExpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface PrometheusSpecPodMonitorSelectorMatchExpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * *Experimental* Namespaces to be selected for Probe discovery. If nil, only check own namespace.
         */
        export interface PrometheusSpecProbeNamespaceSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.monitoring.v1.PrometheusSpecProbeNamespaceSelectorMatchExpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface PrometheusSpecProbeNamespaceSelectorMatchExpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * *Experimental* Probes to be selected for target discovery.
         */
        export interface PrometheusSpecProbeSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.monitoring.v1.PrometheusSpecProbeSelectorMatchExpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface PrometheusSpecProbeSelectorMatchExpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * PrometheusRuleExcludeConfig enables users to configure excluded PrometheusRule names and their namespaces to be ignored while enforcing namespace label for alerts and metrics.
         */
        export interface PrometheusSpecPrometheusRulesExcludedFromEnforce {
            /**
             * RuleNamespace - name of excluded rule
             */
            ruleName: string;
            /**
             * RuleNamespace - namespace of excluded rule
             */
            ruleNamespace: string;
        }

        /**
         * QuerySpec defines the query command line flags when starting Prometheus.
         */
        export interface PrometheusSpecQuery {
            /**
             * The delta difference allowed for retrieving metrics during expression evaluations.
             */
            lookbackDelta?: string;
            /**
             * Number of concurrent queries that can be run at once.
             */
            maxConcurrency?: number;
            /**
             * Maximum number of samples a single query can load into memory. Note that queries will fail if they would load more samples than this into memory, so this also limits the number of samples a query can return.
             */
            maxSamples?: number;
            /**
             * Maximum time a query may take before being aborted.
             */
            timeout?: string;
        }

        /**
         * RemoteReadSpec defines the remote_read configuration for prometheus.
         */
        export interface PrometheusSpecRemoteRead {
            /**
             * BasicAuth for the URL.
             */
            basicAuth?: outputs.monitoring.v1.PrometheusSpecRemoteReadBasicAuth;
            /**
             * bearer token for remote read.
             */
            bearerToken?: string;
            /**
             * File to read bearer token for remote read.
             */
            bearerTokenFile?: string;
            /**
             * The name of the remote read queue, must be unique if specified. The name is used in metrics and logging in order to differentiate read configurations.  Only valid in Prometheus versions 2.15.0 and newer.
             */
            name?: string;
            /**
             * Optional ProxyURL
             */
            proxyUrl?: string;
            /**
             * Whether reads should be made for queries for time ranges that the local storage should have complete data for.
             */
            readRecent?: boolean;
            /**
             * Timeout for requests to the remote read endpoint.
             */
            remoteTimeout?: string;
            /**
             * An optional list of equality matchers which have to be present in a selector to query the remote read endpoint.
             */
            requiredMatchers?: {[key: string]: string};
            /**
             * TLS Config to use for remote read.
             */
            tlsConfig?: outputs.monitoring.v1.PrometheusSpecRemoteReadTlsConfig;
            /**
             * The URL of the endpoint to send samples to.
             */
            url: string;
        }

        /**
         * BasicAuth for the URL.
         */
        export interface PrometheusSpecRemoteReadBasicAuth {
            /**
             * The secret in the service monitor namespace that contains the password for authentication.
             */
            password?: outputs.monitoring.v1.PrometheusSpecRemoteReadBasicAuthPassword;
            /**
             * The secret in the service monitor namespace that contains the username for authentication.
             */
            username?: outputs.monitoring.v1.PrometheusSpecRemoteReadBasicAuthUsername;
        }

        /**
         * The secret in the service monitor namespace that contains the password for authentication.
         */
        export interface PrometheusSpecRemoteReadBasicAuthPassword {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * The secret in the service monitor namespace that contains the username for authentication.
         */
        export interface PrometheusSpecRemoteReadBasicAuthUsername {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * TLS Config to use for remote read.
         */
        export interface PrometheusSpecRemoteReadTlsConfig {
            /**
             * Struct containing the CA cert to use for the targets.
             */
            ca?: outputs.monitoring.v1.PrometheusSpecRemoteReadTlsConfigCa;
            /**
             * Path to the CA cert in the Prometheus container to use for the targets.
             */
            caFile?: string;
            /**
             * Struct containing the client cert file for the targets.
             */
            cert?: outputs.monitoring.v1.PrometheusSpecRemoteReadTlsConfigCert;
            /**
             * Path to the client cert file in the Prometheus container for the targets.
             */
            certFile?: string;
            /**
             * Disable target certificate validation.
             */
            insecureSkipVerify?: boolean;
            /**
             * Path to the client key file in the Prometheus container for the targets.
             */
            keyFile?: string;
            /**
             * Secret containing the client key file for the targets.
             */
            keySecret?: outputs.monitoring.v1.PrometheusSpecRemoteReadTlsConfigKeySecret;
            /**
             * Used to verify the hostname for the targets.
             */
            serverName?: string;
        }

        /**
         * Struct containing the CA cert to use for the targets.
         */
        export interface PrometheusSpecRemoteReadTlsConfigCa {
            /**
             * ConfigMap containing data to use for the targets.
             */
            configMap?: outputs.monitoring.v1.PrometheusSpecRemoteReadTlsConfigCaConfigMap;
            /**
             * Secret containing data to use for the targets.
             */
            secret?: outputs.monitoring.v1.PrometheusSpecRemoteReadTlsConfigCaSecret;
        }

        /**
         * ConfigMap containing data to use for the targets.
         */
        export interface PrometheusSpecRemoteReadTlsConfigCaConfigMap {
            /**
             * The key to select.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the ConfigMap or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Secret containing data to use for the targets.
         */
        export interface PrometheusSpecRemoteReadTlsConfigCaSecret {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Struct containing the client cert file for the targets.
         */
        export interface PrometheusSpecRemoteReadTlsConfigCert {
            /**
             * ConfigMap containing data to use for the targets.
             */
            configMap?: outputs.monitoring.v1.PrometheusSpecRemoteReadTlsConfigCertConfigMap;
            /**
             * Secret containing data to use for the targets.
             */
            secret?: outputs.monitoring.v1.PrometheusSpecRemoteReadTlsConfigCertSecret;
        }

        /**
         * ConfigMap containing data to use for the targets.
         */
        export interface PrometheusSpecRemoteReadTlsConfigCertConfigMap {
            /**
             * The key to select.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the ConfigMap or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Secret containing data to use for the targets.
         */
        export interface PrometheusSpecRemoteReadTlsConfigCertSecret {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Secret containing the client key file for the targets.
         */
        export interface PrometheusSpecRemoteReadTlsConfigKeySecret {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * RemoteWriteSpec defines the remote_write configuration for prometheus.
         */
        export interface PrometheusSpecRemoteWrite {
            /**
             * BasicAuth for the URL.
             */
            basicAuth?: outputs.monitoring.v1.PrometheusSpecRemoteWriteBasicAuth;
            /**
             * File to read bearer token for remote write.
             */
            bearerToken?: string;
            /**
             * File to read bearer token for remote write.
             */
            bearerTokenFile?: string;
            /**
             * The name of the remote write queue, must be unique if specified. The name is used in metrics and logging in order to differentiate queues. Only valid in Prometheus versions 2.15.0 and newer.
             */
            name?: string;
            /**
             * Optional ProxyURL
             */
            proxyUrl?: string;
            /**
             * QueueConfig allows tuning of the remote write queue parameters.
             */
            queueConfig?: outputs.monitoring.v1.PrometheusSpecRemoteWriteQueueConfig;
            /**
             * Timeout for requests to the remote write endpoint.
             */
            remoteTimeout?: string;
            /**
             * TLS Config to use for remote write.
             */
            tlsConfig?: outputs.monitoring.v1.PrometheusSpecRemoteWriteTlsConfig;
            /**
             * The URL of the endpoint to send samples to.
             */
            url: string;
            /**
             * The list of remote write relabel configurations.
             */
            writeRelabelConfigs?: outputs.monitoring.v1.PrometheusSpecRemoteWriteWriteRelabelConfigs[];
        }

        /**
         * BasicAuth for the URL.
         */
        export interface PrometheusSpecRemoteWriteBasicAuth {
            /**
             * The secret in the service monitor namespace that contains the password for authentication.
             */
            password?: outputs.monitoring.v1.PrometheusSpecRemoteWriteBasicAuthPassword;
            /**
             * The secret in the service monitor namespace that contains the username for authentication.
             */
            username?: outputs.monitoring.v1.PrometheusSpecRemoteWriteBasicAuthUsername;
        }

        /**
         * The secret in the service monitor namespace that contains the password for authentication.
         */
        export interface PrometheusSpecRemoteWriteBasicAuthPassword {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * The secret in the service monitor namespace that contains the username for authentication.
         */
        export interface PrometheusSpecRemoteWriteBasicAuthUsername {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * QueueConfig allows tuning of the remote write queue parameters.
         */
        export interface PrometheusSpecRemoteWriteQueueConfig {
            /**
             * BatchSendDeadline is the maximum time a sample will wait in buffer.
             */
            batchSendDeadline?: string;
            /**
             * Capacity is the number of samples to buffer per shard before we start dropping them.
             */
            capacity?: number;
            /**
             * MaxBackoff is the maximum retry delay.
             */
            maxBackoff?: string;
            /**
             * MaxRetries is the maximum number of times to retry a batch on recoverable errors.
             */
            maxRetries?: number;
            /**
             * MaxSamplesPerSend is the maximum number of samples per send.
             */
            maxSamplesPerSend?: number;
            /**
             * MaxShards is the maximum number of shards, i.e. amount of concurrency.
             */
            maxShards?: number;
            /**
             * MinBackoff is the initial retry delay. Gets doubled for every retry.
             */
            minBackoff?: string;
            /**
             * MinShards is the minimum number of shards, i.e. amount of concurrency.
             */
            minShards?: number;
        }

        /**
         * TLS Config to use for remote write.
         */
        export interface PrometheusSpecRemoteWriteTlsConfig {
            /**
             * Struct containing the CA cert to use for the targets.
             */
            ca?: outputs.monitoring.v1.PrometheusSpecRemoteWriteTlsConfigCa;
            /**
             * Path to the CA cert in the Prometheus container to use for the targets.
             */
            caFile?: string;
            /**
             * Struct containing the client cert file for the targets.
             */
            cert?: outputs.monitoring.v1.PrometheusSpecRemoteWriteTlsConfigCert;
            /**
             * Path to the client cert file in the Prometheus container for the targets.
             */
            certFile?: string;
            /**
             * Disable target certificate validation.
             */
            insecureSkipVerify?: boolean;
            /**
             * Path to the client key file in the Prometheus container for the targets.
             */
            keyFile?: string;
            /**
             * Secret containing the client key file for the targets.
             */
            keySecret?: outputs.monitoring.v1.PrometheusSpecRemoteWriteTlsConfigKeySecret;
            /**
             * Used to verify the hostname for the targets.
             */
            serverName?: string;
        }

        /**
         * Struct containing the CA cert to use for the targets.
         */
        export interface PrometheusSpecRemoteWriteTlsConfigCa {
            /**
             * ConfigMap containing data to use for the targets.
             */
            configMap?: outputs.monitoring.v1.PrometheusSpecRemoteWriteTlsConfigCaConfigMap;
            /**
             * Secret containing data to use for the targets.
             */
            secret?: outputs.monitoring.v1.PrometheusSpecRemoteWriteTlsConfigCaSecret;
        }

        /**
         * ConfigMap containing data to use for the targets.
         */
        export interface PrometheusSpecRemoteWriteTlsConfigCaConfigMap {
            /**
             * The key to select.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the ConfigMap or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Secret containing data to use for the targets.
         */
        export interface PrometheusSpecRemoteWriteTlsConfigCaSecret {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Struct containing the client cert file for the targets.
         */
        export interface PrometheusSpecRemoteWriteTlsConfigCert {
            /**
             * ConfigMap containing data to use for the targets.
             */
            configMap?: outputs.monitoring.v1.PrometheusSpecRemoteWriteTlsConfigCertConfigMap;
            /**
             * Secret containing data to use for the targets.
             */
            secret?: outputs.monitoring.v1.PrometheusSpecRemoteWriteTlsConfigCertSecret;
        }

        /**
         * ConfigMap containing data to use for the targets.
         */
        export interface PrometheusSpecRemoteWriteTlsConfigCertConfigMap {
            /**
             * The key to select.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the ConfigMap or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Secret containing data to use for the targets.
         */
        export interface PrometheusSpecRemoteWriteTlsConfigCertSecret {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Secret containing the client key file for the targets.
         */
        export interface PrometheusSpecRemoteWriteTlsConfigKeySecret {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * RelabelConfig allows dynamic rewriting of the label set, being applied to samples before ingestion. It defines `<metric_relabel_configs>`-section of Prometheus configuration. More info: https://prometheus.io/docs/prometheus/latest/configuration/configuration/#metric_relabel_configs
         */
        export interface PrometheusSpecRemoteWriteWriteRelabelConfigs {
            /**
             * Action to perform based on regex matching. Default is 'replace'
             */
            action?: string;
            /**
             * Modulus to take of the hash of the source label values.
             */
            modulus?: number;
            /**
             * Regular expression against which the extracted value is matched. Default is '(.*)'
             */
            regex?: string;
            /**
             * Replacement value against which a regex replace is performed if the regular expression matches. Regex capture groups are available. Default is '$1'
             */
            replacement?: string;
            /**
             * Separator placed between concatenated source label values. default is ';'.
             */
            separator?: string;
            /**
             * The source labels select values from existing labels. Their content is concatenated using the configured separator and matched against the configured regular expression for the replace, keep, and drop actions.
             */
            sourceLabels?: string[];
            /**
             * Label to which the resulting value is written in a replace action. It is mandatory for replace actions. Regex capture groups are available.
             */
            targetLabel?: string;
        }

        /**
         * Define resources requests and limits for single Pods.
         */
        export interface PrometheusSpecResources {
            /**
             * Limits describes the maximum amount of compute resources allowed. More info: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
             */
            limits?: {[key: string]: outputs.monitoring.v1.PrometheusSpecResourcesLimits};
            /**
             * Requests describes the minimum amount of compute resources required. If Requests is omitted for a container, it defaults to Limits if that is explicitly specified, otherwise to an implementation-defined value. More info: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
             */
            requests?: {[key: string]: outputs.monitoring.v1.PrometheusSpecResourcesRequests};
        }

        export interface PrometheusSpecResourcesLimits {
        }

        export interface PrometheusSpecResourcesRequests {
        }

        /**
         * Namespaces to be selected for PrometheusRules discovery. If unspecified, only the same namespace as the Prometheus object is in is used.
         */
        export interface PrometheusSpecRuleNamespaceSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.monitoring.v1.PrometheusSpecRuleNamespaceSelectorMatchExpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface PrometheusSpecRuleNamespaceSelectorMatchExpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * A selector to select which PrometheusRules to mount for loading alerting/recording rules from. Until (excluding) Prometheus Operator v0.24.0 Prometheus Operator will migrate any legacy rule ConfigMaps to PrometheusRule custom resources selected by RuleSelector. Make sure it does not match any config maps that you do not want to be migrated.
         */
        export interface PrometheusSpecRuleSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.monitoring.v1.PrometheusSpecRuleSelectorMatchExpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface PrometheusSpecRuleSelectorMatchExpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * /--rules.*&#47; command-line arguments.
         */
        export interface PrometheusSpecRules {
            /**
             * /--rules.alert.*&#47; command-line arguments
             */
            alert?: outputs.monitoring.v1.PrometheusSpecRulesAlert;
        }

        /**
         * /--rules.alert.*&#47; command-line arguments
         */
        export interface PrometheusSpecRulesAlert {
            /**
             * Minimum duration between alert and restored 'for' state. This is maintained only for alerts with configured 'for' time greater than grace period.
             */
            forGracePeriod?: string;
            /**
             * Max time to tolerate prometheus outage for restoring 'for' state of alert.
             */
            forOutageTolerance?: string;
            /**
             * Minimum amount of time to wait before resending an alert to Alertmanager.
             */
            resendDelay?: string;
        }

        /**
         * SecurityContext holds pod-level security attributes and common container settings. This defaults to the default PodSecurityContext.
         */
        export interface PrometheusSpecSecurityContext {
            /**
             * A special supplemental group that applies to all containers in a pod. Some volume types allow the Kubelet to change the ownership of that volume to be owned by the pod: 
             *  1. The owning GID will be the FSGroup 2. The setgid bit is set (new files created in the volume will be owned by FSGroup) 3. The permission bits are OR'd with rw-rw---- 
             *  If unset, the Kubelet will not modify the ownership and permissions of any volume.
             */
            fsGroup?: number;
            /**
             * fsGroupChangePolicy defines behavior of changing ownership and permission of the volume before being exposed inside Pod. This field will only apply to volume types which support fsGroup based ownership(and permissions). It will have no effect on ephemeral volume types such as: secret, configmaps and emptydir. Valid values are "OnRootMismatch" and "Always". If not specified defaults to "Always".
             */
            fsGroupChangePolicy?: string;
            /**
             * The GID to run the entrypoint of the container process. Uses runtime default if unset. May also be set in SecurityContext.  If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence for that container.
             */
            runAsGroup?: number;
            /**
             * Indicates that the container must run as a non-root user. If true, the Kubelet will validate the image at runtime to ensure that it does not run as UID 0 (root) and fail to start the container if it does. If unset or false, no such validation will be performed. May also be set in SecurityContext.  If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.
             */
            runAsNonRoot?: boolean;
            /**
             * The UID to run the entrypoint of the container process. Defaults to user specified in image metadata if unspecified. May also be set in SecurityContext.  If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence for that container.
             */
            runAsUser?: number;
            /**
             * The SELinux context to be applied to all containers. If unspecified, the container runtime will allocate a random SELinux context for each container.  May also be set in SecurityContext.  If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence for that container.
             */
            seLinuxOptions?: outputs.monitoring.v1.PrometheusSpecSecurityContextSeLinuxOptions;
            /**
             * A list of groups applied to the first process run in each container, in addition to the container's primary GID.  If unspecified, no groups will be added to any container.
             */
            supplementalGroups?: number[];
            /**
             * Sysctls hold a list of namespaced sysctls used for the pod. Pods with unsupported sysctls (by the container runtime) might fail to launch.
             */
            sysctls?: outputs.monitoring.v1.PrometheusSpecSecurityContextSysctls[];
            /**
             * The Windows specific settings applied to all containers. If unspecified, the options within a container's SecurityContext will be used. If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.
             */
            windowsOptions?: outputs.monitoring.v1.PrometheusSpecSecurityContextWindowsOptions;
        }

        /**
         * The SELinux context to be applied to all containers. If unspecified, the container runtime will allocate a random SELinux context for each container.  May also be set in SecurityContext.  If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence for that container.
         */
        export interface PrometheusSpecSecurityContextSeLinuxOptions {
            /**
             * Level is SELinux level label that applies to the container.
             */
            level?: string;
            /**
             * Role is a SELinux role label that applies to the container.
             */
            role?: string;
            /**
             * Type is a SELinux type label that applies to the container.
             */
            type?: string;
            /**
             * User is a SELinux user label that applies to the container.
             */
            user?: string;
        }

        /**
         * Sysctl defines a kernel parameter to be set
         */
        export interface PrometheusSpecSecurityContextSysctls {
            /**
             * Name of a property to set
             */
            name: string;
            /**
             * Value of a property to set
             */
            value: string;
        }

        /**
         * The Windows specific settings applied to all containers. If unspecified, the options within a container's SecurityContext will be used. If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.
         */
        export interface PrometheusSpecSecurityContextWindowsOptions {
            /**
             * GMSACredentialSpec is where the GMSA admission webhook (https://github.com/kubernetes-sigs/windows-gmsa) inlines the contents of the GMSA credential spec named by the GMSACredentialSpecName field.
             */
            gmsaCredentialSpec?: string;
            /**
             * GMSACredentialSpecName is the name of the GMSA credential spec to use.
             */
            gmsaCredentialSpecName?: string;
            /**
             * The UserName in Windows to run the entrypoint of the container process. Defaults to the user specified in image metadata if unspecified. May also be set in PodSecurityContext. If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.
             */
            runAsUserName?: string;
        }

        /**
         * Namespaces to be selected for ServiceMonitor discovery. If nil, only check own namespace.
         */
        export interface PrometheusSpecServiceMonitorNamespaceSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.monitoring.v1.PrometheusSpecServiceMonitorNamespaceSelectorMatchExpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface PrometheusSpecServiceMonitorNamespaceSelectorMatchExpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * ServiceMonitors to be selected for target discovery. *Deprecated:* if neither this nor podMonitorSelector are specified, configuration is unmanaged.
         */
        export interface PrometheusSpecServiceMonitorSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.monitoring.v1.PrometheusSpecServiceMonitorSelectorMatchExpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface PrometheusSpecServiceMonitorSelectorMatchExpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Storage spec to specify how storage shall be used.
         */
        export interface PrometheusSpecStorage {
            /**
             * Deprecated: subPath usage will be disabled by default in a future release, this option will become unnecessary. DisableMountSubPath allows to remove any subPath usage in volume mounts.
             */
            disableMountSubPath?: boolean;
            /**
             * EmptyDirVolumeSource to be used by the Prometheus StatefulSets. If specified, used in place of any volumeClaimTemplate. More info: https://kubernetes.io/docs/concepts/storage/volumes/#emptydir
             */
            emptyDir?: outputs.monitoring.v1.PrometheusSpecStorageEmptyDir;
            /**
             * A PVC spec to be used by the Prometheus StatefulSets.
             */
            volumeClaimTemplate?: outputs.monitoring.v1.PrometheusSpecStorageVolumeClaimTemplate;
        }

        /**
         * EmptyDirVolumeSource to be used by the Prometheus StatefulSets. If specified, used in place of any volumeClaimTemplate. More info: https://kubernetes.io/docs/concepts/storage/volumes/#emptydir
         */
        export interface PrometheusSpecStorageEmptyDir {
            /**
             * What type of storage medium should back this directory. The default is "" which means to use the node's default medium. Must be an empty string (default) or Memory. More info: https://kubernetes.io/docs/concepts/storage/volumes#emptydir
             */
            medium?: string;
            /**
             * Total amount of local storage required for this EmptyDir volume. The size limit is also applicable for memory medium. The maximum usage on memory medium EmptyDir would be the minimum value between the SizeLimit specified here and the sum of memory limits of all containers in a pod. The default is nil which means that the limit is undefined. More info: http://kubernetes.io/docs/user-guide/volumes#emptydir
             */
            sizeLimit?: outputs.monitoring.v1.PrometheusSpecStorageEmptyDirSizeLimit;
        }

        export interface PrometheusSpecStorageEmptyDirSizeLimit {
        }

        /**
         * A PVC spec to be used by the Prometheus StatefulSets.
         */
        export interface PrometheusSpecStorageVolumeClaimTemplate {
            /**
             * APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources
             */
            apiVersion?: string;
            /**
             * Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
             */
            kind?: string;
            /**
             * EmbeddedMetadata contains metadata relevant to an EmbeddedResource.
             */
            metadata?: outputs.monitoring.v1.PrometheusSpecStorageVolumeClaimTemplateMetadata;
            /**
             * Spec defines the desired characteristics of a volume requested by a pod author. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#persistentvolumeclaims
             */
            spec?: outputs.monitoring.v1.PrometheusSpecStorageVolumeClaimTemplateSpec;
            /**
             * Status represents the current information/status of a persistent volume claim. Read-only. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#persistentvolumeclaims
             */
            status?: outputs.monitoring.v1.PrometheusSpecStorageVolumeClaimTemplateStatus;
        }

        /**
         * EmbeddedMetadata contains metadata relevant to an EmbeddedResource.
         */
        export interface PrometheusSpecStorageVolumeClaimTemplateMetadata {
            /**
             * Annotations is an unstructured key value map stored with a resource that may be set by external tools to store and retrieve arbitrary metadata. They are not queryable and should be preserved when modifying objects. More info: http://kubernetes.io/docs/user-guide/annotations
             */
            annotations?: {[key: string]: string};
            /**
             * Map of string keys and values that can be used to organize and categorize (scope and select) objects. May match selectors of replication controllers and services. More info: http://kubernetes.io/docs/user-guide/labels
             */
            labels?: {[key: string]: string};
            /**
             * Name must be unique within a namespace. Is required when creating resources, although some resources may allow a client to request the generation of an appropriate name automatically. Name is primarily intended for creation idempotence and configuration definition. Cannot be updated. More info: http://kubernetes.io/docs/user-guide/identifiers#names
             */
            name?: string;
        }

        /**
         * Spec defines the desired characteristics of a volume requested by a pod author. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#persistentvolumeclaims
         */
        export interface PrometheusSpecStorageVolumeClaimTemplateSpec {
            /**
             * AccessModes contains the desired access modes the volume should have. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#access-modes-1
             */
            accessModes?: string[];
            /**
             * This field can be used to specify either: * An existing VolumeSnapshot object (snapshot.storage.k8s.io/VolumeSnapshot - Beta) * An existing PVC (PersistentVolumeClaim) * An existing custom resource/object that implements data population (Alpha) In order to use VolumeSnapshot object types, the appropriate feature gate must be enabled (VolumeSnapshotDataSource or AnyVolumeDataSource) If the provisioner or an external controller can support the specified data source, it will create a new volume based on the contents of the specified data source. If the specified data source is not supported, the volume will not be created and the failure will be reported as an event. In the future, we plan to support more data source types and the behavior of the provisioner may change.
             */
            dataSource?: outputs.monitoring.v1.PrometheusSpecStorageVolumeClaimTemplateSpecDataSource;
            /**
             * Resources represents the minimum resources the volume should have. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#resources
             */
            resources?: outputs.monitoring.v1.PrometheusSpecStorageVolumeClaimTemplateSpecResources;
            /**
             * A label query over volumes to consider for binding.
             */
            selector?: outputs.monitoring.v1.PrometheusSpecStorageVolumeClaimTemplateSpecSelector;
            /**
             * Name of the StorageClass required by the claim. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#class-1
             */
            storageClassName?: string;
            /**
             * volumeMode defines what type of volume is required by the claim. Value of Filesystem is implied when not included in claim spec.
             */
            volumeMode?: string;
            /**
             * VolumeName is the binding reference to the PersistentVolume backing this claim.
             */
            volumeName?: string;
        }

        /**
         * This field can be used to specify either: * An existing VolumeSnapshot object (snapshot.storage.k8s.io/VolumeSnapshot - Beta) * An existing PVC (PersistentVolumeClaim) * An existing custom resource/object that implements data population (Alpha) In order to use VolumeSnapshot object types, the appropriate feature gate must be enabled (VolumeSnapshotDataSource or AnyVolumeDataSource) If the provisioner or an external controller can support the specified data source, it will create a new volume based on the contents of the specified data source. If the specified data source is not supported, the volume will not be created and the failure will be reported as an event. In the future, we plan to support more data source types and the behavior of the provisioner may change.
         */
        export interface PrometheusSpecStorageVolumeClaimTemplateSpecDataSource {
            /**
             * APIGroup is the group for the resource being referenced. If APIGroup is not specified, the specified Kind must be in the core API group. For any other third-party types, APIGroup is required.
             */
            apiGroup?: string;
            /**
             * Kind is the type of resource being referenced
             */
            kind: string;
            /**
             * Name is the name of resource being referenced
             */
            name: string;
        }

        /**
         * Resources represents the minimum resources the volume should have. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#resources
         */
        export interface PrometheusSpecStorageVolumeClaimTemplateSpecResources {
            /**
             * Limits describes the maximum amount of compute resources allowed. More info: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
             */
            limits?: {[key: string]: outputs.monitoring.v1.PrometheusSpecStorageVolumeClaimTemplateSpecResourcesLimits};
            /**
             * Requests describes the minimum amount of compute resources required. If Requests is omitted for a container, it defaults to Limits if that is explicitly specified, otherwise to an implementation-defined value. More info: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
             */
            requests?: {[key: string]: outputs.monitoring.v1.PrometheusSpecStorageVolumeClaimTemplateSpecResourcesRequests};
        }

        export interface PrometheusSpecStorageVolumeClaimTemplateSpecResourcesLimits {
        }

        export interface PrometheusSpecStorageVolumeClaimTemplateSpecResourcesRequests {
        }

        /**
         * A label query over volumes to consider for binding.
         */
        export interface PrometheusSpecStorageVolumeClaimTemplateSpecSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.monitoring.v1.PrometheusSpecStorageVolumeClaimTemplateSpecSelectorMatchExpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface PrometheusSpecStorageVolumeClaimTemplateSpecSelectorMatchExpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Status represents the current information/status of a persistent volume claim. Read-only. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#persistentvolumeclaims
         */
        export interface PrometheusSpecStorageVolumeClaimTemplateStatus {
            /**
             * AccessModes contains the actual access modes the volume backing the PVC has. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#access-modes-1
             */
            accessModes?: string[];
            /**
             * Represents the actual resources of the underlying volume.
             */
            capacity?: {[key: string]: outputs.monitoring.v1.PrometheusSpecStorageVolumeClaimTemplateStatusCapacity};
            /**
             * Current Condition of persistent volume claim. If underlying persistent volume is being resized then the Condition will be set to 'ResizeStarted'.
             */
            conditions?: outputs.monitoring.v1.PrometheusSpecStorageVolumeClaimTemplateStatusConditions[];
            /**
             * Phase represents the current phase of PersistentVolumeClaim.
             */
            phase?: string;
        }

        export interface PrometheusSpecStorageVolumeClaimTemplateStatusCapacity {
        }

        /**
         * PersistentVolumeClaimCondition contails details about state of pvc
         */
        export interface PrometheusSpecStorageVolumeClaimTemplateStatusConditions {
            /**
             * Last time we probed the condition.
             */
            lastProbeTime?: string;
            /**
             * Last time the condition transitioned from one status to another.
             */
            lastTransitionTime?: string;
            /**
             * Human-readable message indicating details about last transition.
             */
            message?: string;
            /**
             * Unique, this should be a short, machine understandable string that gives the reason for condition's last transition. If it reports "ResizeStarted" that means the underlying persistent volume is being resized.
             */
            reason?: string;
            status: string;
            /**
             * PersistentVolumeClaimConditionType is a valid value of PersistentVolumeClaimCondition.Type
             */
            type: string;
        }

        /**
         * Thanos configuration allows configuring various aspects of a Prometheus server in a Thanos environment. 
         *  This section is experimental, it may change significantly without deprecation notice in any release. 
         *  This is experimental and may change significantly without backward compatibility in any release.
         */
        export interface PrometheusSpecThanos {
            /**
             * Thanos base image if other than default. Deprecated: use 'image' instead
             */
            baseImage?: string;
            /**
             * GRPCServerTLSConfig configures the gRPC server from which Thanos Querier reads recorded rule data. Note: Currently only the CAFile, CertFile, and KeyFile fields are supported. Maps to the '--grpc-server-tls-*' CLI args.
             */
            grpcServerTlsConfig?: outputs.monitoring.v1.PrometheusSpecThanosGrpcServerTlsConfig;
            /**
             * Image if specified has precedence over baseImage, tag and sha combinations. Specifying the version is still necessary to ensure the Prometheus Operator knows what version of Thanos is being configured.
             */
            image?: string;
            /**
             * ListenLocal makes the Thanos sidecar listen on loopback, so that it does not bind against the Pod IP.
             */
            listenLocal?: boolean;
            /**
             * LogFormat for Thanos sidecar to be configured with.
             */
            logFormat?: string;
            /**
             * LogLevel for Thanos sidecar to be configured with.
             */
            logLevel?: string;
            /**
             * MinTime for Thanos sidecar to be configured with. Option can be a constant time in RFC3339 format or time duration relative to current time, such as -1d or 2h45m. Valid duration units are ms, s, m, h, d, w, y.
             */
            minTime?: string;
            /**
             * ObjectStorageConfig configures object storage in Thanos. Alternative to ObjectStorageConfigFile, and lower order priority.
             */
            objectStorageConfig?: outputs.monitoring.v1.PrometheusSpecThanosObjectStorageConfig;
            /**
             * ObjectStorageConfigFile specifies the path of the object storage configuration file. When used alongside with ObjectStorageConfig, ObjectStorageConfigFile takes precedence.
             */
            objectStorageConfigFile?: string;
            /**
             * Resources defines the resource requirements for the Thanos sidecar. If not provided, no requests/limits will be set
             */
            resources?: outputs.monitoring.v1.PrometheusSpecThanosResources;
            /**
             * SHA of Thanos container image to be deployed. Defaults to the value of `version`. Similar to a tag, but the SHA explicitly deploys an immutable container image. Version and Tag are ignored if SHA is set. Deprecated: use 'image' instead.  The image digest can be specified as part of the image URL.
             */
            sha?: string;
            /**
             * Tag of Thanos sidecar container image to be deployed. Defaults to the value of `version`. Version is ignored if Tag is set. Deprecated: use 'image' instead.  The image tag can be specified as part of the image URL.
             */
            tag?: string;
            /**
             * TracingConfig configures tracing in Thanos. This is an experimental feature, it may change in any upcoming release in a breaking way.
             */
            tracingConfig?: outputs.monitoring.v1.PrometheusSpecThanosTracingConfig;
            /**
             * Version describes the version of Thanos to use.
             */
            version?: string;
        }

        /**
         * GRPCServerTLSConfig configures the gRPC server from which Thanos Querier reads recorded rule data. Note: Currently only the CAFile, CertFile, and KeyFile fields are supported. Maps to the '--grpc-server-tls-*' CLI args.
         */
        export interface PrometheusSpecThanosGrpcServerTlsConfig {
            /**
             * Struct containing the CA cert to use for the targets.
             */
            ca?: outputs.monitoring.v1.PrometheusSpecThanosGrpcServerTlsConfigCa;
            /**
             * Path to the CA cert in the Prometheus container to use for the targets.
             */
            caFile?: string;
            /**
             * Struct containing the client cert file for the targets.
             */
            cert?: outputs.monitoring.v1.PrometheusSpecThanosGrpcServerTlsConfigCert;
            /**
             * Path to the client cert file in the Prometheus container for the targets.
             */
            certFile?: string;
            /**
             * Disable target certificate validation.
             */
            insecureSkipVerify?: boolean;
            /**
             * Path to the client key file in the Prometheus container for the targets.
             */
            keyFile?: string;
            /**
             * Secret containing the client key file for the targets.
             */
            keySecret?: outputs.monitoring.v1.PrometheusSpecThanosGrpcServerTlsConfigKeySecret;
            /**
             * Used to verify the hostname for the targets.
             */
            serverName?: string;
        }

        /**
         * Struct containing the CA cert to use for the targets.
         */
        export interface PrometheusSpecThanosGrpcServerTlsConfigCa {
            /**
             * ConfigMap containing data to use for the targets.
             */
            configMap?: outputs.monitoring.v1.PrometheusSpecThanosGrpcServerTlsConfigCaConfigMap;
            /**
             * Secret containing data to use for the targets.
             */
            secret?: outputs.monitoring.v1.PrometheusSpecThanosGrpcServerTlsConfigCaSecret;
        }

        /**
         * ConfigMap containing data to use for the targets.
         */
        export interface PrometheusSpecThanosGrpcServerTlsConfigCaConfigMap {
            /**
             * The key to select.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the ConfigMap or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Secret containing data to use for the targets.
         */
        export interface PrometheusSpecThanosGrpcServerTlsConfigCaSecret {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Struct containing the client cert file for the targets.
         */
        export interface PrometheusSpecThanosGrpcServerTlsConfigCert {
            /**
             * ConfigMap containing data to use for the targets.
             */
            configMap?: outputs.monitoring.v1.PrometheusSpecThanosGrpcServerTlsConfigCertConfigMap;
            /**
             * Secret containing data to use for the targets.
             */
            secret?: outputs.monitoring.v1.PrometheusSpecThanosGrpcServerTlsConfigCertSecret;
        }

        /**
         * ConfigMap containing data to use for the targets.
         */
        export interface PrometheusSpecThanosGrpcServerTlsConfigCertConfigMap {
            /**
             * The key to select.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the ConfigMap or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Secret containing data to use for the targets.
         */
        export interface PrometheusSpecThanosGrpcServerTlsConfigCertSecret {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Secret containing the client key file for the targets.
         */
        export interface PrometheusSpecThanosGrpcServerTlsConfigKeySecret {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * ObjectStorageConfig configures object storage in Thanos. Alternative to ObjectStorageConfigFile, and lower order priority.
         */
        export interface PrometheusSpecThanosObjectStorageConfig {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Resources defines the resource requirements for the Thanos sidecar. If not provided, no requests/limits will be set
         */
        export interface PrometheusSpecThanosResources {
            /**
             * Limits describes the maximum amount of compute resources allowed. More info: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
             */
            limits?: {[key: string]: outputs.monitoring.v1.PrometheusSpecThanosResourcesLimits};
            /**
             * Requests describes the minimum amount of compute resources required. If Requests is omitted for a container, it defaults to Limits if that is explicitly specified, otherwise to an implementation-defined value. More info: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
             */
            requests?: {[key: string]: outputs.monitoring.v1.PrometheusSpecThanosResourcesRequests};
        }

        export interface PrometheusSpecThanosResourcesLimits {
        }

        export interface PrometheusSpecThanosResourcesRequests {
        }

        /**
         * TracingConfig configures tracing in Thanos. This is an experimental feature, it may change in any upcoming release in a breaking way.
         */
        export interface PrometheusSpecThanosTracingConfig {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * The pod this Toleration is attached to tolerates any taint that matches the triple <key,value,effect> using the matching operator <operator>.
         */
        export interface PrometheusSpecTolerations {
            /**
             * Effect indicates the taint effect to match. Empty means match all taint effects. When specified, allowed values are NoSchedule, PreferNoSchedule and NoExecute.
             */
            effect?: string;
            /**
             * Key is the taint key that the toleration applies to. Empty means match all taint keys. If the key is empty, operator must be Exists; this combination means to match all values and all keys.
             */
            key?: string;
            /**
             * Operator represents a key's relationship to the value. Valid operators are Exists and Equal. Defaults to Equal. Exists is equivalent to wildcard for value, so that a pod can tolerate all taints of a particular category.
             */
            operator?: string;
            /**
             * TolerationSeconds represents the period of time the toleration (which must be of effect NoExecute, otherwise this field is ignored) tolerates the taint. By default, it is not set, which means tolerate the taint forever (do not evict). Zero and negative values will be treated as 0 (evict immediately) by the system.
             */
            tolerationSeconds?: number;
            /**
             * Value is the taint value the toleration matches to. If the operator is Exists, the value should be empty, otherwise just a regular string.
             */
            value?: string;
        }

        /**
         * TopologySpreadConstraint specifies how to spread matching pods among the given topology.
         */
        export interface PrometheusSpecTopologySpreadConstraints {
            /**
             * LabelSelector is used to find matching pods. Pods that match this label selector are counted to determine the number of pods in their corresponding topology domain.
             */
            labelSelector?: outputs.monitoring.v1.PrometheusSpecTopologySpreadConstraintsLabelSelector;
            /**
             * MaxSkew describes the degree to which pods may be unevenly distributed. It's the maximum permitted difference between the number of matching pods in any two topology domains of a given topology type. For example, in a 3-zone cluster, MaxSkew is set to 1, and pods with the same labelSelector spread as 1/1/0: | zone1 | zone2 | zone3 | |   P   |   P   |       | - if MaxSkew is 1, incoming pod can only be scheduled to zone3 to become 1/1/1; scheduling it onto zone1(zone2) would make the ActualSkew(2-0) on zone1(zone2) violate MaxSkew(1). - if MaxSkew is 2, incoming pod can be scheduled onto any zone. It's a required field. Default value is 1 and 0 is not allowed.
             */
            maxSkew: number;
            /**
             * TopologyKey is the key of node labels. Nodes that have a label with this key and identical values are considered to be in the same topology. We consider each <key, value> as a "bucket", and try to put balanced number of pods into each bucket. It's a required field.
             */
            topologyKey: string;
            /**
             * WhenUnsatisfiable indicates how to deal with a pod if it doesn't satisfy the spread constraint. - DoNotSchedule (default) tells the scheduler not to schedule it - ScheduleAnyway tells the scheduler to still schedule it It's considered as "Unsatisfiable" if and only if placing incoming pod on any topology violates "MaxSkew". For example, in a 3-zone cluster, MaxSkew is set to 1, and pods with the same labelSelector spread as 3/1/1: | zone1 | zone2 | zone3 | | P P P |   P   |   P   | If WhenUnsatisfiable is set to DoNotSchedule, incoming pod can only be scheduled to zone2(zone3) to become 3/2/1(3/1/2) as ActualSkew(2-1) on zone2(zone3) satisfies MaxSkew(1). In other words, the cluster can still be imbalanced, but scheduler won't make it *more* imbalanced. It's a required field.
             */
            whenUnsatisfiable: string;
        }

        /**
         * LabelSelector is used to find matching pods. Pods that match this label selector are counted to determine the number of pods in their corresponding topology domain.
         */
        export interface PrometheusSpecTopologySpreadConstraintsLabelSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.monitoring.v1.PrometheusSpecTopologySpreadConstraintsLabelSelectorMatchExpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface PrometheusSpecTopologySpreadConstraintsLabelSelectorMatchExpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * VolumeMount describes a mounting of a Volume within a container.
         */
        export interface PrometheusSpecVolumeMounts {
            /**
             * Path within the container at which the volume should be mounted.  Must not contain ':'.
             */
            mountPath: string;
            /**
             * mountPropagation determines how mounts are propagated from the host to container and the other way around. When not set, MountPropagationNone is used. This field is beta in 1.10.
             */
            mountPropagation?: string;
            /**
             * This must match the Name of a Volume.
             */
            name: string;
            /**
             * Mounted read-only if true, read-write otherwise (false or unspecified). Defaults to false.
             */
            readOnly?: boolean;
            /**
             * Path within the volume from which the container's volume should be mounted. Defaults to "" (volume's root).
             */
            subPath?: string;
            /**
             * Expanded path within the volume from which the container's volume should be mounted. Behaves similarly to SubPath but environment variable references $(VAR_NAME) are expanded using the container's environment. Defaults to "" (volume's root). SubPathExpr and SubPath are mutually exclusive.
             */
            subPathExpr?: string;
        }

        /**
         * Volume represents a named volume in a pod that may be accessed by any container in the pod.
         */
        export interface PrometheusSpecVolumes {
            /**
             * AWSElasticBlockStore represents an AWS Disk resource that is attached to a kubelet's host machine and then exposed to the pod. More info: https://kubernetes.io/docs/concepts/storage/volumes#awselasticblockstore
             */
            awsElasticBlockStore?: outputs.monitoring.v1.PrometheusSpecVolumesAwsElasticBlockStore;
            /**
             * AzureDisk represents an Azure Data Disk mount on the host and bind mount to the pod.
             */
            azureDisk?: outputs.monitoring.v1.PrometheusSpecVolumesAzureDisk;
            /**
             * AzureFile represents an Azure File Service mount on the host and bind mount to the pod.
             */
            azureFile?: outputs.monitoring.v1.PrometheusSpecVolumesAzureFile;
            /**
             * CephFS represents a Ceph FS mount on the host that shares a pod's lifetime
             */
            cephfs?: outputs.monitoring.v1.PrometheusSpecVolumesCephfs;
            /**
             * Cinder represents a cinder volume attached and mounted on kubelets host machine. More info: https://examples.k8s.io/mysql-cinder-pd/README.md
             */
            cinder?: outputs.monitoring.v1.PrometheusSpecVolumesCinder;
            /**
             * ConfigMap represents a configMap that should populate this volume
             */
            configMap?: outputs.monitoring.v1.PrometheusSpecVolumesConfigMap;
            /**
             * CSI (Container Storage Interface) represents storage that is handled by an external CSI driver (Alpha feature).
             */
            csi?: outputs.monitoring.v1.PrometheusSpecVolumesCsi;
            /**
             * DownwardAPI represents downward API about the pod that should populate this volume
             */
            downwardAPI?: outputs.monitoring.v1.PrometheusSpecVolumesDownwardAPI;
            /**
             * EmptyDir represents a temporary directory that shares a pod's lifetime. More info: https://kubernetes.io/docs/concepts/storage/volumes#emptydir
             */
            emptyDir?: outputs.monitoring.v1.PrometheusSpecVolumesEmptyDir;
            /**
             * FC represents a Fibre Channel resource that is attached to a kubelet's host machine and then exposed to the pod.
             */
            fc?: outputs.monitoring.v1.PrometheusSpecVolumesFc;
            /**
             * FlexVolume represents a generic volume resource that is provisioned/attached using an exec based plugin.
             */
            flexVolume?: outputs.monitoring.v1.PrometheusSpecVolumesFlexVolume;
            /**
             * Flocker represents a Flocker volume attached to a kubelet's host machine. This depends on the Flocker control service being running
             */
            flocker?: outputs.monitoring.v1.PrometheusSpecVolumesFlocker;
            /**
             * GCEPersistentDisk represents a GCE Disk resource that is attached to a kubelet's host machine and then exposed to the pod. More info: https://kubernetes.io/docs/concepts/storage/volumes#gcepersistentdisk
             */
            gcePersistentDisk?: outputs.monitoring.v1.PrometheusSpecVolumesGcePersistentDisk;
            /**
             * GitRepo represents a git repository at a particular revision. DEPRECATED: GitRepo is deprecated. To provision a container with a git repo, mount an EmptyDir into an InitContainer that clones the repo using git, then mount the EmptyDir into the Pod's container.
             */
            gitRepo?: outputs.monitoring.v1.PrometheusSpecVolumesGitRepo;
            /**
             * Glusterfs represents a Glusterfs mount on the host that shares a pod's lifetime. More info: https://examples.k8s.io/volumes/glusterfs/README.md
             */
            glusterfs?: outputs.monitoring.v1.PrometheusSpecVolumesGlusterfs;
            /**
             * HostPath represents a pre-existing file or directory on the host machine that is directly exposed to the container. This is generally used for system agents or other privileged things that are allowed to see the host machine. Most containers will NOT need this. More info: https://kubernetes.io/docs/concepts/storage/volumes#hostpath --- TODO(jonesdl) We need to restrict who can use host directory mounts and who can/can not mount host directories as read/write.
             */
            hostPath?: outputs.monitoring.v1.PrometheusSpecVolumesHostPath;
            /**
             * ISCSI represents an ISCSI Disk resource that is attached to a kubelet's host machine and then exposed to the pod. More info: https://examples.k8s.io/volumes/iscsi/README.md
             */
            iscsi?: outputs.monitoring.v1.PrometheusSpecVolumesIscsi;
            /**
             * Volume's name. Must be a DNS_LABEL and unique within the pod. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
            /**
             * NFS represents an NFS mount on the host that shares a pod's lifetime More info: https://kubernetes.io/docs/concepts/storage/volumes#nfs
             */
            nfs?: outputs.monitoring.v1.PrometheusSpecVolumesNfs;
            /**
             * PersistentVolumeClaimVolumeSource represents a reference to a PersistentVolumeClaim in the same namespace. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#persistentvolumeclaims
             */
            persistentVolumeClaim?: outputs.monitoring.v1.PrometheusSpecVolumesPersistentVolumeClaim;
            /**
             * PhotonPersistentDisk represents a PhotonController persistent disk attached and mounted on kubelets host machine
             */
            photonPersistentDisk?: outputs.monitoring.v1.PrometheusSpecVolumesPhotonPersistentDisk;
            /**
             * PortworxVolume represents a portworx volume attached and mounted on kubelets host machine
             */
            portworxVolume?: outputs.monitoring.v1.PrometheusSpecVolumesPortworxVolume;
            /**
             * Items for all in one resources secrets, configmaps, and downward API
             */
            projected?: outputs.monitoring.v1.PrometheusSpecVolumesProjected;
            /**
             * Quobyte represents a Quobyte mount on the host that shares a pod's lifetime
             */
            quobyte?: outputs.monitoring.v1.PrometheusSpecVolumesQuobyte;
            /**
             * RBD represents a Rados Block Device mount on the host that shares a pod's lifetime. More info: https://examples.k8s.io/volumes/rbd/README.md
             */
            rbd?: outputs.monitoring.v1.PrometheusSpecVolumesRbd;
            /**
             * ScaleIO represents a ScaleIO persistent volume attached and mounted on Kubernetes nodes.
             */
            scaleIO?: outputs.monitoring.v1.PrometheusSpecVolumesScaleIO;
            /**
             * Secret represents a secret that should populate this volume. More info: https://kubernetes.io/docs/concepts/storage/volumes#secret
             */
            secret?: outputs.monitoring.v1.PrometheusSpecVolumesSecret;
            /**
             * StorageOS represents a StorageOS volume attached and mounted on Kubernetes nodes.
             */
            storageos?: outputs.monitoring.v1.PrometheusSpecVolumesStorageos;
            /**
             * VsphereVolume represents a vSphere volume attached and mounted on kubelets host machine
             */
            vsphereVolume?: outputs.monitoring.v1.PrometheusSpecVolumesVsphereVolume;
        }

        /**
         * AWSElasticBlockStore represents an AWS Disk resource that is attached to a kubelet's host machine and then exposed to the pod. More info: https://kubernetes.io/docs/concepts/storage/volumes#awselasticblockstore
         */
        export interface PrometheusSpecVolumesAwsElasticBlockStore {
            /**
             * Filesystem type of the volume that you want to mount. Tip: Ensure that the filesystem type is supported by the host operating system. Examples: "ext4", "xfs", "ntfs". Implicitly inferred to be "ext4" if unspecified. More info: https://kubernetes.io/docs/concepts/storage/volumes#awselasticblockstore TODO: how do we prevent errors in the filesystem from compromising the machine
             */
            fsType?: string;
            /**
             * The partition in the volume that you want to mount. If omitted, the default is to mount by volume name. Examples: For volume /dev/sda1, you specify the partition as "1". Similarly, the volume partition for /dev/sda is "0" (or you can leave the property empty).
             */
            partition?: number;
            /**
             * Specify "true" to force and set the ReadOnly property in VolumeMounts to "true". If omitted, the default is "false". More info: https://kubernetes.io/docs/concepts/storage/volumes#awselasticblockstore
             */
            readOnly?: boolean;
            /**
             * Unique ID of the persistent disk resource in AWS (Amazon EBS volume). More info: https://kubernetes.io/docs/concepts/storage/volumes#awselasticblockstore
             */
            volumeID: string;
        }

        /**
         * AzureDisk represents an Azure Data Disk mount on the host and bind mount to the pod.
         */
        export interface PrometheusSpecVolumesAzureDisk {
            /**
             * Host Caching mode: None, Read Only, Read Write.
             */
            cachingMode?: string;
            /**
             * The Name of the data disk in the blob storage
             */
            diskName: string;
            /**
             * The URI the data disk in the blob storage
             */
            diskURI: string;
            /**
             * Filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. "ext4", "xfs", "ntfs". Implicitly inferred to be "ext4" if unspecified.
             */
            fsType?: string;
            /**
             * Expected values Shared: multiple blob disks per storage account  Dedicated: single blob disk per storage account  Managed: azure managed data disk (only in managed availability set). defaults to shared
             */
            kind?: string;
            /**
             * Defaults to false (read/write). ReadOnly here will force the ReadOnly setting in VolumeMounts.
             */
            readOnly?: boolean;
        }

        /**
         * AzureFile represents an Azure File Service mount on the host and bind mount to the pod.
         */
        export interface PrometheusSpecVolumesAzureFile {
            /**
             * Defaults to false (read/write). ReadOnly here will force the ReadOnly setting in VolumeMounts.
             */
            readOnly?: boolean;
            /**
             * the name of secret that contains Azure Storage Account Name and Key
             */
            secretName: string;
            /**
             * Share Name
             */
            shareName: string;
        }

        /**
         * CephFS represents a Ceph FS mount on the host that shares a pod's lifetime
         */
        export interface PrometheusSpecVolumesCephfs {
            /**
             * Required: Monitors is a collection of Ceph monitors More info: https://examples.k8s.io/volumes/cephfs/README.md#how-to-use-it
             */
            monitors: string[];
            /**
             * Optional: Used as the mounted root, rather than the full Ceph tree, default is /
             */
            path?: string;
            /**
             * Optional: Defaults to false (read/write). ReadOnly here will force the ReadOnly setting in VolumeMounts. More info: https://examples.k8s.io/volumes/cephfs/README.md#how-to-use-it
             */
            readOnly?: boolean;
            /**
             * Optional: SecretFile is the path to key ring for User, default is /etc/ceph/user.secret More info: https://examples.k8s.io/volumes/cephfs/README.md#how-to-use-it
             */
            secretFile?: string;
            /**
             * Optional: SecretRef is reference to the authentication secret for User, default is empty. More info: https://examples.k8s.io/volumes/cephfs/README.md#how-to-use-it
             */
            secretRef?: outputs.monitoring.v1.PrometheusSpecVolumesCephfsSecretRef;
            /**
             * Optional: User is the rados user name, default is admin More info: https://examples.k8s.io/volumes/cephfs/README.md#how-to-use-it
             */
            user?: string;
        }

        /**
         * Optional: SecretRef is reference to the authentication secret for User, default is empty. More info: https://examples.k8s.io/volumes/cephfs/README.md#how-to-use-it
         */
        export interface PrometheusSpecVolumesCephfsSecretRef {
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
        }

        /**
         * Cinder represents a cinder volume attached and mounted on kubelets host machine. More info: https://examples.k8s.io/mysql-cinder-pd/README.md
         */
        export interface PrometheusSpecVolumesCinder {
            /**
             * Filesystem type to mount. Must be a filesystem type supported by the host operating system. Examples: "ext4", "xfs", "ntfs". Implicitly inferred to be "ext4" if unspecified. More info: https://examples.k8s.io/mysql-cinder-pd/README.md
             */
            fsType?: string;
            /**
             * Optional: Defaults to false (read/write). ReadOnly here will force the ReadOnly setting in VolumeMounts. More info: https://examples.k8s.io/mysql-cinder-pd/README.md
             */
            readOnly?: boolean;
            /**
             * Optional: points to a secret object containing parameters used to connect to OpenStack.
             */
            secretRef?: outputs.monitoring.v1.PrometheusSpecVolumesCinderSecretRef;
            /**
             * volume id used to identify the volume in cinder. More info: https://examples.k8s.io/mysql-cinder-pd/README.md
             */
            volumeID: string;
        }

        /**
         * Optional: points to a secret object containing parameters used to connect to OpenStack.
         */
        export interface PrometheusSpecVolumesCinderSecretRef {
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
        }

        /**
         * ConfigMap represents a configMap that should populate this volume
         */
        export interface PrometheusSpecVolumesConfigMap {
            /**
             * Optional: mode bits to use on created files by default. Must be a value between 0 and 0777. Defaults to 0644. Directories within the path are not affected by this setting. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set.
             */
            defaultMode?: number;
            /**
             * If unspecified, each key-value pair in the Data field of the referenced ConfigMap will be projected into the volume as a file whose name is the key and content is the value. If specified, the listed keys will be projected into the specified paths, and unlisted keys will not be present. If a key is specified which is not present in the ConfigMap, the volume setup will error unless it is marked optional. Paths must be relative and may not contain the '..' path or start with '..'.
             */
            items?: outputs.monitoring.v1.PrometheusSpecVolumesConfigMapItems[];
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the ConfigMap or its keys must be defined
             */
            optional?: boolean;
        }

        /**
         * Maps a string key to a path within a volume.
         */
        export interface PrometheusSpecVolumesConfigMapItems {
            /**
             * The key to project.
             */
            key: string;
            /**
             * Optional: mode bits to use on this file, must be a value between 0 and 0777. If not specified, the volume defaultMode will be used. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set.
             */
            mode?: number;
            /**
             * The relative path of the file to map the key to. May not be an absolute path. May not contain the path element '..'. May not start with the string '..'.
             */
            path: string;
        }

        /**
         * CSI (Container Storage Interface) represents storage that is handled by an external CSI driver (Alpha feature).
         */
        export interface PrometheusSpecVolumesCsi {
            /**
             * Driver is the name of the CSI driver that handles this volume. Consult with your admin for the correct name as registered in the cluster.
             */
            driver: string;
            /**
             * Filesystem type to mount. Ex. "ext4", "xfs", "ntfs". If not provided, the empty value is passed to the associated CSI driver which will determine the default filesystem to apply.
             */
            fsType?: string;
            /**
             * NodePublishSecretRef is a reference to the secret object containing sensitive information to pass to the CSI driver to complete the CSI NodePublishVolume and NodeUnpublishVolume calls. This field is optional, and  may be empty if no secret is required. If the secret object contains more than one secret, all secret references are passed.
             */
            nodePublishSecretRef?: outputs.monitoring.v1.PrometheusSpecVolumesCsiNodePublishSecretRef;
            /**
             * Specifies a read-only configuration for the volume. Defaults to false (read/write).
             */
            readOnly?: boolean;
            /**
             * VolumeAttributes stores driver-specific properties that are passed to the CSI driver. Consult your driver's documentation for supported values.
             */
            volumeAttributes?: {[key: string]: string};
        }

        /**
         * NodePublishSecretRef is a reference to the secret object containing sensitive information to pass to the CSI driver to complete the CSI NodePublishVolume and NodeUnpublishVolume calls. This field is optional, and  may be empty if no secret is required. If the secret object contains more than one secret, all secret references are passed.
         */
        export interface PrometheusSpecVolumesCsiNodePublishSecretRef {
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
        }

        /**
         * DownwardAPI represents downward API about the pod that should populate this volume
         */
        export interface PrometheusSpecVolumesDownwardAPI {
            /**
             * Optional: mode bits to use on created files by default. Must be a value between 0 and 0777. Defaults to 0644. Directories within the path are not affected by this setting. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set.
             */
            defaultMode?: number;
            /**
             * Items is a list of downward API volume file
             */
            items?: outputs.monitoring.v1.PrometheusSpecVolumesDownwardAPIItems[];
        }

        /**
         * DownwardAPIVolumeFile represents information to create the file containing the pod field
         */
        export interface PrometheusSpecVolumesDownwardAPIItems {
            /**
             * Required: Selects a field of the pod: only annotations, labels, name and namespace are supported.
             */
            fieldRef?: outputs.monitoring.v1.PrometheusSpecVolumesDownwardAPIItemsFieldRef;
            /**
             * Optional: mode bits to use on this file, must be a value between 0 and 0777. If not specified, the volume defaultMode will be used. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set.
             */
            mode?: number;
            /**
             * Required: Path is  the relative path name of the file to be created. Must not be absolute or contain the '..' path. Must be utf-8 encoded. The first item of the relative path must not start with '..'
             */
            path: string;
            /**
             * Selects a resource of the container: only resources limits and requests (limits.cpu, limits.memory, requests.cpu and requests.memory) are currently supported.
             */
            resourceFieldRef?: outputs.monitoring.v1.PrometheusSpecVolumesDownwardAPIItemsResourceFieldRef;
        }

        /**
         * Required: Selects a field of the pod: only annotations, labels, name and namespace are supported.
         */
        export interface PrometheusSpecVolumesDownwardAPIItemsFieldRef {
            /**
             * Version of the schema the FieldPath is written in terms of, defaults to "v1".
             */
            apiVersion?: string;
            /**
             * Path of the field to select in the specified API version.
             */
            fieldPath: string;
        }

        /**
         * Selects a resource of the container: only resources limits and requests (limits.cpu, limits.memory, requests.cpu and requests.memory) are currently supported.
         */
        export interface PrometheusSpecVolumesDownwardAPIItemsResourceFieldRef {
            /**
             * Container name: required for volumes, optional for env vars
             */
            containerName?: string;
            /**
             * Specifies the output format of the exposed resources, defaults to "1"
             */
            divisor?: outputs.monitoring.v1.PrometheusSpecVolumesDownwardAPIItemsResourceFieldRefDivisor;
            /**
             * Required: resource to select
             */
            resource: string;
        }

        export interface PrometheusSpecVolumesDownwardAPIItemsResourceFieldRefDivisor {
        }

        /**
         * EmptyDir represents a temporary directory that shares a pod's lifetime. More info: https://kubernetes.io/docs/concepts/storage/volumes#emptydir
         */
        export interface PrometheusSpecVolumesEmptyDir {
            /**
             * What type of storage medium should back this directory. The default is "" which means to use the node's default medium. Must be an empty string (default) or Memory. More info: https://kubernetes.io/docs/concepts/storage/volumes#emptydir
             */
            medium?: string;
            /**
             * Total amount of local storage required for this EmptyDir volume. The size limit is also applicable for memory medium. The maximum usage on memory medium EmptyDir would be the minimum value between the SizeLimit specified here and the sum of memory limits of all containers in a pod. The default is nil which means that the limit is undefined. More info: http://kubernetes.io/docs/user-guide/volumes#emptydir
             */
            sizeLimit?: outputs.monitoring.v1.PrometheusSpecVolumesEmptyDirSizeLimit;
        }

        export interface PrometheusSpecVolumesEmptyDirSizeLimit {
        }

        /**
         * FC represents a Fibre Channel resource that is attached to a kubelet's host machine and then exposed to the pod.
         */
        export interface PrometheusSpecVolumesFc {
            /**
             * Filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. "ext4", "xfs", "ntfs". Implicitly inferred to be "ext4" if unspecified. TODO: how do we prevent errors in the filesystem from compromising the machine
             */
            fsType?: string;
            /**
             * Optional: FC target lun number
             */
            lun?: number;
            /**
             * Optional: Defaults to false (read/write). ReadOnly here will force the ReadOnly setting in VolumeMounts.
             */
            readOnly?: boolean;
            /**
             * Optional: FC target worldwide names (WWNs)
             */
            targetWWNs?: string[];
            /**
             * Optional: FC volume world wide identifiers (wwids) Either wwids or combination of targetWWNs and lun must be set, but not both simultaneously.
             */
            wwids?: string[];
        }

        /**
         * FlexVolume represents a generic volume resource that is provisioned/attached using an exec based plugin.
         */
        export interface PrometheusSpecVolumesFlexVolume {
            /**
             * Driver is the name of the driver to use for this volume.
             */
            driver: string;
            /**
             * Filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. "ext4", "xfs", "ntfs". The default filesystem depends on FlexVolume script.
             */
            fsType?: string;
            /**
             * Optional: Extra command options if any.
             */
            options?: {[key: string]: string};
            /**
             * Optional: Defaults to false (read/write). ReadOnly here will force the ReadOnly setting in VolumeMounts.
             */
            readOnly?: boolean;
            /**
             * Optional: SecretRef is reference to the secret object containing sensitive information to pass to the plugin scripts. This may be empty if no secret object is specified. If the secret object contains more than one secret, all secrets are passed to the plugin scripts.
             */
            secretRef?: outputs.monitoring.v1.PrometheusSpecVolumesFlexVolumeSecretRef;
        }

        /**
         * Optional: SecretRef is reference to the secret object containing sensitive information to pass to the plugin scripts. This may be empty if no secret object is specified. If the secret object contains more than one secret, all secrets are passed to the plugin scripts.
         */
        export interface PrometheusSpecVolumesFlexVolumeSecretRef {
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
        }

        /**
         * Flocker represents a Flocker volume attached to a kubelet's host machine. This depends on the Flocker control service being running
         */
        export interface PrometheusSpecVolumesFlocker {
            /**
             * Name of the dataset stored as metadata -> name on the dataset for Flocker should be considered as deprecated
             */
            datasetName?: string;
            /**
             * UUID of the dataset. This is unique identifier of a Flocker dataset
             */
            datasetUUID?: string;
        }

        /**
         * GCEPersistentDisk represents a GCE Disk resource that is attached to a kubelet's host machine and then exposed to the pod. More info: https://kubernetes.io/docs/concepts/storage/volumes#gcepersistentdisk
         */
        export interface PrometheusSpecVolumesGcePersistentDisk {
            /**
             * Filesystem type of the volume that you want to mount. Tip: Ensure that the filesystem type is supported by the host operating system. Examples: "ext4", "xfs", "ntfs". Implicitly inferred to be "ext4" if unspecified. More info: https://kubernetes.io/docs/concepts/storage/volumes#gcepersistentdisk TODO: how do we prevent errors in the filesystem from compromising the machine
             */
            fsType?: string;
            /**
             * The partition in the volume that you want to mount. If omitted, the default is to mount by volume name. Examples: For volume /dev/sda1, you specify the partition as "1". Similarly, the volume partition for /dev/sda is "0" (or you can leave the property empty). More info: https://kubernetes.io/docs/concepts/storage/volumes#gcepersistentdisk
             */
            partition?: number;
            /**
             * Unique name of the PD resource in GCE. Used to identify the disk in GCE. More info: https://kubernetes.io/docs/concepts/storage/volumes#gcepersistentdisk
             */
            pdName: string;
            /**
             * ReadOnly here will force the ReadOnly setting in VolumeMounts. Defaults to false. More info: https://kubernetes.io/docs/concepts/storage/volumes#gcepersistentdisk
             */
            readOnly?: boolean;
        }

        /**
         * GitRepo represents a git repository at a particular revision. DEPRECATED: GitRepo is deprecated. To provision a container with a git repo, mount an EmptyDir into an InitContainer that clones the repo using git, then mount the EmptyDir into the Pod's container.
         */
        export interface PrometheusSpecVolumesGitRepo {
            /**
             * Target directory name. Must not contain or start with '..'.  If '.' is supplied, the volume directory will be the git repository.  Otherwise, if specified, the volume will contain the git repository in the subdirectory with the given name.
             */
            directory?: string;
            /**
             * Repository URL
             */
            repository: string;
            /**
             * Commit hash for the specified revision.
             */
            revision?: string;
        }

        /**
         * Glusterfs represents a Glusterfs mount on the host that shares a pod's lifetime. More info: https://examples.k8s.io/volumes/glusterfs/README.md
         */
        export interface PrometheusSpecVolumesGlusterfs {
            /**
             * EndpointsName is the endpoint name that details Glusterfs topology. More info: https://examples.k8s.io/volumes/glusterfs/README.md#create-a-pod
             */
            endpoints: string;
            /**
             * Path is the Glusterfs volume path. More info: https://examples.k8s.io/volumes/glusterfs/README.md#create-a-pod
             */
            path: string;
            /**
             * ReadOnly here will force the Glusterfs volume to be mounted with read-only permissions. Defaults to false. More info: https://examples.k8s.io/volumes/glusterfs/README.md#create-a-pod
             */
            readOnly?: boolean;
        }

        /**
         * HostPath represents a pre-existing file or directory on the host machine that is directly exposed to the container. This is generally used for system agents or other privileged things that are allowed to see the host machine. Most containers will NOT need this. More info: https://kubernetes.io/docs/concepts/storage/volumes#hostpath --- TODO(jonesdl) We need to restrict who can use host directory mounts and who can/can not mount host directories as read/write.
         */
        export interface PrometheusSpecVolumesHostPath {
            /**
             * Path of the directory on the host. If the path is a symlink, it will follow the link to the real path. More info: https://kubernetes.io/docs/concepts/storage/volumes#hostpath
             */
            path: string;
            /**
             * Type for HostPath Volume Defaults to "" More info: https://kubernetes.io/docs/concepts/storage/volumes#hostpath
             */
            type?: string;
        }

        /**
         * ISCSI represents an ISCSI Disk resource that is attached to a kubelet's host machine and then exposed to the pod. More info: https://examples.k8s.io/volumes/iscsi/README.md
         */
        export interface PrometheusSpecVolumesIscsi {
            /**
             * whether support iSCSI Discovery CHAP authentication
             */
            chapAuthDiscovery?: boolean;
            /**
             * whether support iSCSI Session CHAP authentication
             */
            chapAuthSession?: boolean;
            /**
             * Filesystem type of the volume that you want to mount. Tip: Ensure that the filesystem type is supported by the host operating system. Examples: "ext4", "xfs", "ntfs". Implicitly inferred to be "ext4" if unspecified. More info: https://kubernetes.io/docs/concepts/storage/volumes#iscsi TODO: how do we prevent errors in the filesystem from compromising the machine
             */
            fsType?: string;
            /**
             * Custom iSCSI Initiator Name. If initiatorName is specified with iscsiInterface simultaneously, new iSCSI interface <target portal>:<volume name> will be created for the connection.
             */
            initiatorName?: string;
            /**
             * Target iSCSI Qualified Name.
             */
            iqn: string;
            /**
             * iSCSI Interface Name that uses an iSCSI transport. Defaults to 'default' (tcp).
             */
            iscsiInterface?: string;
            /**
             * iSCSI Target Lun number.
             */
            lun: number;
            /**
             * iSCSI Target Portal List. The portal is either an IP or ip_addr:port if the port is other than default (typically TCP ports 860 and 3260).
             */
            portals?: string[];
            /**
             * ReadOnly here will force the ReadOnly setting in VolumeMounts. Defaults to false.
             */
            readOnly?: boolean;
            /**
             * CHAP Secret for iSCSI target and initiator authentication
             */
            secretRef?: outputs.monitoring.v1.PrometheusSpecVolumesIscsiSecretRef;
            /**
             * iSCSI Target Portal. The Portal is either an IP or ip_addr:port if the port is other than default (typically TCP ports 860 and 3260).
             */
            targetPortal: string;
        }

        /**
         * CHAP Secret for iSCSI target and initiator authentication
         */
        export interface PrometheusSpecVolumesIscsiSecretRef {
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
        }

        /**
         * NFS represents an NFS mount on the host that shares a pod's lifetime More info: https://kubernetes.io/docs/concepts/storage/volumes#nfs
         */
        export interface PrometheusSpecVolumesNfs {
            /**
             * Path that is exported by the NFS server. More info: https://kubernetes.io/docs/concepts/storage/volumes#nfs
             */
            path: string;
            /**
             * ReadOnly here will force the NFS export to be mounted with read-only permissions. Defaults to false. More info: https://kubernetes.io/docs/concepts/storage/volumes#nfs
             */
            readOnly?: boolean;
            /**
             * Server is the hostname or IP address of the NFS server. More info: https://kubernetes.io/docs/concepts/storage/volumes#nfs
             */
            server: string;
        }

        /**
         * PersistentVolumeClaimVolumeSource represents a reference to a PersistentVolumeClaim in the same namespace. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#persistentvolumeclaims
         */
        export interface PrometheusSpecVolumesPersistentVolumeClaim {
            /**
             * ClaimName is the name of a PersistentVolumeClaim in the same namespace as the pod using this volume. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#persistentvolumeclaims
             */
            claimName: string;
            /**
             * Will force the ReadOnly setting in VolumeMounts. Default false.
             */
            readOnly?: boolean;
        }

        /**
         * PhotonPersistentDisk represents a PhotonController persistent disk attached and mounted on kubelets host machine
         */
        export interface PrometheusSpecVolumesPhotonPersistentDisk {
            /**
             * Filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. "ext4", "xfs", "ntfs". Implicitly inferred to be "ext4" if unspecified.
             */
            fsType?: string;
            /**
             * ID that identifies Photon Controller persistent disk
             */
            pdID: string;
        }

        /**
         * PortworxVolume represents a portworx volume attached and mounted on kubelets host machine
         */
        export interface PrometheusSpecVolumesPortworxVolume {
            /**
             * FSType represents the filesystem type to mount Must be a filesystem type supported by the host operating system. Ex. "ext4", "xfs". Implicitly inferred to be "ext4" if unspecified.
             */
            fsType?: string;
            /**
             * Defaults to false (read/write). ReadOnly here will force the ReadOnly setting in VolumeMounts.
             */
            readOnly?: boolean;
            /**
             * VolumeID uniquely identifies a Portworx volume
             */
            volumeID: string;
        }

        /**
         * Items for all in one resources secrets, configmaps, and downward API
         */
        export interface PrometheusSpecVolumesProjected {
            /**
             * Mode bits to use on created files by default. Must be a value between 0 and 0777. Directories within the path are not affected by this setting. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set.
             */
            defaultMode?: number;
            /**
             * list of volume projections
             */
            sources: outputs.monitoring.v1.PrometheusSpecVolumesProjectedSources[];
        }

        /**
         * Projection that may be projected along with other supported volume types
         */
        export interface PrometheusSpecVolumesProjectedSources {
            /**
             * information about the configMap data to project
             */
            configMap?: outputs.monitoring.v1.PrometheusSpecVolumesProjectedSourcesConfigMap;
            /**
             * information about the downwardAPI data to project
             */
            downwardAPI?: outputs.monitoring.v1.PrometheusSpecVolumesProjectedSourcesDownwardAPI;
            /**
             * information about the secret data to project
             */
            secret?: outputs.monitoring.v1.PrometheusSpecVolumesProjectedSourcesSecret;
            /**
             * information about the serviceAccountToken data to project
             */
            serviceAccountToken?: outputs.monitoring.v1.PrometheusSpecVolumesProjectedSourcesServiceAccountToken;
        }

        /**
         * information about the configMap data to project
         */
        export interface PrometheusSpecVolumesProjectedSourcesConfigMap {
            /**
             * If unspecified, each key-value pair in the Data field of the referenced ConfigMap will be projected into the volume as a file whose name is the key and content is the value. If specified, the listed keys will be projected into the specified paths, and unlisted keys will not be present. If a key is specified which is not present in the ConfigMap, the volume setup will error unless it is marked optional. Paths must be relative and may not contain the '..' path or start with '..'.
             */
            items?: outputs.monitoring.v1.PrometheusSpecVolumesProjectedSourcesConfigMapItems[];
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the ConfigMap or its keys must be defined
             */
            optional?: boolean;
        }

        /**
         * Maps a string key to a path within a volume.
         */
        export interface PrometheusSpecVolumesProjectedSourcesConfigMapItems {
            /**
             * The key to project.
             */
            key: string;
            /**
             * Optional: mode bits to use on this file, must be a value between 0 and 0777. If not specified, the volume defaultMode will be used. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set.
             */
            mode?: number;
            /**
             * The relative path of the file to map the key to. May not be an absolute path. May not contain the path element '..'. May not start with the string '..'.
             */
            path: string;
        }

        /**
         * information about the downwardAPI data to project
         */
        export interface PrometheusSpecVolumesProjectedSourcesDownwardAPI {
            /**
             * Items is a list of DownwardAPIVolume file
             */
            items?: outputs.monitoring.v1.PrometheusSpecVolumesProjectedSourcesDownwardAPIItems[];
        }

        /**
         * DownwardAPIVolumeFile represents information to create the file containing the pod field
         */
        export interface PrometheusSpecVolumesProjectedSourcesDownwardAPIItems {
            /**
             * Required: Selects a field of the pod: only annotations, labels, name and namespace are supported.
             */
            fieldRef?: outputs.monitoring.v1.PrometheusSpecVolumesProjectedSourcesDownwardAPIItemsFieldRef;
            /**
             * Optional: mode bits to use on this file, must be a value between 0 and 0777. If not specified, the volume defaultMode will be used. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set.
             */
            mode?: number;
            /**
             * Required: Path is  the relative path name of the file to be created. Must not be absolute or contain the '..' path. Must be utf-8 encoded. The first item of the relative path must not start with '..'
             */
            path: string;
            /**
             * Selects a resource of the container: only resources limits and requests (limits.cpu, limits.memory, requests.cpu and requests.memory) are currently supported.
             */
            resourceFieldRef?: outputs.monitoring.v1.PrometheusSpecVolumesProjectedSourcesDownwardAPIItemsResourceFieldRef;
        }

        /**
         * Required: Selects a field of the pod: only annotations, labels, name and namespace are supported.
         */
        export interface PrometheusSpecVolumesProjectedSourcesDownwardAPIItemsFieldRef {
            /**
             * Version of the schema the FieldPath is written in terms of, defaults to "v1".
             */
            apiVersion?: string;
            /**
             * Path of the field to select in the specified API version.
             */
            fieldPath: string;
        }

        /**
         * Selects a resource of the container: only resources limits and requests (limits.cpu, limits.memory, requests.cpu and requests.memory) are currently supported.
         */
        export interface PrometheusSpecVolumesProjectedSourcesDownwardAPIItemsResourceFieldRef {
            /**
             * Container name: required for volumes, optional for env vars
             */
            containerName?: string;
            /**
             * Specifies the output format of the exposed resources, defaults to "1"
             */
            divisor?: outputs.monitoring.v1.PrometheusSpecVolumesProjectedSourcesDownwardAPIItemsResourceFieldRefDivisor;
            /**
             * Required: resource to select
             */
            resource: string;
        }

        export interface PrometheusSpecVolumesProjectedSourcesDownwardAPIItemsResourceFieldRefDivisor {
        }

        /**
         * information about the secret data to project
         */
        export interface PrometheusSpecVolumesProjectedSourcesSecret {
            /**
             * If unspecified, each key-value pair in the Data field of the referenced Secret will be projected into the volume as a file whose name is the key and content is the value. If specified, the listed keys will be projected into the specified paths, and unlisted keys will not be present. If a key is specified which is not present in the Secret, the volume setup will error unless it is marked optional. Paths must be relative and may not contain the '..' path or start with '..'.
             */
            items?: outputs.monitoring.v1.PrometheusSpecVolumesProjectedSourcesSecretItems[];
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Maps a string key to a path within a volume.
         */
        export interface PrometheusSpecVolumesProjectedSourcesSecretItems {
            /**
             * The key to project.
             */
            key: string;
            /**
             * Optional: mode bits to use on this file, must be a value between 0 and 0777. If not specified, the volume defaultMode will be used. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set.
             */
            mode?: number;
            /**
             * The relative path of the file to map the key to. May not be an absolute path. May not contain the path element '..'. May not start with the string '..'.
             */
            path: string;
        }

        /**
         * information about the serviceAccountToken data to project
         */
        export interface PrometheusSpecVolumesProjectedSourcesServiceAccountToken {
            /**
             * Audience is the intended audience of the token. A recipient of a token must identify itself with an identifier specified in the audience of the token, and otherwise should reject the token. The audience defaults to the identifier of the apiserver.
             */
            audience?: string;
            /**
             * ExpirationSeconds is the requested duration of validity of the service account token. As the token approaches expiration, the kubelet volume plugin will proactively rotate the service account token. The kubelet will start trying to rotate the token if the token is older than 80 percent of its time to live or if the token is older than 24 hours.Defaults to 1 hour and must be at least 10 minutes.
             */
            expirationSeconds?: number;
            /**
             * Path is the path relative to the mount point of the file to project the token into.
             */
            path: string;
        }

        /**
         * Quobyte represents a Quobyte mount on the host that shares a pod's lifetime
         */
        export interface PrometheusSpecVolumesQuobyte {
            /**
             * Group to map volume access to Default is no group
             */
            group?: string;
            /**
             * ReadOnly here will force the Quobyte volume to be mounted with read-only permissions. Defaults to false.
             */
            readOnly?: boolean;
            /**
             * Registry represents a single or multiple Quobyte Registry services specified as a string as host:port pair (multiple entries are separated with commas) which acts as the central registry for volumes
             */
            registry: string;
            /**
             * Tenant owning the given Quobyte volume in the Backend Used with dynamically provisioned Quobyte volumes, value is set by the plugin
             */
            tenant?: string;
            /**
             * User to map volume access to Defaults to serivceaccount user
             */
            user?: string;
            /**
             * Volume is a string that references an already created Quobyte volume by name.
             */
            volume: string;
        }

        /**
         * RBD represents a Rados Block Device mount on the host that shares a pod's lifetime. More info: https://examples.k8s.io/volumes/rbd/README.md
         */
        export interface PrometheusSpecVolumesRbd {
            /**
             * Filesystem type of the volume that you want to mount. Tip: Ensure that the filesystem type is supported by the host operating system. Examples: "ext4", "xfs", "ntfs". Implicitly inferred to be "ext4" if unspecified. More info: https://kubernetes.io/docs/concepts/storage/volumes#rbd TODO: how do we prevent errors in the filesystem from compromising the machine
             */
            fsType?: string;
            /**
             * The rados image name. More info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it
             */
            image: string;
            /**
             * Keyring is the path to key ring for RBDUser. Default is /etc/ceph/keyring. More info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it
             */
            keyring?: string;
            /**
             * A collection of Ceph monitors. More info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it
             */
            monitors: string[];
            /**
             * The rados pool name. Default is rbd. More info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it
             */
            pool?: string;
            /**
             * ReadOnly here will force the ReadOnly setting in VolumeMounts. Defaults to false. More info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it
             */
            readOnly?: boolean;
            /**
             * SecretRef is name of the authentication secret for RBDUser. If provided overrides keyring. Default is nil. More info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it
             */
            secretRef?: outputs.monitoring.v1.PrometheusSpecVolumesRbdSecretRef;
            /**
             * The rados user name. Default is admin. More info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it
             */
            user?: string;
        }

        /**
         * SecretRef is name of the authentication secret for RBDUser. If provided overrides keyring. Default is nil. More info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it
         */
        export interface PrometheusSpecVolumesRbdSecretRef {
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
        }

        /**
         * ScaleIO represents a ScaleIO persistent volume attached and mounted on Kubernetes nodes.
         */
        export interface PrometheusSpecVolumesScaleIO {
            /**
             * Filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. "ext4", "xfs", "ntfs". Default is "xfs".
             */
            fsType?: string;
            /**
             * The host address of the ScaleIO API Gateway.
             */
            gateway: string;
            /**
             * The name of the ScaleIO Protection Domain for the configured storage.
             */
            protectionDomain?: string;
            /**
             * Defaults to false (read/write). ReadOnly here will force the ReadOnly setting in VolumeMounts.
             */
            readOnly?: boolean;
            /**
             * SecretRef references to the secret for ScaleIO user and other sensitive information. If this is not provided, Login operation will fail.
             */
            secretRef: outputs.monitoring.v1.PrometheusSpecVolumesScaleIOSecretRef;
            /**
             * Flag to enable/disable SSL communication with Gateway, default false
             */
            sslEnabled?: boolean;
            /**
             * Indicates whether the storage for a volume should be ThickProvisioned or ThinProvisioned. Default is ThinProvisioned.
             */
            storageMode?: string;
            /**
             * The ScaleIO Storage Pool associated with the protection domain.
             */
            storagePool?: string;
            /**
             * The name of the storage system as configured in ScaleIO.
             */
            system: string;
            /**
             * The name of a volume already created in the ScaleIO system that is associated with this volume source.
             */
            volumeName?: string;
        }

        /**
         * SecretRef references to the secret for ScaleIO user and other sensitive information. If this is not provided, Login operation will fail.
         */
        export interface PrometheusSpecVolumesScaleIOSecretRef {
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
        }

        /**
         * Secret represents a secret that should populate this volume. More info: https://kubernetes.io/docs/concepts/storage/volumes#secret
         */
        export interface PrometheusSpecVolumesSecret {
            /**
             * Optional: mode bits to use on created files by default. Must be a value between 0 and 0777. Defaults to 0644. Directories within the path are not affected by this setting. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set.
             */
            defaultMode?: number;
            /**
             * If unspecified, each key-value pair in the Data field of the referenced Secret will be projected into the volume as a file whose name is the key and content is the value. If specified, the listed keys will be projected into the specified paths, and unlisted keys will not be present. If a key is specified which is not present in the Secret, the volume setup will error unless it is marked optional. Paths must be relative and may not contain the '..' path or start with '..'.
             */
            items?: outputs.monitoring.v1.PrometheusSpecVolumesSecretItems[];
            /**
             * Specify whether the Secret or its keys must be defined
             */
            optional?: boolean;
            /**
             * Name of the secret in the pod's namespace to use. More info: https://kubernetes.io/docs/concepts/storage/volumes#secret
             */
            secretName?: string;
        }

        /**
         * Maps a string key to a path within a volume.
         */
        export interface PrometheusSpecVolumesSecretItems {
            /**
             * The key to project.
             */
            key: string;
            /**
             * Optional: mode bits to use on this file, must be a value between 0 and 0777. If not specified, the volume defaultMode will be used. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set.
             */
            mode?: number;
            /**
             * The relative path of the file to map the key to. May not be an absolute path. May not contain the path element '..'. May not start with the string '..'.
             */
            path: string;
        }

        /**
         * StorageOS represents a StorageOS volume attached and mounted on Kubernetes nodes.
         */
        export interface PrometheusSpecVolumesStorageos {
            /**
             * Filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. "ext4", "xfs", "ntfs". Implicitly inferred to be "ext4" if unspecified.
             */
            fsType?: string;
            /**
             * Defaults to false (read/write). ReadOnly here will force the ReadOnly setting in VolumeMounts.
             */
            readOnly?: boolean;
            /**
             * SecretRef specifies the secret to use for obtaining the StorageOS API credentials.  If not specified, default values will be attempted.
             */
            secretRef?: outputs.monitoring.v1.PrometheusSpecVolumesStorageosSecretRef;
            /**
             * VolumeName is the human-readable name of the StorageOS volume.  Volume names are only unique within a namespace.
             */
            volumeName?: string;
            /**
             * VolumeNamespace specifies the scope of the volume within StorageOS.  If no namespace is specified then the Pod's namespace will be used.  This allows the Kubernetes name scoping to be mirrored within StorageOS for tighter integration. Set VolumeName to any name to override the default behaviour. Set to "default" if you are not using namespaces within StorageOS. Namespaces that do not pre-exist within StorageOS will be created.
             */
            volumeNamespace?: string;
        }

        /**
         * SecretRef specifies the secret to use for obtaining the StorageOS API credentials.  If not specified, default values will be attempted.
         */
        export interface PrometheusSpecVolumesStorageosSecretRef {
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
        }

        /**
         * VsphereVolume represents a vSphere volume attached and mounted on kubelets host machine
         */
        export interface PrometheusSpecVolumesVsphereVolume {
            /**
             * Filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. "ext4", "xfs", "ntfs". Implicitly inferred to be "ext4" if unspecified.
             */
            fsType?: string;
            /**
             * Storage Policy Based Management (SPBM) profile ID associated with the StoragePolicyName.
             */
            storagePolicyID?: string;
            /**
             * Storage Policy Based Management (SPBM) profile name.
             */
            storagePolicyName?: string;
            /**
             * Path that identifies vSphere volume vmdk
             */
            volumePath: string;
        }

        /**
         * WebSpec defines the web command line flags when starting Prometheus.
         */
        export interface PrometheusSpecWeb {
            /**
             * The prometheus web page title
             */
            pageTitle?: string;
        }

        /**
         * Most recent observed status of the Prometheus cluster. Read-only. Not included when requesting from the apiserver, only from the Prometheus Operator API itself. More info: https://github.com/kubernetes/community/blob/master/contributors/devel/sig-architecture/api-conventions.md#spec-and-status
         */
        export interface PrometheusStatus {
            /**
             * Total number of available pods (ready for at least minReadySeconds) targeted by this Prometheus deployment.
             */
            availableReplicas: number;
            /**
             * Represents whether any actions on the underlying managed objects are being performed. Only delete actions will be performed.
             */
            paused: boolean;
            /**
             * Total number of non-terminated pods targeted by this Prometheus deployment (their labels match the selector).
             */
            replicas: number;
            /**
             * Total number of unavailable pods targeted by this Prometheus deployment.
             */
            unavailableReplicas: number;
            /**
             * Total number of non-terminated pods targeted by this Prometheus deployment that have the desired version spec.
             */
            updatedReplicas: number;
        }

        /**
         * Specification of desired Service selection for target discovery by Prometheus.
         */
        export interface ServiceMonitorSpec {
            /**
             * A list of endpoints allowed as part of this ServiceMonitor.
             */
            endpoints: outputs.monitoring.v1.ServiceMonitorSpecEndpoints[];
            /**
             * The label to use to retrieve the job name from.
             */
            jobLabel?: string;
            /**
             * Selector to select which namespaces the Endpoints objects are discovered from.
             */
            namespaceSelector?: outputs.monitoring.v1.ServiceMonitorSpecNamespaceSelector;
            /**
             * PodTargetLabels transfers labels on the Kubernetes Pod onto the target.
             */
            podTargetLabels?: string[];
            /**
             * SampleLimit defines per-scrape limit on number of scraped samples that will be accepted.
             */
            sampleLimit?: number;
            /**
             * Selector to select Endpoints objects.
             */
            selector: outputs.monitoring.v1.ServiceMonitorSpecSelector;
            /**
             * TargetLabels transfers labels on the Kubernetes Service onto the target.
             */
            targetLabels?: string[];
            /**
             * TargetLimit defines a limit on the number of scraped targets that will be accepted.
             */
            targetLimit?: number;
        }

        /**
         * Endpoint defines a scrapeable endpoint serving Prometheus metrics.
         */
        export interface ServiceMonitorSpecEndpoints {
            /**
             * BasicAuth allow an endpoint to authenticate over basic authentication More info: https://prometheus.io/docs/operating/configuration/#endpoints
             */
            basicAuth?: outputs.monitoring.v1.ServiceMonitorSpecEndpointsBasicAuth;
            /**
             * File to read bearer token for scraping targets.
             */
            bearerTokenFile?: string;
            /**
             * Secret to mount to read bearer token for scraping targets. The secret needs to be in the same namespace as the service monitor and accessible by the Prometheus Operator.
             */
            bearerTokenSecret?: outputs.monitoring.v1.ServiceMonitorSpecEndpointsBearerTokenSecret;
            /**
             * HonorLabels chooses the metric's labels on collisions with target labels.
             */
            honorLabels?: boolean;
            /**
             * HonorTimestamps controls whether Prometheus respects the timestamps present in scraped data.
             */
            honorTimestamps?: boolean;
            /**
             * Interval at which metrics should be scraped
             */
            interval?: string;
            /**
             * MetricRelabelConfigs to apply to samples before ingestion.
             */
            metricRelabelings?: outputs.monitoring.v1.ServiceMonitorSpecEndpointsMetricRelabelings[];
            /**
             * Optional HTTP URL parameters
             */
            params?: {[key: string]: string[]};
            /**
             * HTTP path to scrape for metrics.
             */
            path?: string;
            /**
             * Name of the service port this endpoint refers to. Mutually exclusive with targetPort.
             */
            port?: string;
            /**
             * ProxyURL eg http://proxyserver:2195 Directs scrapes to proxy through this endpoint.
             */
            proxyUrl?: string;
            /**
             * RelabelConfigs to apply to samples before scraping. More info: https://prometheus.io/docs/prometheus/latest/configuration/configuration/#relabel_config
             */
            relabelings?: outputs.monitoring.v1.ServiceMonitorSpecEndpointsRelabelings[];
            /**
             * HTTP scheme to use for scraping.
             */
            scheme?: string;
            /**
             * Timeout after which the scrape is ended
             */
            scrapeTimeout?: string;
            /**
             * Name or number of the target port of the Pod behind the Service, the port must be specified with container port property. Mutually exclusive with port.
             */
            targetPort?: outputs.monitoring.v1.ServiceMonitorSpecEndpointsTargetPort;
            /**
             * TLS configuration to use when scraping the endpoint
             */
            tlsConfig?: outputs.monitoring.v1.ServiceMonitorSpecEndpointsTlsConfig;
        }

        /**
         * BasicAuth allow an endpoint to authenticate over basic authentication More info: https://prometheus.io/docs/operating/configuration/#endpoints
         */
        export interface ServiceMonitorSpecEndpointsBasicAuth {
            /**
             * The secret in the service monitor namespace that contains the password for authentication.
             */
            password?: outputs.monitoring.v1.ServiceMonitorSpecEndpointsBasicAuthPassword;
            /**
             * The secret in the service monitor namespace that contains the username for authentication.
             */
            username?: outputs.monitoring.v1.ServiceMonitorSpecEndpointsBasicAuthUsername;
        }

        /**
         * The secret in the service monitor namespace that contains the password for authentication.
         */
        export interface ServiceMonitorSpecEndpointsBasicAuthPassword {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * The secret in the service monitor namespace that contains the username for authentication.
         */
        export interface ServiceMonitorSpecEndpointsBasicAuthUsername {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Secret to mount to read bearer token for scraping targets. The secret needs to be in the same namespace as the service monitor and accessible by the Prometheus Operator.
         */
        export interface ServiceMonitorSpecEndpointsBearerTokenSecret {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * RelabelConfig allows dynamic rewriting of the label set, being applied to samples before ingestion. It defines `<metric_relabel_configs>`-section of Prometheus configuration. More info: https://prometheus.io/docs/prometheus/latest/configuration/configuration/#metric_relabel_configs
         */
        export interface ServiceMonitorSpecEndpointsMetricRelabelings {
            /**
             * Action to perform based on regex matching. Default is 'replace'
             */
            action?: string;
            /**
             * Modulus to take of the hash of the source label values.
             */
            modulus?: number;
            /**
             * Regular expression against which the extracted value is matched. Default is '(.*)'
             */
            regex?: string;
            /**
             * Replacement value against which a regex replace is performed if the regular expression matches. Regex capture groups are available. Default is '$1'
             */
            replacement?: string;
            /**
             * Separator placed between concatenated source label values. default is ';'.
             */
            separator?: string;
            /**
             * The source labels select values from existing labels. Their content is concatenated using the configured separator and matched against the configured regular expression for the replace, keep, and drop actions.
             */
            sourceLabels?: string[];
            /**
             * Label to which the resulting value is written in a replace action. It is mandatory for replace actions. Regex capture groups are available.
             */
            targetLabel?: string;
        }

        /**
         * RelabelConfig allows dynamic rewriting of the label set, being applied to samples before ingestion. It defines `<metric_relabel_configs>`-section of Prometheus configuration. More info: https://prometheus.io/docs/prometheus/latest/configuration/configuration/#metric_relabel_configs
         */
        export interface ServiceMonitorSpecEndpointsRelabelings {
            /**
             * Action to perform based on regex matching. Default is 'replace'
             */
            action?: string;
            /**
             * Modulus to take of the hash of the source label values.
             */
            modulus?: number;
            /**
             * Regular expression against which the extracted value is matched. Default is '(.*)'
             */
            regex?: string;
            /**
             * Replacement value against which a regex replace is performed if the regular expression matches. Regex capture groups are available. Default is '$1'
             */
            replacement?: string;
            /**
             * Separator placed between concatenated source label values. default is ';'.
             */
            separator?: string;
            /**
             * The source labels select values from existing labels. Their content is concatenated using the configured separator and matched against the configured regular expression for the replace, keep, and drop actions.
             */
            sourceLabels?: string[];
            /**
             * Label to which the resulting value is written in a replace action. It is mandatory for replace actions. Regex capture groups are available.
             */
            targetLabel?: string;
        }

        export interface ServiceMonitorSpecEndpointsTargetPort {
        }

        /**
         * TLS configuration to use when scraping the endpoint
         */
        export interface ServiceMonitorSpecEndpointsTlsConfig {
            /**
             * Struct containing the CA cert to use for the targets.
             */
            ca?: outputs.monitoring.v1.ServiceMonitorSpecEndpointsTlsConfigCa;
            /**
             * Path to the CA cert in the Prometheus container to use for the targets.
             */
            caFile?: string;
            /**
             * Struct containing the client cert file for the targets.
             */
            cert?: outputs.monitoring.v1.ServiceMonitorSpecEndpointsTlsConfigCert;
            /**
             * Path to the client cert file in the Prometheus container for the targets.
             */
            certFile?: string;
            /**
             * Disable target certificate validation.
             */
            insecureSkipVerify?: boolean;
            /**
             * Path to the client key file in the Prometheus container for the targets.
             */
            keyFile?: string;
            /**
             * Secret containing the client key file for the targets.
             */
            keySecret?: outputs.monitoring.v1.ServiceMonitorSpecEndpointsTlsConfigKeySecret;
            /**
             * Used to verify the hostname for the targets.
             */
            serverName?: string;
        }

        /**
         * Struct containing the CA cert to use for the targets.
         */
        export interface ServiceMonitorSpecEndpointsTlsConfigCa {
            /**
             * ConfigMap containing data to use for the targets.
             */
            configMap?: outputs.monitoring.v1.ServiceMonitorSpecEndpointsTlsConfigCaConfigMap;
            /**
             * Secret containing data to use for the targets.
             */
            secret?: outputs.monitoring.v1.ServiceMonitorSpecEndpointsTlsConfigCaSecret;
        }

        /**
         * ConfigMap containing data to use for the targets.
         */
        export interface ServiceMonitorSpecEndpointsTlsConfigCaConfigMap {
            /**
             * The key to select.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the ConfigMap or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Secret containing data to use for the targets.
         */
        export interface ServiceMonitorSpecEndpointsTlsConfigCaSecret {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Struct containing the client cert file for the targets.
         */
        export interface ServiceMonitorSpecEndpointsTlsConfigCert {
            /**
             * ConfigMap containing data to use for the targets.
             */
            configMap?: outputs.monitoring.v1.ServiceMonitorSpecEndpointsTlsConfigCertConfigMap;
            /**
             * Secret containing data to use for the targets.
             */
            secret?: outputs.monitoring.v1.ServiceMonitorSpecEndpointsTlsConfigCertSecret;
        }

        /**
         * ConfigMap containing data to use for the targets.
         */
        export interface ServiceMonitorSpecEndpointsTlsConfigCertConfigMap {
            /**
             * The key to select.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the ConfigMap or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Secret containing data to use for the targets.
         */
        export interface ServiceMonitorSpecEndpointsTlsConfigCertSecret {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Secret containing the client key file for the targets.
         */
        export interface ServiceMonitorSpecEndpointsTlsConfigKeySecret {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Selector to select which namespaces the Endpoints objects are discovered from.
         */
        export interface ServiceMonitorSpecNamespaceSelector {
            /**
             * Boolean describing whether all namespaces are selected in contrast to a list restricting them.
             */
            any?: boolean;
            /**
             * List of namespace names.
             */
            matchNames?: string[];
        }

        /**
         * Selector to select Endpoints objects.
         */
        export interface ServiceMonitorSpecSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.monitoring.v1.ServiceMonitorSpecSelectorMatchExpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ServiceMonitorSpecSelectorMatchExpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Specification of the desired behavior of the ThanosRuler cluster. More info: https://github.com/kubernetes/community/blob/master/contributors/devel/sig-architecture/api-conventions.md#spec-and-status
         */
        export interface ThanosRulerSpec {
            /**
             * If specified, the pod's scheduling constraints.
             */
            affinity?: outputs.monitoring.v1.ThanosRulerSpecAffinity;
            /**
             * AlertDropLabels configure the label names which should be dropped in ThanosRuler alerts. If `labels` field is not provided, `thanos_ruler_replica` will be dropped in alerts by default.
             */
            alertDropLabels?: string[];
            /**
             * The external Query URL the Thanos Ruler will set in the 'Source' field of all alerts. Maps to the '--alert.query-url' CLI arg.
             */
            alertQueryUrl?: string;
            /**
             * Define configuration for connecting to alertmanager.  Only available with thanos v0.10.0 and higher.  Maps to the `alertmanagers.config` arg.
             */
            alertmanagersConfig?: outputs.monitoring.v1.ThanosRulerSpecAlertmanagersConfig;
            /**
             * Define URLs to send alerts to Alertmanager.  For Thanos v0.10.0 and higher, AlertManagersConfig should be used instead.  Note: this field will be ignored if AlertManagersConfig is specified. Maps to the `alertmanagers.url` arg.
             */
            alertmanagersUrl?: string[];
            /**
             * Containers allows injecting additional containers or modifying operator generated containers. This can be used to allow adding an authentication proxy to a ThanosRuler pod or to change the behavior of an operator generated container. Containers described here modify an operator generated container if they share the same name and modifications are done via a strategic merge patch. The current container names are: `thanos-ruler` and `config-reloader`. Overriding containers is entirely outside the scope of what the maintainers will support and by doing so, you accept that this behaviour may break at any time without notice.
             */
            containers?: outputs.monitoring.v1.ThanosRulerSpecContainers[];
            /**
             * EnforcedNamespaceLabel enforces adding a namespace label of origin for each alert and metric that is user created. The label value will always be the namespace of the object that is being created.
             */
            enforcedNamespaceLabel?: string;
            /**
             * Interval between consecutive evaluations.
             */
            evaluationInterval?: string;
            /**
             * The external URL the Thanos Ruler instances will be available under. This is necessary to generate correct URLs. This is necessary if Thanos Ruler is not served from root of a DNS name.
             */
            externalPrefix?: string;
            /**
             * GRPCServerTLSConfig configures the gRPC server from which Thanos Querier reads recorded rule data. Note: Currently only the CAFile, CertFile, and KeyFile fields are supported. Maps to the '--grpc-server-tls-*' CLI args.
             */
            grpcServerTlsConfig?: outputs.monitoring.v1.ThanosRulerSpecGrpcServerTlsConfig;
            /**
             * Thanos container image URL.
             */
            image?: string;
            /**
             * An optional list of references to secrets in the same namespace to use for pulling thanos images from registries see http://kubernetes.io/docs/user-guide/images#specifying-imagepullsecrets-on-a-pod
             */
            imagePullSecrets?: outputs.monitoring.v1.ThanosRulerSpecImagePullSecrets[];
            /**
             * InitContainers allows adding initContainers to the pod definition. Those can be used to e.g. fetch secrets for injection into the ThanosRuler configuration from external sources. Any errors during the execution of an initContainer will lead to a restart of the Pod. More info: https://kubernetes.io/docs/concepts/workloads/pods/init-containers/ Using initContainers for any use case other then secret fetching is entirely outside the scope of what the maintainers will support and by doing so, you accept that this behaviour may break at any time without notice.
             */
            initContainers?: outputs.monitoring.v1.ThanosRulerSpecInitContainers[];
            /**
             * Labels configure the external label pairs to ThanosRuler. If not provided, default replica label `thanos_ruler_replica` will be added as a label and be dropped in alerts.
             */
            labels?: {[key: string]: string};
            /**
             * ListenLocal makes the Thanos ruler listen on loopback, so that it does not bind against the Pod IP.
             */
            listenLocal?: boolean;
            /**
             * Log format for ThanosRuler to be configured with.
             */
            logFormat?: string;
            /**
             * Log level for ThanosRuler to be configured with.
             */
            logLevel?: string;
            /**
             * Define which Nodes the Pods are scheduled on.
             */
            nodeSelector?: {[key: string]: string};
            /**
             * ObjectStorageConfig configures object storage in Thanos. Alternative to ObjectStorageConfigFile, and lower order priority.
             */
            objectStorageConfig?: outputs.monitoring.v1.ThanosRulerSpecObjectStorageConfig;
            /**
             * ObjectStorageConfigFile specifies the path of the object storage configuration file. When used alongside with ObjectStorageConfig, ObjectStorageConfigFile takes precedence.
             */
            objectStorageConfigFile?: string;
            /**
             * When a ThanosRuler deployment is paused, no actions except for deletion will be performed on the underlying objects.
             */
            paused?: boolean;
            /**
             * PodMetadata contains Labels and Annotations gets propagated to the thanos ruler pods.
             */
            podMetadata?: outputs.monitoring.v1.ThanosRulerSpecPodMetadata;
            /**
             * Port name used for the pods and governing service. This defaults to web
             */
            portName?: string;
            /**
             * Priority class assigned to the Pods
             */
            priorityClassName?: string;
            /**
             * PrometheusRulesExcludedFromEnforce - list of Prometheus rules to be excluded from enforcing of adding namespace labels. Works only if enforcedNamespaceLabel set to true. Make sure both ruleNamespace and ruleName are set for each pair
             */
            prometheusRulesExcludedFromEnforce?: outputs.monitoring.v1.ThanosRulerSpecPrometheusRulesExcludedFromEnforce[];
            /**
             * Define configuration for connecting to thanos query instances. If this is defined, the QueryEndpoints field will be ignored. Maps to the `query.config` CLI argument. Only available with thanos v0.11.0 and higher.
             */
            queryConfig?: outputs.monitoring.v1.ThanosRulerSpecQueryConfig;
            /**
             * QueryEndpoints defines Thanos querier endpoints from which to query metrics. Maps to the --query flag of thanos ruler.
             */
            queryEndpoints?: string[];
            /**
             * Number of thanos ruler instances to deploy.
             */
            replicas?: number;
            /**
             * Resources defines the resource requirements for single Pods. If not provided, no requests/limits will be set
             */
            resources?: outputs.monitoring.v1.ThanosRulerSpecResources;
            /**
             * Time duration ThanosRuler shall retain data for. Default is '24h', and must match the regular expression `[0-9]+(ms|s|m|h|d|w|y)` (milliseconds seconds minutes hours days weeks years).
             */
            retention?: string;
            /**
             * The route prefix ThanosRuler registers HTTP handlers for. This allows thanos UI to be served on a sub-path.
             */
            routePrefix?: string;
            /**
             * Namespaces to be selected for Rules discovery. If unspecified, only the same namespace as the ThanosRuler object is in is used.
             */
            ruleNamespaceSelector?: outputs.monitoring.v1.ThanosRulerSpecRuleNamespaceSelector;
            /**
             * A label selector to select which PrometheusRules to mount for alerting and recording.
             */
            ruleSelector?: outputs.monitoring.v1.ThanosRulerSpecRuleSelector;
            /**
             * SecurityContext holds pod-level security attributes and common container settings. This defaults to the default PodSecurityContext.
             */
            securityContext?: outputs.monitoring.v1.ThanosRulerSpecSecurityContext;
            /**
             * ServiceAccountName is the name of the ServiceAccount to use to run the Thanos Ruler Pods.
             */
            serviceAccountName?: string;
            /**
             * Storage spec to specify how storage shall be used.
             */
            storage?: outputs.monitoring.v1.ThanosRulerSpecStorage;
            /**
             * If specified, the pod's tolerations.
             */
            tolerations?: outputs.monitoring.v1.ThanosRulerSpecTolerations[];
            /**
             * If specified, the pod's topology spread constraints.
             */
            topologySpreadConstraints?: outputs.monitoring.v1.ThanosRulerSpecTopologySpreadConstraints[];
            /**
             * TracingConfig configures tracing in Thanos. This is an experimental feature, it may change in any upcoming release in a breaking way.
             */
            tracingConfig?: outputs.monitoring.v1.ThanosRulerSpecTracingConfig;
            /**
             * Volumes allows configuration of additional volumes on the output StatefulSet definition. Volumes specified will be appended to other volumes that are generated as a result of StorageSpec objects.
             */
            volumes?: outputs.monitoring.v1.ThanosRulerSpecVolumes[];
        }

        /**
         * If specified, the pod's scheduling constraints.
         */
        export interface ThanosRulerSpecAffinity {
            /**
             * Describes node affinity scheduling rules for the pod.
             */
            nodeAffinity?: outputs.monitoring.v1.ThanosRulerSpecAffinityNodeAffinity;
            /**
             * Describes pod affinity scheduling rules (e.g. co-locate this pod in the same node, zone, etc. as some other pod(s)).
             */
            podAffinity?: outputs.monitoring.v1.ThanosRulerSpecAffinityPodAffinity;
            /**
             * Describes pod anti-affinity scheduling rules (e.g. avoid putting this pod in the same node, zone, etc. as some other pod(s)).
             */
            podAntiAffinity?: outputs.monitoring.v1.ThanosRulerSpecAffinityPodAntiAffinity;
        }

        /**
         * Describes node affinity scheduling rules for the pod.
         */
        export interface ThanosRulerSpecAffinityNodeAffinity {
            /**
             * The scheduler will prefer to schedule pods to nodes that satisfy the affinity expressions specified by this field, but it may choose a node that violates one or more of the expressions. The node that is most preferred is the one with the greatest sum of weights, i.e. for each node that meets all of the scheduling requirements (resource request, requiredDuringScheduling affinity expressions, etc.), compute a sum by iterating through the elements of this field and adding "weight" to the sum if the node matches the corresponding matchExpressions; the node(s) with the highest sum are the most preferred.
             */
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.monitoring.v1.ThanosRulerSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            /**
             * If the affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to an update), the system may or may not try to eventually evict the pod from its node.
             */
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.monitoring.v1.ThanosRulerSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution;
        }

        /**
         * An empty preferred scheduling term matches all objects with implicit weight 0 (i.e. it's a no-op). A null preferred scheduling term matches no objects (i.e. is also a no-op).
         */
        export interface ThanosRulerSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            /**
             * A node selector term, associated with the corresponding weight.
             */
            preference: outputs.monitoring.v1.ThanosRulerSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference;
            /**
             * Weight associated with matching the corresponding nodeSelectorTerm, in the range 1-100.
             */
            weight: number;
        }

        /**
         * A node selector term, associated with the corresponding weight.
         */
        export interface ThanosRulerSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference {
            /**
             * A list of node selector requirements by node's labels.
             */
            matchExpressions?: outputs.monitoring.v1.ThanosRulerSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions[];
            /**
             * A list of node selector requirements by node's fields.
             */
            matchFields?: outputs.monitoring.v1.ThanosRulerSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields[];
        }

        /**
         * A node selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ThanosRulerSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions {
            /**
             * The label key that the selector applies to.
             */
            key: string;
            /**
             * Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
             */
            operator: string;
            /**
             * An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * A node selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ThanosRulerSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields {
            /**
             * The label key that the selector applies to.
             */
            key: string;
            /**
             * Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
             */
            operator: string;
            /**
             * An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * If the affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to an update), the system may or may not try to eventually evict the pod from its node.
         */
        export interface ThanosRulerSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            /**
             * Required. A list of node selector terms. The terms are ORed.
             */
            nodeSelectorTerms: outputs.monitoring.v1.ThanosRulerSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms[];
        }

        /**
         * A null or empty node selector term matches no objects. The requirements of them are ANDed. The TopologySelectorTerm type implements a subset of the NodeSelectorTerm.
         */
        export interface ThanosRulerSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms {
            /**
             * A list of node selector requirements by node's labels.
             */
            matchExpressions?: outputs.monitoring.v1.ThanosRulerSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions[];
            /**
             * A list of node selector requirements by node's fields.
             */
            matchFields?: outputs.monitoring.v1.ThanosRulerSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields[];
        }

        /**
         * A node selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ThanosRulerSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions {
            /**
             * The label key that the selector applies to.
             */
            key: string;
            /**
             * Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
             */
            operator: string;
            /**
             * An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * A node selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ThanosRulerSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields {
            /**
             * The label key that the selector applies to.
             */
            key: string;
            /**
             * Represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.
             */
            operator: string;
            /**
             * An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Describes pod affinity scheduling rules (e.g. co-locate this pod in the same node, zone, etc. as some other pod(s)).
         */
        export interface ThanosRulerSpecAffinityPodAffinity {
            /**
             * The scheduler will prefer to schedule pods to nodes that satisfy the affinity expressions specified by this field, but it may choose a node that violates one or more of the expressions. The node that is most preferred is the one with the greatest sum of weights, i.e. for each node that meets all of the scheduling requirements (resource request, requiredDuringScheduling affinity expressions, etc.), compute a sum by iterating through the elements of this field and adding "weight" to the sum if the node has pods which matches the corresponding podAffinityTerm; the node(s) with the highest sum are the most preferred.
             */
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.monitoring.v1.ThanosRulerSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            /**
             * If the affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to a pod label update), the system may or may not try to eventually evict the pod from its node. When there are multiple elements, the lists of nodes corresponding to each podAffinityTerm are intersected, i.e. all terms must be satisfied.
             */
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.monitoring.v1.ThanosRulerSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        /**
         * The weights of all of the matched WeightedPodAffinityTerm fields are added per-node to find the most preferred node(s)
         */
        export interface ThanosRulerSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            /**
             * Required. A pod affinity term, associated with the corresponding weight.
             */
            podAffinityTerm: outputs.monitoring.v1.ThanosRulerSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            /**
             * weight associated with matching the corresponding podAffinityTerm, in the range 1-100.
             */
            weight: number;
        }

        /**
         * Required. A pod affinity term, associated with the corresponding weight.
         */
        export interface ThanosRulerSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            /**
             * A label query over a set of resources, in this case pods.
             */
            labelSelector?: outputs.monitoring.v1.ThanosRulerSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            /**
             * namespaces specifies which namespaces the labelSelector applies to (matches against); null or empty list means "this pod's namespace"
             */
            namespaces?: string[];
            /**
             * This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed.
             */
            topologyKey: string;
        }

        /**
         * A label query over a set of resources, in this case pods.
         */
        export interface ThanosRulerSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.monitoring.v1.ThanosRulerSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ThanosRulerSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Defines a set of pods (namely those matching the labelSelector relative to the given namespace(s)) that this pod should be co-located (affinity) or not co-located (anti-affinity) with, where co-located is defined as running on a node whose value of the label with key <topologyKey> matches that of any node on which a pod of the set of pods is running
         */
        export interface ThanosRulerSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            /**
             * A label query over a set of resources, in this case pods.
             */
            labelSelector?: outputs.monitoring.v1.ThanosRulerSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            /**
             * namespaces specifies which namespaces the labelSelector applies to (matches against); null or empty list means "this pod's namespace"
             */
            namespaces?: string[];
            /**
             * This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed.
             */
            topologyKey: string;
        }

        /**
         * A label query over a set of resources, in this case pods.
         */
        export interface ThanosRulerSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.monitoring.v1.ThanosRulerSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ThanosRulerSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Describes pod anti-affinity scheduling rules (e.g. avoid putting this pod in the same node, zone, etc. as some other pod(s)).
         */
        export interface ThanosRulerSpecAffinityPodAntiAffinity {
            /**
             * The scheduler will prefer to schedule pods to nodes that satisfy the anti-affinity expressions specified by this field, but it may choose a node that violates one or more of the expressions. The node that is most preferred is the one with the greatest sum of weights, i.e. for each node that meets all of the scheduling requirements (resource request, requiredDuringScheduling anti-affinity expressions, etc.), compute a sum by iterating through the elements of this field and adding "weight" to the sum if the node has pods which matches the corresponding podAffinityTerm; the node(s) with the highest sum are the most preferred.
             */
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.monitoring.v1.ThanosRulerSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            /**
             * If the anti-affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the anti-affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to a pod label update), the system may or may not try to eventually evict the pod from its node. When there are multiple elements, the lists of nodes corresponding to each podAffinityTerm are intersected, i.e. all terms must be satisfied.
             */
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.monitoring.v1.ThanosRulerSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        /**
         * The weights of all of the matched WeightedPodAffinityTerm fields are added per-node to find the most preferred node(s)
         */
        export interface ThanosRulerSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            /**
             * Required. A pod affinity term, associated with the corresponding weight.
             */
            podAffinityTerm: outputs.monitoring.v1.ThanosRulerSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            /**
             * weight associated with matching the corresponding podAffinityTerm, in the range 1-100.
             */
            weight: number;
        }

        /**
         * Required. A pod affinity term, associated with the corresponding weight.
         */
        export interface ThanosRulerSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            /**
             * A label query over a set of resources, in this case pods.
             */
            labelSelector?: outputs.monitoring.v1.ThanosRulerSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            /**
             * namespaces specifies which namespaces the labelSelector applies to (matches against); null or empty list means "this pod's namespace"
             */
            namespaces?: string[];
            /**
             * This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed.
             */
            topologyKey: string;
        }

        /**
         * A label query over a set of resources, in this case pods.
         */
        export interface ThanosRulerSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.monitoring.v1.ThanosRulerSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ThanosRulerSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Defines a set of pods (namely those matching the labelSelector relative to the given namespace(s)) that this pod should be co-located (affinity) or not co-located (anti-affinity) with, where co-located is defined as running on a node whose value of the label with key <topologyKey> matches that of any node on which a pod of the set of pods is running
         */
        export interface ThanosRulerSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            /**
             * A label query over a set of resources, in this case pods.
             */
            labelSelector?: outputs.monitoring.v1.ThanosRulerSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            /**
             * namespaces specifies which namespaces the labelSelector applies to (matches against); null or empty list means "this pod's namespace"
             */
            namespaces?: string[];
            /**
             * This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching the labelSelector in the specified namespaces, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected pods is running. Empty topologyKey is not allowed.
             */
            topologyKey: string;
        }

        /**
         * A label query over a set of resources, in this case pods.
         */
        export interface ThanosRulerSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.monitoring.v1.ThanosRulerSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ThanosRulerSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Define configuration for connecting to alertmanager.  Only available with thanos v0.10.0 and higher.  Maps to the `alertmanagers.config` arg.
         */
        export interface ThanosRulerSpecAlertmanagersConfig {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * A single application container that you want to run within a pod.
         */
        export interface ThanosRulerSpecContainers {
            /**
             * Arguments to the entrypoint. The docker image's CMD is used if this is not provided. Variable references $(VAR_NAME) are expanded using the container's environment. If a variable cannot be resolved, the reference in the input string will be unchanged. The $(VAR_NAME) syntax can be escaped with a double $$, ie: $$(VAR_NAME). Escaped references will never be expanded, regardless of whether the variable exists or not. Cannot be updated. More info: https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#running-a-command-in-a-shell
             */
            args?: string[];
            /**
             * Entrypoint array. Not executed within a shell. The docker image's ENTRYPOINT is used if this is not provided. Variable references $(VAR_NAME) are expanded using the container's environment. If a variable cannot be resolved, the reference in the input string will be unchanged. The $(VAR_NAME) syntax can be escaped with a double $$, ie: $$(VAR_NAME). Escaped references will never be expanded, regardless of whether the variable exists or not. Cannot be updated. More info: https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#running-a-command-in-a-shell
             */
            command?: string[];
            /**
             * List of environment variables to set in the container. Cannot be updated.
             */
            env?: outputs.monitoring.v1.ThanosRulerSpecContainersEnv[];
            /**
             * List of sources to populate environment variables in the container. The keys defined within a source must be a C_IDENTIFIER. All invalid keys will be reported as an event when the container is starting. When a key exists in multiple sources, the value associated with the last source will take precedence. Values defined by an Env with a duplicate key will take precedence. Cannot be updated.
             */
            envFrom?: outputs.monitoring.v1.ThanosRulerSpecContainersEnvFrom[];
            /**
             * Docker image name. More info: https://kubernetes.io/docs/concepts/containers/images This field is optional to allow higher level config management to default or override container images in workload controllers like Deployments and StatefulSets.
             */
            image?: string;
            /**
             * Image pull policy. One of Always, Never, IfNotPresent. Defaults to Always if :latest tag is specified, or IfNotPresent otherwise. Cannot be updated. More info: https://kubernetes.io/docs/concepts/containers/images#updating-images
             */
            imagePullPolicy?: string;
            /**
             * Actions that the management system should take in response to container lifecycle events. Cannot be updated.
             */
            lifecycle?: outputs.monitoring.v1.ThanosRulerSpecContainersLifecycle;
            /**
             * Periodic probe of container liveness. Container will be restarted if the probe fails. Cannot be updated. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
             */
            livenessProbe?: outputs.monitoring.v1.ThanosRulerSpecContainersLivenessProbe;
            /**
             * Name of the container specified as a DNS_LABEL. Each container in a pod must have a unique name (DNS_LABEL). Cannot be updated.
             */
            name: string;
            /**
             * List of ports to expose from the container. Exposing a port here gives the system additional information about the network connections a container uses, but is primarily informational. Not specifying a port here DOES NOT prevent that port from being exposed. Any port which is listening on the default "0.0.0.0" address inside a container will be accessible from the network. Cannot be updated.
             */
            ports?: outputs.monitoring.v1.ThanosRulerSpecContainersPorts[];
            /**
             * Periodic probe of container service readiness. Container will be removed from service endpoints if the probe fails. Cannot be updated. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
             */
            readinessProbe?: outputs.monitoring.v1.ThanosRulerSpecContainersReadinessProbe;
            /**
             * Compute Resources required by this container. Cannot be updated. More info: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
             */
            resources?: outputs.monitoring.v1.ThanosRulerSpecContainersResources;
            /**
             * Security options the pod should run with. More info: https://kubernetes.io/docs/concepts/policy/security-context/ More info: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/
             */
            securityContext?: outputs.monitoring.v1.ThanosRulerSpecContainersSecurityContext;
            /**
             * StartupProbe indicates that the Pod has successfully initialized. If specified, no other probes are executed until this completes successfully. If this probe fails, the Pod will be restarted, just as if the livenessProbe failed. This can be used to provide different probe parameters at the beginning of a Pod's lifecycle, when it might take a long time to load data or warm a cache, than during steady-state operation. This cannot be updated. This is a beta feature enabled by the StartupProbe feature flag. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
             */
            startupProbe?: outputs.monitoring.v1.ThanosRulerSpecContainersStartupProbe;
            /**
             * Whether this container should allocate a buffer for stdin in the container runtime. If this is not set, reads from stdin in the container will always result in EOF. Default is false.
             */
            stdin?: boolean;
            /**
             * Whether the container runtime should close the stdin channel after it has been opened by a single attach. When stdin is true the stdin stream will remain open across multiple attach sessions. If stdinOnce is set to true, stdin is opened on container start, is empty until the first client attaches to stdin, and then remains open and accepts data until the client disconnects, at which time stdin is closed and remains closed until the container is restarted. If this flag is false, a container processes that reads from stdin will never receive an EOF. Default is false
             */
            stdinOnce?: boolean;
            /**
             * Optional: Path at which the file to which the container's termination message will be written is mounted into the container's filesystem. Message written is intended to be brief final status, such as an assertion failure message. Will be truncated by the node if greater than 4096 bytes. The total message length across all containers will be limited to 12kb. Defaults to /dev/termination-log. Cannot be updated.
             */
            terminationMessagePath?: string;
            /**
             * Indicate how the termination message should be populated. File will use the contents of terminationMessagePath to populate the container status message on both success and failure. FallbackToLogsOnError will use the last chunk of container log output if the termination message file is empty and the container exited with an error. The log output is limited to 2048 bytes or 80 lines, whichever is smaller. Defaults to File. Cannot be updated.
             */
            terminationMessagePolicy?: string;
            /**
             * Whether this container should allocate a TTY for itself, also requires 'stdin' to be true. Default is false.
             */
            tty?: boolean;
            /**
             * volumeDevices is the list of block devices to be used by the container.
             */
            volumeDevices?: outputs.monitoring.v1.ThanosRulerSpecContainersVolumeDevices[];
            /**
             * Pod volumes to mount into the container's filesystem. Cannot be updated.
             */
            volumeMounts?: outputs.monitoring.v1.ThanosRulerSpecContainersVolumeMounts[];
            /**
             * Container's working directory. If not specified, the container runtime's default will be used, which might be configured in the container image. Cannot be updated.
             */
            workingDir?: string;
        }

        /**
         * EnvVar represents an environment variable present in a Container.
         */
        export interface ThanosRulerSpecContainersEnv {
            /**
             * Name of the environment variable. Must be a C_IDENTIFIER.
             */
            name: string;
            /**
             * Variable references $(VAR_NAME) are expanded using the previous defined environment variables in the container and any service environment variables. If a variable cannot be resolved, the reference in the input string will be unchanged. The $(VAR_NAME) syntax can be escaped with a double $$, ie: $$(VAR_NAME). Escaped references will never be expanded, regardless of whether the variable exists or not. Defaults to "".
             */
            value?: string;
            /**
             * Source for the environment variable's value. Cannot be used if value is not empty.
             */
            valueFrom?: outputs.monitoring.v1.ThanosRulerSpecContainersEnvValueFrom;
        }

        /**
         * EnvFromSource represents the source of a set of ConfigMaps
         */
        export interface ThanosRulerSpecContainersEnvFrom {
            /**
             * The ConfigMap to select from
             */
            configMapRef?: outputs.monitoring.v1.ThanosRulerSpecContainersEnvFromConfigMapRef;
            /**
             * An optional identifier to prepend to each key in the ConfigMap. Must be a C_IDENTIFIER.
             */
            prefix?: string;
            /**
             * The Secret to select from
             */
            secretRef?: outputs.monitoring.v1.ThanosRulerSpecContainersEnvFromSecretRef;
        }

        /**
         * The ConfigMap to select from
         */
        export interface ThanosRulerSpecContainersEnvFromConfigMapRef {
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the ConfigMap must be defined
             */
            optional?: boolean;
        }

        /**
         * The Secret to select from
         */
        export interface ThanosRulerSpecContainersEnvFromSecretRef {
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret must be defined
             */
            optional?: boolean;
        }

        /**
         * Source for the environment variable's value. Cannot be used if value is not empty.
         */
        export interface ThanosRulerSpecContainersEnvValueFrom {
            /**
             * Selects a key of a ConfigMap.
             */
            configMapKeyRef?: outputs.monitoring.v1.ThanosRulerSpecContainersEnvValueFromConfigMapKeyRef;
            /**
             * Selects a field of the pod: supports metadata.name, metadata.namespace, metadata.labels, metadata.annotations, spec.nodeName, spec.serviceAccountName, status.hostIP, status.podIP, status.podIPs.
             */
            fieldRef?: outputs.monitoring.v1.ThanosRulerSpecContainersEnvValueFromFieldRef;
            /**
             * Selects a resource of the container: only resources limits and requests (limits.cpu, limits.memory, limits.ephemeral-storage, requests.cpu, requests.memory and requests.ephemeral-storage) are currently supported.
             */
            resourceFieldRef?: outputs.monitoring.v1.ThanosRulerSpecContainersEnvValueFromResourceFieldRef;
            /**
             * Selects a key of a secret in the pod's namespace
             */
            secretKeyRef?: outputs.monitoring.v1.ThanosRulerSpecContainersEnvValueFromSecretKeyRef;
        }

        /**
         * Selects a key of a ConfigMap.
         */
        export interface ThanosRulerSpecContainersEnvValueFromConfigMapKeyRef {
            /**
             * The key to select.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the ConfigMap or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Selects a field of the pod: supports metadata.name, metadata.namespace, metadata.labels, metadata.annotations, spec.nodeName, spec.serviceAccountName, status.hostIP, status.podIP, status.podIPs.
         */
        export interface ThanosRulerSpecContainersEnvValueFromFieldRef {
            /**
             * Version of the schema the FieldPath is written in terms of, defaults to "v1".
             */
            apiVersion?: string;
            /**
             * Path of the field to select in the specified API version.
             */
            fieldPath: string;
        }

        /**
         * Selects a resource of the container: only resources limits and requests (limits.cpu, limits.memory, limits.ephemeral-storage, requests.cpu, requests.memory and requests.ephemeral-storage) are currently supported.
         */
        export interface ThanosRulerSpecContainersEnvValueFromResourceFieldRef {
            /**
             * Container name: required for volumes, optional for env vars
             */
            containerName?: string;
            /**
             * Specifies the output format of the exposed resources, defaults to "1"
             */
            divisor?: outputs.monitoring.v1.ThanosRulerSpecContainersEnvValueFromResourceFieldRefDivisor;
            /**
             * Required: resource to select
             */
            resource: string;
        }

        export interface ThanosRulerSpecContainersEnvValueFromResourceFieldRefDivisor {
        }

        /**
         * Selects a key of a secret in the pod's namespace
         */
        export interface ThanosRulerSpecContainersEnvValueFromSecretKeyRef {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Actions that the management system should take in response to container lifecycle events. Cannot be updated.
         */
        export interface ThanosRulerSpecContainersLifecycle {
            /**
             * PostStart is called immediately after a container is created. If the handler fails, the container is terminated and restarted according to its restart policy. Other management of the container blocks until the hook completes. More info: https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks/#container-hooks
             */
            postStart?: outputs.monitoring.v1.ThanosRulerSpecContainersLifecyclePostStart;
            /**
             * PreStop is called immediately before a container is terminated due to an API request or management event such as liveness/startup probe failure, preemption, resource contention, etc. The handler is not called if the container crashes or exits. The reason for termination is passed to the handler. The Pod's termination grace period countdown begins before the PreStop hooked is executed. Regardless of the outcome of the handler, the container will eventually terminate within the Pod's termination grace period. Other management of the container blocks until the hook completes or until the termination grace period is reached. More info: https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks/#container-hooks
             */
            preStop?: outputs.monitoring.v1.ThanosRulerSpecContainersLifecyclePreStop;
        }

        /**
         * PostStart is called immediately after a container is created. If the handler fails, the container is terminated and restarted according to its restart policy. Other management of the container blocks until the hook completes. More info: https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks/#container-hooks
         */
        export interface ThanosRulerSpecContainersLifecyclePostStart {
            /**
             * One and only one of the following should be specified. Exec specifies the action to take.
             */
            exec?: outputs.monitoring.v1.ThanosRulerSpecContainersLifecyclePostStartExec;
            /**
             * HTTPGet specifies the http request to perform.
             */
            httpGet?: outputs.monitoring.v1.ThanosRulerSpecContainersLifecyclePostStartHttpGet;
            /**
             * TCPSocket specifies an action involving a TCP port. TCP hooks not yet supported TODO: implement a realistic TCP lifecycle hook
             */
            tcpSocket?: outputs.monitoring.v1.ThanosRulerSpecContainersLifecyclePostStartTcpSocket;
        }

        /**
         * One and only one of the following should be specified. Exec specifies the action to take.
         */
        export interface ThanosRulerSpecContainersLifecyclePostStartExec {
            /**
             * Command is the command line to execute inside the container, the working directory for the command  is root ('/') in the container's filesystem. The command is simply exec'd, it is not run inside a shell, so traditional shell instructions ('|', etc) won't work. To use a shell, you need to explicitly call out to that shell. Exit status of 0 is treated as live/healthy and non-zero is unhealthy.
             */
            command?: string[];
        }

        /**
         * HTTPGet specifies the http request to perform.
         */
        export interface ThanosRulerSpecContainersLifecyclePostStartHttpGet {
            /**
             * Host name to connect to, defaults to the pod IP. You probably want to set "Host" in httpHeaders instead.
             */
            host?: string;
            /**
             * Custom headers to set in the request. HTTP allows repeated headers.
             */
            httpHeaders?: outputs.monitoring.v1.ThanosRulerSpecContainersLifecyclePostStartHttpGetHttpHeaders[];
            /**
             * Path to access on the HTTP server.
             */
            path?: string;
            /**
             * Name or number of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME.
             */
            port: outputs.monitoring.v1.ThanosRulerSpecContainersLifecyclePostStartHttpGetPort;
            /**
             * Scheme to use for connecting to the host. Defaults to HTTP.
             */
            scheme?: string;
        }

        /**
         * HTTPHeader describes a custom header to be used in HTTP probes
         */
        export interface ThanosRulerSpecContainersLifecyclePostStartHttpGetHttpHeaders {
            /**
             * The header field name
             */
            name: string;
            /**
             * The header field value
             */
            value: string;
        }

        export interface ThanosRulerSpecContainersLifecyclePostStartHttpGetPort {
        }

        /**
         * TCPSocket specifies an action involving a TCP port. TCP hooks not yet supported TODO: implement a realistic TCP lifecycle hook
         */
        export interface ThanosRulerSpecContainersLifecyclePostStartTcpSocket {
            /**
             * Optional: Host name to connect to, defaults to the pod IP.
             */
            host?: string;
            /**
             * Number or name of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME.
             */
            port: outputs.monitoring.v1.ThanosRulerSpecContainersLifecyclePostStartTcpSocketPort;
        }

        export interface ThanosRulerSpecContainersLifecyclePostStartTcpSocketPort {
        }

        /**
         * PreStop is called immediately before a container is terminated due to an API request or management event such as liveness/startup probe failure, preemption, resource contention, etc. The handler is not called if the container crashes or exits. The reason for termination is passed to the handler. The Pod's termination grace period countdown begins before the PreStop hooked is executed. Regardless of the outcome of the handler, the container will eventually terminate within the Pod's termination grace period. Other management of the container blocks until the hook completes or until the termination grace period is reached. More info: https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks/#container-hooks
         */
        export interface ThanosRulerSpecContainersLifecyclePreStop {
            /**
             * One and only one of the following should be specified. Exec specifies the action to take.
             */
            exec?: outputs.monitoring.v1.ThanosRulerSpecContainersLifecyclePreStopExec;
            /**
             * HTTPGet specifies the http request to perform.
             */
            httpGet?: outputs.monitoring.v1.ThanosRulerSpecContainersLifecyclePreStopHttpGet;
            /**
             * TCPSocket specifies an action involving a TCP port. TCP hooks not yet supported TODO: implement a realistic TCP lifecycle hook
             */
            tcpSocket?: outputs.monitoring.v1.ThanosRulerSpecContainersLifecyclePreStopTcpSocket;
        }

        /**
         * One and only one of the following should be specified. Exec specifies the action to take.
         */
        export interface ThanosRulerSpecContainersLifecyclePreStopExec {
            /**
             * Command is the command line to execute inside the container, the working directory for the command  is root ('/') in the container's filesystem. The command is simply exec'd, it is not run inside a shell, so traditional shell instructions ('|', etc) won't work. To use a shell, you need to explicitly call out to that shell. Exit status of 0 is treated as live/healthy and non-zero is unhealthy.
             */
            command?: string[];
        }

        /**
         * HTTPGet specifies the http request to perform.
         */
        export interface ThanosRulerSpecContainersLifecyclePreStopHttpGet {
            /**
             * Host name to connect to, defaults to the pod IP. You probably want to set "Host" in httpHeaders instead.
             */
            host?: string;
            /**
             * Custom headers to set in the request. HTTP allows repeated headers.
             */
            httpHeaders?: outputs.monitoring.v1.ThanosRulerSpecContainersLifecyclePreStopHttpGetHttpHeaders[];
            /**
             * Path to access on the HTTP server.
             */
            path?: string;
            /**
             * Name or number of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME.
             */
            port: outputs.monitoring.v1.ThanosRulerSpecContainersLifecyclePreStopHttpGetPort;
            /**
             * Scheme to use for connecting to the host. Defaults to HTTP.
             */
            scheme?: string;
        }

        /**
         * HTTPHeader describes a custom header to be used in HTTP probes
         */
        export interface ThanosRulerSpecContainersLifecyclePreStopHttpGetHttpHeaders {
            /**
             * The header field name
             */
            name: string;
            /**
             * The header field value
             */
            value: string;
        }

        export interface ThanosRulerSpecContainersLifecyclePreStopHttpGetPort {
        }

        /**
         * TCPSocket specifies an action involving a TCP port. TCP hooks not yet supported TODO: implement a realistic TCP lifecycle hook
         */
        export interface ThanosRulerSpecContainersLifecyclePreStopTcpSocket {
            /**
             * Optional: Host name to connect to, defaults to the pod IP.
             */
            host?: string;
            /**
             * Number or name of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME.
             */
            port: outputs.monitoring.v1.ThanosRulerSpecContainersLifecyclePreStopTcpSocketPort;
        }

        export interface ThanosRulerSpecContainersLifecyclePreStopTcpSocketPort {
        }

        /**
         * Periodic probe of container liveness. Container will be restarted if the probe fails. Cannot be updated. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
         */
        export interface ThanosRulerSpecContainersLivenessProbe {
            /**
             * One and only one of the following should be specified. Exec specifies the action to take.
             */
            exec?: outputs.monitoring.v1.ThanosRulerSpecContainersLivenessProbeExec;
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * HTTPGet specifies the http request to perform.
             */
            httpGet?: outputs.monitoring.v1.ThanosRulerSpecContainersLivenessProbeHttpGet;
            /**
             * Number of seconds after the container has started before liveness probes are initiated. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness and startup. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * TCPSocket specifies an action involving a TCP port. TCP hooks not yet supported TODO: implement a realistic TCP lifecycle hook
             */
            tcpSocket?: outputs.monitoring.v1.ThanosRulerSpecContainersLivenessProbeTcpSocket;
            /**
             * Number of seconds after which the probe times out. Defaults to 1 second. Minimum value is 1. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
             */
            timeoutSeconds?: number;
        }

        /**
         * One and only one of the following should be specified. Exec specifies the action to take.
         */
        export interface ThanosRulerSpecContainersLivenessProbeExec {
            /**
             * Command is the command line to execute inside the container, the working directory for the command  is root ('/') in the container's filesystem. The command is simply exec'd, it is not run inside a shell, so traditional shell instructions ('|', etc) won't work. To use a shell, you need to explicitly call out to that shell. Exit status of 0 is treated as live/healthy and non-zero is unhealthy.
             */
            command?: string[];
        }

        /**
         * HTTPGet specifies the http request to perform.
         */
        export interface ThanosRulerSpecContainersLivenessProbeHttpGet {
            /**
             * Host name to connect to, defaults to the pod IP. You probably want to set "Host" in httpHeaders instead.
             */
            host?: string;
            /**
             * Custom headers to set in the request. HTTP allows repeated headers.
             */
            httpHeaders?: outputs.monitoring.v1.ThanosRulerSpecContainersLivenessProbeHttpGetHttpHeaders[];
            /**
             * Path to access on the HTTP server.
             */
            path?: string;
            /**
             * Name or number of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME.
             */
            port: outputs.monitoring.v1.ThanosRulerSpecContainersLivenessProbeHttpGetPort;
            /**
             * Scheme to use for connecting to the host. Defaults to HTTP.
             */
            scheme?: string;
        }

        /**
         * HTTPHeader describes a custom header to be used in HTTP probes
         */
        export interface ThanosRulerSpecContainersLivenessProbeHttpGetHttpHeaders {
            /**
             * The header field name
             */
            name: string;
            /**
             * The header field value
             */
            value: string;
        }

        export interface ThanosRulerSpecContainersLivenessProbeHttpGetPort {
        }

        /**
         * TCPSocket specifies an action involving a TCP port. TCP hooks not yet supported TODO: implement a realistic TCP lifecycle hook
         */
        export interface ThanosRulerSpecContainersLivenessProbeTcpSocket {
            /**
             * Optional: Host name to connect to, defaults to the pod IP.
             */
            host?: string;
            /**
             * Number or name of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME.
             */
            port: outputs.monitoring.v1.ThanosRulerSpecContainersLivenessProbeTcpSocketPort;
        }

        export interface ThanosRulerSpecContainersLivenessProbeTcpSocketPort {
        }

        /**
         * ContainerPort represents a network port in a single container.
         */
        export interface ThanosRulerSpecContainersPorts {
            /**
             * Number of port to expose on the pod's IP address. This must be a valid port number, 0 < x < 65536.
             */
            containerPort: number;
            /**
             * What host IP to bind the external port to.
             */
            hostIP?: string;
            /**
             * Number of port to expose on the host. If specified, this must be a valid port number, 0 < x < 65536. If HostNetwork is specified, this must match ContainerPort. Most containers do not need this.
             */
            hostPort?: number;
            /**
             * If specified, this must be an IANA_SVC_NAME and unique within the pod. Each named port in a pod must have a unique name. Name for the port that can be referred to by services.
             */
            name?: string;
            /**
             * Protocol for port. Must be UDP, TCP, or SCTP. Defaults to "TCP".
             */
            protocol?: string;
        }

        /**
         * Periodic probe of container service readiness. Container will be removed from service endpoints if the probe fails. Cannot be updated. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
         */
        export interface ThanosRulerSpecContainersReadinessProbe {
            /**
             * One and only one of the following should be specified. Exec specifies the action to take.
             */
            exec?: outputs.monitoring.v1.ThanosRulerSpecContainersReadinessProbeExec;
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * HTTPGet specifies the http request to perform.
             */
            httpGet?: outputs.monitoring.v1.ThanosRulerSpecContainersReadinessProbeHttpGet;
            /**
             * Number of seconds after the container has started before liveness probes are initiated. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness and startup. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * TCPSocket specifies an action involving a TCP port. TCP hooks not yet supported TODO: implement a realistic TCP lifecycle hook
             */
            tcpSocket?: outputs.monitoring.v1.ThanosRulerSpecContainersReadinessProbeTcpSocket;
            /**
             * Number of seconds after which the probe times out. Defaults to 1 second. Minimum value is 1. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
             */
            timeoutSeconds?: number;
        }

        /**
         * One and only one of the following should be specified. Exec specifies the action to take.
         */
        export interface ThanosRulerSpecContainersReadinessProbeExec {
            /**
             * Command is the command line to execute inside the container, the working directory for the command  is root ('/') in the container's filesystem. The command is simply exec'd, it is not run inside a shell, so traditional shell instructions ('|', etc) won't work. To use a shell, you need to explicitly call out to that shell. Exit status of 0 is treated as live/healthy and non-zero is unhealthy.
             */
            command?: string[];
        }

        /**
         * HTTPGet specifies the http request to perform.
         */
        export interface ThanosRulerSpecContainersReadinessProbeHttpGet {
            /**
             * Host name to connect to, defaults to the pod IP. You probably want to set "Host" in httpHeaders instead.
             */
            host?: string;
            /**
             * Custom headers to set in the request. HTTP allows repeated headers.
             */
            httpHeaders?: outputs.monitoring.v1.ThanosRulerSpecContainersReadinessProbeHttpGetHttpHeaders[];
            /**
             * Path to access on the HTTP server.
             */
            path?: string;
            /**
             * Name or number of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME.
             */
            port: outputs.monitoring.v1.ThanosRulerSpecContainersReadinessProbeHttpGetPort;
            /**
             * Scheme to use for connecting to the host. Defaults to HTTP.
             */
            scheme?: string;
        }

        /**
         * HTTPHeader describes a custom header to be used in HTTP probes
         */
        export interface ThanosRulerSpecContainersReadinessProbeHttpGetHttpHeaders {
            /**
             * The header field name
             */
            name: string;
            /**
             * The header field value
             */
            value: string;
        }

        export interface ThanosRulerSpecContainersReadinessProbeHttpGetPort {
        }

        /**
         * TCPSocket specifies an action involving a TCP port. TCP hooks not yet supported TODO: implement a realistic TCP lifecycle hook
         */
        export interface ThanosRulerSpecContainersReadinessProbeTcpSocket {
            /**
             * Optional: Host name to connect to, defaults to the pod IP.
             */
            host?: string;
            /**
             * Number or name of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME.
             */
            port: outputs.monitoring.v1.ThanosRulerSpecContainersReadinessProbeTcpSocketPort;
        }

        export interface ThanosRulerSpecContainersReadinessProbeTcpSocketPort {
        }

        /**
         * Compute Resources required by this container. Cannot be updated. More info: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
         */
        export interface ThanosRulerSpecContainersResources {
            /**
             * Limits describes the maximum amount of compute resources allowed. More info: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
             */
            limits?: {[key: string]: outputs.monitoring.v1.ThanosRulerSpecContainersResourcesLimits};
            /**
             * Requests describes the minimum amount of compute resources required. If Requests is omitted for a container, it defaults to Limits if that is explicitly specified, otherwise to an implementation-defined value. More info: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
             */
            requests?: {[key: string]: outputs.monitoring.v1.ThanosRulerSpecContainersResourcesRequests};
        }

        export interface ThanosRulerSpecContainersResourcesLimits {
        }

        export interface ThanosRulerSpecContainersResourcesRequests {
        }

        /**
         * Security options the pod should run with. More info: https://kubernetes.io/docs/concepts/policy/security-context/ More info: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/
         */
        export interface ThanosRulerSpecContainersSecurityContext {
            /**
             * AllowPrivilegeEscalation controls whether a process can gain more privileges than its parent process. This bool directly controls if the no_new_privs flag will be set on the container process. AllowPrivilegeEscalation is true always when the container is: 1) run as Privileged 2) has CAP_SYS_ADMIN
             */
            allowPrivilegeEscalation?: boolean;
            /**
             * The capabilities to add/drop when running containers. Defaults to the default set of capabilities granted by the container runtime.
             */
            capabilities?: outputs.monitoring.v1.ThanosRulerSpecContainersSecurityContextCapabilities;
            /**
             * Run container in privileged mode. Processes in privileged containers are essentially equivalent to root on the host. Defaults to false.
             */
            privileged?: boolean;
            /**
             * procMount denotes the type of proc mount to use for the containers. The default is DefaultProcMount which uses the container runtime defaults for readonly paths and masked paths. This requires the ProcMountType feature flag to be enabled.
             */
            procMount?: string;
            /**
             * Whether this container has a read-only root filesystem. Default is false.
             */
            readOnlyRootFilesystem?: boolean;
            /**
             * The GID to run the entrypoint of the container process. Uses runtime default if unset. May also be set in PodSecurityContext.  If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.
             */
            runAsGroup?: number;
            /**
             * Indicates that the container must run as a non-root user. If true, the Kubelet will validate the image at runtime to ensure that it does not run as UID 0 (root) and fail to start the container if it does. If unset or false, no such validation will be performed. May also be set in PodSecurityContext.  If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.
             */
            runAsNonRoot?: boolean;
            /**
             * The UID to run the entrypoint of the container process. Defaults to user specified in image metadata if unspecified. May also be set in PodSecurityContext.  If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.
             */
            runAsUser?: number;
            /**
             * The SELinux context to be applied to the container. If unspecified, the container runtime will allocate a random SELinux context for each container.  May also be set in PodSecurityContext.  If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.
             */
            seLinuxOptions?: outputs.monitoring.v1.ThanosRulerSpecContainersSecurityContextSeLinuxOptions;
            /**
             * The Windows specific settings applied to all containers. If unspecified, the options from the PodSecurityContext will be used. If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.
             */
            windowsOptions?: outputs.monitoring.v1.ThanosRulerSpecContainersSecurityContextWindowsOptions;
        }

        /**
         * The capabilities to add/drop when running containers. Defaults to the default set of capabilities granted by the container runtime.
         */
        export interface ThanosRulerSpecContainersSecurityContextCapabilities {
            /**
             * Added capabilities
             */
            add?: string[];
            /**
             * Removed capabilities
             */
            drop?: string[];
        }

        /**
         * The SELinux context to be applied to the container. If unspecified, the container runtime will allocate a random SELinux context for each container.  May also be set in PodSecurityContext.  If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.
         */
        export interface ThanosRulerSpecContainersSecurityContextSeLinuxOptions {
            /**
             * Level is SELinux level label that applies to the container.
             */
            level?: string;
            /**
             * Role is a SELinux role label that applies to the container.
             */
            role?: string;
            /**
             * Type is a SELinux type label that applies to the container.
             */
            type?: string;
            /**
             * User is a SELinux user label that applies to the container.
             */
            user?: string;
        }

        /**
         * The Windows specific settings applied to all containers. If unspecified, the options from the PodSecurityContext will be used. If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.
         */
        export interface ThanosRulerSpecContainersSecurityContextWindowsOptions {
            /**
             * GMSACredentialSpec is where the GMSA admission webhook (https://github.com/kubernetes-sigs/windows-gmsa) inlines the contents of the GMSA credential spec named by the GMSACredentialSpecName field.
             */
            gmsaCredentialSpec?: string;
            /**
             * GMSACredentialSpecName is the name of the GMSA credential spec to use.
             */
            gmsaCredentialSpecName?: string;
            /**
             * The UserName in Windows to run the entrypoint of the container process. Defaults to the user specified in image metadata if unspecified. May also be set in PodSecurityContext. If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.
             */
            runAsUserName?: string;
        }

        /**
         * StartupProbe indicates that the Pod has successfully initialized. If specified, no other probes are executed until this completes successfully. If this probe fails, the Pod will be restarted, just as if the livenessProbe failed. This can be used to provide different probe parameters at the beginning of a Pod's lifecycle, when it might take a long time to load data or warm a cache, than during steady-state operation. This cannot be updated. This is a beta feature enabled by the StartupProbe feature flag. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
         */
        export interface ThanosRulerSpecContainersStartupProbe {
            /**
             * One and only one of the following should be specified. Exec specifies the action to take.
             */
            exec?: outputs.monitoring.v1.ThanosRulerSpecContainersStartupProbeExec;
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * HTTPGet specifies the http request to perform.
             */
            httpGet?: outputs.monitoring.v1.ThanosRulerSpecContainersStartupProbeHttpGet;
            /**
             * Number of seconds after the container has started before liveness probes are initiated. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness and startup. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * TCPSocket specifies an action involving a TCP port. TCP hooks not yet supported TODO: implement a realistic TCP lifecycle hook
             */
            tcpSocket?: outputs.monitoring.v1.ThanosRulerSpecContainersStartupProbeTcpSocket;
            /**
             * Number of seconds after which the probe times out. Defaults to 1 second. Minimum value is 1. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
             */
            timeoutSeconds?: number;
        }

        /**
         * One and only one of the following should be specified. Exec specifies the action to take.
         */
        export interface ThanosRulerSpecContainersStartupProbeExec {
            /**
             * Command is the command line to execute inside the container, the working directory for the command  is root ('/') in the container's filesystem. The command is simply exec'd, it is not run inside a shell, so traditional shell instructions ('|', etc) won't work. To use a shell, you need to explicitly call out to that shell. Exit status of 0 is treated as live/healthy and non-zero is unhealthy.
             */
            command?: string[];
        }

        /**
         * HTTPGet specifies the http request to perform.
         */
        export interface ThanosRulerSpecContainersStartupProbeHttpGet {
            /**
             * Host name to connect to, defaults to the pod IP. You probably want to set "Host" in httpHeaders instead.
             */
            host?: string;
            /**
             * Custom headers to set in the request. HTTP allows repeated headers.
             */
            httpHeaders?: outputs.monitoring.v1.ThanosRulerSpecContainersStartupProbeHttpGetHttpHeaders[];
            /**
             * Path to access on the HTTP server.
             */
            path?: string;
            /**
             * Name or number of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME.
             */
            port: outputs.monitoring.v1.ThanosRulerSpecContainersStartupProbeHttpGetPort;
            /**
             * Scheme to use for connecting to the host. Defaults to HTTP.
             */
            scheme?: string;
        }

        /**
         * HTTPHeader describes a custom header to be used in HTTP probes
         */
        export interface ThanosRulerSpecContainersStartupProbeHttpGetHttpHeaders {
            /**
             * The header field name
             */
            name: string;
            /**
             * The header field value
             */
            value: string;
        }

        export interface ThanosRulerSpecContainersStartupProbeHttpGetPort {
        }

        /**
         * TCPSocket specifies an action involving a TCP port. TCP hooks not yet supported TODO: implement a realistic TCP lifecycle hook
         */
        export interface ThanosRulerSpecContainersStartupProbeTcpSocket {
            /**
             * Optional: Host name to connect to, defaults to the pod IP.
             */
            host?: string;
            /**
             * Number or name of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME.
             */
            port: outputs.monitoring.v1.ThanosRulerSpecContainersStartupProbeTcpSocketPort;
        }

        export interface ThanosRulerSpecContainersStartupProbeTcpSocketPort {
        }

        /**
         * volumeDevice describes a mapping of a raw block device within a container.
         */
        export interface ThanosRulerSpecContainersVolumeDevices {
            /**
             * devicePath is the path inside of the container that the device will be mapped to.
             */
            devicePath: string;
            /**
             * name must match the name of a persistentVolumeClaim in the pod
             */
            name: string;
        }

        /**
         * VolumeMount describes a mounting of a Volume within a container.
         */
        export interface ThanosRulerSpecContainersVolumeMounts {
            /**
             * Path within the container at which the volume should be mounted.  Must not contain ':'.
             */
            mountPath: string;
            /**
             * mountPropagation determines how mounts are propagated from the host to container and the other way around. When not set, MountPropagationNone is used. This field is beta in 1.10.
             */
            mountPropagation?: string;
            /**
             * This must match the Name of a Volume.
             */
            name: string;
            /**
             * Mounted read-only if true, read-write otherwise (false or unspecified). Defaults to false.
             */
            readOnly?: boolean;
            /**
             * Path within the volume from which the container's volume should be mounted. Defaults to "" (volume's root).
             */
            subPath?: string;
            /**
             * Expanded path within the volume from which the container's volume should be mounted. Behaves similarly to SubPath but environment variable references $(VAR_NAME) are expanded using the container's environment. Defaults to "" (volume's root). SubPathExpr and SubPath are mutually exclusive.
             */
            subPathExpr?: string;
        }

        /**
         * GRPCServerTLSConfig configures the gRPC server from which Thanos Querier reads recorded rule data. Note: Currently only the CAFile, CertFile, and KeyFile fields are supported. Maps to the '--grpc-server-tls-*' CLI args.
         */
        export interface ThanosRulerSpecGrpcServerTlsConfig {
            /**
             * Struct containing the CA cert to use for the targets.
             */
            ca?: outputs.monitoring.v1.ThanosRulerSpecGrpcServerTlsConfigCa;
            /**
             * Path to the CA cert in the Prometheus container to use for the targets.
             */
            caFile?: string;
            /**
             * Struct containing the client cert file for the targets.
             */
            cert?: outputs.monitoring.v1.ThanosRulerSpecGrpcServerTlsConfigCert;
            /**
             * Path to the client cert file in the Prometheus container for the targets.
             */
            certFile?: string;
            /**
             * Disable target certificate validation.
             */
            insecureSkipVerify?: boolean;
            /**
             * Path to the client key file in the Prometheus container for the targets.
             */
            keyFile?: string;
            /**
             * Secret containing the client key file for the targets.
             */
            keySecret?: outputs.monitoring.v1.ThanosRulerSpecGrpcServerTlsConfigKeySecret;
            /**
             * Used to verify the hostname for the targets.
             */
            serverName?: string;
        }

        /**
         * Struct containing the CA cert to use for the targets.
         */
        export interface ThanosRulerSpecGrpcServerTlsConfigCa {
            /**
             * ConfigMap containing data to use for the targets.
             */
            configMap?: outputs.monitoring.v1.ThanosRulerSpecGrpcServerTlsConfigCaConfigMap;
            /**
             * Secret containing data to use for the targets.
             */
            secret?: outputs.monitoring.v1.ThanosRulerSpecGrpcServerTlsConfigCaSecret;
        }

        /**
         * ConfigMap containing data to use for the targets.
         */
        export interface ThanosRulerSpecGrpcServerTlsConfigCaConfigMap {
            /**
             * The key to select.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the ConfigMap or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Secret containing data to use for the targets.
         */
        export interface ThanosRulerSpecGrpcServerTlsConfigCaSecret {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Struct containing the client cert file for the targets.
         */
        export interface ThanosRulerSpecGrpcServerTlsConfigCert {
            /**
             * ConfigMap containing data to use for the targets.
             */
            configMap?: outputs.monitoring.v1.ThanosRulerSpecGrpcServerTlsConfigCertConfigMap;
            /**
             * Secret containing data to use for the targets.
             */
            secret?: outputs.monitoring.v1.ThanosRulerSpecGrpcServerTlsConfigCertSecret;
        }

        /**
         * ConfigMap containing data to use for the targets.
         */
        export interface ThanosRulerSpecGrpcServerTlsConfigCertConfigMap {
            /**
             * The key to select.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the ConfigMap or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Secret containing data to use for the targets.
         */
        export interface ThanosRulerSpecGrpcServerTlsConfigCertSecret {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Secret containing the client key file for the targets.
         */
        export interface ThanosRulerSpecGrpcServerTlsConfigKeySecret {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * LocalObjectReference contains enough information to let you locate the referenced object inside the same namespace.
         */
        export interface ThanosRulerSpecImagePullSecrets {
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
        }

        /**
         * A single application container that you want to run within a pod.
         */
        export interface ThanosRulerSpecInitContainers {
            /**
             * Arguments to the entrypoint. The docker image's CMD is used if this is not provided. Variable references $(VAR_NAME) are expanded using the container's environment. If a variable cannot be resolved, the reference in the input string will be unchanged. The $(VAR_NAME) syntax can be escaped with a double $$, ie: $$(VAR_NAME). Escaped references will never be expanded, regardless of whether the variable exists or not. Cannot be updated. More info: https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#running-a-command-in-a-shell
             */
            args?: string[];
            /**
             * Entrypoint array. Not executed within a shell. The docker image's ENTRYPOINT is used if this is not provided. Variable references $(VAR_NAME) are expanded using the container's environment. If a variable cannot be resolved, the reference in the input string will be unchanged. The $(VAR_NAME) syntax can be escaped with a double $$, ie: $$(VAR_NAME). Escaped references will never be expanded, regardless of whether the variable exists or not. Cannot be updated. More info: https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#running-a-command-in-a-shell
             */
            command?: string[];
            /**
             * List of environment variables to set in the container. Cannot be updated.
             */
            env?: outputs.monitoring.v1.ThanosRulerSpecInitContainersEnv[];
            /**
             * List of sources to populate environment variables in the container. The keys defined within a source must be a C_IDENTIFIER. All invalid keys will be reported as an event when the container is starting. When a key exists in multiple sources, the value associated with the last source will take precedence. Values defined by an Env with a duplicate key will take precedence. Cannot be updated.
             */
            envFrom?: outputs.monitoring.v1.ThanosRulerSpecInitContainersEnvFrom[];
            /**
             * Docker image name. More info: https://kubernetes.io/docs/concepts/containers/images This field is optional to allow higher level config management to default or override container images in workload controllers like Deployments and StatefulSets.
             */
            image?: string;
            /**
             * Image pull policy. One of Always, Never, IfNotPresent. Defaults to Always if :latest tag is specified, or IfNotPresent otherwise. Cannot be updated. More info: https://kubernetes.io/docs/concepts/containers/images#updating-images
             */
            imagePullPolicy?: string;
            /**
             * Actions that the management system should take in response to container lifecycle events. Cannot be updated.
             */
            lifecycle?: outputs.monitoring.v1.ThanosRulerSpecInitContainersLifecycle;
            /**
             * Periodic probe of container liveness. Container will be restarted if the probe fails. Cannot be updated. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
             */
            livenessProbe?: outputs.monitoring.v1.ThanosRulerSpecInitContainersLivenessProbe;
            /**
             * Name of the container specified as a DNS_LABEL. Each container in a pod must have a unique name (DNS_LABEL). Cannot be updated.
             */
            name: string;
            /**
             * List of ports to expose from the container. Exposing a port here gives the system additional information about the network connections a container uses, but is primarily informational. Not specifying a port here DOES NOT prevent that port from being exposed. Any port which is listening on the default "0.0.0.0" address inside a container will be accessible from the network. Cannot be updated.
             */
            ports?: outputs.monitoring.v1.ThanosRulerSpecInitContainersPorts[];
            /**
             * Periodic probe of container service readiness. Container will be removed from service endpoints if the probe fails. Cannot be updated. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
             */
            readinessProbe?: outputs.monitoring.v1.ThanosRulerSpecInitContainersReadinessProbe;
            /**
             * Compute Resources required by this container. Cannot be updated. More info: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
             */
            resources?: outputs.monitoring.v1.ThanosRulerSpecInitContainersResources;
            /**
             * Security options the pod should run with. More info: https://kubernetes.io/docs/concepts/policy/security-context/ More info: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/
             */
            securityContext?: outputs.monitoring.v1.ThanosRulerSpecInitContainersSecurityContext;
            /**
             * StartupProbe indicates that the Pod has successfully initialized. If specified, no other probes are executed until this completes successfully. If this probe fails, the Pod will be restarted, just as if the livenessProbe failed. This can be used to provide different probe parameters at the beginning of a Pod's lifecycle, when it might take a long time to load data or warm a cache, than during steady-state operation. This cannot be updated. This is a beta feature enabled by the StartupProbe feature flag. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
             */
            startupProbe?: outputs.monitoring.v1.ThanosRulerSpecInitContainersStartupProbe;
            /**
             * Whether this container should allocate a buffer for stdin in the container runtime. If this is not set, reads from stdin in the container will always result in EOF. Default is false.
             */
            stdin?: boolean;
            /**
             * Whether the container runtime should close the stdin channel after it has been opened by a single attach. When stdin is true the stdin stream will remain open across multiple attach sessions. If stdinOnce is set to true, stdin is opened on container start, is empty until the first client attaches to stdin, and then remains open and accepts data until the client disconnects, at which time stdin is closed and remains closed until the container is restarted. If this flag is false, a container processes that reads from stdin will never receive an EOF. Default is false
             */
            stdinOnce?: boolean;
            /**
             * Optional: Path at which the file to which the container's termination message will be written is mounted into the container's filesystem. Message written is intended to be brief final status, such as an assertion failure message. Will be truncated by the node if greater than 4096 bytes. The total message length across all containers will be limited to 12kb. Defaults to /dev/termination-log. Cannot be updated.
             */
            terminationMessagePath?: string;
            /**
             * Indicate how the termination message should be populated. File will use the contents of terminationMessagePath to populate the container status message on both success and failure. FallbackToLogsOnError will use the last chunk of container log output if the termination message file is empty and the container exited with an error. The log output is limited to 2048 bytes or 80 lines, whichever is smaller. Defaults to File. Cannot be updated.
             */
            terminationMessagePolicy?: string;
            /**
             * Whether this container should allocate a TTY for itself, also requires 'stdin' to be true. Default is false.
             */
            tty?: boolean;
            /**
             * volumeDevices is the list of block devices to be used by the container.
             */
            volumeDevices?: outputs.monitoring.v1.ThanosRulerSpecInitContainersVolumeDevices[];
            /**
             * Pod volumes to mount into the container's filesystem. Cannot be updated.
             */
            volumeMounts?: outputs.monitoring.v1.ThanosRulerSpecInitContainersVolumeMounts[];
            /**
             * Container's working directory. If not specified, the container runtime's default will be used, which might be configured in the container image. Cannot be updated.
             */
            workingDir?: string;
        }

        /**
         * EnvVar represents an environment variable present in a Container.
         */
        export interface ThanosRulerSpecInitContainersEnv {
            /**
             * Name of the environment variable. Must be a C_IDENTIFIER.
             */
            name: string;
            /**
             * Variable references $(VAR_NAME) are expanded using the previous defined environment variables in the container and any service environment variables. If a variable cannot be resolved, the reference in the input string will be unchanged. The $(VAR_NAME) syntax can be escaped with a double $$, ie: $$(VAR_NAME). Escaped references will never be expanded, regardless of whether the variable exists or not. Defaults to "".
             */
            value?: string;
            /**
             * Source for the environment variable's value. Cannot be used if value is not empty.
             */
            valueFrom?: outputs.monitoring.v1.ThanosRulerSpecInitContainersEnvValueFrom;
        }

        /**
         * EnvFromSource represents the source of a set of ConfigMaps
         */
        export interface ThanosRulerSpecInitContainersEnvFrom {
            /**
             * The ConfigMap to select from
             */
            configMapRef?: outputs.monitoring.v1.ThanosRulerSpecInitContainersEnvFromConfigMapRef;
            /**
             * An optional identifier to prepend to each key in the ConfigMap. Must be a C_IDENTIFIER.
             */
            prefix?: string;
            /**
             * The Secret to select from
             */
            secretRef?: outputs.monitoring.v1.ThanosRulerSpecInitContainersEnvFromSecretRef;
        }

        /**
         * The ConfigMap to select from
         */
        export interface ThanosRulerSpecInitContainersEnvFromConfigMapRef {
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the ConfigMap must be defined
             */
            optional?: boolean;
        }

        /**
         * The Secret to select from
         */
        export interface ThanosRulerSpecInitContainersEnvFromSecretRef {
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret must be defined
             */
            optional?: boolean;
        }

        /**
         * Source for the environment variable's value. Cannot be used if value is not empty.
         */
        export interface ThanosRulerSpecInitContainersEnvValueFrom {
            /**
             * Selects a key of a ConfigMap.
             */
            configMapKeyRef?: outputs.monitoring.v1.ThanosRulerSpecInitContainersEnvValueFromConfigMapKeyRef;
            /**
             * Selects a field of the pod: supports metadata.name, metadata.namespace, metadata.labels, metadata.annotations, spec.nodeName, spec.serviceAccountName, status.hostIP, status.podIP, status.podIPs.
             */
            fieldRef?: outputs.monitoring.v1.ThanosRulerSpecInitContainersEnvValueFromFieldRef;
            /**
             * Selects a resource of the container: only resources limits and requests (limits.cpu, limits.memory, limits.ephemeral-storage, requests.cpu, requests.memory and requests.ephemeral-storage) are currently supported.
             */
            resourceFieldRef?: outputs.monitoring.v1.ThanosRulerSpecInitContainersEnvValueFromResourceFieldRef;
            /**
             * Selects a key of a secret in the pod's namespace
             */
            secretKeyRef?: outputs.monitoring.v1.ThanosRulerSpecInitContainersEnvValueFromSecretKeyRef;
        }

        /**
         * Selects a key of a ConfigMap.
         */
        export interface ThanosRulerSpecInitContainersEnvValueFromConfigMapKeyRef {
            /**
             * The key to select.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the ConfigMap or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Selects a field of the pod: supports metadata.name, metadata.namespace, metadata.labels, metadata.annotations, spec.nodeName, spec.serviceAccountName, status.hostIP, status.podIP, status.podIPs.
         */
        export interface ThanosRulerSpecInitContainersEnvValueFromFieldRef {
            /**
             * Version of the schema the FieldPath is written in terms of, defaults to "v1".
             */
            apiVersion?: string;
            /**
             * Path of the field to select in the specified API version.
             */
            fieldPath: string;
        }

        /**
         * Selects a resource of the container: only resources limits and requests (limits.cpu, limits.memory, limits.ephemeral-storage, requests.cpu, requests.memory and requests.ephemeral-storage) are currently supported.
         */
        export interface ThanosRulerSpecInitContainersEnvValueFromResourceFieldRef {
            /**
             * Container name: required for volumes, optional for env vars
             */
            containerName?: string;
            /**
             * Specifies the output format of the exposed resources, defaults to "1"
             */
            divisor?: outputs.monitoring.v1.ThanosRulerSpecInitContainersEnvValueFromResourceFieldRefDivisor;
            /**
             * Required: resource to select
             */
            resource: string;
        }

        export interface ThanosRulerSpecInitContainersEnvValueFromResourceFieldRefDivisor {
        }

        /**
         * Selects a key of a secret in the pod's namespace
         */
        export interface ThanosRulerSpecInitContainersEnvValueFromSecretKeyRef {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Actions that the management system should take in response to container lifecycle events. Cannot be updated.
         */
        export interface ThanosRulerSpecInitContainersLifecycle {
            /**
             * PostStart is called immediately after a container is created. If the handler fails, the container is terminated and restarted according to its restart policy. Other management of the container blocks until the hook completes. More info: https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks/#container-hooks
             */
            postStart?: outputs.monitoring.v1.ThanosRulerSpecInitContainersLifecyclePostStart;
            /**
             * PreStop is called immediately before a container is terminated due to an API request or management event such as liveness/startup probe failure, preemption, resource contention, etc. The handler is not called if the container crashes or exits. The reason for termination is passed to the handler. The Pod's termination grace period countdown begins before the PreStop hooked is executed. Regardless of the outcome of the handler, the container will eventually terminate within the Pod's termination grace period. Other management of the container blocks until the hook completes or until the termination grace period is reached. More info: https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks/#container-hooks
             */
            preStop?: outputs.monitoring.v1.ThanosRulerSpecInitContainersLifecyclePreStop;
        }

        /**
         * PostStart is called immediately after a container is created. If the handler fails, the container is terminated and restarted according to its restart policy. Other management of the container blocks until the hook completes. More info: https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks/#container-hooks
         */
        export interface ThanosRulerSpecInitContainersLifecyclePostStart {
            /**
             * One and only one of the following should be specified. Exec specifies the action to take.
             */
            exec?: outputs.monitoring.v1.ThanosRulerSpecInitContainersLifecyclePostStartExec;
            /**
             * HTTPGet specifies the http request to perform.
             */
            httpGet?: outputs.monitoring.v1.ThanosRulerSpecInitContainersLifecyclePostStartHttpGet;
            /**
             * TCPSocket specifies an action involving a TCP port. TCP hooks not yet supported TODO: implement a realistic TCP lifecycle hook
             */
            tcpSocket?: outputs.monitoring.v1.ThanosRulerSpecInitContainersLifecyclePostStartTcpSocket;
        }

        /**
         * One and only one of the following should be specified. Exec specifies the action to take.
         */
        export interface ThanosRulerSpecInitContainersLifecyclePostStartExec {
            /**
             * Command is the command line to execute inside the container, the working directory for the command  is root ('/') in the container's filesystem. The command is simply exec'd, it is not run inside a shell, so traditional shell instructions ('|', etc) won't work. To use a shell, you need to explicitly call out to that shell. Exit status of 0 is treated as live/healthy and non-zero is unhealthy.
             */
            command?: string[];
        }

        /**
         * HTTPGet specifies the http request to perform.
         */
        export interface ThanosRulerSpecInitContainersLifecyclePostStartHttpGet {
            /**
             * Host name to connect to, defaults to the pod IP. You probably want to set "Host" in httpHeaders instead.
             */
            host?: string;
            /**
             * Custom headers to set in the request. HTTP allows repeated headers.
             */
            httpHeaders?: outputs.monitoring.v1.ThanosRulerSpecInitContainersLifecyclePostStartHttpGetHttpHeaders[];
            /**
             * Path to access on the HTTP server.
             */
            path?: string;
            /**
             * Name or number of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME.
             */
            port: outputs.monitoring.v1.ThanosRulerSpecInitContainersLifecyclePostStartHttpGetPort;
            /**
             * Scheme to use for connecting to the host. Defaults to HTTP.
             */
            scheme?: string;
        }

        /**
         * HTTPHeader describes a custom header to be used in HTTP probes
         */
        export interface ThanosRulerSpecInitContainersLifecyclePostStartHttpGetHttpHeaders {
            /**
             * The header field name
             */
            name: string;
            /**
             * The header field value
             */
            value: string;
        }

        export interface ThanosRulerSpecInitContainersLifecyclePostStartHttpGetPort {
        }

        /**
         * TCPSocket specifies an action involving a TCP port. TCP hooks not yet supported TODO: implement a realistic TCP lifecycle hook
         */
        export interface ThanosRulerSpecInitContainersLifecyclePostStartTcpSocket {
            /**
             * Optional: Host name to connect to, defaults to the pod IP.
             */
            host?: string;
            /**
             * Number or name of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME.
             */
            port: outputs.monitoring.v1.ThanosRulerSpecInitContainersLifecyclePostStartTcpSocketPort;
        }

        export interface ThanosRulerSpecInitContainersLifecyclePostStartTcpSocketPort {
        }

        /**
         * PreStop is called immediately before a container is terminated due to an API request or management event such as liveness/startup probe failure, preemption, resource contention, etc. The handler is not called if the container crashes or exits. The reason for termination is passed to the handler. The Pod's termination grace period countdown begins before the PreStop hooked is executed. Regardless of the outcome of the handler, the container will eventually terminate within the Pod's termination grace period. Other management of the container blocks until the hook completes or until the termination grace period is reached. More info: https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks/#container-hooks
         */
        export interface ThanosRulerSpecInitContainersLifecyclePreStop {
            /**
             * One and only one of the following should be specified. Exec specifies the action to take.
             */
            exec?: outputs.monitoring.v1.ThanosRulerSpecInitContainersLifecyclePreStopExec;
            /**
             * HTTPGet specifies the http request to perform.
             */
            httpGet?: outputs.monitoring.v1.ThanosRulerSpecInitContainersLifecyclePreStopHttpGet;
            /**
             * TCPSocket specifies an action involving a TCP port. TCP hooks not yet supported TODO: implement a realistic TCP lifecycle hook
             */
            tcpSocket?: outputs.monitoring.v1.ThanosRulerSpecInitContainersLifecyclePreStopTcpSocket;
        }

        /**
         * One and only one of the following should be specified. Exec specifies the action to take.
         */
        export interface ThanosRulerSpecInitContainersLifecyclePreStopExec {
            /**
             * Command is the command line to execute inside the container, the working directory for the command  is root ('/') in the container's filesystem. The command is simply exec'd, it is not run inside a shell, so traditional shell instructions ('|', etc) won't work. To use a shell, you need to explicitly call out to that shell. Exit status of 0 is treated as live/healthy and non-zero is unhealthy.
             */
            command?: string[];
        }

        /**
         * HTTPGet specifies the http request to perform.
         */
        export interface ThanosRulerSpecInitContainersLifecyclePreStopHttpGet {
            /**
             * Host name to connect to, defaults to the pod IP. You probably want to set "Host" in httpHeaders instead.
             */
            host?: string;
            /**
             * Custom headers to set in the request. HTTP allows repeated headers.
             */
            httpHeaders?: outputs.monitoring.v1.ThanosRulerSpecInitContainersLifecyclePreStopHttpGetHttpHeaders[];
            /**
             * Path to access on the HTTP server.
             */
            path?: string;
            /**
             * Name or number of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME.
             */
            port: outputs.monitoring.v1.ThanosRulerSpecInitContainersLifecyclePreStopHttpGetPort;
            /**
             * Scheme to use for connecting to the host. Defaults to HTTP.
             */
            scheme?: string;
        }

        /**
         * HTTPHeader describes a custom header to be used in HTTP probes
         */
        export interface ThanosRulerSpecInitContainersLifecyclePreStopHttpGetHttpHeaders {
            /**
             * The header field name
             */
            name: string;
            /**
             * The header field value
             */
            value: string;
        }

        export interface ThanosRulerSpecInitContainersLifecyclePreStopHttpGetPort {
        }

        /**
         * TCPSocket specifies an action involving a TCP port. TCP hooks not yet supported TODO: implement a realistic TCP lifecycle hook
         */
        export interface ThanosRulerSpecInitContainersLifecyclePreStopTcpSocket {
            /**
             * Optional: Host name to connect to, defaults to the pod IP.
             */
            host?: string;
            /**
             * Number or name of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME.
             */
            port: outputs.monitoring.v1.ThanosRulerSpecInitContainersLifecyclePreStopTcpSocketPort;
        }

        export interface ThanosRulerSpecInitContainersLifecyclePreStopTcpSocketPort {
        }

        /**
         * Periodic probe of container liveness. Container will be restarted if the probe fails. Cannot be updated. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
         */
        export interface ThanosRulerSpecInitContainersLivenessProbe {
            /**
             * One and only one of the following should be specified. Exec specifies the action to take.
             */
            exec?: outputs.monitoring.v1.ThanosRulerSpecInitContainersLivenessProbeExec;
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * HTTPGet specifies the http request to perform.
             */
            httpGet?: outputs.monitoring.v1.ThanosRulerSpecInitContainersLivenessProbeHttpGet;
            /**
             * Number of seconds after the container has started before liveness probes are initiated. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness and startup. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * TCPSocket specifies an action involving a TCP port. TCP hooks not yet supported TODO: implement a realistic TCP lifecycle hook
             */
            tcpSocket?: outputs.monitoring.v1.ThanosRulerSpecInitContainersLivenessProbeTcpSocket;
            /**
             * Number of seconds after which the probe times out. Defaults to 1 second. Minimum value is 1. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
             */
            timeoutSeconds?: number;
        }

        /**
         * One and only one of the following should be specified. Exec specifies the action to take.
         */
        export interface ThanosRulerSpecInitContainersLivenessProbeExec {
            /**
             * Command is the command line to execute inside the container, the working directory for the command  is root ('/') in the container's filesystem. The command is simply exec'd, it is not run inside a shell, so traditional shell instructions ('|', etc) won't work. To use a shell, you need to explicitly call out to that shell. Exit status of 0 is treated as live/healthy and non-zero is unhealthy.
             */
            command?: string[];
        }

        /**
         * HTTPGet specifies the http request to perform.
         */
        export interface ThanosRulerSpecInitContainersLivenessProbeHttpGet {
            /**
             * Host name to connect to, defaults to the pod IP. You probably want to set "Host" in httpHeaders instead.
             */
            host?: string;
            /**
             * Custom headers to set in the request. HTTP allows repeated headers.
             */
            httpHeaders?: outputs.monitoring.v1.ThanosRulerSpecInitContainersLivenessProbeHttpGetHttpHeaders[];
            /**
             * Path to access on the HTTP server.
             */
            path?: string;
            /**
             * Name or number of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME.
             */
            port: outputs.monitoring.v1.ThanosRulerSpecInitContainersLivenessProbeHttpGetPort;
            /**
             * Scheme to use for connecting to the host. Defaults to HTTP.
             */
            scheme?: string;
        }

        /**
         * HTTPHeader describes a custom header to be used in HTTP probes
         */
        export interface ThanosRulerSpecInitContainersLivenessProbeHttpGetHttpHeaders {
            /**
             * The header field name
             */
            name: string;
            /**
             * The header field value
             */
            value: string;
        }

        export interface ThanosRulerSpecInitContainersLivenessProbeHttpGetPort {
        }

        /**
         * TCPSocket specifies an action involving a TCP port. TCP hooks not yet supported TODO: implement a realistic TCP lifecycle hook
         */
        export interface ThanosRulerSpecInitContainersLivenessProbeTcpSocket {
            /**
             * Optional: Host name to connect to, defaults to the pod IP.
             */
            host?: string;
            /**
             * Number or name of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME.
             */
            port: outputs.monitoring.v1.ThanosRulerSpecInitContainersLivenessProbeTcpSocketPort;
        }

        export interface ThanosRulerSpecInitContainersLivenessProbeTcpSocketPort {
        }

        /**
         * ContainerPort represents a network port in a single container.
         */
        export interface ThanosRulerSpecInitContainersPorts {
            /**
             * Number of port to expose on the pod's IP address. This must be a valid port number, 0 < x < 65536.
             */
            containerPort: number;
            /**
             * What host IP to bind the external port to.
             */
            hostIP?: string;
            /**
             * Number of port to expose on the host. If specified, this must be a valid port number, 0 < x < 65536. If HostNetwork is specified, this must match ContainerPort. Most containers do not need this.
             */
            hostPort?: number;
            /**
             * If specified, this must be an IANA_SVC_NAME and unique within the pod. Each named port in a pod must have a unique name. Name for the port that can be referred to by services.
             */
            name?: string;
            /**
             * Protocol for port. Must be UDP, TCP, or SCTP. Defaults to "TCP".
             */
            protocol?: string;
        }

        /**
         * Periodic probe of container service readiness. Container will be removed from service endpoints if the probe fails. Cannot be updated. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
         */
        export interface ThanosRulerSpecInitContainersReadinessProbe {
            /**
             * One and only one of the following should be specified. Exec specifies the action to take.
             */
            exec?: outputs.monitoring.v1.ThanosRulerSpecInitContainersReadinessProbeExec;
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * HTTPGet specifies the http request to perform.
             */
            httpGet?: outputs.monitoring.v1.ThanosRulerSpecInitContainersReadinessProbeHttpGet;
            /**
             * Number of seconds after the container has started before liveness probes are initiated. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness and startup. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * TCPSocket specifies an action involving a TCP port. TCP hooks not yet supported TODO: implement a realistic TCP lifecycle hook
             */
            tcpSocket?: outputs.monitoring.v1.ThanosRulerSpecInitContainersReadinessProbeTcpSocket;
            /**
             * Number of seconds after which the probe times out. Defaults to 1 second. Minimum value is 1. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
             */
            timeoutSeconds?: number;
        }

        /**
         * One and only one of the following should be specified. Exec specifies the action to take.
         */
        export interface ThanosRulerSpecInitContainersReadinessProbeExec {
            /**
             * Command is the command line to execute inside the container, the working directory for the command  is root ('/') in the container's filesystem. The command is simply exec'd, it is not run inside a shell, so traditional shell instructions ('|', etc) won't work. To use a shell, you need to explicitly call out to that shell. Exit status of 0 is treated as live/healthy and non-zero is unhealthy.
             */
            command?: string[];
        }

        /**
         * HTTPGet specifies the http request to perform.
         */
        export interface ThanosRulerSpecInitContainersReadinessProbeHttpGet {
            /**
             * Host name to connect to, defaults to the pod IP. You probably want to set "Host" in httpHeaders instead.
             */
            host?: string;
            /**
             * Custom headers to set in the request. HTTP allows repeated headers.
             */
            httpHeaders?: outputs.monitoring.v1.ThanosRulerSpecInitContainersReadinessProbeHttpGetHttpHeaders[];
            /**
             * Path to access on the HTTP server.
             */
            path?: string;
            /**
             * Name or number of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME.
             */
            port: outputs.monitoring.v1.ThanosRulerSpecInitContainersReadinessProbeHttpGetPort;
            /**
             * Scheme to use for connecting to the host. Defaults to HTTP.
             */
            scheme?: string;
        }

        /**
         * HTTPHeader describes a custom header to be used in HTTP probes
         */
        export interface ThanosRulerSpecInitContainersReadinessProbeHttpGetHttpHeaders {
            /**
             * The header field name
             */
            name: string;
            /**
             * The header field value
             */
            value: string;
        }

        export interface ThanosRulerSpecInitContainersReadinessProbeHttpGetPort {
        }

        /**
         * TCPSocket specifies an action involving a TCP port. TCP hooks not yet supported TODO: implement a realistic TCP lifecycle hook
         */
        export interface ThanosRulerSpecInitContainersReadinessProbeTcpSocket {
            /**
             * Optional: Host name to connect to, defaults to the pod IP.
             */
            host?: string;
            /**
             * Number or name of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME.
             */
            port: outputs.monitoring.v1.ThanosRulerSpecInitContainersReadinessProbeTcpSocketPort;
        }

        export interface ThanosRulerSpecInitContainersReadinessProbeTcpSocketPort {
        }

        /**
         * Compute Resources required by this container. Cannot be updated. More info: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
         */
        export interface ThanosRulerSpecInitContainersResources {
            /**
             * Limits describes the maximum amount of compute resources allowed. More info: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
             */
            limits?: {[key: string]: outputs.monitoring.v1.ThanosRulerSpecInitContainersResourcesLimits};
            /**
             * Requests describes the minimum amount of compute resources required. If Requests is omitted for a container, it defaults to Limits if that is explicitly specified, otherwise to an implementation-defined value. More info: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
             */
            requests?: {[key: string]: outputs.monitoring.v1.ThanosRulerSpecInitContainersResourcesRequests};
        }

        export interface ThanosRulerSpecInitContainersResourcesLimits {
        }

        export interface ThanosRulerSpecInitContainersResourcesRequests {
        }

        /**
         * Security options the pod should run with. More info: https://kubernetes.io/docs/concepts/policy/security-context/ More info: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/
         */
        export interface ThanosRulerSpecInitContainersSecurityContext {
            /**
             * AllowPrivilegeEscalation controls whether a process can gain more privileges than its parent process. This bool directly controls if the no_new_privs flag will be set on the container process. AllowPrivilegeEscalation is true always when the container is: 1) run as Privileged 2) has CAP_SYS_ADMIN
             */
            allowPrivilegeEscalation?: boolean;
            /**
             * The capabilities to add/drop when running containers. Defaults to the default set of capabilities granted by the container runtime.
             */
            capabilities?: outputs.monitoring.v1.ThanosRulerSpecInitContainersSecurityContextCapabilities;
            /**
             * Run container in privileged mode. Processes in privileged containers are essentially equivalent to root on the host. Defaults to false.
             */
            privileged?: boolean;
            /**
             * procMount denotes the type of proc mount to use for the containers. The default is DefaultProcMount which uses the container runtime defaults for readonly paths and masked paths. This requires the ProcMountType feature flag to be enabled.
             */
            procMount?: string;
            /**
             * Whether this container has a read-only root filesystem. Default is false.
             */
            readOnlyRootFilesystem?: boolean;
            /**
             * The GID to run the entrypoint of the container process. Uses runtime default if unset. May also be set in PodSecurityContext.  If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.
             */
            runAsGroup?: number;
            /**
             * Indicates that the container must run as a non-root user. If true, the Kubelet will validate the image at runtime to ensure that it does not run as UID 0 (root) and fail to start the container if it does. If unset or false, no such validation will be performed. May also be set in PodSecurityContext.  If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.
             */
            runAsNonRoot?: boolean;
            /**
             * The UID to run the entrypoint of the container process. Defaults to user specified in image metadata if unspecified. May also be set in PodSecurityContext.  If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.
             */
            runAsUser?: number;
            /**
             * The SELinux context to be applied to the container. If unspecified, the container runtime will allocate a random SELinux context for each container.  May also be set in PodSecurityContext.  If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.
             */
            seLinuxOptions?: outputs.monitoring.v1.ThanosRulerSpecInitContainersSecurityContextSeLinuxOptions;
            /**
             * The Windows specific settings applied to all containers. If unspecified, the options from the PodSecurityContext will be used. If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.
             */
            windowsOptions?: outputs.monitoring.v1.ThanosRulerSpecInitContainersSecurityContextWindowsOptions;
        }

        /**
         * The capabilities to add/drop when running containers. Defaults to the default set of capabilities granted by the container runtime.
         */
        export interface ThanosRulerSpecInitContainersSecurityContextCapabilities {
            /**
             * Added capabilities
             */
            add?: string[];
            /**
             * Removed capabilities
             */
            drop?: string[];
        }

        /**
         * The SELinux context to be applied to the container. If unspecified, the container runtime will allocate a random SELinux context for each container.  May also be set in PodSecurityContext.  If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.
         */
        export interface ThanosRulerSpecInitContainersSecurityContextSeLinuxOptions {
            /**
             * Level is SELinux level label that applies to the container.
             */
            level?: string;
            /**
             * Role is a SELinux role label that applies to the container.
             */
            role?: string;
            /**
             * Type is a SELinux type label that applies to the container.
             */
            type?: string;
            /**
             * User is a SELinux user label that applies to the container.
             */
            user?: string;
        }

        /**
         * The Windows specific settings applied to all containers. If unspecified, the options from the PodSecurityContext will be used. If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.
         */
        export interface ThanosRulerSpecInitContainersSecurityContextWindowsOptions {
            /**
             * GMSACredentialSpec is where the GMSA admission webhook (https://github.com/kubernetes-sigs/windows-gmsa) inlines the contents of the GMSA credential spec named by the GMSACredentialSpecName field.
             */
            gmsaCredentialSpec?: string;
            /**
             * GMSACredentialSpecName is the name of the GMSA credential spec to use.
             */
            gmsaCredentialSpecName?: string;
            /**
             * The UserName in Windows to run the entrypoint of the container process. Defaults to the user specified in image metadata if unspecified. May also be set in PodSecurityContext. If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.
             */
            runAsUserName?: string;
        }

        /**
         * StartupProbe indicates that the Pod has successfully initialized. If specified, no other probes are executed until this completes successfully. If this probe fails, the Pod will be restarted, just as if the livenessProbe failed. This can be used to provide different probe parameters at the beginning of a Pod's lifecycle, when it might take a long time to load data or warm a cache, than during steady-state operation. This cannot be updated. This is a beta feature enabled by the StartupProbe feature flag. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
         */
        export interface ThanosRulerSpecInitContainersStartupProbe {
            /**
             * One and only one of the following should be specified. Exec specifies the action to take.
             */
            exec?: outputs.monitoring.v1.ThanosRulerSpecInitContainersStartupProbeExec;
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * HTTPGet specifies the http request to perform.
             */
            httpGet?: outputs.monitoring.v1.ThanosRulerSpecInitContainersStartupProbeHttpGet;
            /**
             * Number of seconds after the container has started before liveness probes are initiated. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness and startup. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * TCPSocket specifies an action involving a TCP port. TCP hooks not yet supported TODO: implement a realistic TCP lifecycle hook
             */
            tcpSocket?: outputs.monitoring.v1.ThanosRulerSpecInitContainersStartupProbeTcpSocket;
            /**
             * Number of seconds after which the probe times out. Defaults to 1 second. Minimum value is 1. More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
             */
            timeoutSeconds?: number;
        }

        /**
         * One and only one of the following should be specified. Exec specifies the action to take.
         */
        export interface ThanosRulerSpecInitContainersStartupProbeExec {
            /**
             * Command is the command line to execute inside the container, the working directory for the command  is root ('/') in the container's filesystem. The command is simply exec'd, it is not run inside a shell, so traditional shell instructions ('|', etc) won't work. To use a shell, you need to explicitly call out to that shell. Exit status of 0 is treated as live/healthy and non-zero is unhealthy.
             */
            command?: string[];
        }

        /**
         * HTTPGet specifies the http request to perform.
         */
        export interface ThanosRulerSpecInitContainersStartupProbeHttpGet {
            /**
             * Host name to connect to, defaults to the pod IP. You probably want to set "Host" in httpHeaders instead.
             */
            host?: string;
            /**
             * Custom headers to set in the request. HTTP allows repeated headers.
             */
            httpHeaders?: outputs.monitoring.v1.ThanosRulerSpecInitContainersStartupProbeHttpGetHttpHeaders[];
            /**
             * Path to access on the HTTP server.
             */
            path?: string;
            /**
             * Name or number of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME.
             */
            port: outputs.monitoring.v1.ThanosRulerSpecInitContainersStartupProbeHttpGetPort;
            /**
             * Scheme to use for connecting to the host. Defaults to HTTP.
             */
            scheme?: string;
        }

        /**
         * HTTPHeader describes a custom header to be used in HTTP probes
         */
        export interface ThanosRulerSpecInitContainersStartupProbeHttpGetHttpHeaders {
            /**
             * The header field name
             */
            name: string;
            /**
             * The header field value
             */
            value: string;
        }

        export interface ThanosRulerSpecInitContainersStartupProbeHttpGetPort {
        }

        /**
         * TCPSocket specifies an action involving a TCP port. TCP hooks not yet supported TODO: implement a realistic TCP lifecycle hook
         */
        export interface ThanosRulerSpecInitContainersStartupProbeTcpSocket {
            /**
             * Optional: Host name to connect to, defaults to the pod IP.
             */
            host?: string;
            /**
             * Number or name of the port to access on the container. Number must be in the range 1 to 65535. Name must be an IANA_SVC_NAME.
             */
            port: outputs.monitoring.v1.ThanosRulerSpecInitContainersStartupProbeTcpSocketPort;
        }

        export interface ThanosRulerSpecInitContainersStartupProbeTcpSocketPort {
        }

        /**
         * volumeDevice describes a mapping of a raw block device within a container.
         */
        export interface ThanosRulerSpecInitContainersVolumeDevices {
            /**
             * devicePath is the path inside of the container that the device will be mapped to.
             */
            devicePath: string;
            /**
             * name must match the name of a persistentVolumeClaim in the pod
             */
            name: string;
        }

        /**
         * VolumeMount describes a mounting of a Volume within a container.
         */
        export interface ThanosRulerSpecInitContainersVolumeMounts {
            /**
             * Path within the container at which the volume should be mounted.  Must not contain ':'.
             */
            mountPath: string;
            /**
             * mountPropagation determines how mounts are propagated from the host to container and the other way around. When not set, MountPropagationNone is used. This field is beta in 1.10.
             */
            mountPropagation?: string;
            /**
             * This must match the Name of a Volume.
             */
            name: string;
            /**
             * Mounted read-only if true, read-write otherwise (false or unspecified). Defaults to false.
             */
            readOnly?: boolean;
            /**
             * Path within the volume from which the container's volume should be mounted. Defaults to "" (volume's root).
             */
            subPath?: string;
            /**
             * Expanded path within the volume from which the container's volume should be mounted. Behaves similarly to SubPath but environment variable references $(VAR_NAME) are expanded using the container's environment. Defaults to "" (volume's root). SubPathExpr and SubPath are mutually exclusive.
             */
            subPathExpr?: string;
        }

        /**
         * ObjectStorageConfig configures object storage in Thanos. Alternative to ObjectStorageConfigFile, and lower order priority.
         */
        export interface ThanosRulerSpecObjectStorageConfig {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * PodMetadata contains Labels and Annotations gets propagated to the thanos ruler pods.
         */
        export interface ThanosRulerSpecPodMetadata {
            /**
             * Annotations is an unstructured key value map stored with a resource that may be set by external tools to store and retrieve arbitrary metadata. They are not queryable and should be preserved when modifying objects. More info: http://kubernetes.io/docs/user-guide/annotations
             */
            annotations?: {[key: string]: string};
            /**
             * Map of string keys and values that can be used to organize and categorize (scope and select) objects. May match selectors of replication controllers and services. More info: http://kubernetes.io/docs/user-guide/labels
             */
            labels?: {[key: string]: string};
            /**
             * Name must be unique within a namespace. Is required when creating resources, although some resources may allow a client to request the generation of an appropriate name automatically. Name is primarily intended for creation idempotence and configuration definition. Cannot be updated. More info: http://kubernetes.io/docs/user-guide/identifiers#names
             */
            name?: string;
        }

        /**
         * PrometheusRuleExcludeConfig enables users to configure excluded PrometheusRule names and their namespaces to be ignored while enforcing namespace label for alerts and metrics.
         */
        export interface ThanosRulerSpecPrometheusRulesExcludedFromEnforce {
            /**
             * RuleNamespace - name of excluded rule
             */
            ruleName: string;
            /**
             * RuleNamespace - namespace of excluded rule
             */
            ruleNamespace: string;
        }

        /**
         * Define configuration for connecting to thanos query instances. If this is defined, the QueryEndpoints field will be ignored. Maps to the `query.config` CLI argument. Only available with thanos v0.11.0 and higher.
         */
        export interface ThanosRulerSpecQueryConfig {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Resources defines the resource requirements for single Pods. If not provided, no requests/limits will be set
         */
        export interface ThanosRulerSpecResources {
            /**
             * Limits describes the maximum amount of compute resources allowed. More info: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
             */
            limits?: {[key: string]: outputs.monitoring.v1.ThanosRulerSpecResourcesLimits};
            /**
             * Requests describes the minimum amount of compute resources required. If Requests is omitted for a container, it defaults to Limits if that is explicitly specified, otherwise to an implementation-defined value. More info: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
             */
            requests?: {[key: string]: outputs.monitoring.v1.ThanosRulerSpecResourcesRequests};
        }

        export interface ThanosRulerSpecResourcesLimits {
        }

        export interface ThanosRulerSpecResourcesRequests {
        }

        /**
         * Namespaces to be selected for Rules discovery. If unspecified, only the same namespace as the ThanosRuler object is in is used.
         */
        export interface ThanosRulerSpecRuleNamespaceSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.monitoring.v1.ThanosRulerSpecRuleNamespaceSelectorMatchExpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ThanosRulerSpecRuleNamespaceSelectorMatchExpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * A label selector to select which PrometheusRules to mount for alerting and recording.
         */
        export interface ThanosRulerSpecRuleSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.monitoring.v1.ThanosRulerSpecRuleSelectorMatchExpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ThanosRulerSpecRuleSelectorMatchExpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * SecurityContext holds pod-level security attributes and common container settings. This defaults to the default PodSecurityContext.
         */
        export interface ThanosRulerSpecSecurityContext {
            /**
             * A special supplemental group that applies to all containers in a pod. Some volume types allow the Kubelet to change the ownership of that volume to be owned by the pod: 
             *  1. The owning GID will be the FSGroup 2. The setgid bit is set (new files created in the volume will be owned by FSGroup) 3. The permission bits are OR'd with rw-rw---- 
             *  If unset, the Kubelet will not modify the ownership and permissions of any volume.
             */
            fsGroup?: number;
            /**
             * fsGroupChangePolicy defines behavior of changing ownership and permission of the volume before being exposed inside Pod. This field will only apply to volume types which support fsGroup based ownership(and permissions). It will have no effect on ephemeral volume types such as: secret, configmaps and emptydir. Valid values are "OnRootMismatch" and "Always". If not specified defaults to "Always".
             */
            fsGroupChangePolicy?: string;
            /**
             * The GID to run the entrypoint of the container process. Uses runtime default if unset. May also be set in SecurityContext.  If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence for that container.
             */
            runAsGroup?: number;
            /**
             * Indicates that the container must run as a non-root user. If true, the Kubelet will validate the image at runtime to ensure that it does not run as UID 0 (root) and fail to start the container if it does. If unset or false, no such validation will be performed. May also be set in SecurityContext.  If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.
             */
            runAsNonRoot?: boolean;
            /**
             * The UID to run the entrypoint of the container process. Defaults to user specified in image metadata if unspecified. May also be set in SecurityContext.  If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence for that container.
             */
            runAsUser?: number;
            /**
             * The SELinux context to be applied to all containers. If unspecified, the container runtime will allocate a random SELinux context for each container.  May also be set in SecurityContext.  If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence for that container.
             */
            seLinuxOptions?: outputs.monitoring.v1.ThanosRulerSpecSecurityContextSeLinuxOptions;
            /**
             * A list of groups applied to the first process run in each container, in addition to the container's primary GID.  If unspecified, no groups will be added to any container.
             */
            supplementalGroups?: number[];
            /**
             * Sysctls hold a list of namespaced sysctls used for the pod. Pods with unsupported sysctls (by the container runtime) might fail to launch.
             */
            sysctls?: outputs.monitoring.v1.ThanosRulerSpecSecurityContextSysctls[];
            /**
             * The Windows specific settings applied to all containers. If unspecified, the options within a container's SecurityContext will be used. If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.
             */
            windowsOptions?: outputs.monitoring.v1.ThanosRulerSpecSecurityContextWindowsOptions;
        }

        /**
         * The SELinux context to be applied to all containers. If unspecified, the container runtime will allocate a random SELinux context for each container.  May also be set in SecurityContext.  If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence for that container.
         */
        export interface ThanosRulerSpecSecurityContextSeLinuxOptions {
            /**
             * Level is SELinux level label that applies to the container.
             */
            level?: string;
            /**
             * Role is a SELinux role label that applies to the container.
             */
            role?: string;
            /**
             * Type is a SELinux type label that applies to the container.
             */
            type?: string;
            /**
             * User is a SELinux user label that applies to the container.
             */
            user?: string;
        }

        /**
         * Sysctl defines a kernel parameter to be set
         */
        export interface ThanosRulerSpecSecurityContextSysctls {
            /**
             * Name of a property to set
             */
            name: string;
            /**
             * Value of a property to set
             */
            value: string;
        }

        /**
         * The Windows specific settings applied to all containers. If unspecified, the options within a container's SecurityContext will be used. If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.
         */
        export interface ThanosRulerSpecSecurityContextWindowsOptions {
            /**
             * GMSACredentialSpec is where the GMSA admission webhook (https://github.com/kubernetes-sigs/windows-gmsa) inlines the contents of the GMSA credential spec named by the GMSACredentialSpecName field.
             */
            gmsaCredentialSpec?: string;
            /**
             * GMSACredentialSpecName is the name of the GMSA credential spec to use.
             */
            gmsaCredentialSpecName?: string;
            /**
             * The UserName in Windows to run the entrypoint of the container process. Defaults to the user specified in image metadata if unspecified. May also be set in PodSecurityContext. If set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.
             */
            runAsUserName?: string;
        }

        /**
         * Storage spec to specify how storage shall be used.
         */
        export interface ThanosRulerSpecStorage {
            /**
             * Deprecated: subPath usage will be disabled by default in a future release, this option will become unnecessary. DisableMountSubPath allows to remove any subPath usage in volume mounts.
             */
            disableMountSubPath?: boolean;
            /**
             * EmptyDirVolumeSource to be used by the Prometheus StatefulSets. If specified, used in place of any volumeClaimTemplate. More info: https://kubernetes.io/docs/concepts/storage/volumes/#emptydir
             */
            emptyDir?: outputs.monitoring.v1.ThanosRulerSpecStorageEmptyDir;
            /**
             * A PVC spec to be used by the Prometheus StatefulSets.
             */
            volumeClaimTemplate?: outputs.monitoring.v1.ThanosRulerSpecStorageVolumeClaimTemplate;
        }

        /**
         * EmptyDirVolumeSource to be used by the Prometheus StatefulSets. If specified, used in place of any volumeClaimTemplate. More info: https://kubernetes.io/docs/concepts/storage/volumes/#emptydir
         */
        export interface ThanosRulerSpecStorageEmptyDir {
            /**
             * What type of storage medium should back this directory. The default is "" which means to use the node's default medium. Must be an empty string (default) or Memory. More info: https://kubernetes.io/docs/concepts/storage/volumes#emptydir
             */
            medium?: string;
            /**
             * Total amount of local storage required for this EmptyDir volume. The size limit is also applicable for memory medium. The maximum usage on memory medium EmptyDir would be the minimum value between the SizeLimit specified here and the sum of memory limits of all containers in a pod. The default is nil which means that the limit is undefined. More info: http://kubernetes.io/docs/user-guide/volumes#emptydir
             */
            sizeLimit?: outputs.monitoring.v1.ThanosRulerSpecStorageEmptyDirSizeLimit;
        }

        export interface ThanosRulerSpecStorageEmptyDirSizeLimit {
        }

        /**
         * A PVC spec to be used by the Prometheus StatefulSets.
         */
        export interface ThanosRulerSpecStorageVolumeClaimTemplate {
            /**
             * APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources
             */
            apiVersion?: string;
            /**
             * Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
             */
            kind?: string;
            /**
             * EmbeddedMetadata contains metadata relevant to an EmbeddedResource.
             */
            metadata?: outputs.monitoring.v1.ThanosRulerSpecStorageVolumeClaimTemplateMetadata;
            /**
             * Spec defines the desired characteristics of a volume requested by a pod author. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#persistentvolumeclaims
             */
            spec?: outputs.monitoring.v1.ThanosRulerSpecStorageVolumeClaimTemplateSpec;
            /**
             * Status represents the current information/status of a persistent volume claim. Read-only. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#persistentvolumeclaims
             */
            status?: outputs.monitoring.v1.ThanosRulerSpecStorageVolumeClaimTemplateStatus;
        }

        /**
         * EmbeddedMetadata contains metadata relevant to an EmbeddedResource.
         */
        export interface ThanosRulerSpecStorageVolumeClaimTemplateMetadata {
            /**
             * Annotations is an unstructured key value map stored with a resource that may be set by external tools to store and retrieve arbitrary metadata. They are not queryable and should be preserved when modifying objects. More info: http://kubernetes.io/docs/user-guide/annotations
             */
            annotations?: {[key: string]: string};
            /**
             * Map of string keys and values that can be used to organize and categorize (scope and select) objects. May match selectors of replication controllers and services. More info: http://kubernetes.io/docs/user-guide/labels
             */
            labels?: {[key: string]: string};
            /**
             * Name must be unique within a namespace. Is required when creating resources, although some resources may allow a client to request the generation of an appropriate name automatically. Name is primarily intended for creation idempotence and configuration definition. Cannot be updated. More info: http://kubernetes.io/docs/user-guide/identifiers#names
             */
            name?: string;
        }

        /**
         * Spec defines the desired characteristics of a volume requested by a pod author. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#persistentvolumeclaims
         */
        export interface ThanosRulerSpecStorageVolumeClaimTemplateSpec {
            /**
             * AccessModes contains the desired access modes the volume should have. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#access-modes-1
             */
            accessModes?: string[];
            /**
             * This field can be used to specify either: * An existing VolumeSnapshot object (snapshot.storage.k8s.io/VolumeSnapshot - Beta) * An existing PVC (PersistentVolumeClaim) * An existing custom resource/object that implements data population (Alpha) In order to use VolumeSnapshot object types, the appropriate feature gate must be enabled (VolumeSnapshotDataSource or AnyVolumeDataSource) If the provisioner or an external controller can support the specified data source, it will create a new volume based on the contents of the specified data source. If the specified data source is not supported, the volume will not be created and the failure will be reported as an event. In the future, we plan to support more data source types and the behavior of the provisioner may change.
             */
            dataSource?: outputs.monitoring.v1.ThanosRulerSpecStorageVolumeClaimTemplateSpecDataSource;
            /**
             * Resources represents the minimum resources the volume should have. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#resources
             */
            resources?: outputs.monitoring.v1.ThanosRulerSpecStorageVolumeClaimTemplateSpecResources;
            /**
             * A label query over volumes to consider for binding.
             */
            selector?: outputs.monitoring.v1.ThanosRulerSpecStorageVolumeClaimTemplateSpecSelector;
            /**
             * Name of the StorageClass required by the claim. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#class-1
             */
            storageClassName?: string;
            /**
             * volumeMode defines what type of volume is required by the claim. Value of Filesystem is implied when not included in claim spec.
             */
            volumeMode?: string;
            /**
             * VolumeName is the binding reference to the PersistentVolume backing this claim.
             */
            volumeName?: string;
        }

        /**
         * This field can be used to specify either: * An existing VolumeSnapshot object (snapshot.storage.k8s.io/VolumeSnapshot - Beta) * An existing PVC (PersistentVolumeClaim) * An existing custom resource/object that implements data population (Alpha) In order to use VolumeSnapshot object types, the appropriate feature gate must be enabled (VolumeSnapshotDataSource or AnyVolumeDataSource) If the provisioner or an external controller can support the specified data source, it will create a new volume based on the contents of the specified data source. If the specified data source is not supported, the volume will not be created and the failure will be reported as an event. In the future, we plan to support more data source types and the behavior of the provisioner may change.
         */
        export interface ThanosRulerSpecStorageVolumeClaimTemplateSpecDataSource {
            /**
             * APIGroup is the group for the resource being referenced. If APIGroup is not specified, the specified Kind must be in the core API group. For any other third-party types, APIGroup is required.
             */
            apiGroup?: string;
            /**
             * Kind is the type of resource being referenced
             */
            kind: string;
            /**
             * Name is the name of resource being referenced
             */
            name: string;
        }

        /**
         * Resources represents the minimum resources the volume should have. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#resources
         */
        export interface ThanosRulerSpecStorageVolumeClaimTemplateSpecResources {
            /**
             * Limits describes the maximum amount of compute resources allowed. More info: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
             */
            limits?: {[key: string]: outputs.monitoring.v1.ThanosRulerSpecStorageVolumeClaimTemplateSpecResourcesLimits};
            /**
             * Requests describes the minimum amount of compute resources required. If Requests is omitted for a container, it defaults to Limits if that is explicitly specified, otherwise to an implementation-defined value. More info: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
             */
            requests?: {[key: string]: outputs.monitoring.v1.ThanosRulerSpecStorageVolumeClaimTemplateSpecResourcesRequests};
        }

        export interface ThanosRulerSpecStorageVolumeClaimTemplateSpecResourcesLimits {
        }

        export interface ThanosRulerSpecStorageVolumeClaimTemplateSpecResourcesRequests {
        }

        /**
         * A label query over volumes to consider for binding.
         */
        export interface ThanosRulerSpecStorageVolumeClaimTemplateSpecSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.monitoring.v1.ThanosRulerSpecStorageVolumeClaimTemplateSpecSelectorMatchExpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ThanosRulerSpecStorageVolumeClaimTemplateSpecSelectorMatchExpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * Status represents the current information/status of a persistent volume claim. Read-only. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#persistentvolumeclaims
         */
        export interface ThanosRulerSpecStorageVolumeClaimTemplateStatus {
            /**
             * AccessModes contains the actual access modes the volume backing the PVC has. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#access-modes-1
             */
            accessModes?: string[];
            /**
             * Represents the actual resources of the underlying volume.
             */
            capacity?: {[key: string]: outputs.monitoring.v1.ThanosRulerSpecStorageVolumeClaimTemplateStatusCapacity};
            /**
             * Current Condition of persistent volume claim. If underlying persistent volume is being resized then the Condition will be set to 'ResizeStarted'.
             */
            conditions?: outputs.monitoring.v1.ThanosRulerSpecStorageVolumeClaimTemplateStatusConditions[];
            /**
             * Phase represents the current phase of PersistentVolumeClaim.
             */
            phase?: string;
        }

        export interface ThanosRulerSpecStorageVolumeClaimTemplateStatusCapacity {
        }

        /**
         * PersistentVolumeClaimCondition contails details about state of pvc
         */
        export interface ThanosRulerSpecStorageVolumeClaimTemplateStatusConditions {
            /**
             * Last time we probed the condition.
             */
            lastProbeTime?: string;
            /**
             * Last time the condition transitioned from one status to another.
             */
            lastTransitionTime?: string;
            /**
             * Human-readable message indicating details about last transition.
             */
            message?: string;
            /**
             * Unique, this should be a short, machine understandable string that gives the reason for condition's last transition. If it reports "ResizeStarted" that means the underlying persistent volume is being resized.
             */
            reason?: string;
            status: string;
            /**
             * PersistentVolumeClaimConditionType is a valid value of PersistentVolumeClaimCondition.Type
             */
            type: string;
        }

        /**
         * The pod this Toleration is attached to tolerates any taint that matches the triple <key,value,effect> using the matching operator <operator>.
         */
        export interface ThanosRulerSpecTolerations {
            /**
             * Effect indicates the taint effect to match. Empty means match all taint effects. When specified, allowed values are NoSchedule, PreferNoSchedule and NoExecute.
             */
            effect?: string;
            /**
             * Key is the taint key that the toleration applies to. Empty means match all taint keys. If the key is empty, operator must be Exists; this combination means to match all values and all keys.
             */
            key?: string;
            /**
             * Operator represents a key's relationship to the value. Valid operators are Exists and Equal. Defaults to Equal. Exists is equivalent to wildcard for value, so that a pod can tolerate all taints of a particular category.
             */
            operator?: string;
            /**
             * TolerationSeconds represents the period of time the toleration (which must be of effect NoExecute, otherwise this field is ignored) tolerates the taint. By default, it is not set, which means tolerate the taint forever (do not evict). Zero and negative values will be treated as 0 (evict immediately) by the system.
             */
            tolerationSeconds?: number;
            /**
             * Value is the taint value the toleration matches to. If the operator is Exists, the value should be empty, otherwise just a regular string.
             */
            value?: string;
        }

        /**
         * TopologySpreadConstraint specifies how to spread matching pods among the given topology.
         */
        export interface ThanosRulerSpecTopologySpreadConstraints {
            /**
             * LabelSelector is used to find matching pods. Pods that match this label selector are counted to determine the number of pods in their corresponding topology domain.
             */
            labelSelector?: outputs.monitoring.v1.ThanosRulerSpecTopologySpreadConstraintsLabelSelector;
            /**
             * MaxSkew describes the degree to which pods may be unevenly distributed. It's the maximum permitted difference between the number of matching pods in any two topology domains of a given topology type. For example, in a 3-zone cluster, MaxSkew is set to 1, and pods with the same labelSelector spread as 1/1/0: | zone1 | zone2 | zone3 | |   P   |   P   |       | - if MaxSkew is 1, incoming pod can only be scheduled to zone3 to become 1/1/1; scheduling it onto zone1(zone2) would make the ActualSkew(2-0) on zone1(zone2) violate MaxSkew(1). - if MaxSkew is 2, incoming pod can be scheduled onto any zone. It's a required field. Default value is 1 and 0 is not allowed.
             */
            maxSkew: number;
            /**
             * TopologyKey is the key of node labels. Nodes that have a label with this key and identical values are considered to be in the same topology. We consider each <key, value> as a "bucket", and try to put balanced number of pods into each bucket. It's a required field.
             */
            topologyKey: string;
            /**
             * WhenUnsatisfiable indicates how to deal with a pod if it doesn't satisfy the spread constraint. - DoNotSchedule (default) tells the scheduler not to schedule it - ScheduleAnyway tells the scheduler to still schedule it It's considered as "Unsatisfiable" if and only if placing incoming pod on any topology violates "MaxSkew". For example, in a 3-zone cluster, MaxSkew is set to 1, and pods with the same labelSelector spread as 3/1/1: | zone1 | zone2 | zone3 | | P P P |   P   |   P   | If WhenUnsatisfiable is set to DoNotSchedule, incoming pod can only be scheduled to zone2(zone3) to become 3/2/1(3/1/2) as ActualSkew(2-1) on zone2(zone3) satisfies MaxSkew(1). In other words, the cluster can still be imbalanced, but scheduler won't make it *more* imbalanced. It's a required field.
             */
            whenUnsatisfiable: string;
        }

        /**
         * LabelSelector is used to find matching pods. Pods that match this label selector are counted to determine the number of pods in their corresponding topology domain.
         */
        export interface ThanosRulerSpecTopologySpreadConstraintsLabelSelector {
            /**
             * matchExpressions is a list of label selector requirements. The requirements are ANDed.
             */
            matchExpressions?: outputs.monitoring.v1.ThanosRulerSpecTopologySpreadConstraintsLabelSelectorMatchExpressions[];
            /**
             * matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.
             */
            matchLabels?: {[key: string]: string};
        }

        /**
         * A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
         */
        export interface ThanosRulerSpecTopologySpreadConstraintsLabelSelectorMatchExpressions {
            /**
             * key is the label key that the selector applies to.
             */
            key: string;
            /**
             * operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.
             */
            operator: string;
            /**
             * values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.
             */
            values?: string[];
        }

        /**
         * TracingConfig configures tracing in Thanos. This is an experimental feature, it may change in any upcoming release in a breaking way.
         */
        export interface ThanosRulerSpecTracingConfig {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Volume represents a named volume in a pod that may be accessed by any container in the pod.
         */
        export interface ThanosRulerSpecVolumes {
            /**
             * AWSElasticBlockStore represents an AWS Disk resource that is attached to a kubelet's host machine and then exposed to the pod. More info: https://kubernetes.io/docs/concepts/storage/volumes#awselasticblockstore
             */
            awsElasticBlockStore?: outputs.monitoring.v1.ThanosRulerSpecVolumesAwsElasticBlockStore;
            /**
             * AzureDisk represents an Azure Data Disk mount on the host and bind mount to the pod.
             */
            azureDisk?: outputs.monitoring.v1.ThanosRulerSpecVolumesAzureDisk;
            /**
             * AzureFile represents an Azure File Service mount on the host and bind mount to the pod.
             */
            azureFile?: outputs.monitoring.v1.ThanosRulerSpecVolumesAzureFile;
            /**
             * CephFS represents a Ceph FS mount on the host that shares a pod's lifetime
             */
            cephfs?: outputs.monitoring.v1.ThanosRulerSpecVolumesCephfs;
            /**
             * Cinder represents a cinder volume attached and mounted on kubelets host machine. More info: https://examples.k8s.io/mysql-cinder-pd/README.md
             */
            cinder?: outputs.monitoring.v1.ThanosRulerSpecVolumesCinder;
            /**
             * ConfigMap represents a configMap that should populate this volume
             */
            configMap?: outputs.monitoring.v1.ThanosRulerSpecVolumesConfigMap;
            /**
             * CSI (Container Storage Interface) represents storage that is handled by an external CSI driver (Alpha feature).
             */
            csi?: outputs.monitoring.v1.ThanosRulerSpecVolumesCsi;
            /**
             * DownwardAPI represents downward API about the pod that should populate this volume
             */
            downwardAPI?: outputs.monitoring.v1.ThanosRulerSpecVolumesDownwardAPI;
            /**
             * EmptyDir represents a temporary directory that shares a pod's lifetime. More info: https://kubernetes.io/docs/concepts/storage/volumes#emptydir
             */
            emptyDir?: outputs.monitoring.v1.ThanosRulerSpecVolumesEmptyDir;
            /**
             * FC represents a Fibre Channel resource that is attached to a kubelet's host machine and then exposed to the pod.
             */
            fc?: outputs.monitoring.v1.ThanosRulerSpecVolumesFc;
            /**
             * FlexVolume represents a generic volume resource that is provisioned/attached using an exec based plugin.
             */
            flexVolume?: outputs.monitoring.v1.ThanosRulerSpecVolumesFlexVolume;
            /**
             * Flocker represents a Flocker volume attached to a kubelet's host machine. This depends on the Flocker control service being running
             */
            flocker?: outputs.monitoring.v1.ThanosRulerSpecVolumesFlocker;
            /**
             * GCEPersistentDisk represents a GCE Disk resource that is attached to a kubelet's host machine and then exposed to the pod. More info: https://kubernetes.io/docs/concepts/storage/volumes#gcepersistentdisk
             */
            gcePersistentDisk?: outputs.monitoring.v1.ThanosRulerSpecVolumesGcePersistentDisk;
            /**
             * GitRepo represents a git repository at a particular revision. DEPRECATED: GitRepo is deprecated. To provision a container with a git repo, mount an EmptyDir into an InitContainer that clones the repo using git, then mount the EmptyDir into the Pod's container.
             */
            gitRepo?: outputs.monitoring.v1.ThanosRulerSpecVolumesGitRepo;
            /**
             * Glusterfs represents a Glusterfs mount on the host that shares a pod's lifetime. More info: https://examples.k8s.io/volumes/glusterfs/README.md
             */
            glusterfs?: outputs.monitoring.v1.ThanosRulerSpecVolumesGlusterfs;
            /**
             * HostPath represents a pre-existing file or directory on the host machine that is directly exposed to the container. This is generally used for system agents or other privileged things that are allowed to see the host machine. Most containers will NOT need this. More info: https://kubernetes.io/docs/concepts/storage/volumes#hostpath --- TODO(jonesdl) We need to restrict who can use host directory mounts and who can/can not mount host directories as read/write.
             */
            hostPath?: outputs.monitoring.v1.ThanosRulerSpecVolumesHostPath;
            /**
             * ISCSI represents an ISCSI Disk resource that is attached to a kubelet's host machine and then exposed to the pod. More info: https://examples.k8s.io/volumes/iscsi/README.md
             */
            iscsi?: outputs.monitoring.v1.ThanosRulerSpecVolumesIscsi;
            /**
             * Volume's name. Must be a DNS_LABEL and unique within the pod. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
             */
            name: string;
            /**
             * NFS represents an NFS mount on the host that shares a pod's lifetime More info: https://kubernetes.io/docs/concepts/storage/volumes#nfs
             */
            nfs?: outputs.monitoring.v1.ThanosRulerSpecVolumesNfs;
            /**
             * PersistentVolumeClaimVolumeSource represents a reference to a PersistentVolumeClaim in the same namespace. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#persistentvolumeclaims
             */
            persistentVolumeClaim?: outputs.monitoring.v1.ThanosRulerSpecVolumesPersistentVolumeClaim;
            /**
             * PhotonPersistentDisk represents a PhotonController persistent disk attached and mounted on kubelets host machine
             */
            photonPersistentDisk?: outputs.monitoring.v1.ThanosRulerSpecVolumesPhotonPersistentDisk;
            /**
             * PortworxVolume represents a portworx volume attached and mounted on kubelets host machine
             */
            portworxVolume?: outputs.monitoring.v1.ThanosRulerSpecVolumesPortworxVolume;
            /**
             * Items for all in one resources secrets, configmaps, and downward API
             */
            projected?: outputs.monitoring.v1.ThanosRulerSpecVolumesProjected;
            /**
             * Quobyte represents a Quobyte mount on the host that shares a pod's lifetime
             */
            quobyte?: outputs.monitoring.v1.ThanosRulerSpecVolumesQuobyte;
            /**
             * RBD represents a Rados Block Device mount on the host that shares a pod's lifetime. More info: https://examples.k8s.io/volumes/rbd/README.md
             */
            rbd?: outputs.monitoring.v1.ThanosRulerSpecVolumesRbd;
            /**
             * ScaleIO represents a ScaleIO persistent volume attached and mounted on Kubernetes nodes.
             */
            scaleIO?: outputs.monitoring.v1.ThanosRulerSpecVolumesScaleIO;
            /**
             * Secret represents a secret that should populate this volume. More info: https://kubernetes.io/docs/concepts/storage/volumes#secret
             */
            secret?: outputs.monitoring.v1.ThanosRulerSpecVolumesSecret;
            /**
             * StorageOS represents a StorageOS volume attached and mounted on Kubernetes nodes.
             */
            storageos?: outputs.monitoring.v1.ThanosRulerSpecVolumesStorageos;
            /**
             * VsphereVolume represents a vSphere volume attached and mounted on kubelets host machine
             */
            vsphereVolume?: outputs.monitoring.v1.ThanosRulerSpecVolumesVsphereVolume;
        }

        /**
         * AWSElasticBlockStore represents an AWS Disk resource that is attached to a kubelet's host machine and then exposed to the pod. More info: https://kubernetes.io/docs/concepts/storage/volumes#awselasticblockstore
         */
        export interface ThanosRulerSpecVolumesAwsElasticBlockStore {
            /**
             * Filesystem type of the volume that you want to mount. Tip: Ensure that the filesystem type is supported by the host operating system. Examples: "ext4", "xfs", "ntfs". Implicitly inferred to be "ext4" if unspecified. More info: https://kubernetes.io/docs/concepts/storage/volumes#awselasticblockstore TODO: how do we prevent errors in the filesystem from compromising the machine
             */
            fsType?: string;
            /**
             * The partition in the volume that you want to mount. If omitted, the default is to mount by volume name. Examples: For volume /dev/sda1, you specify the partition as "1". Similarly, the volume partition for /dev/sda is "0" (or you can leave the property empty).
             */
            partition?: number;
            /**
             * Specify "true" to force and set the ReadOnly property in VolumeMounts to "true". If omitted, the default is "false". More info: https://kubernetes.io/docs/concepts/storage/volumes#awselasticblockstore
             */
            readOnly?: boolean;
            /**
             * Unique ID of the persistent disk resource in AWS (Amazon EBS volume). More info: https://kubernetes.io/docs/concepts/storage/volumes#awselasticblockstore
             */
            volumeID: string;
        }

        /**
         * AzureDisk represents an Azure Data Disk mount on the host and bind mount to the pod.
         */
        export interface ThanosRulerSpecVolumesAzureDisk {
            /**
             * Host Caching mode: None, Read Only, Read Write.
             */
            cachingMode?: string;
            /**
             * The Name of the data disk in the blob storage
             */
            diskName: string;
            /**
             * The URI the data disk in the blob storage
             */
            diskURI: string;
            /**
             * Filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. "ext4", "xfs", "ntfs". Implicitly inferred to be "ext4" if unspecified.
             */
            fsType?: string;
            /**
             * Expected values Shared: multiple blob disks per storage account  Dedicated: single blob disk per storage account  Managed: azure managed data disk (only in managed availability set). defaults to shared
             */
            kind?: string;
            /**
             * Defaults to false (read/write). ReadOnly here will force the ReadOnly setting in VolumeMounts.
             */
            readOnly?: boolean;
        }

        /**
         * AzureFile represents an Azure File Service mount on the host and bind mount to the pod.
         */
        export interface ThanosRulerSpecVolumesAzureFile {
            /**
             * Defaults to false (read/write). ReadOnly here will force the ReadOnly setting in VolumeMounts.
             */
            readOnly?: boolean;
            /**
             * the name of secret that contains Azure Storage Account Name and Key
             */
            secretName: string;
            /**
             * Share Name
             */
            shareName: string;
        }

        /**
         * CephFS represents a Ceph FS mount on the host that shares a pod's lifetime
         */
        export interface ThanosRulerSpecVolumesCephfs {
            /**
             * Required: Monitors is a collection of Ceph monitors More info: https://examples.k8s.io/volumes/cephfs/README.md#how-to-use-it
             */
            monitors: string[];
            /**
             * Optional: Used as the mounted root, rather than the full Ceph tree, default is /
             */
            path?: string;
            /**
             * Optional: Defaults to false (read/write). ReadOnly here will force the ReadOnly setting in VolumeMounts. More info: https://examples.k8s.io/volumes/cephfs/README.md#how-to-use-it
             */
            readOnly?: boolean;
            /**
             * Optional: SecretFile is the path to key ring for User, default is /etc/ceph/user.secret More info: https://examples.k8s.io/volumes/cephfs/README.md#how-to-use-it
             */
            secretFile?: string;
            /**
             * Optional: SecretRef is reference to the authentication secret for User, default is empty. More info: https://examples.k8s.io/volumes/cephfs/README.md#how-to-use-it
             */
            secretRef?: outputs.monitoring.v1.ThanosRulerSpecVolumesCephfsSecretRef;
            /**
             * Optional: User is the rados user name, default is admin More info: https://examples.k8s.io/volumes/cephfs/README.md#how-to-use-it
             */
            user?: string;
        }

        /**
         * Optional: SecretRef is reference to the authentication secret for User, default is empty. More info: https://examples.k8s.io/volumes/cephfs/README.md#how-to-use-it
         */
        export interface ThanosRulerSpecVolumesCephfsSecretRef {
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
        }

        /**
         * Cinder represents a cinder volume attached and mounted on kubelets host machine. More info: https://examples.k8s.io/mysql-cinder-pd/README.md
         */
        export interface ThanosRulerSpecVolumesCinder {
            /**
             * Filesystem type to mount. Must be a filesystem type supported by the host operating system. Examples: "ext4", "xfs", "ntfs". Implicitly inferred to be "ext4" if unspecified. More info: https://examples.k8s.io/mysql-cinder-pd/README.md
             */
            fsType?: string;
            /**
             * Optional: Defaults to false (read/write). ReadOnly here will force the ReadOnly setting in VolumeMounts. More info: https://examples.k8s.io/mysql-cinder-pd/README.md
             */
            readOnly?: boolean;
            /**
             * Optional: points to a secret object containing parameters used to connect to OpenStack.
             */
            secretRef?: outputs.monitoring.v1.ThanosRulerSpecVolumesCinderSecretRef;
            /**
             * volume id used to identify the volume in cinder. More info: https://examples.k8s.io/mysql-cinder-pd/README.md
             */
            volumeID: string;
        }

        /**
         * Optional: points to a secret object containing parameters used to connect to OpenStack.
         */
        export interface ThanosRulerSpecVolumesCinderSecretRef {
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
        }

        /**
         * ConfigMap represents a configMap that should populate this volume
         */
        export interface ThanosRulerSpecVolumesConfigMap {
            /**
             * Optional: mode bits to use on created files by default. Must be a value between 0 and 0777. Defaults to 0644. Directories within the path are not affected by this setting. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set.
             */
            defaultMode?: number;
            /**
             * If unspecified, each key-value pair in the Data field of the referenced ConfigMap will be projected into the volume as a file whose name is the key and content is the value. If specified, the listed keys will be projected into the specified paths, and unlisted keys will not be present. If a key is specified which is not present in the ConfigMap, the volume setup will error unless it is marked optional. Paths must be relative and may not contain the '..' path or start with '..'.
             */
            items?: outputs.monitoring.v1.ThanosRulerSpecVolumesConfigMapItems[];
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the ConfigMap or its keys must be defined
             */
            optional?: boolean;
        }

        /**
         * Maps a string key to a path within a volume.
         */
        export interface ThanosRulerSpecVolumesConfigMapItems {
            /**
             * The key to project.
             */
            key: string;
            /**
             * Optional: mode bits to use on this file, must be a value between 0 and 0777. If not specified, the volume defaultMode will be used. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set.
             */
            mode?: number;
            /**
             * The relative path of the file to map the key to. May not be an absolute path. May not contain the path element '..'. May not start with the string '..'.
             */
            path: string;
        }

        /**
         * CSI (Container Storage Interface) represents storage that is handled by an external CSI driver (Alpha feature).
         */
        export interface ThanosRulerSpecVolumesCsi {
            /**
             * Driver is the name of the CSI driver that handles this volume. Consult with your admin for the correct name as registered in the cluster.
             */
            driver: string;
            /**
             * Filesystem type to mount. Ex. "ext4", "xfs", "ntfs". If not provided, the empty value is passed to the associated CSI driver which will determine the default filesystem to apply.
             */
            fsType?: string;
            /**
             * NodePublishSecretRef is a reference to the secret object containing sensitive information to pass to the CSI driver to complete the CSI NodePublishVolume and NodeUnpublishVolume calls. This field is optional, and  may be empty if no secret is required. If the secret object contains more than one secret, all secret references are passed.
             */
            nodePublishSecretRef?: outputs.monitoring.v1.ThanosRulerSpecVolumesCsiNodePublishSecretRef;
            /**
             * Specifies a read-only configuration for the volume. Defaults to false (read/write).
             */
            readOnly?: boolean;
            /**
             * VolumeAttributes stores driver-specific properties that are passed to the CSI driver. Consult your driver's documentation for supported values.
             */
            volumeAttributes?: {[key: string]: string};
        }

        /**
         * NodePublishSecretRef is a reference to the secret object containing sensitive information to pass to the CSI driver to complete the CSI NodePublishVolume and NodeUnpublishVolume calls. This field is optional, and  may be empty if no secret is required. If the secret object contains more than one secret, all secret references are passed.
         */
        export interface ThanosRulerSpecVolumesCsiNodePublishSecretRef {
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
        }

        /**
         * DownwardAPI represents downward API about the pod that should populate this volume
         */
        export interface ThanosRulerSpecVolumesDownwardAPI {
            /**
             * Optional: mode bits to use on created files by default. Must be a value between 0 and 0777. Defaults to 0644. Directories within the path are not affected by this setting. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set.
             */
            defaultMode?: number;
            /**
             * Items is a list of downward API volume file
             */
            items?: outputs.monitoring.v1.ThanosRulerSpecVolumesDownwardAPIItems[];
        }

        /**
         * DownwardAPIVolumeFile represents information to create the file containing the pod field
         */
        export interface ThanosRulerSpecVolumesDownwardAPIItems {
            /**
             * Required: Selects a field of the pod: only annotations, labels, name and namespace are supported.
             */
            fieldRef?: outputs.monitoring.v1.ThanosRulerSpecVolumesDownwardAPIItemsFieldRef;
            /**
             * Optional: mode bits to use on this file, must be a value between 0 and 0777. If not specified, the volume defaultMode will be used. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set.
             */
            mode?: number;
            /**
             * Required: Path is  the relative path name of the file to be created. Must not be absolute or contain the '..' path. Must be utf-8 encoded. The first item of the relative path must not start with '..'
             */
            path: string;
            /**
             * Selects a resource of the container: only resources limits and requests (limits.cpu, limits.memory, requests.cpu and requests.memory) are currently supported.
             */
            resourceFieldRef?: outputs.monitoring.v1.ThanosRulerSpecVolumesDownwardAPIItemsResourceFieldRef;
        }

        /**
         * Required: Selects a field of the pod: only annotations, labels, name and namespace are supported.
         */
        export interface ThanosRulerSpecVolumesDownwardAPIItemsFieldRef {
            /**
             * Version of the schema the FieldPath is written in terms of, defaults to "v1".
             */
            apiVersion?: string;
            /**
             * Path of the field to select in the specified API version.
             */
            fieldPath: string;
        }

        /**
         * Selects a resource of the container: only resources limits and requests (limits.cpu, limits.memory, requests.cpu and requests.memory) are currently supported.
         */
        export interface ThanosRulerSpecVolumesDownwardAPIItemsResourceFieldRef {
            /**
             * Container name: required for volumes, optional for env vars
             */
            containerName?: string;
            /**
             * Specifies the output format of the exposed resources, defaults to "1"
             */
            divisor?: outputs.monitoring.v1.ThanosRulerSpecVolumesDownwardAPIItemsResourceFieldRefDivisor;
            /**
             * Required: resource to select
             */
            resource: string;
        }

        export interface ThanosRulerSpecVolumesDownwardAPIItemsResourceFieldRefDivisor {
        }

        /**
         * EmptyDir represents a temporary directory that shares a pod's lifetime. More info: https://kubernetes.io/docs/concepts/storage/volumes#emptydir
         */
        export interface ThanosRulerSpecVolumesEmptyDir {
            /**
             * What type of storage medium should back this directory. The default is "" which means to use the node's default medium. Must be an empty string (default) or Memory. More info: https://kubernetes.io/docs/concepts/storage/volumes#emptydir
             */
            medium?: string;
            /**
             * Total amount of local storage required for this EmptyDir volume. The size limit is also applicable for memory medium. The maximum usage on memory medium EmptyDir would be the minimum value between the SizeLimit specified here and the sum of memory limits of all containers in a pod. The default is nil which means that the limit is undefined. More info: http://kubernetes.io/docs/user-guide/volumes#emptydir
             */
            sizeLimit?: outputs.monitoring.v1.ThanosRulerSpecVolumesEmptyDirSizeLimit;
        }

        export interface ThanosRulerSpecVolumesEmptyDirSizeLimit {
        }

        /**
         * FC represents a Fibre Channel resource that is attached to a kubelet's host machine and then exposed to the pod.
         */
        export interface ThanosRulerSpecVolumesFc {
            /**
             * Filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. "ext4", "xfs", "ntfs". Implicitly inferred to be "ext4" if unspecified. TODO: how do we prevent errors in the filesystem from compromising the machine
             */
            fsType?: string;
            /**
             * Optional: FC target lun number
             */
            lun?: number;
            /**
             * Optional: Defaults to false (read/write). ReadOnly here will force the ReadOnly setting in VolumeMounts.
             */
            readOnly?: boolean;
            /**
             * Optional: FC target worldwide names (WWNs)
             */
            targetWWNs?: string[];
            /**
             * Optional: FC volume world wide identifiers (wwids) Either wwids or combination of targetWWNs and lun must be set, but not both simultaneously.
             */
            wwids?: string[];
        }

        /**
         * FlexVolume represents a generic volume resource that is provisioned/attached using an exec based plugin.
         */
        export interface ThanosRulerSpecVolumesFlexVolume {
            /**
             * Driver is the name of the driver to use for this volume.
             */
            driver: string;
            /**
             * Filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. "ext4", "xfs", "ntfs". The default filesystem depends on FlexVolume script.
             */
            fsType?: string;
            /**
             * Optional: Extra command options if any.
             */
            options?: {[key: string]: string};
            /**
             * Optional: Defaults to false (read/write). ReadOnly here will force the ReadOnly setting in VolumeMounts.
             */
            readOnly?: boolean;
            /**
             * Optional: SecretRef is reference to the secret object containing sensitive information to pass to the plugin scripts. This may be empty if no secret object is specified. If the secret object contains more than one secret, all secrets are passed to the plugin scripts.
             */
            secretRef?: outputs.monitoring.v1.ThanosRulerSpecVolumesFlexVolumeSecretRef;
        }

        /**
         * Optional: SecretRef is reference to the secret object containing sensitive information to pass to the plugin scripts. This may be empty if no secret object is specified. If the secret object contains more than one secret, all secrets are passed to the plugin scripts.
         */
        export interface ThanosRulerSpecVolumesFlexVolumeSecretRef {
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
        }

        /**
         * Flocker represents a Flocker volume attached to a kubelet's host machine. This depends on the Flocker control service being running
         */
        export interface ThanosRulerSpecVolumesFlocker {
            /**
             * Name of the dataset stored as metadata -> name on the dataset for Flocker should be considered as deprecated
             */
            datasetName?: string;
            /**
             * UUID of the dataset. This is unique identifier of a Flocker dataset
             */
            datasetUUID?: string;
        }

        /**
         * GCEPersistentDisk represents a GCE Disk resource that is attached to a kubelet's host machine and then exposed to the pod. More info: https://kubernetes.io/docs/concepts/storage/volumes#gcepersistentdisk
         */
        export interface ThanosRulerSpecVolumesGcePersistentDisk {
            /**
             * Filesystem type of the volume that you want to mount. Tip: Ensure that the filesystem type is supported by the host operating system. Examples: "ext4", "xfs", "ntfs". Implicitly inferred to be "ext4" if unspecified. More info: https://kubernetes.io/docs/concepts/storage/volumes#gcepersistentdisk TODO: how do we prevent errors in the filesystem from compromising the machine
             */
            fsType?: string;
            /**
             * The partition in the volume that you want to mount. If omitted, the default is to mount by volume name. Examples: For volume /dev/sda1, you specify the partition as "1". Similarly, the volume partition for /dev/sda is "0" (or you can leave the property empty). More info: https://kubernetes.io/docs/concepts/storage/volumes#gcepersistentdisk
             */
            partition?: number;
            /**
             * Unique name of the PD resource in GCE. Used to identify the disk in GCE. More info: https://kubernetes.io/docs/concepts/storage/volumes#gcepersistentdisk
             */
            pdName: string;
            /**
             * ReadOnly here will force the ReadOnly setting in VolumeMounts. Defaults to false. More info: https://kubernetes.io/docs/concepts/storage/volumes#gcepersistentdisk
             */
            readOnly?: boolean;
        }

        /**
         * GitRepo represents a git repository at a particular revision. DEPRECATED: GitRepo is deprecated. To provision a container with a git repo, mount an EmptyDir into an InitContainer that clones the repo using git, then mount the EmptyDir into the Pod's container.
         */
        export interface ThanosRulerSpecVolumesGitRepo {
            /**
             * Target directory name. Must not contain or start with '..'.  If '.' is supplied, the volume directory will be the git repository.  Otherwise, if specified, the volume will contain the git repository in the subdirectory with the given name.
             */
            directory?: string;
            /**
             * Repository URL
             */
            repository: string;
            /**
             * Commit hash for the specified revision.
             */
            revision?: string;
        }

        /**
         * Glusterfs represents a Glusterfs mount on the host that shares a pod's lifetime. More info: https://examples.k8s.io/volumes/glusterfs/README.md
         */
        export interface ThanosRulerSpecVolumesGlusterfs {
            /**
             * EndpointsName is the endpoint name that details Glusterfs topology. More info: https://examples.k8s.io/volumes/glusterfs/README.md#create-a-pod
             */
            endpoints: string;
            /**
             * Path is the Glusterfs volume path. More info: https://examples.k8s.io/volumes/glusterfs/README.md#create-a-pod
             */
            path: string;
            /**
             * ReadOnly here will force the Glusterfs volume to be mounted with read-only permissions. Defaults to false. More info: https://examples.k8s.io/volumes/glusterfs/README.md#create-a-pod
             */
            readOnly?: boolean;
        }

        /**
         * HostPath represents a pre-existing file or directory on the host machine that is directly exposed to the container. This is generally used for system agents or other privileged things that are allowed to see the host machine. Most containers will NOT need this. More info: https://kubernetes.io/docs/concepts/storage/volumes#hostpath --- TODO(jonesdl) We need to restrict who can use host directory mounts and who can/can not mount host directories as read/write.
         */
        export interface ThanosRulerSpecVolumesHostPath {
            /**
             * Path of the directory on the host. If the path is a symlink, it will follow the link to the real path. More info: https://kubernetes.io/docs/concepts/storage/volumes#hostpath
             */
            path: string;
            /**
             * Type for HostPath Volume Defaults to "" More info: https://kubernetes.io/docs/concepts/storage/volumes#hostpath
             */
            type?: string;
        }

        /**
         * ISCSI represents an ISCSI Disk resource that is attached to a kubelet's host machine and then exposed to the pod. More info: https://examples.k8s.io/volumes/iscsi/README.md
         */
        export interface ThanosRulerSpecVolumesIscsi {
            /**
             * whether support iSCSI Discovery CHAP authentication
             */
            chapAuthDiscovery?: boolean;
            /**
             * whether support iSCSI Session CHAP authentication
             */
            chapAuthSession?: boolean;
            /**
             * Filesystem type of the volume that you want to mount. Tip: Ensure that the filesystem type is supported by the host operating system. Examples: "ext4", "xfs", "ntfs". Implicitly inferred to be "ext4" if unspecified. More info: https://kubernetes.io/docs/concepts/storage/volumes#iscsi TODO: how do we prevent errors in the filesystem from compromising the machine
             */
            fsType?: string;
            /**
             * Custom iSCSI Initiator Name. If initiatorName is specified with iscsiInterface simultaneously, new iSCSI interface <target portal>:<volume name> will be created for the connection.
             */
            initiatorName?: string;
            /**
             * Target iSCSI Qualified Name.
             */
            iqn: string;
            /**
             * iSCSI Interface Name that uses an iSCSI transport. Defaults to 'default' (tcp).
             */
            iscsiInterface?: string;
            /**
             * iSCSI Target Lun number.
             */
            lun: number;
            /**
             * iSCSI Target Portal List. The portal is either an IP or ip_addr:port if the port is other than default (typically TCP ports 860 and 3260).
             */
            portals?: string[];
            /**
             * ReadOnly here will force the ReadOnly setting in VolumeMounts. Defaults to false.
             */
            readOnly?: boolean;
            /**
             * CHAP Secret for iSCSI target and initiator authentication
             */
            secretRef?: outputs.monitoring.v1.ThanosRulerSpecVolumesIscsiSecretRef;
            /**
             * iSCSI Target Portal. The Portal is either an IP or ip_addr:port if the port is other than default (typically TCP ports 860 and 3260).
             */
            targetPortal: string;
        }

        /**
         * CHAP Secret for iSCSI target and initiator authentication
         */
        export interface ThanosRulerSpecVolumesIscsiSecretRef {
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
        }

        /**
         * NFS represents an NFS mount on the host that shares a pod's lifetime More info: https://kubernetes.io/docs/concepts/storage/volumes#nfs
         */
        export interface ThanosRulerSpecVolumesNfs {
            /**
             * Path that is exported by the NFS server. More info: https://kubernetes.io/docs/concepts/storage/volumes#nfs
             */
            path: string;
            /**
             * ReadOnly here will force the NFS export to be mounted with read-only permissions. Defaults to false. More info: https://kubernetes.io/docs/concepts/storage/volumes#nfs
             */
            readOnly?: boolean;
            /**
             * Server is the hostname or IP address of the NFS server. More info: https://kubernetes.io/docs/concepts/storage/volumes#nfs
             */
            server: string;
        }

        /**
         * PersistentVolumeClaimVolumeSource represents a reference to a PersistentVolumeClaim in the same namespace. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#persistentvolumeclaims
         */
        export interface ThanosRulerSpecVolumesPersistentVolumeClaim {
            /**
             * ClaimName is the name of a PersistentVolumeClaim in the same namespace as the pod using this volume. More info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#persistentvolumeclaims
             */
            claimName: string;
            /**
             * Will force the ReadOnly setting in VolumeMounts. Default false.
             */
            readOnly?: boolean;
        }

        /**
         * PhotonPersistentDisk represents a PhotonController persistent disk attached and mounted on kubelets host machine
         */
        export interface ThanosRulerSpecVolumesPhotonPersistentDisk {
            /**
             * Filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. "ext4", "xfs", "ntfs". Implicitly inferred to be "ext4" if unspecified.
             */
            fsType?: string;
            /**
             * ID that identifies Photon Controller persistent disk
             */
            pdID: string;
        }

        /**
         * PortworxVolume represents a portworx volume attached and mounted on kubelets host machine
         */
        export interface ThanosRulerSpecVolumesPortworxVolume {
            /**
             * FSType represents the filesystem type to mount Must be a filesystem type supported by the host operating system. Ex. "ext4", "xfs". Implicitly inferred to be "ext4" if unspecified.
             */
            fsType?: string;
            /**
             * Defaults to false (read/write). ReadOnly here will force the ReadOnly setting in VolumeMounts.
             */
            readOnly?: boolean;
            /**
             * VolumeID uniquely identifies a Portworx volume
             */
            volumeID: string;
        }

        /**
         * Items for all in one resources secrets, configmaps, and downward API
         */
        export interface ThanosRulerSpecVolumesProjected {
            /**
             * Mode bits to use on created files by default. Must be a value between 0 and 0777. Directories within the path are not affected by this setting. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set.
             */
            defaultMode?: number;
            /**
             * list of volume projections
             */
            sources: outputs.monitoring.v1.ThanosRulerSpecVolumesProjectedSources[];
        }

        /**
         * Projection that may be projected along with other supported volume types
         */
        export interface ThanosRulerSpecVolumesProjectedSources {
            /**
             * information about the configMap data to project
             */
            configMap?: outputs.monitoring.v1.ThanosRulerSpecVolumesProjectedSourcesConfigMap;
            /**
             * information about the downwardAPI data to project
             */
            downwardAPI?: outputs.monitoring.v1.ThanosRulerSpecVolumesProjectedSourcesDownwardAPI;
            /**
             * information about the secret data to project
             */
            secret?: outputs.monitoring.v1.ThanosRulerSpecVolumesProjectedSourcesSecret;
            /**
             * information about the serviceAccountToken data to project
             */
            serviceAccountToken?: outputs.monitoring.v1.ThanosRulerSpecVolumesProjectedSourcesServiceAccountToken;
        }

        /**
         * information about the configMap data to project
         */
        export interface ThanosRulerSpecVolumesProjectedSourcesConfigMap {
            /**
             * If unspecified, each key-value pair in the Data field of the referenced ConfigMap will be projected into the volume as a file whose name is the key and content is the value. If specified, the listed keys will be projected into the specified paths, and unlisted keys will not be present. If a key is specified which is not present in the ConfigMap, the volume setup will error unless it is marked optional. Paths must be relative and may not contain the '..' path or start with '..'.
             */
            items?: outputs.monitoring.v1.ThanosRulerSpecVolumesProjectedSourcesConfigMapItems[];
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the ConfigMap or its keys must be defined
             */
            optional?: boolean;
        }

        /**
         * Maps a string key to a path within a volume.
         */
        export interface ThanosRulerSpecVolumesProjectedSourcesConfigMapItems {
            /**
             * The key to project.
             */
            key: string;
            /**
             * Optional: mode bits to use on this file, must be a value between 0 and 0777. If not specified, the volume defaultMode will be used. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set.
             */
            mode?: number;
            /**
             * The relative path of the file to map the key to. May not be an absolute path. May not contain the path element '..'. May not start with the string '..'.
             */
            path: string;
        }

        /**
         * information about the downwardAPI data to project
         */
        export interface ThanosRulerSpecVolumesProjectedSourcesDownwardAPI {
            /**
             * Items is a list of DownwardAPIVolume file
             */
            items?: outputs.monitoring.v1.ThanosRulerSpecVolumesProjectedSourcesDownwardAPIItems[];
        }

        /**
         * DownwardAPIVolumeFile represents information to create the file containing the pod field
         */
        export interface ThanosRulerSpecVolumesProjectedSourcesDownwardAPIItems {
            /**
             * Required: Selects a field of the pod: only annotations, labels, name and namespace are supported.
             */
            fieldRef?: outputs.monitoring.v1.ThanosRulerSpecVolumesProjectedSourcesDownwardAPIItemsFieldRef;
            /**
             * Optional: mode bits to use on this file, must be a value between 0 and 0777. If not specified, the volume defaultMode will be used. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set.
             */
            mode?: number;
            /**
             * Required: Path is  the relative path name of the file to be created. Must not be absolute or contain the '..' path. Must be utf-8 encoded. The first item of the relative path must not start with '..'
             */
            path: string;
            /**
             * Selects a resource of the container: only resources limits and requests (limits.cpu, limits.memory, requests.cpu and requests.memory) are currently supported.
             */
            resourceFieldRef?: outputs.monitoring.v1.ThanosRulerSpecVolumesProjectedSourcesDownwardAPIItemsResourceFieldRef;
        }

        /**
         * Required: Selects a field of the pod: only annotations, labels, name and namespace are supported.
         */
        export interface ThanosRulerSpecVolumesProjectedSourcesDownwardAPIItemsFieldRef {
            /**
             * Version of the schema the FieldPath is written in terms of, defaults to "v1".
             */
            apiVersion?: string;
            /**
             * Path of the field to select in the specified API version.
             */
            fieldPath: string;
        }

        /**
         * Selects a resource of the container: only resources limits and requests (limits.cpu, limits.memory, requests.cpu and requests.memory) are currently supported.
         */
        export interface ThanosRulerSpecVolumesProjectedSourcesDownwardAPIItemsResourceFieldRef {
            /**
             * Container name: required for volumes, optional for env vars
             */
            containerName?: string;
            /**
             * Specifies the output format of the exposed resources, defaults to "1"
             */
            divisor?: outputs.monitoring.v1.ThanosRulerSpecVolumesProjectedSourcesDownwardAPIItemsResourceFieldRefDivisor;
            /**
             * Required: resource to select
             */
            resource: string;
        }

        export interface ThanosRulerSpecVolumesProjectedSourcesDownwardAPIItemsResourceFieldRefDivisor {
        }

        /**
         * information about the secret data to project
         */
        export interface ThanosRulerSpecVolumesProjectedSourcesSecret {
            /**
             * If unspecified, each key-value pair in the Data field of the referenced Secret will be projected into the volume as a file whose name is the key and content is the value. If specified, the listed keys will be projected into the specified paths, and unlisted keys will not be present. If a key is specified which is not present in the Secret, the volume setup will error unless it is marked optional. Paths must be relative and may not contain the '..' path or start with '..'.
             */
            items?: outputs.monitoring.v1.ThanosRulerSpecVolumesProjectedSourcesSecretItems[];
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Maps a string key to a path within a volume.
         */
        export interface ThanosRulerSpecVolumesProjectedSourcesSecretItems {
            /**
             * The key to project.
             */
            key: string;
            /**
             * Optional: mode bits to use on this file, must be a value between 0 and 0777. If not specified, the volume defaultMode will be used. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set.
             */
            mode?: number;
            /**
             * The relative path of the file to map the key to. May not be an absolute path. May not contain the path element '..'. May not start with the string '..'.
             */
            path: string;
        }

        /**
         * information about the serviceAccountToken data to project
         */
        export interface ThanosRulerSpecVolumesProjectedSourcesServiceAccountToken {
            /**
             * Audience is the intended audience of the token. A recipient of a token must identify itself with an identifier specified in the audience of the token, and otherwise should reject the token. The audience defaults to the identifier of the apiserver.
             */
            audience?: string;
            /**
             * ExpirationSeconds is the requested duration of validity of the service account token. As the token approaches expiration, the kubelet volume plugin will proactively rotate the service account token. The kubelet will start trying to rotate the token if the token is older than 80 percent of its time to live or if the token is older than 24 hours.Defaults to 1 hour and must be at least 10 minutes.
             */
            expirationSeconds?: number;
            /**
             * Path is the path relative to the mount point of the file to project the token into.
             */
            path: string;
        }

        /**
         * Quobyte represents a Quobyte mount on the host that shares a pod's lifetime
         */
        export interface ThanosRulerSpecVolumesQuobyte {
            /**
             * Group to map volume access to Default is no group
             */
            group?: string;
            /**
             * ReadOnly here will force the Quobyte volume to be mounted with read-only permissions. Defaults to false.
             */
            readOnly?: boolean;
            /**
             * Registry represents a single or multiple Quobyte Registry services specified as a string as host:port pair (multiple entries are separated with commas) which acts as the central registry for volumes
             */
            registry: string;
            /**
             * Tenant owning the given Quobyte volume in the Backend Used with dynamically provisioned Quobyte volumes, value is set by the plugin
             */
            tenant?: string;
            /**
             * User to map volume access to Defaults to serivceaccount user
             */
            user?: string;
            /**
             * Volume is a string that references an already created Quobyte volume by name.
             */
            volume: string;
        }

        /**
         * RBD represents a Rados Block Device mount on the host that shares a pod's lifetime. More info: https://examples.k8s.io/volumes/rbd/README.md
         */
        export interface ThanosRulerSpecVolumesRbd {
            /**
             * Filesystem type of the volume that you want to mount. Tip: Ensure that the filesystem type is supported by the host operating system. Examples: "ext4", "xfs", "ntfs". Implicitly inferred to be "ext4" if unspecified. More info: https://kubernetes.io/docs/concepts/storage/volumes#rbd TODO: how do we prevent errors in the filesystem from compromising the machine
             */
            fsType?: string;
            /**
             * The rados image name. More info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it
             */
            image: string;
            /**
             * Keyring is the path to key ring for RBDUser. Default is /etc/ceph/keyring. More info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it
             */
            keyring?: string;
            /**
             * A collection of Ceph monitors. More info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it
             */
            monitors: string[];
            /**
             * The rados pool name. Default is rbd. More info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it
             */
            pool?: string;
            /**
             * ReadOnly here will force the ReadOnly setting in VolumeMounts. Defaults to false. More info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it
             */
            readOnly?: boolean;
            /**
             * SecretRef is name of the authentication secret for RBDUser. If provided overrides keyring. Default is nil. More info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it
             */
            secretRef?: outputs.monitoring.v1.ThanosRulerSpecVolumesRbdSecretRef;
            /**
             * The rados user name. Default is admin. More info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it
             */
            user?: string;
        }

        /**
         * SecretRef is name of the authentication secret for RBDUser. If provided overrides keyring. Default is nil. More info: https://examples.k8s.io/volumes/rbd/README.md#how-to-use-it
         */
        export interface ThanosRulerSpecVolumesRbdSecretRef {
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
        }

        /**
         * ScaleIO represents a ScaleIO persistent volume attached and mounted on Kubernetes nodes.
         */
        export interface ThanosRulerSpecVolumesScaleIO {
            /**
             * Filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. "ext4", "xfs", "ntfs". Default is "xfs".
             */
            fsType?: string;
            /**
             * The host address of the ScaleIO API Gateway.
             */
            gateway: string;
            /**
             * The name of the ScaleIO Protection Domain for the configured storage.
             */
            protectionDomain?: string;
            /**
             * Defaults to false (read/write). ReadOnly here will force the ReadOnly setting in VolumeMounts.
             */
            readOnly?: boolean;
            /**
             * SecretRef references to the secret for ScaleIO user and other sensitive information. If this is not provided, Login operation will fail.
             */
            secretRef: outputs.monitoring.v1.ThanosRulerSpecVolumesScaleIOSecretRef;
            /**
             * Flag to enable/disable SSL communication with Gateway, default false
             */
            sslEnabled?: boolean;
            /**
             * Indicates whether the storage for a volume should be ThickProvisioned or ThinProvisioned. Default is ThinProvisioned.
             */
            storageMode?: string;
            /**
             * The ScaleIO Storage Pool associated with the protection domain.
             */
            storagePool?: string;
            /**
             * The name of the storage system as configured in ScaleIO.
             */
            system: string;
            /**
             * The name of a volume already created in the ScaleIO system that is associated with this volume source.
             */
            volumeName?: string;
        }

        /**
         * SecretRef references to the secret for ScaleIO user and other sensitive information. If this is not provided, Login operation will fail.
         */
        export interface ThanosRulerSpecVolumesScaleIOSecretRef {
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
        }

        /**
         * Secret represents a secret that should populate this volume. More info: https://kubernetes.io/docs/concepts/storage/volumes#secret
         */
        export interface ThanosRulerSpecVolumesSecret {
            /**
             * Optional: mode bits to use on created files by default. Must be a value between 0 and 0777. Defaults to 0644. Directories within the path are not affected by this setting. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set.
             */
            defaultMode?: number;
            /**
             * If unspecified, each key-value pair in the Data field of the referenced Secret will be projected into the volume as a file whose name is the key and content is the value. If specified, the listed keys will be projected into the specified paths, and unlisted keys will not be present. If a key is specified which is not present in the Secret, the volume setup will error unless it is marked optional. Paths must be relative and may not contain the '..' path or start with '..'.
             */
            items?: outputs.monitoring.v1.ThanosRulerSpecVolumesSecretItems[];
            /**
             * Specify whether the Secret or its keys must be defined
             */
            optional?: boolean;
            /**
             * Name of the secret in the pod's namespace to use. More info: https://kubernetes.io/docs/concepts/storage/volumes#secret
             */
            secretName?: string;
        }

        /**
         * Maps a string key to a path within a volume.
         */
        export interface ThanosRulerSpecVolumesSecretItems {
            /**
             * The key to project.
             */
            key: string;
            /**
             * Optional: mode bits to use on this file, must be a value between 0 and 0777. If not specified, the volume defaultMode will be used. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set.
             */
            mode?: number;
            /**
             * The relative path of the file to map the key to. May not be an absolute path. May not contain the path element '..'. May not start with the string '..'.
             */
            path: string;
        }

        /**
         * StorageOS represents a StorageOS volume attached and mounted on Kubernetes nodes.
         */
        export interface ThanosRulerSpecVolumesStorageos {
            /**
             * Filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. "ext4", "xfs", "ntfs". Implicitly inferred to be "ext4" if unspecified.
             */
            fsType?: string;
            /**
             * Defaults to false (read/write). ReadOnly here will force the ReadOnly setting in VolumeMounts.
             */
            readOnly?: boolean;
            /**
             * SecretRef specifies the secret to use for obtaining the StorageOS API credentials.  If not specified, default values will be attempted.
             */
            secretRef?: outputs.monitoring.v1.ThanosRulerSpecVolumesStorageosSecretRef;
            /**
             * VolumeName is the human-readable name of the StorageOS volume.  Volume names are only unique within a namespace.
             */
            volumeName?: string;
            /**
             * VolumeNamespace specifies the scope of the volume within StorageOS.  If no namespace is specified then the Pod's namespace will be used.  This allows the Kubernetes name scoping to be mirrored within StorageOS for tighter integration. Set VolumeName to any name to override the default behaviour. Set to "default" if you are not using namespaces within StorageOS. Namespaces that do not pre-exist within StorageOS will be created.
             */
            volumeNamespace?: string;
        }

        /**
         * SecretRef specifies the secret to use for obtaining the StorageOS API credentials.  If not specified, default values will be attempted.
         */
        export interface ThanosRulerSpecVolumesStorageosSecretRef {
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
        }

        /**
         * VsphereVolume represents a vSphere volume attached and mounted on kubelets host machine
         */
        export interface ThanosRulerSpecVolumesVsphereVolume {
            /**
             * Filesystem type to mount. Must be a filesystem type supported by the host operating system. Ex. "ext4", "xfs", "ntfs". Implicitly inferred to be "ext4" if unspecified.
             */
            fsType?: string;
            /**
             * Storage Policy Based Management (SPBM) profile ID associated with the StoragePolicyName.
             */
            storagePolicyID?: string;
            /**
             * Storage Policy Based Management (SPBM) profile name.
             */
            storagePolicyName?: string;
            /**
             * Path that identifies vSphere volume vmdk
             */
            volumePath: string;
        }

        /**
         * Most recent observed status of the ThanosRuler cluster. Read-only. Not included when requesting from the apiserver, only from the ThanosRuler Operator API itself. More info: https://github.com/kubernetes/community/blob/master/contributors/devel/sig-architecture/api-conventions.md#spec-and-status
         */
        export interface ThanosRulerStatus {
            /**
             * Total number of available pods (ready for at least minReadySeconds) targeted by this ThanosRuler deployment.
             */
            availableReplicas: number;
            /**
             * Represents whether any actions on the underlying managed objects are being performed. Only delete actions will be performed.
             */
            paused: boolean;
            /**
             * Total number of non-terminated pods targeted by this ThanosRuler deployment (their labels match the selector).
             */
            replicas: number;
            /**
             * Total number of unavailable pods targeted by this ThanosRuler deployment.
             */
            unavailableReplicas: number;
            /**
             * Total number of non-terminated pods targeted by this ThanosRuler deployment that have the desired version spec.
             */
            updatedReplicas: number;
        }
    }

    export namespace v1alpha1 {
        /**
         * AlertmanagerConfigSpec is a specification of the desired behavior of the Alertmanager configuration. By definition, the Alertmanager configuration only applies to alerts for which the `namespace` label is equal to the namespace of the AlertmanagerConfig resource.
         */
        export interface AlertmanagerConfigSpec {
            /**
             * List of inhibition rules. The rules will only apply to alerts matching the resource’s namespace.
             */
            inhibitRules?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecInhibitRules[];
            /**
             * List of receivers.
             */
            receivers?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceivers[];
            /**
             * The Alertmanager route definition for alerts matching the resource’s namespace. It will be added to the generated Alertmanager configuration as a first-level route.
             */
            route?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecRoute;
        }

        /**
         * InhibitRule defines an inhibition rule that allows to mute alerts when other alerts are already firing. See https://prometheus.io/docs/alerting/latest/configuration/#inhibit_rule
         */
        export interface AlertmanagerConfigSpecInhibitRules {
            /**
             * Labels that must have an equal value in the source and target alert for the inhibition to take effect.
             */
            equal?: string[];
            /**
             * Matchers for which one or more alerts have to exist for the inhibition to take effect. The operator enforces that the alert matches the resource’s namespace.
             */
            sourceMatch?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecInhibitRulesSourceMatch[];
            /**
             * Matchers that have to be fulfilled in the alerts to be muted. The operator enforces that the alert matches the resource’s namespace.
             */
            targetMatch?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecInhibitRulesTargetMatch[];
        }

        /**
         * Matcher defines how to match on alert's labels.
         */
        export interface AlertmanagerConfigSpecInhibitRulesSourceMatch {
            /**
             * Label to match.
             */
            name: string;
            /**
             * Whether to match on equality (false) or regular-expression (true).
             */
            regex?: boolean;
            /**
             * Label value to match.
             */
            value: string;
        }

        /**
         * Matcher defines how to match on alert's labels.
         */
        export interface AlertmanagerConfigSpecInhibitRulesTargetMatch {
            /**
             * Label to match.
             */
            name: string;
            /**
             * Whether to match on equality (false) or regular-expression (true).
             */
            regex?: boolean;
            /**
             * Label value to match.
             */
            value: string;
        }

        /**
         * Receiver defines one or more notification integrations.
         */
        export interface AlertmanagerConfigSpecReceivers {
            /**
             * List of Email configurations.
             */
            emailConfigs?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversEmailConfigs[];
            /**
             * Name of the receiver. Must be unique across all items from the list.
             */
            name: string;
            /**
             * List of OpsGenie configurations.
             */
            opsgenieConfigs?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversOpsgenieConfigs[];
            /**
             * List of PagerDuty configurations.
             */
            pagerdutyConfigs?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversPagerdutyConfigs[];
            /**
             * List of Pushover configurations.
             */
            pushoverConfigs?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversPushoverConfigs[];
            /**
             * List of Slack configurations.
             */
            slackConfigs?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversSlackConfigs[];
            /**
             * List of VictorOps configurations.
             */
            victoropsConfigs?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversVictoropsConfigs[];
            /**
             * List of webhook configurations.
             */
            webhookConfigs?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversWebhookConfigs[];
            /**
             * List of WeChat configurations.
             */
            wechatConfigs?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversWechatConfigs[];
        }

        /**
         * EmailConfig configures notifications via Email.
         */
        export interface AlertmanagerConfigSpecReceiversEmailConfigs {
            authIdentity?: string;
            /**
             * SecretKeySelector selects a key of a Secret.
             */
            authPassword?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversEmailConfigsAuthPassword;
            /**
             * SecretKeySelector selects a key of a Secret.
             */
            authSecret?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversEmailConfigsAuthSecret;
            /**
             * SMTP authentication information.
             */
            authUsername?: string;
            /**
             * The sender address.
             */
            from?: string;
            /**
             * Further headers email header key/value pairs. Overrides any headers previously set by the notification implementation.
             */
            headers?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversEmailConfigsHeaders[];
            /**
             * The hostname to identify to the SMTP server.
             */
            hello?: string;
            /**
             * The HTML body of the email notification.
             */
            html?: string;
            /**
             * The SMTP TLS requirement. Note that Go does not support unencrypted connections to remote SMTP endpoints.
             */
            requireTLS?: boolean;
            /**
             * Whether or not to notify about resolved alerts.
             */
            sendResolved?: boolean;
            /**
             * The SMTP host through which emails are sent.
             */
            smarthost?: string;
            /**
             * The text body of the email notification.
             */
            text?: string;
            /**
             * TLS configuration
             */
            tlsConfig?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversEmailConfigsTlsConfig;
            /**
             * The email address to send notifications to.
             */
            to?: string;
        }

        /**
         * SecretKeySelector selects a key of a Secret.
         */
        export interface AlertmanagerConfigSpecReceiversEmailConfigsAuthPassword {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * SecretKeySelector selects a key of a Secret.
         */
        export interface AlertmanagerConfigSpecReceiversEmailConfigsAuthSecret {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * KeyValue defines a (key, value) tuple.
         */
        export interface AlertmanagerConfigSpecReceiversEmailConfigsHeaders {
            /**
             * Key of the tuple.
             */
            key: string;
            /**
             * Value of the tuple.
             */
            value: string;
        }

        /**
         * TLS configuration
         */
        export interface AlertmanagerConfigSpecReceiversEmailConfigsTlsConfig {
            /**
             * Struct containing the CA cert to use for the targets.
             */
            ca?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversEmailConfigsTlsConfigCa;
            /**
             * Struct containing the client cert file for the targets.
             */
            cert?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversEmailConfigsTlsConfigCert;
            /**
             * Disable target certificate validation.
             */
            insecureSkipVerify?: boolean;
            /**
             * Secret containing the client key file for the targets.
             */
            keySecret?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversEmailConfigsTlsConfigKeySecret;
            /**
             * Used to verify the hostname for the targets.
             */
            serverName?: string;
        }

        /**
         * Struct containing the CA cert to use for the targets.
         */
        export interface AlertmanagerConfigSpecReceiversEmailConfigsTlsConfigCa {
            /**
             * ConfigMap containing data to use for the targets.
             */
            configMap?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversEmailConfigsTlsConfigCaConfigMap;
            /**
             * Secret containing data to use for the targets.
             */
            secret?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversEmailConfigsTlsConfigCaSecret;
        }

        /**
         * ConfigMap containing data to use for the targets.
         */
        export interface AlertmanagerConfigSpecReceiversEmailConfigsTlsConfigCaConfigMap {
            /**
             * The key to select.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the ConfigMap or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Secret containing data to use for the targets.
         */
        export interface AlertmanagerConfigSpecReceiversEmailConfigsTlsConfigCaSecret {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Struct containing the client cert file for the targets.
         */
        export interface AlertmanagerConfigSpecReceiversEmailConfigsTlsConfigCert {
            /**
             * ConfigMap containing data to use for the targets.
             */
            configMap?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversEmailConfigsTlsConfigCertConfigMap;
            /**
             * Secret containing data to use for the targets.
             */
            secret?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversEmailConfigsTlsConfigCertSecret;
        }

        /**
         * ConfigMap containing data to use for the targets.
         */
        export interface AlertmanagerConfigSpecReceiversEmailConfigsTlsConfigCertConfigMap {
            /**
             * The key to select.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the ConfigMap or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Secret containing data to use for the targets.
         */
        export interface AlertmanagerConfigSpecReceiversEmailConfigsTlsConfigCertSecret {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Secret containing the client key file for the targets.
         */
        export interface AlertmanagerConfigSpecReceiversEmailConfigsTlsConfigKeySecret {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * OpsGenieConfig configures notifications via OpsGenie. See https://prometheus.io/docs/alerting/latest/configuration/#opsgenie_config
         */
        export interface AlertmanagerConfigSpecReceiversOpsgenieConfigs {
            /**
             * The secret's key that contains the OpsGenie API key. The secret needs to be in the same namespace as the AlertmanagerConfig object and accessible by the Prometheus Operator.
             */
            apiKey?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversOpsgenieConfigsApiKey;
            /**
             * The URL to send OpsGenie API requests to.
             */
            apiURL?: string;
            /**
             * Description of the incident.
             */
            description?: string;
            /**
             * A set of arbitrary key/value pairs that provide further detail about the incident.
             */
            details?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversOpsgenieConfigsDetails[];
            /**
             * HTTP client configuration.
             */
            httpConfig?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversOpsgenieConfigsHttpConfig;
            /**
             * Alert text limited to 130 characters.
             */
            message?: string;
            /**
             * Additional alert note.
             */
            note?: string;
            /**
             * Priority level of alert. Possible values are P1, P2, P3, P4, and P5.
             */
            priority?: string;
            /**
             * List of responders responsible for notifications.
             */
            responders?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversOpsgenieConfigsResponders[];
            /**
             * Whether or not to notify about resolved alerts.
             */
            sendResolved?: boolean;
            /**
             * Backlink to the sender of the notification.
             */
            source?: string;
            /**
             * Comma separated list of tags attached to the notifications.
             */
            tags?: string;
        }

        /**
         * The secret's key that contains the OpsGenie API key. The secret needs to be in the same namespace as the AlertmanagerConfig object and accessible by the Prometheus Operator.
         */
        export interface AlertmanagerConfigSpecReceiversOpsgenieConfigsApiKey {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * KeyValue defines a (key, value) tuple.
         */
        export interface AlertmanagerConfigSpecReceiversOpsgenieConfigsDetails {
            /**
             * Key of the tuple.
             */
            key: string;
            /**
             * Value of the tuple.
             */
            value: string;
        }

        /**
         * HTTP client configuration.
         */
        export interface AlertmanagerConfigSpecReceiversOpsgenieConfigsHttpConfig {
            /**
             * BasicAuth for the client.
             */
            basicAuth?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversOpsgenieConfigsHttpConfigBasicAuth;
            /**
             * The secret's key that contains the bearer token to be used by the client for authentication. The secret needs to be in the same namespace as the AlertmanagerConfig object and accessible by the Prometheus Operator.
             */
            bearerTokenSecret?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversOpsgenieConfigsHttpConfigBearerTokenSecret;
            /**
             * Optional proxy URL.
             */
            proxyURL?: string;
            /**
             * TLS configuration for the client.
             */
            tlsConfig?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversOpsgenieConfigsHttpConfigTlsConfig;
        }

        /**
         * BasicAuth for the client.
         */
        export interface AlertmanagerConfigSpecReceiversOpsgenieConfigsHttpConfigBasicAuth {
            /**
             * The secret in the service monitor namespace that contains the password for authentication.
             */
            password?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversOpsgenieConfigsHttpConfigBasicAuthPassword;
            /**
             * The secret in the service monitor namespace that contains the username for authentication.
             */
            username?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversOpsgenieConfigsHttpConfigBasicAuthUsername;
        }

        /**
         * The secret in the service monitor namespace that contains the password for authentication.
         */
        export interface AlertmanagerConfigSpecReceiversOpsgenieConfigsHttpConfigBasicAuthPassword {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * The secret in the service monitor namespace that contains the username for authentication.
         */
        export interface AlertmanagerConfigSpecReceiversOpsgenieConfigsHttpConfigBasicAuthUsername {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * The secret's key that contains the bearer token to be used by the client for authentication. The secret needs to be in the same namespace as the AlertmanagerConfig object and accessible by the Prometheus Operator.
         */
        export interface AlertmanagerConfigSpecReceiversOpsgenieConfigsHttpConfigBearerTokenSecret {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * TLS configuration for the client.
         */
        export interface AlertmanagerConfigSpecReceiversOpsgenieConfigsHttpConfigTlsConfig {
            /**
             * Struct containing the CA cert to use for the targets.
             */
            ca?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversOpsgenieConfigsHttpConfigTlsConfigCa;
            /**
             * Struct containing the client cert file for the targets.
             */
            cert?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversOpsgenieConfigsHttpConfigTlsConfigCert;
            /**
             * Disable target certificate validation.
             */
            insecureSkipVerify?: boolean;
            /**
             * Secret containing the client key file for the targets.
             */
            keySecret?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversOpsgenieConfigsHttpConfigTlsConfigKeySecret;
            /**
             * Used to verify the hostname for the targets.
             */
            serverName?: string;
        }

        /**
         * Struct containing the CA cert to use for the targets.
         */
        export interface AlertmanagerConfigSpecReceiversOpsgenieConfigsHttpConfigTlsConfigCa {
            /**
             * ConfigMap containing data to use for the targets.
             */
            configMap?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversOpsgenieConfigsHttpConfigTlsConfigCaConfigMap;
            /**
             * Secret containing data to use for the targets.
             */
            secret?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversOpsgenieConfigsHttpConfigTlsConfigCaSecret;
        }

        /**
         * ConfigMap containing data to use for the targets.
         */
        export interface AlertmanagerConfigSpecReceiversOpsgenieConfigsHttpConfigTlsConfigCaConfigMap {
            /**
             * The key to select.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the ConfigMap or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Secret containing data to use for the targets.
         */
        export interface AlertmanagerConfigSpecReceiversOpsgenieConfigsHttpConfigTlsConfigCaSecret {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Struct containing the client cert file for the targets.
         */
        export interface AlertmanagerConfigSpecReceiversOpsgenieConfigsHttpConfigTlsConfigCert {
            /**
             * ConfigMap containing data to use for the targets.
             */
            configMap?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversOpsgenieConfigsHttpConfigTlsConfigCertConfigMap;
            /**
             * Secret containing data to use for the targets.
             */
            secret?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversOpsgenieConfigsHttpConfigTlsConfigCertSecret;
        }

        /**
         * ConfigMap containing data to use for the targets.
         */
        export interface AlertmanagerConfigSpecReceiversOpsgenieConfigsHttpConfigTlsConfigCertConfigMap {
            /**
             * The key to select.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the ConfigMap or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Secret containing data to use for the targets.
         */
        export interface AlertmanagerConfigSpecReceiversOpsgenieConfigsHttpConfigTlsConfigCertSecret {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Secret containing the client key file for the targets.
         */
        export interface AlertmanagerConfigSpecReceiversOpsgenieConfigsHttpConfigTlsConfigKeySecret {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * OpsGenieConfigResponder defines a responder to an incident. One of id, name or username has to be defined.
         */
        export interface AlertmanagerConfigSpecReceiversOpsgenieConfigsResponders {
            /**
             * ID of the responder.
             */
            id?: string;
            /**
             * Name of the responder.
             */
            name?: string;
            /**
             * Type of responder.
             */
            type?: string;
            /**
             * Username of the responder.
             */
            username?: string;
        }

        /**
         * PagerDutyConfig configures notifications via PagerDuty. See https://prometheus.io/docs/alerting/latest/configuration/#pagerduty_config
         */
        export interface AlertmanagerConfigSpecReceiversPagerdutyConfigs {
            /**
             * The class/type of the event.
             */
            class?: string;
            /**
             * Client identification.
             */
            client?: string;
            /**
             * Backlink to the sender of notification.
             */
            clientURL?: string;
            /**
             * The part or component of the affected system that is broken.
             */
            component?: string;
            /**
             * Description of the incident.
             */
            description?: string;
            /**
             * Arbitrary key/value pairs that provide further detail about the incident.
             */
            details?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversPagerdutyConfigsDetails[];
            /**
             * A cluster or grouping of sources.
             */
            group?: string;
            /**
             * HTTP client configuration.
             */
            httpConfig?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversPagerdutyConfigsHttpConfig;
            /**
             * The secret's key that contains the PagerDuty integration key (when using Events API v2). Either this field or `serviceKey` needs to be defined. The secret needs to be in the same namespace as the AlertmanagerConfig object and accessible by the Prometheus Operator.
             */
            routingKey?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversPagerdutyConfigsRoutingKey;
            /**
             * Whether or not to notify about resolved alerts.
             */
            sendResolved?: boolean;
            /**
             * The secret's key that contains the PagerDuty service key (when using integration type "Prometheus"). Either this field or `routingKey` needs to be defined. The secret needs to be in the same namespace as the AlertmanagerConfig object and accessible by the Prometheus Operator.
             */
            serviceKey?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversPagerdutyConfigsServiceKey;
            /**
             * Severity of the incident.
             */
            severity?: string;
            /**
             * The URL to send requests to.
             */
            url?: string;
        }

        /**
         * KeyValue defines a (key, value) tuple.
         */
        export interface AlertmanagerConfigSpecReceiversPagerdutyConfigsDetails {
            /**
             * Key of the tuple.
             */
            key: string;
            /**
             * Value of the tuple.
             */
            value: string;
        }

        /**
         * HTTP client configuration.
         */
        export interface AlertmanagerConfigSpecReceiversPagerdutyConfigsHttpConfig {
            /**
             * BasicAuth for the client.
             */
            basicAuth?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversPagerdutyConfigsHttpConfigBasicAuth;
            /**
             * The secret's key that contains the bearer token to be used by the client for authentication. The secret needs to be in the same namespace as the AlertmanagerConfig object and accessible by the Prometheus Operator.
             */
            bearerTokenSecret?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversPagerdutyConfigsHttpConfigBearerTokenSecret;
            /**
             * Optional proxy URL.
             */
            proxyURL?: string;
            /**
             * TLS configuration for the client.
             */
            tlsConfig?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversPagerdutyConfigsHttpConfigTlsConfig;
        }

        /**
         * BasicAuth for the client.
         */
        export interface AlertmanagerConfigSpecReceiversPagerdutyConfigsHttpConfigBasicAuth {
            /**
             * The secret in the service monitor namespace that contains the password for authentication.
             */
            password?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversPagerdutyConfigsHttpConfigBasicAuthPassword;
            /**
             * The secret in the service monitor namespace that contains the username for authentication.
             */
            username?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversPagerdutyConfigsHttpConfigBasicAuthUsername;
        }

        /**
         * The secret in the service monitor namespace that contains the password for authentication.
         */
        export interface AlertmanagerConfigSpecReceiversPagerdutyConfigsHttpConfigBasicAuthPassword {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * The secret in the service monitor namespace that contains the username for authentication.
         */
        export interface AlertmanagerConfigSpecReceiversPagerdutyConfigsHttpConfigBasicAuthUsername {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * The secret's key that contains the bearer token to be used by the client for authentication. The secret needs to be in the same namespace as the AlertmanagerConfig object and accessible by the Prometheus Operator.
         */
        export interface AlertmanagerConfigSpecReceiversPagerdutyConfigsHttpConfigBearerTokenSecret {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * TLS configuration for the client.
         */
        export interface AlertmanagerConfigSpecReceiversPagerdutyConfigsHttpConfigTlsConfig {
            /**
             * Struct containing the CA cert to use for the targets.
             */
            ca?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversPagerdutyConfigsHttpConfigTlsConfigCa;
            /**
             * Struct containing the client cert file for the targets.
             */
            cert?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversPagerdutyConfigsHttpConfigTlsConfigCert;
            /**
             * Disable target certificate validation.
             */
            insecureSkipVerify?: boolean;
            /**
             * Secret containing the client key file for the targets.
             */
            keySecret?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversPagerdutyConfigsHttpConfigTlsConfigKeySecret;
            /**
             * Used to verify the hostname for the targets.
             */
            serverName?: string;
        }

        /**
         * Struct containing the CA cert to use for the targets.
         */
        export interface AlertmanagerConfigSpecReceiversPagerdutyConfigsHttpConfigTlsConfigCa {
            /**
             * ConfigMap containing data to use for the targets.
             */
            configMap?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversPagerdutyConfigsHttpConfigTlsConfigCaConfigMap;
            /**
             * Secret containing data to use for the targets.
             */
            secret?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversPagerdutyConfigsHttpConfigTlsConfigCaSecret;
        }

        /**
         * ConfigMap containing data to use for the targets.
         */
        export interface AlertmanagerConfigSpecReceiversPagerdutyConfigsHttpConfigTlsConfigCaConfigMap {
            /**
             * The key to select.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the ConfigMap or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Secret containing data to use for the targets.
         */
        export interface AlertmanagerConfigSpecReceiversPagerdutyConfigsHttpConfigTlsConfigCaSecret {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Struct containing the client cert file for the targets.
         */
        export interface AlertmanagerConfigSpecReceiversPagerdutyConfigsHttpConfigTlsConfigCert {
            /**
             * ConfigMap containing data to use for the targets.
             */
            configMap?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversPagerdutyConfigsHttpConfigTlsConfigCertConfigMap;
            /**
             * Secret containing data to use for the targets.
             */
            secret?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversPagerdutyConfigsHttpConfigTlsConfigCertSecret;
        }

        /**
         * ConfigMap containing data to use for the targets.
         */
        export interface AlertmanagerConfigSpecReceiversPagerdutyConfigsHttpConfigTlsConfigCertConfigMap {
            /**
             * The key to select.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the ConfigMap or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Secret containing data to use for the targets.
         */
        export interface AlertmanagerConfigSpecReceiversPagerdutyConfigsHttpConfigTlsConfigCertSecret {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Secret containing the client key file for the targets.
         */
        export interface AlertmanagerConfigSpecReceiversPagerdutyConfigsHttpConfigTlsConfigKeySecret {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * The secret's key that contains the PagerDuty integration key (when using Events API v2). Either this field or `serviceKey` needs to be defined. The secret needs to be in the same namespace as the AlertmanagerConfig object and accessible by the Prometheus Operator.
         */
        export interface AlertmanagerConfigSpecReceiversPagerdutyConfigsRoutingKey {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * The secret's key that contains the PagerDuty service key (when using integration type "Prometheus"). Either this field or `routingKey` needs to be defined. The secret needs to be in the same namespace as the AlertmanagerConfig object and accessible by the Prometheus Operator.
         */
        export interface AlertmanagerConfigSpecReceiversPagerdutyConfigsServiceKey {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * PushoverConfig configures notifications via Pushover. See https://prometheus.io/docs/alerting/latest/configuration/#pushover_config
         */
        export interface AlertmanagerConfigSpecReceiversPushoverConfigs {
            /**
             * How long your notification will continue to be retried for, unless the user acknowledges the notification.
             */
            expire?: string;
            /**
             * Whether notification message is HTML or plain text.
             */
            html?: boolean;
            /**
             * HTTP client configuration.
             */
            httpConfig?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversPushoverConfigsHttpConfig;
            /**
             * Notification message.
             */
            message?: string;
            /**
             * Priority, see https://pushover.net/api#priority
             */
            priority?: string;
            /**
             * How often the Pushover servers will send the same notification to the user. Must be at least 30 seconds.
             */
            retry?: string;
            /**
             * Whether or not to notify about resolved alerts.
             */
            sendResolved?: boolean;
            /**
             * The name of one of the sounds supported by device clients to override the user's default sound choice
             */
            sound?: string;
            /**
             * Notification title.
             */
            title?: string;
            /**
             * Your registered application’s API token, see https://pushover.net/apps
             */
            token?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversPushoverConfigsToken;
            /**
             * A supplementary URL shown alongside the message.
             */
            url?: string;
            /**
             * A title for supplementary URL, otherwise just the URL is shown
             */
            urlTitle?: string;
            /**
             * The recipient user’s user key.
             */
            userKey?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversPushoverConfigsUserKey;
        }

        /**
         * HTTP client configuration.
         */
        export interface AlertmanagerConfigSpecReceiversPushoverConfigsHttpConfig {
            /**
             * BasicAuth for the client.
             */
            basicAuth?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversPushoverConfigsHttpConfigBasicAuth;
            /**
             * The secret's key that contains the bearer token to be used by the client for authentication. The secret needs to be in the same namespace as the AlertmanagerConfig object and accessible by the Prometheus Operator.
             */
            bearerTokenSecret?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversPushoverConfigsHttpConfigBearerTokenSecret;
            /**
             * Optional proxy URL.
             */
            proxyURL?: string;
            /**
             * TLS configuration for the client.
             */
            tlsConfig?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversPushoverConfigsHttpConfigTlsConfig;
        }

        /**
         * BasicAuth for the client.
         */
        export interface AlertmanagerConfigSpecReceiversPushoverConfigsHttpConfigBasicAuth {
            /**
             * The secret in the service monitor namespace that contains the password for authentication.
             */
            password?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversPushoverConfigsHttpConfigBasicAuthPassword;
            /**
             * The secret in the service monitor namespace that contains the username for authentication.
             */
            username?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversPushoverConfigsHttpConfigBasicAuthUsername;
        }

        /**
         * The secret in the service monitor namespace that contains the password for authentication.
         */
        export interface AlertmanagerConfigSpecReceiversPushoverConfigsHttpConfigBasicAuthPassword {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * The secret in the service monitor namespace that contains the username for authentication.
         */
        export interface AlertmanagerConfigSpecReceiversPushoverConfigsHttpConfigBasicAuthUsername {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * The secret's key that contains the bearer token to be used by the client for authentication. The secret needs to be in the same namespace as the AlertmanagerConfig object and accessible by the Prometheus Operator.
         */
        export interface AlertmanagerConfigSpecReceiversPushoverConfigsHttpConfigBearerTokenSecret {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * TLS configuration for the client.
         */
        export interface AlertmanagerConfigSpecReceiversPushoverConfigsHttpConfigTlsConfig {
            /**
             * Struct containing the CA cert to use for the targets.
             */
            ca?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversPushoverConfigsHttpConfigTlsConfigCa;
            /**
             * Struct containing the client cert file for the targets.
             */
            cert?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversPushoverConfigsHttpConfigTlsConfigCert;
            /**
             * Disable target certificate validation.
             */
            insecureSkipVerify?: boolean;
            /**
             * Secret containing the client key file for the targets.
             */
            keySecret?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversPushoverConfigsHttpConfigTlsConfigKeySecret;
            /**
             * Used to verify the hostname for the targets.
             */
            serverName?: string;
        }

        /**
         * Struct containing the CA cert to use for the targets.
         */
        export interface AlertmanagerConfigSpecReceiversPushoverConfigsHttpConfigTlsConfigCa {
            /**
             * ConfigMap containing data to use for the targets.
             */
            configMap?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversPushoverConfigsHttpConfigTlsConfigCaConfigMap;
            /**
             * Secret containing data to use for the targets.
             */
            secret?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversPushoverConfigsHttpConfigTlsConfigCaSecret;
        }

        /**
         * ConfigMap containing data to use for the targets.
         */
        export interface AlertmanagerConfigSpecReceiversPushoverConfigsHttpConfigTlsConfigCaConfigMap {
            /**
             * The key to select.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the ConfigMap or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Secret containing data to use for the targets.
         */
        export interface AlertmanagerConfigSpecReceiversPushoverConfigsHttpConfigTlsConfigCaSecret {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Struct containing the client cert file for the targets.
         */
        export interface AlertmanagerConfigSpecReceiversPushoverConfigsHttpConfigTlsConfigCert {
            /**
             * ConfigMap containing data to use for the targets.
             */
            configMap?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversPushoverConfigsHttpConfigTlsConfigCertConfigMap;
            /**
             * Secret containing data to use for the targets.
             */
            secret?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversPushoverConfigsHttpConfigTlsConfigCertSecret;
        }

        /**
         * ConfigMap containing data to use for the targets.
         */
        export interface AlertmanagerConfigSpecReceiversPushoverConfigsHttpConfigTlsConfigCertConfigMap {
            /**
             * The key to select.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the ConfigMap or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Secret containing data to use for the targets.
         */
        export interface AlertmanagerConfigSpecReceiversPushoverConfigsHttpConfigTlsConfigCertSecret {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Secret containing the client key file for the targets.
         */
        export interface AlertmanagerConfigSpecReceiversPushoverConfigsHttpConfigTlsConfigKeySecret {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Your registered application’s API token, see https://pushover.net/apps
         */
        export interface AlertmanagerConfigSpecReceiversPushoverConfigsToken {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * The recipient user’s user key.
         */
        export interface AlertmanagerConfigSpecReceiversPushoverConfigsUserKey {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * SlackConfig configures notifications via Slack. See https://prometheus.io/docs/alerting/latest/configuration/#slack_config
         */
        export interface AlertmanagerConfigSpecReceiversSlackConfigs {
            /**
             * A list of Slack actions that are sent with each notification.
             */
            actions?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversSlackConfigsActions[];
            /**
             * The secret's key that contains the Slack webhook URL. The secret needs to be in the same namespace as the AlertmanagerConfig object and accessible by the Prometheus Operator.
             */
            apiURL?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversSlackConfigsApiURL;
            callbackId?: string;
            /**
             * The channel or user to send notifications to.
             */
            channel?: string;
            color?: string;
            fallback?: string;
            /**
             * A list of Slack fields that are sent with each notification.
             */
            fields?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversSlackConfigsFields[];
            footer?: string;
            /**
             * HTTP client configuration.
             */
            httpConfig?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversSlackConfigsHttpConfig;
            iconEmoji?: string;
            iconURL?: string;
            imageURL?: string;
            linkNames?: boolean;
            mrkdwnIn?: string[];
            pretext?: string;
            /**
             * Whether or not to notify about resolved alerts.
             */
            sendResolved?: boolean;
            shortFields?: boolean;
            text?: string;
            thumbURL?: string;
            title?: string;
            titleLink?: string;
            username?: string;
        }

        /**
         * SlackAction configures a single Slack action that is sent with each notification. See https://api.slack.com/docs/message-attachments#action_fields and https://api.slack.com/docs/message-buttons for more information.
         */
        export interface AlertmanagerConfigSpecReceiversSlackConfigsActions {
            /**
             * SlackConfirmationField protect users from destructive actions or particularly distinguished decisions by asking them to confirm their button click one more time. See https://api.slack.com/docs/interactive-message-field-guide#confirmation_fields for more information.
             */
            confirm?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversSlackConfigsActionsConfirm;
            name?: string;
            style?: string;
            text: string;
            type: string;
            url?: string;
            value?: string;
        }

        /**
         * SlackConfirmationField protect users from destructive actions or particularly distinguished decisions by asking them to confirm their button click one more time. See https://api.slack.com/docs/interactive-message-field-guide#confirmation_fields for more information.
         */
        export interface AlertmanagerConfigSpecReceiversSlackConfigsActionsConfirm {
            dismissText?: string;
            okText?: string;
            text: string;
            title?: string;
        }

        /**
         * The secret's key that contains the Slack webhook URL. The secret needs to be in the same namespace as the AlertmanagerConfig object and accessible by the Prometheus Operator.
         */
        export interface AlertmanagerConfigSpecReceiversSlackConfigsApiURL {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * SlackField configures a single Slack field that is sent with each notification. Each field must contain a title, value, and optionally, a boolean value to indicate if the field is short enough to be displayed next to other fields designated as short. See https://api.slack.com/docs/message-attachments#fields for more information.
         */
        export interface AlertmanagerConfigSpecReceiversSlackConfigsFields {
            short?: boolean;
            title: string;
            value: string;
        }

        /**
         * HTTP client configuration.
         */
        export interface AlertmanagerConfigSpecReceiversSlackConfigsHttpConfig {
            /**
             * BasicAuth for the client.
             */
            basicAuth?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversSlackConfigsHttpConfigBasicAuth;
            /**
             * The secret's key that contains the bearer token to be used by the client for authentication. The secret needs to be in the same namespace as the AlertmanagerConfig object and accessible by the Prometheus Operator.
             */
            bearerTokenSecret?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversSlackConfigsHttpConfigBearerTokenSecret;
            /**
             * Optional proxy URL.
             */
            proxyURL?: string;
            /**
             * TLS configuration for the client.
             */
            tlsConfig?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversSlackConfigsHttpConfigTlsConfig;
        }

        /**
         * BasicAuth for the client.
         */
        export interface AlertmanagerConfigSpecReceiversSlackConfigsHttpConfigBasicAuth {
            /**
             * The secret in the service monitor namespace that contains the password for authentication.
             */
            password?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversSlackConfigsHttpConfigBasicAuthPassword;
            /**
             * The secret in the service monitor namespace that contains the username for authentication.
             */
            username?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversSlackConfigsHttpConfigBasicAuthUsername;
        }

        /**
         * The secret in the service monitor namespace that contains the password for authentication.
         */
        export interface AlertmanagerConfigSpecReceiversSlackConfigsHttpConfigBasicAuthPassword {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * The secret in the service monitor namespace that contains the username for authentication.
         */
        export interface AlertmanagerConfigSpecReceiversSlackConfigsHttpConfigBasicAuthUsername {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * The secret's key that contains the bearer token to be used by the client for authentication. The secret needs to be in the same namespace as the AlertmanagerConfig object and accessible by the Prometheus Operator.
         */
        export interface AlertmanagerConfigSpecReceiversSlackConfigsHttpConfigBearerTokenSecret {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * TLS configuration for the client.
         */
        export interface AlertmanagerConfigSpecReceiversSlackConfigsHttpConfigTlsConfig {
            /**
             * Struct containing the CA cert to use for the targets.
             */
            ca?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversSlackConfigsHttpConfigTlsConfigCa;
            /**
             * Struct containing the client cert file for the targets.
             */
            cert?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversSlackConfigsHttpConfigTlsConfigCert;
            /**
             * Disable target certificate validation.
             */
            insecureSkipVerify?: boolean;
            /**
             * Secret containing the client key file for the targets.
             */
            keySecret?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversSlackConfigsHttpConfigTlsConfigKeySecret;
            /**
             * Used to verify the hostname for the targets.
             */
            serverName?: string;
        }

        /**
         * Struct containing the CA cert to use for the targets.
         */
        export interface AlertmanagerConfigSpecReceiversSlackConfigsHttpConfigTlsConfigCa {
            /**
             * ConfigMap containing data to use for the targets.
             */
            configMap?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversSlackConfigsHttpConfigTlsConfigCaConfigMap;
            /**
             * Secret containing data to use for the targets.
             */
            secret?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversSlackConfigsHttpConfigTlsConfigCaSecret;
        }

        /**
         * ConfigMap containing data to use for the targets.
         */
        export interface AlertmanagerConfigSpecReceiversSlackConfigsHttpConfigTlsConfigCaConfigMap {
            /**
             * The key to select.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the ConfigMap or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Secret containing data to use for the targets.
         */
        export interface AlertmanagerConfigSpecReceiversSlackConfigsHttpConfigTlsConfigCaSecret {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Struct containing the client cert file for the targets.
         */
        export interface AlertmanagerConfigSpecReceiversSlackConfigsHttpConfigTlsConfigCert {
            /**
             * ConfigMap containing data to use for the targets.
             */
            configMap?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversSlackConfigsHttpConfigTlsConfigCertConfigMap;
            /**
             * Secret containing data to use for the targets.
             */
            secret?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversSlackConfigsHttpConfigTlsConfigCertSecret;
        }

        /**
         * ConfigMap containing data to use for the targets.
         */
        export interface AlertmanagerConfigSpecReceiversSlackConfigsHttpConfigTlsConfigCertConfigMap {
            /**
             * The key to select.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the ConfigMap or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Secret containing data to use for the targets.
         */
        export interface AlertmanagerConfigSpecReceiversSlackConfigsHttpConfigTlsConfigCertSecret {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Secret containing the client key file for the targets.
         */
        export interface AlertmanagerConfigSpecReceiversSlackConfigsHttpConfigTlsConfigKeySecret {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * VictorOpsConfig configures notifications via VictorOps. See https://prometheus.io/docs/alerting/latest/configuration/#victorops_config
         */
        export interface AlertmanagerConfigSpecReceiversVictoropsConfigs {
            /**
             * The API key to use when talking to the VictorOps API.
             */
            apiKey?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversVictoropsConfigsApiKey;
            /**
             * The VictorOps API URL.
             */
            apiUrl?: string;
            /**
             * Additional custom fields for notification.
             */
            customFields?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversVictoropsConfigsCustomFields[];
            /**
             * Contains summary of the alerted problem.
             */
            entityDisplayName?: string;
            /**
             * The HTTP client's configuration.
             */
            httpConfig?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversVictoropsConfigsHttpConfig;
            /**
             * Describes the behavior of the alert (CRITICAL, WARNING, INFO).
             */
            messageType?: string;
            /**
             * The monitoring tool the state message is from.
             */
            monitoringTool?: string;
            /**
             * A key used to map the alert to a team.
             */
            routingKey: string;
            /**
             * Whether or not to notify about resolved alerts.
             */
            sendResolved?: boolean;
            /**
             * Contains long explanation of the alerted problem.
             */
            stateMessage?: string;
        }

        /**
         * The API key to use when talking to the VictorOps API.
         */
        export interface AlertmanagerConfigSpecReceiversVictoropsConfigsApiKey {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * KeyValue defines a (key, value) tuple.
         */
        export interface AlertmanagerConfigSpecReceiversVictoropsConfigsCustomFields {
            /**
             * Key of the tuple.
             */
            key: string;
            /**
             * Value of the tuple.
             */
            value: string;
        }

        /**
         * The HTTP client's configuration.
         */
        export interface AlertmanagerConfigSpecReceiversVictoropsConfigsHttpConfig {
            /**
             * BasicAuth for the client.
             */
            basicAuth?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversVictoropsConfigsHttpConfigBasicAuth;
            /**
             * The secret's key that contains the bearer token to be used by the client for authentication. The secret needs to be in the same namespace as the AlertmanagerConfig object and accessible by the Prometheus Operator.
             */
            bearerTokenSecret?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversVictoropsConfigsHttpConfigBearerTokenSecret;
            /**
             * Optional proxy URL.
             */
            proxyURL?: string;
            /**
             * TLS configuration for the client.
             */
            tlsConfig?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversVictoropsConfigsHttpConfigTlsConfig;
        }

        /**
         * BasicAuth for the client.
         */
        export interface AlertmanagerConfigSpecReceiversVictoropsConfigsHttpConfigBasicAuth {
            /**
             * The secret in the service monitor namespace that contains the password for authentication.
             */
            password?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversVictoropsConfigsHttpConfigBasicAuthPassword;
            /**
             * The secret in the service monitor namespace that contains the username for authentication.
             */
            username?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversVictoropsConfigsHttpConfigBasicAuthUsername;
        }

        /**
         * The secret in the service monitor namespace that contains the password for authentication.
         */
        export interface AlertmanagerConfigSpecReceiversVictoropsConfigsHttpConfigBasicAuthPassword {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * The secret in the service monitor namespace that contains the username for authentication.
         */
        export interface AlertmanagerConfigSpecReceiversVictoropsConfigsHttpConfigBasicAuthUsername {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * The secret's key that contains the bearer token to be used by the client for authentication. The secret needs to be in the same namespace as the AlertmanagerConfig object and accessible by the Prometheus Operator.
         */
        export interface AlertmanagerConfigSpecReceiversVictoropsConfigsHttpConfigBearerTokenSecret {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * TLS configuration for the client.
         */
        export interface AlertmanagerConfigSpecReceiversVictoropsConfigsHttpConfigTlsConfig {
            /**
             * Struct containing the CA cert to use for the targets.
             */
            ca?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversVictoropsConfigsHttpConfigTlsConfigCa;
            /**
             * Struct containing the client cert file for the targets.
             */
            cert?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversVictoropsConfigsHttpConfigTlsConfigCert;
            /**
             * Disable target certificate validation.
             */
            insecureSkipVerify?: boolean;
            /**
             * Secret containing the client key file for the targets.
             */
            keySecret?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversVictoropsConfigsHttpConfigTlsConfigKeySecret;
            /**
             * Used to verify the hostname for the targets.
             */
            serverName?: string;
        }

        /**
         * Struct containing the CA cert to use for the targets.
         */
        export interface AlertmanagerConfigSpecReceiversVictoropsConfigsHttpConfigTlsConfigCa {
            /**
             * ConfigMap containing data to use for the targets.
             */
            configMap?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversVictoropsConfigsHttpConfigTlsConfigCaConfigMap;
            /**
             * Secret containing data to use for the targets.
             */
            secret?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversVictoropsConfigsHttpConfigTlsConfigCaSecret;
        }

        /**
         * ConfigMap containing data to use for the targets.
         */
        export interface AlertmanagerConfigSpecReceiversVictoropsConfigsHttpConfigTlsConfigCaConfigMap {
            /**
             * The key to select.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the ConfigMap or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Secret containing data to use for the targets.
         */
        export interface AlertmanagerConfigSpecReceiversVictoropsConfigsHttpConfigTlsConfigCaSecret {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Struct containing the client cert file for the targets.
         */
        export interface AlertmanagerConfigSpecReceiversVictoropsConfigsHttpConfigTlsConfigCert {
            /**
             * ConfigMap containing data to use for the targets.
             */
            configMap?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversVictoropsConfigsHttpConfigTlsConfigCertConfigMap;
            /**
             * Secret containing data to use for the targets.
             */
            secret?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversVictoropsConfigsHttpConfigTlsConfigCertSecret;
        }

        /**
         * ConfigMap containing data to use for the targets.
         */
        export interface AlertmanagerConfigSpecReceiversVictoropsConfigsHttpConfigTlsConfigCertConfigMap {
            /**
             * The key to select.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the ConfigMap or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Secret containing data to use for the targets.
         */
        export interface AlertmanagerConfigSpecReceiversVictoropsConfigsHttpConfigTlsConfigCertSecret {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Secret containing the client key file for the targets.
         */
        export interface AlertmanagerConfigSpecReceiversVictoropsConfigsHttpConfigTlsConfigKeySecret {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * WebhookConfig configures notifications via a generic receiver supporting the webhook payload. See https://prometheus.io/docs/alerting/latest/configuration/#webhook_config
         */
        export interface AlertmanagerConfigSpecReceiversWebhookConfigs {
            /**
             * HTTP client configuration.
             */
            httpConfig?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversWebhookConfigsHttpConfig;
            /**
             * Maximum number of alerts to be sent per webhook message.
             */
            maxAlerts?: number;
            /**
             * Whether or not to notify about resolved alerts.
             */
            sendResolved?: boolean;
            /**
             * The URL to send HTTP POST requests to. `urlSecret` takes precedence over `url`. One of `urlSecret` and `url` should be defined.
             */
            url?: string;
            /**
             * The secret's key that contains the webhook URL to send HTTP requests to. `urlSecret` takes precedence over `url`. One of `urlSecret` and `url` should be defined. The secret needs to be in the same namespace as the AlertmanagerConfig object and accessible by the Prometheus Operator.
             */
            urlSecret?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversWebhookConfigsUrlSecret;
        }

        /**
         * HTTP client configuration.
         */
        export interface AlertmanagerConfigSpecReceiversWebhookConfigsHttpConfig {
            /**
             * BasicAuth for the client.
             */
            basicAuth?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversWebhookConfigsHttpConfigBasicAuth;
            /**
             * The secret's key that contains the bearer token to be used by the client for authentication. The secret needs to be in the same namespace as the AlertmanagerConfig object and accessible by the Prometheus Operator.
             */
            bearerTokenSecret?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversWebhookConfigsHttpConfigBearerTokenSecret;
            /**
             * Optional proxy URL.
             */
            proxyURL?: string;
            /**
             * TLS configuration for the client.
             */
            tlsConfig?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversWebhookConfigsHttpConfigTlsConfig;
        }

        /**
         * BasicAuth for the client.
         */
        export interface AlertmanagerConfigSpecReceiversWebhookConfigsHttpConfigBasicAuth {
            /**
             * The secret in the service monitor namespace that contains the password for authentication.
             */
            password?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversWebhookConfigsHttpConfigBasicAuthPassword;
            /**
             * The secret in the service monitor namespace that contains the username for authentication.
             */
            username?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversWebhookConfigsHttpConfigBasicAuthUsername;
        }

        /**
         * The secret in the service monitor namespace that contains the password for authentication.
         */
        export interface AlertmanagerConfigSpecReceiversWebhookConfigsHttpConfigBasicAuthPassword {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * The secret in the service monitor namespace that contains the username for authentication.
         */
        export interface AlertmanagerConfigSpecReceiversWebhookConfigsHttpConfigBasicAuthUsername {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * The secret's key that contains the bearer token to be used by the client for authentication. The secret needs to be in the same namespace as the AlertmanagerConfig object and accessible by the Prometheus Operator.
         */
        export interface AlertmanagerConfigSpecReceiversWebhookConfigsHttpConfigBearerTokenSecret {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * TLS configuration for the client.
         */
        export interface AlertmanagerConfigSpecReceiversWebhookConfigsHttpConfigTlsConfig {
            /**
             * Struct containing the CA cert to use for the targets.
             */
            ca?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversWebhookConfigsHttpConfigTlsConfigCa;
            /**
             * Struct containing the client cert file for the targets.
             */
            cert?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversWebhookConfigsHttpConfigTlsConfigCert;
            /**
             * Disable target certificate validation.
             */
            insecureSkipVerify?: boolean;
            /**
             * Secret containing the client key file for the targets.
             */
            keySecret?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversWebhookConfigsHttpConfigTlsConfigKeySecret;
            /**
             * Used to verify the hostname for the targets.
             */
            serverName?: string;
        }

        /**
         * Struct containing the CA cert to use for the targets.
         */
        export interface AlertmanagerConfigSpecReceiversWebhookConfigsHttpConfigTlsConfigCa {
            /**
             * ConfigMap containing data to use for the targets.
             */
            configMap?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversWebhookConfigsHttpConfigTlsConfigCaConfigMap;
            /**
             * Secret containing data to use for the targets.
             */
            secret?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversWebhookConfigsHttpConfigTlsConfigCaSecret;
        }

        /**
         * ConfigMap containing data to use for the targets.
         */
        export interface AlertmanagerConfigSpecReceiversWebhookConfigsHttpConfigTlsConfigCaConfigMap {
            /**
             * The key to select.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the ConfigMap or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Secret containing data to use for the targets.
         */
        export interface AlertmanagerConfigSpecReceiversWebhookConfigsHttpConfigTlsConfigCaSecret {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Struct containing the client cert file for the targets.
         */
        export interface AlertmanagerConfigSpecReceiversWebhookConfigsHttpConfigTlsConfigCert {
            /**
             * ConfigMap containing data to use for the targets.
             */
            configMap?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversWebhookConfigsHttpConfigTlsConfigCertConfigMap;
            /**
             * Secret containing data to use for the targets.
             */
            secret?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversWebhookConfigsHttpConfigTlsConfigCertSecret;
        }

        /**
         * ConfigMap containing data to use for the targets.
         */
        export interface AlertmanagerConfigSpecReceiversWebhookConfigsHttpConfigTlsConfigCertConfigMap {
            /**
             * The key to select.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the ConfigMap or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Secret containing data to use for the targets.
         */
        export interface AlertmanagerConfigSpecReceiversWebhookConfigsHttpConfigTlsConfigCertSecret {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Secret containing the client key file for the targets.
         */
        export interface AlertmanagerConfigSpecReceiversWebhookConfigsHttpConfigTlsConfigKeySecret {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * The secret's key that contains the webhook URL to send HTTP requests to. `urlSecret` takes precedence over `url`. One of `urlSecret` and `url` should be defined. The secret needs to be in the same namespace as the AlertmanagerConfig object and accessible by the Prometheus Operator.
         */
        export interface AlertmanagerConfigSpecReceiversWebhookConfigsUrlSecret {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * WeChatConfig configures notifications via WeChat. See https://prometheus.io/docs/alerting/latest/configuration/#wechat_config
         */
        export interface AlertmanagerConfigSpecReceiversWechatConfigs {
            agentID?: string;
            /**
             * The secret's key that contains the WeChat API key. The secret needs to be in the same namespace as the AlertmanagerConfig object and accessible by the Prometheus Operator.
             */
            apiSecret?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversWechatConfigsApiSecret;
            /**
             * The WeChat API URL.
             */
            apiURL?: string;
            /**
             * The corp id for authentication.
             */
            corpID?: string;
            /**
             * HTTP client configuration.
             */
            httpConfig?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversWechatConfigsHttpConfig;
            /**
             * API request data as defined by the WeChat API.
             */
            message?: string;
            messageType?: string;
            /**
             * Whether or not to notify about resolved alerts.
             */
            sendResolved?: boolean;
            toParty?: string;
            toTag?: string;
            toUser?: string;
        }

        /**
         * The secret's key that contains the WeChat API key. The secret needs to be in the same namespace as the AlertmanagerConfig object and accessible by the Prometheus Operator.
         */
        export interface AlertmanagerConfigSpecReceiversWechatConfigsApiSecret {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * HTTP client configuration.
         */
        export interface AlertmanagerConfigSpecReceiversWechatConfigsHttpConfig {
            /**
             * BasicAuth for the client.
             */
            basicAuth?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversWechatConfigsHttpConfigBasicAuth;
            /**
             * The secret's key that contains the bearer token to be used by the client for authentication. The secret needs to be in the same namespace as the AlertmanagerConfig object and accessible by the Prometheus Operator.
             */
            bearerTokenSecret?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversWechatConfigsHttpConfigBearerTokenSecret;
            /**
             * Optional proxy URL.
             */
            proxyURL?: string;
            /**
             * TLS configuration for the client.
             */
            tlsConfig?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversWechatConfigsHttpConfigTlsConfig;
        }

        /**
         * BasicAuth for the client.
         */
        export interface AlertmanagerConfigSpecReceiversWechatConfigsHttpConfigBasicAuth {
            /**
             * The secret in the service monitor namespace that contains the password for authentication.
             */
            password?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversWechatConfigsHttpConfigBasicAuthPassword;
            /**
             * The secret in the service monitor namespace that contains the username for authentication.
             */
            username?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversWechatConfigsHttpConfigBasicAuthUsername;
        }

        /**
         * The secret in the service monitor namespace that contains the password for authentication.
         */
        export interface AlertmanagerConfigSpecReceiversWechatConfigsHttpConfigBasicAuthPassword {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * The secret in the service monitor namespace that contains the username for authentication.
         */
        export interface AlertmanagerConfigSpecReceiversWechatConfigsHttpConfigBasicAuthUsername {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * The secret's key that contains the bearer token to be used by the client for authentication. The secret needs to be in the same namespace as the AlertmanagerConfig object and accessible by the Prometheus Operator.
         */
        export interface AlertmanagerConfigSpecReceiversWechatConfigsHttpConfigBearerTokenSecret {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * TLS configuration for the client.
         */
        export interface AlertmanagerConfigSpecReceiversWechatConfigsHttpConfigTlsConfig {
            /**
             * Struct containing the CA cert to use for the targets.
             */
            ca?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversWechatConfigsHttpConfigTlsConfigCa;
            /**
             * Struct containing the client cert file for the targets.
             */
            cert?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversWechatConfigsHttpConfigTlsConfigCert;
            /**
             * Disable target certificate validation.
             */
            insecureSkipVerify?: boolean;
            /**
             * Secret containing the client key file for the targets.
             */
            keySecret?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversWechatConfigsHttpConfigTlsConfigKeySecret;
            /**
             * Used to verify the hostname for the targets.
             */
            serverName?: string;
        }

        /**
         * Struct containing the CA cert to use for the targets.
         */
        export interface AlertmanagerConfigSpecReceiversWechatConfigsHttpConfigTlsConfigCa {
            /**
             * ConfigMap containing data to use for the targets.
             */
            configMap?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversWechatConfigsHttpConfigTlsConfigCaConfigMap;
            /**
             * Secret containing data to use for the targets.
             */
            secret?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversWechatConfigsHttpConfigTlsConfigCaSecret;
        }

        /**
         * ConfigMap containing data to use for the targets.
         */
        export interface AlertmanagerConfigSpecReceiversWechatConfigsHttpConfigTlsConfigCaConfigMap {
            /**
             * The key to select.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the ConfigMap or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Secret containing data to use for the targets.
         */
        export interface AlertmanagerConfigSpecReceiversWechatConfigsHttpConfigTlsConfigCaSecret {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Struct containing the client cert file for the targets.
         */
        export interface AlertmanagerConfigSpecReceiversWechatConfigsHttpConfigTlsConfigCert {
            /**
             * ConfigMap containing data to use for the targets.
             */
            configMap?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversWechatConfigsHttpConfigTlsConfigCertConfigMap;
            /**
             * Secret containing data to use for the targets.
             */
            secret?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecReceiversWechatConfigsHttpConfigTlsConfigCertSecret;
        }

        /**
         * ConfigMap containing data to use for the targets.
         */
        export interface AlertmanagerConfigSpecReceiversWechatConfigsHttpConfigTlsConfigCertConfigMap {
            /**
             * The key to select.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the ConfigMap or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Secret containing data to use for the targets.
         */
        export interface AlertmanagerConfigSpecReceiversWechatConfigsHttpConfigTlsConfigCertSecret {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * Secret containing the client key file for the targets.
         */
        export interface AlertmanagerConfigSpecReceiversWechatConfigsHttpConfigTlsConfigKeySecret {
            /**
             * The key of the secret to select from.  Must be a valid secret key.
             */
            key: string;
            /**
             * Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names TODO: Add other useful fields. apiVersion, kind, uid?
             */
            name?: string;
            /**
             * Specify whether the Secret or its key must be defined
             */
            optional?: boolean;
        }

        /**
         * The Alertmanager route definition for alerts matching the resource’s namespace. It will be added to the generated Alertmanager configuration as a first-level route.
         */
        export interface AlertmanagerConfigSpecRoute {
            /**
             * Boolean indicating whether an alert should continue matching subsequent sibling nodes. It will always be overridden to true for the first-level route by the Prometheus operator.
             */
            continue?: boolean;
            /**
             * List of labels to group by.
             */
            groupBy?: string[];
            /**
             * How long to wait before sending an updated notification. Must match the regular expression `[0-9]+(ms|s|m|h)` (milliseconds seconds minutes hours).
             */
            groupInterval?: string;
            /**
             * How long to wait before sending the initial notification. Must match the regular expression `[0-9]+(ms|s|m|h)` (milliseconds seconds minutes hours).
             */
            groupWait?: string;
            /**
             * List of matchers that the alert’s labels should match. For the first level route, the operator removes any existing equality and regexp matcher on the `namespace` label and adds a `namespace: <object namespace>` matcher.
             */
            matchers?: outputs.monitoring.v1alpha1.AlertmanagerConfigSpecRouteMatchers[];
            /**
             * Name of the receiver for this route. If present, it should be listed in the `receivers` field. The field can be omitted only for nested routes otherwise it is mandatory.
             */
            receiver?: string;
            /**
             * How long to wait before repeating the last notification. Must match the regular expression `[0-9]+(ms|s|m|h)` (milliseconds seconds minutes hours).
             */
            repeatInterval?: string;
            /**
             * Child routes.
             */
            routes?: {[key: string]: any}[];
        }

        /**
         * Matcher defines how to match on alert's labels.
         */
        export interface AlertmanagerConfigSpecRouteMatchers {
            /**
             * Label to match.
             */
            name: string;
            /**
             * Whether to match on equality (false) or regular-expression (true).
             */
            regex?: boolean;
            /**
             * Label value to match.
             */
            value: string;
        }
    }
}
